<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Intel® Neural Compressor .htmlash; Intel® Neural Compressor  documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples" href="docs/examples_readme.html" />
    <link rel="prev" title="Intel® Neural Compressor Documentation" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Intel® Neural Compressor
          </a>
              <div class="version">
                1.14.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Intel® Neural Compressor</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-on-linux">Install on Linux</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#getting-started">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#quantization-with-python-api">Quantization with Python API</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quantization-with-gui">Quantization with GUI</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quantization-with-auto-coding-api-experimental">Quantization with Auto-coding API (Experimental)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#system-requirements">System Requirements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#validated-software-environment">Validated Software Environment</a></li>
<li class="toctree-l3"><a class="reference internal" href="#validated-models">Validated Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#documentation">Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#selected-publications">Selected Publications</a></li>
<li class="toctree-l2"><a class="reference internal" href="#additional-content">Additional Content</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hiring">Hiring</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="docs/examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="docs/doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="docs/releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="docs/contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="docs/legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="docs/security_policy.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Intel® Neural Compressor</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/README.html.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div align="center"><div class="section" id="intel-neural-compressor">
<h1>Intel® Neural Compressor<a class="headerlink" href="#intel-neural-compressor" title="Permalink to this headline">¶</a></h1>
<p><h3> An open-source Python library supporting popular model compression techniques on all mainstream deep learning frameworks (TensorFlow, PyTorch, ONNX Runtime, and MXNet)</h3></p>
<p><a class="reference external" href="https://github.com/intel/neural-compressor"><img alt="python" src="https://img.shields.io/badge/python-3.7%2B-blue" /></a>
<a class="reference external" href="https://github.com/intel/neural-compressor/releases"><img alt="version" src="https://img.shields.io/badge/release-1.12-green" /></a>
<a class="reference external" href="https://github.com/intel/neural-compressor/blob/master/LICENSE"><img alt="license" src="https://img.shields.io/badge/license-Apache%202-blue" /></a>
<a class="reference external" href="https://github.com/intel/neural-compressor"><img alt="coverage" src="https://img.shields.io/badge/coverage-90%25-green" /></a>
<a class="reference external" href="https://pepy.tech/project/neural-compressor"><img alt="Downloads" src="https://static.pepy.tech/personalized-badge/neural-compressor?period=total&amp;units=international_system&amp;left_color=grey&amp;right_color=green&amp;left_text=downloads" /></a></p>
</div><hr class="docutils" />
<div align="left"><p>Intel® Neural Compressor, formerly known as Intel® Low Precision Optimization Tool, is an open-source Python library that runs on Intel CPUs and GPUs, which delivers unified interfaces across multiple deep-learning frameworks for popular network compression technologies such as quantization, pruning, and knowledge distillation. This tool supports automatic accuracy-driven tuning strategies to help the user quickly find out the best quantized model. It also implements different weight-pruning algorithms to generate a pruned model with predefined sparsity goal. It also supports knowledge distillation to distill the knowledge from the teacher model to the student model.
Intel® Neural Compressor is a critical AI software component in the <a class="reference external" href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/ai-analytics-toolkit.html">Intel® oneAPI AI Analytics Toolkit</a>.</p>
<blockquote>
<div><p><strong>Note:</strong>
GPU support is under development.</p>
</div></blockquote>
<p><strong>Visit the Intel® Neural Compressor online document website at: <a class="reference external" href="https://intel.github.io/neural-compressor">https://intel.github.io/neural-compressor</a>.</strong></p>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="prerequisites">
<h3>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h3>
<p>Python version: 3.7, 3.8, 3.9, 3.10</p>
</div>
<div class="section" id="install-on-linux">
<h3>Install on Linux<a class="headerlink" href="#install-on-linux" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>Release binary install</p>
<div class="highlight-Shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># install stable basic version from pip</span>
pip install neural-compressor
<span class="c1"># Or install stable full version from pip (including GUI)</span>
pip install neural-compressor-full
</pre></div>
</div>
</li>
<li><p>Nightly binary install</p>
<div class="highlight-Shell notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/intel/neural-compressor.git
<span class="nb">cd</span> neural-compressor
pip install -r requirements.txt
<span class="c1"># install nightly basic version from pip</span>
pip install -i https://test.pypi.org/simple/ neural-compressor
<span class="c1"># Or install nightly full version from pip (including GUI)</span>
pip install -i https://test.pypi.org/simple/ neural-compressor-full
</pre></div>
</div>
</li>
</ul>
<p>More installation methods can be found at <a class="reference internal" href="docs/installation_guide.html"><span class="doc">Installation Guide</span></a>. Please check out our <a class="reference internal" href="docs/faq.html"><span class="doc">FAQ</span></a> for more details.</p>
</div>
</div>
<div class="section" id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h2>
<div class="section" id="quantization-with-python-api">
<h3>Quantization with Python API<a class="headerlink" href="#quantization-with-python-api" title="Permalink to this headline">¶</a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># A TensorFlow Example</span>
pip install tensorflow
<span class="c1"># Prepare fp32 model</span>
wget https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_6/mobilenet_v1_1.0_224_frozen.pb
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">neural_compressor.experimental</span> <span class="kn">import</span> <span class="n">Quantization</span><span class="p">,</span> <span class="n">common</span>
<span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">disable_eager_execution</span><span class="p">()</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">Quantization</span><span class="p">()</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;./mobilenet_v1_1.0_224_frozen.pb&#39;</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">quantizer</span><span class="o">.</span><span class="n">dataset</span><span class="p">(</span><span class="s1">&#39;dummy&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">calib_dataloader</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="quantization-with-gui">
<h3>Quantization with <a class="reference internal" href="docs/bench.html"><span class="doc">GUI</span></a><a class="headerlink" href="#quantization-with-gui" title="Permalink to this headline">¶</a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># An ONNX Example</span>
pip install <span class="nv">onnx</span><span class="o">==</span><span class="m">1</span>.12.0 <span class="nv">onnxruntime</span><span class="o">==</span><span class="m">1</span>.12.1 onnxruntime-extensions
<span class="c1"># Prepare fp32 model</span>
wget https://github.com/onnx/models/raw/main/vision/classification/resnet/model/resnet50-v1-12.onnx
<span class="c1"># Start GUI</span>
inc_bench
</pre></div>
</div>
<a target="_blank" href="./docs/imgs/INC_GUI.gif">
  <img src="./docs/imgs/INC_GUI.gif" alt="Architecture">
</a></div>
<div class="section" id="quantization-with-auto-coding-api-experimental">
<h3>Quantization with <a class="reference internal" href="neural_coder/docs/AutoQuant.html"><span class="doc">Auto-coding API</span></a> (Experimental)<a class="headerlink" href="#quantization-with-auto-coding-api-experimental" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">neural_coder</span> <span class="kn">import</span> <span class="n">auto_quant</span>
<span class="n">auto_quant</span><span class="p">(</span>
    <span class="n">code</span><span class="o">=</span><span class="s2">&quot;https://github.com/huggingface/transformers/blob/v4.21-release/examples/pytorch/text-classification/run_glue.py&quot;</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="s2">&quot;--model_name_or_path albert-base-v2 </span><span class="se">\</span>
<span class="s2">          --task_name sst2 </span><span class="se">\</span>
<span class="s2">          --do_eval </span><span class="se">\</span>
<span class="s2">          --output_dir result </span><span class="se">\</span>
<span class="s2">          --overwrite_output_dir&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="system-requirements">
<h2>System Requirements<a class="headerlink" href="#system-requirements" title="Permalink to this headline">¶</a></h2>
<p>Intel® Neural Compressor supports systems based on <a class="reference external" href="https://en.wikipedia.org/wiki/X86-64">Intel 64 architecture or compatible processors</a> that are specifically optimized for the following CPUs:</p>
<ul class="simple">
<li><p>Intel Xeon Scalable processor (formerly Skylake, Cascade Lake, Cooper Lake, and Icelake)</p></li>
<li><p>Future Intel Xeon Scalable processor (code name Sapphire Rapids)</p></li>
</ul>
<div class="section" id="validated-software-environment">
<h3>Validated Software Environment<a class="headerlink" href="#validated-software-environment" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>OS version: CentOS 8.4, Ubuntu 20.04</p></li>
<li><p>Python version: 3.7, 3.8, 3.9, 3.10</p></li>
</ul>
<table class="docutils">
<thead>
  <tr>
    <th>Framework</th>
    <th>TensorFlow</th>
    <th>Intel TensorFlow</th>
    <th>PyTorch</th>
    <th>IPEX</th>
    <th>ONNX Runtime</th>
    <th>MXNet</th>
  </tr>
</thead>
<tbody>
  <tr align="center">
    <th>Version</th>
    <td class="tg-7zrl"><a href=https://github.com/tensorflow/tensorflow/tree/v2.9.1>2.9.1</a><br>
    <a href=https://github.com/tensorflow/tensorflow/tree/v2.8.2>2.8.2</a><br>
    <a href=https://github.com/tensorflow/tensorflow/tree/v2.7.3>2.7.3</a><br>
    <td class="tg-7zrl"><a href=https://github.com/Intel-tensorflow/tensorflow/tree/v2.9.1>2.9.1</a><br>
    <a href=https://github.com/Intel-tensorflow/tensorflow/tree/v2.8.0>2.8.0</a><br>
    <a href=https://github.com/Intel-tensorflow/tensorflow/tree/v2.7.0>2.7.0</a><br>
    <td class="tg-7zrl"><a href=https://download.pytorch.org/whl/torch_stable.html>1.12.0+cpu</a><br>
    <a href=https://download.pytorch.org/whl/torch_stable.html>1.11.0+cpu</a><br>
    <a href=https://download.pytorch.org/whl/torch_stable.html>1.10.0+cpu</a></td>
    <td class="tg-7zrl"><a href=https://github.com/intel/intel-extension-for-pytorch/tree/v1.12.0>1.12.0</a><br>
    <a href=https://github.com/intel/intel-extension-for-pytorch/tree/v1.10.0>1.11.0</a><br>
    <a href=https://github.com/intel/intel-extension-for-pytorch/tree/v1.9.0>1.10.0</a></td>
    <td class="tg-7zrl"><a href=https://github.com/microsoft/onnxruntime/tree/v1.11.0>1.11.0</a><br>
    <a href=https://github.com/microsoft/onnxruntime/tree/v1.10.0>1.10.0</a><br>
    <a href=https://github.com/microsoft/onnxruntime/tree/v1.9.0>1.9.0</a></td>
    <td class="tg-7zrl"><a href=https://github.com/apache/incubator-mxnet/tree/1.8.0>1.8.0</a><br>
    <a href=https://github.com/apache/incubator-mxnet/tree/1.7.0>1.7.0</a><br>
    <a href=https://github.com/apache/incubator-mxnet/tree/1.6.0>1.6.0</a></td>
  </tr>
</tbody>
</table><blockquote>
<div><p><strong>Note:</strong>
Set the environment variable <code class="docutils literal notranslate"><span class="pre">TF_ENABLE_ONEDNN_OPTS=1</span></code> to enable oneDNN optimizations if you are using TensorFlow v2.6 to v2.8. oneDNN is the default for TensorFlow v2.9.</p>
</div></blockquote>
</div>
<div class="section" id="validated-models">
<h3>Validated Models<a class="headerlink" href="#validated-models" title="Permalink to this headline">¶</a></h3>
<p>Intel® Neural Compressor validated 420+ <a class="reference external" href="https://github.com/intel/neural-compressor/tree/1f957eba304eebaf7d1e4bc11501ba7acee777f1/./examples">examples</a> for quantization with a performance speedup geomean of 2.2x and up to 4.2x on VNNI while minimizing accuracy loss. Over 30 pruning and knowledge distillation samples are also available. More details for validated models are available <a class="reference internal" href="docs/validated_model_list.html"><span class="doc">here</span></a>.</p>
<div style = "width: 77%; margin-bottom: 2%;">
  <a target="_blank" href="./docs/imgs/release_data.png">
    <img src="./docs/imgs/release_data.png" alt="Architecture" width=800 height=600>
  </a>
</div></div>
</div>
<div class="section" id="documentation">
<h2>Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline">¶</a></h2>
<table class="docutils">
  <thead>
  <tr>
    <th colspan="9">Overview</th>
  </tr>
  </thead>
  <tbody>
    <tr>
      <td colspan="3" align="center"><a href="docs/design.html">Architecture</a></td>
      <td colspan="2" align="center"><a href="https://github.com/intel/neural-compressor/tree/master/examples">Examples</a></td>
      <td colspan="2" align="center"><a href="docs/bench.html">GUI</a></td>
      <td colspan="2" align="center"><a href="docs/api-introduction.html">APIs</a></td>
    </tr>
    <tr>
      <td colspan="5" align="center"><a href="https://software.intel.com/content/www/us/en/develop/documentation/get-started-with-ai-linux/top.html">Intel oneAPI AI Analytics Toolkit</a></td>
      <td colspan="4" align="center"><a href="https://github.com/oneapi-src/oneAPI-samples/tree/master/AI-and-Analytics">AI and Analytics Samples</a></td>
    </tr>
  </tbody>
  <thead>
  <tr>
    <th colspan="9">Basic API</th>
  </tr>
  </thead>
  <tbody>
    <tr>
      <td colspan="2" align="center"><a href="docs/transform.html">Transform</a></td>
      <td colspan="2" align="center"><a href="docs/dataset.html">Dataset</a></td>
      <td colspan="2" align="center"><a href="docs/metric.html">Metric</a></td>
      <td colspan="3" align="center"><a href="docs/objective.html">Objective</a></td>
    </tr>
  </tbody>
  <thead>
    <tr>
      <th colspan="9">Deep Dive</th>
    </tr>
  </thead>
  <tbody>
    <tr>
        <td colspan="2" align="center"><a href="docs/Quantization.html">Quantization</a></td>
        <td colspan="1" align="center"><a href="docs/pruning.html">Pruning</a> <a href="docs/sparsity.html">(Sparsity)</a> </td> 
        <td colspan="2" align="center"><a href="docs/distillation.html">Knowledge Distillation</a></td>
        <td colspan="2" align="center"><a href="docs/mixed_precision.html">Mixed Precision</a></td>
        <td colspan="2" align="center"><a href="docs/orchestration.html">Orchestration</a></td>
    </tr>
    <tr>
        <td colspan="2" align="center"><a href="docs/benchmark.html">Benchmarking</a></td>
        <td colspan="3" align="center"><a href="docs/distributed.html">Distributed Training</a></td>
        <td colspan="2" align="center"><a href="docs/model_conversion.html">Model Conversion</a></td>
        <td colspan="2" align="center"><a href="docs/tensorboard.html">TensorBoard</a></td>
    </tr>
    <tr>
        <td colspan="4" align="center"><a href="docs/distillation_quantization.html">Distillation for Quantization</a></td>
        <td colspan="5" align="center"><a href="neural_coder">Neural Coder (No-Code Solution)</a></td>
    </tr>      </tbody>
  <thead>
      <tr>
        <th colspan="9">Advanced Topics</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td colspan="3" align="center"><a href="docs/adaptor.html">Adaptor</a></td>
          <td colspan="3" align="center"><a href="docs/tuning_strategies.html">Strategy</a></td>
          <td colspan="3" align="center"><a href="docs/reference_examples.html">Reference Example</a></td>
      </tr>
  </tbody>
</table></div>
<div class="section" id="selected-publications">
<h2>Selected Publications<a class="headerlink" href="#selected-publications" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://twitter.com/i/status/1574909338203967497">Neural Coder (Intel Neural Compressor Plug-in): One-Click, No-Code Solution (Pat’s Keynote IntelON 2022)</a> (Sep 2022)</p></li>
<li><p><a class="reference external" href="https://medium.com/intel-analytics-software/alibaba-cloud-collaborates-with-intel-neural-compressor-for-better-productivity-and-performance-83cdb6500420">Alibaba Cloud and Intel Neural Compressor Deliver Better Productivity for PyTorch Users</a> (Sep 2022)</p></li>
<li><p><a class="reference external" href="https://medium.com/intel-analytics-software/efficient-text-classification-with-intel-neural-compressor-4853296deeac">Efficient Text Classification with Intel Neural Compressor</a> (Sep 2022)</p></li>
<li><p><a class="reference external" href="https://medium.com/intel-analytics-software/dynamic-neural-architecture-search-with-intel-neural-compressor-7b05eaf325f3">Dynamic Neural Architecture Search with Intel Neural Compressor</a> (Sep 2022)</p></li>
<li><p><a class="reference external" href="https://medium.com/intel-analytics-software/easy-quantization-in-pytorch-using-fine-grained-fx-80be2c4bc2d6">Easy Quantization in PyTorch Using Fine-Grained FX</a> (Sep 2022)</p></li>
<li><p><a class="reference external" href="https://medium.com/intel-analytics-software/one-click-enable-intel-neural-compressor-features-in-pytorch-scripts-5d4e31f5a22b">One-Click Enabling of Intel Neural Compressor Features in PyTorch Scripts</a> (Aug 2022)</p></li>
<li><p><a class="reference external" href="https://zhuanlan.zhihu.com/p/552484413?utm_source=ZHShareTargetIDMore&amp;utm_medium=social&amp;utm_oi=667097517833981952">Deep learning inference optimization for Address Purification</a> (Aug 2022)</p></li>
</ul>
<blockquote>
<div><p>View our <a class="reference internal" href="docs/publication_list.html"><span class="doc">full publication list</span></a>.</p>
</div></blockquote>
</div>
<div class="section" id="additional-content">
<h2>Additional Content<a class="headerlink" href="#additional-content" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="docs/releases_info.html"><span class="doc">Release Information</span></a></p></li>
<li><p><a class="reference internal" href="docs/contributions.html"><span class="doc">Contribution Guidelines</span></a></p></li>
<li><p><a class="reference internal" href="docs/legal_information.html"><span class="doc">Legal Information</span></a></p></li>
<li><p><a class="reference internal" href="docs/security_policy.html"><span class="doc">Security Policy</span></a></p></li>
<li><p><a class="reference external" href="https://intel.github.io/neural-compressor">Intel® Neural Compressor Website</a></p></li>
</ul>
</div>
<div class="section" id="hiring">
<h2>Hiring<a class="headerlink" href="#hiring" title="Permalink to this headline">¶</a></h2>
<p>We are actively hiring. Send your resume to inc.maintainers&#64;intel.com if you are interested in model compression techniques.</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Intel® Neural Compressor Documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="docs/examples_readme.html" class="btn btn-neutral float-right" title="Examples" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>