# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

pr:
- wenxin-test

pool: docker-agent

variables:
  PYTHON: 'python3.8'
  IMAGE_NAME: 'neural-compressor'
  IMAGE_TAG: 'py38'

stages:
- stage: Build
  displayName: Build and push stage
  jobs:
  - job: Build
    displayName: Build
    steps:
    - checkout: none
    
    - script: |
        echo ${BUILD_SOURCESDIRECTORY}
        sudo rm -fr ${BUILD_SOURCESDIRECTORY} || true
      displayName: 'Clean workspace'
    
    - script: |
        cd ${BUILD_SOURCESDIRECTORY}
        git clone --single-branch --branch=$(System.PullRequest.SourceBranch) $(Build.Repository.Uri)
        #git -c fetch --force --tags --prune --prune-tags --progress --no-recurse-submodules origin ${BUILD_SOURCESDIRECTORY}
      displayName: "checkout repo"
    
    - script: |
        if [[ ! $(docker images | grep -i neural-compressor) ]]; then
            docker build -f docker/Dockerfile.devel -t ${IMAGE_NAME}:${IMAGE_TAG} .
        fi
      displayName: "build images"

    - script: |
        docker stop $(docker ps -aq)
        docker rm -vf $(docker ps -aq) || true
      displayName: 'Clean Docker'

    - script: |
        docker run --disable-content-trust --privileged --name="pr" --hostname="pr-host" -v ${BUILD_SOURCESDIRECTORY}:/neural_compressor  ${IMAGE_NAME}:${IMAGE_TAG} /bin/bash +x -c "cd /neural_compressor && python -m pip install --no-cache-dir -r requirements.txt && pip install intel-tensorflow && python setup.py sdist bdist_wheel && pip install dist/neural_compressor-*.whl && pip list && python test/strategy/test_bayesian.py"
      displayName: 'find repo'

    - script: |
        docker images | grep -i neural-compressor
        docker ps
      displayName: 'Check docker'

