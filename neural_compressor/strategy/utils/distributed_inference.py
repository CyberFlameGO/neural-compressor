from typing import List, Any
from .remote_task import Trial, ResultMonitor

class Adaptor:
    def __init__(self) -> None:
        pass

    def __repr__(self) -> str:
        return "This is adaptor."

class Strategy:
    def __init__(self,
                 model,
                 conf,
                 q_dataloader=None,
                 q_func=None,
                 eval_dataloader=None,
                 eval_func=None,
                 resume=None,
                 q_hooks=None) -> None:
        self.model = model
        self.calib_dataloader = q_dataloader
        self.q_func = q_func
        self.adaptor = None # Initialize the adaptor.
        pass

    def _evaluate(self, qmodel):
        val = 1 # eval result
        return val

    def next_tune_cfg(self):
        tune_cfg = None # The tune cfg generated by the different strategy.
        yield tune_cfg

    def traverse(self):
        for tune_cfg in self.next_tune_cfg():
            # Get q model
            self.q_model = self.adaptor.quantize(tune_cfg, self.model, self.calib_dataloader, self.q_func)
            # Evaluate the q model
            self.last_tune_result = self._evaluate(self.q_model)
            # Collect and update the evaluation result and best qmodel.
        # Return best qmodel
        
            
    def dispatch_trial(self, tune_cfg, fp32_model, calibration, q_func, eval_func, result_monitor):
        # Create a new trial and dispatch is to remote worker.
        trial = Trial(tune_cfg, fp32_model, calibration, q_func, eval_func, result_monitor)
        self.trial_lst.append(trial)

    def distributed_traverse(self):
        self.trial_lst = [] # Collect all trials
        self.result_monitor = ResultMonitor()  # Initializing the result monitor.
        
        for tune_cfg in self.next_tune_cfg():
            self.dispatch_trial(tune_cfg, fp32_model, calibration, q_func, eval_func, self.result_monitor)

        while True:
            if self.result_monitor.has_update():
                # Collect finished trials.
                new_result = self.result_monitor.last_result()
                # collect and update the evaluation result and best qmodel.
        # Return best qmodel

    def __repr__(self) -> str:
        return "This strategy."


class Component(object):
    def __init__(self) -> None:
        pass

    def __repr__(self) -> str:
        return "This is Component."
    
class Quantization(Component):
    def __init__(self) -> None:
        pass

    def __repr__(self) -> str:
        return "This is Quantization."

    def __call__(self, *args: Any, **kwds: Any) -> Any:
        self.strategy = Strategy()
        best_qmodel = self.strategy.traverse()
        return best_qmodel
    
    
