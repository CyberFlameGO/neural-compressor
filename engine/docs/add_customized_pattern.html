<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Add a Customized Pattern to Engine Compile &mdash; Intel® Neural Compressor  documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Intel® Neural Compressor
          </a>
              <div class="version">
                1.8
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Introduction to Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/api-introduction.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../security_policy.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Add a Customized Pattern to Engine Compile</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/engine/docs/add_customized_pattern.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="add-a-customized-pattern-to-engine-compile">
<h1>Add a Customized Pattern to Engine Compile<a class="headerlink" href="#add-a-customized-pattern-to-engine-compile" title="Permalink to this headline">¶</a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">Engine</span></code> in <code class="docutils literal notranslate"><span class="pre">Neural_Compressor</span></code> support user add customized pattern of model. Which means you can compile your own pretrained model to <code class="docutils literal notranslate"><span class="pre">Engine</span></code> ir just by adding the specific patterns which the <code class="docutils literal notranslate"><span class="pre">engine.compile</span></code> does not contain.</p>
<p>The intermediate graph in <code class="docutils literal notranslate"><span class="pre">Engine</span></code> can be treated as a <code class="docutils literal notranslate"><span class="pre">list</span></code> that stores all nodes of model under control flow. Some certain nodes may compose a pattern which need to be fused for speeding up inference. For simplifying the network structure, we also design different attributes attached to fused nodes. So aim at adding a customized pattern, there needs three steps: <strong>1. register the nodes’ op_types; 2.  set the pattern mapping config and register the pattern; 3. fuse pattern and set attributes of new pattern after fusion.</strong></p>
<p><img alt="../../_images/layernorm_distilbert_base_onnx.png" src="../../_images/layernorm_distilbert_base_onnx.png" /></p>
<p>Above is a <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> pattern in <code class="docutils literal notranslate"><span class="pre">distilbert_base</span></code> onnx model. Assume it is a customized pattern in your model that need to be added in <code class="docutils literal notranslate"><span class="pre">Engine.compile</span></code>.  Follow the steps below to make <code class="docutils literal notranslate"><span class="pre">Engine</span></code> support this pattern, and fuse these 9 nodes to one node called <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> in <code class="docutils literal notranslate"><span class="pre">Engine</span></code>.</p>
<div class="section" id="register-the-nodes-op-types">
<h2>Register the nodes’ op_types<a class="headerlink" href="#register-the-nodes-op-types" title="Permalink to this headline">¶</a></h2>
<p>First you should check whether the nodes’ op_types in the pattern are registered in <code class="docutils literal notranslate"><span class="pre">Engine</span></code> or not.  If not, you need to add the op_type class for <code class="docutils literal notranslate"><span class="pre">engine.compile</span></code> loading and extracting the origin model. All the ops can be found from this <a class="reference external" href="https://github.com/intel/neural-compressor/blob/master/engine/compile/ops/op.py">link</a>. For quick check, use the commands below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># make sure you have cloned neural_compressor repo and installed neural_compressor </span>
<span class="kn">from</span> <span class="nn">engine.compile.ops.op</span> <span class="kn">import</span> <span class="n">OPERATORS</span>
<span class="c1"># All the op_type names and objects are stored in `OPERATORS`</span>
<span class="k">print</span><span class="p">(</span><span class="n">OPERATORS</span><span class="p">)</span>
</pre></div>
</div>
<p>The print result will show all registered ops, for example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>{&#39;All&#39;: &lt;class &#39;engine.compile.ops.all.All&#39;&gt;, &#39;Assert&#39;: &lt;class &#39;engine.compile.ops.assert.Assert&#39;&gt;, &#39;BatchMatMul&#39;: &lt;class &#39;engine.compile.ops.batch_matmul.BatchMatMul&#39;&gt;, &#39;BatchMatMulV2&#39;: &lt;class &#39;engine.compile.ops.batch_matmul_v2.BatchMatMulV2&#39;&gt;, &#39;BiasAdd&#39;: &lt;class &#39;engine.compile.ops.bias_add.BiasAdd&#39;&gt;, &#39;Cast&#39;: &lt;class &#39;engine.compile.ops.cast.Cast&#39;&gt;, &#39;Concat&#39;: &lt;class &#39;engine.compile.ops.concat.Concat&#39;&gt;, &#39;AddV2&#39;: &lt;class &#39;engine.compile.ops.empty_ops.AddV2&#39;&gt;, &#39;Add&#39;: &lt;class &#39;engine.compile.ops.empty_ops.Add&#39;&gt;, &#39;BinaryAdd&#39;: &lt;class &#39;engine.compile.ops.empty_ops.BinaryAdd&#39;&gt;, &#39;ConstantOfShape&#39;: &lt;class &#39;engine.compile.ops.empty_ops.ConstantOfShape&#39;&gt;, &#39;DequantizeLinear&#39;: &lt;class &#39;engine.compile.ops.empty_ops.DequantizeLinear&#39;&gt;, &#39;Div&#39;: &lt;class &#39;engine.compile.ops.empty_ops.Div&#39;&gt;, &#39;Equal&#39;: &lt;class &#39;engine.compile.ops.empty_ops.Equal&#39;&gt;, &#39;Erf&#39;: &lt;class &#39;engine.compile.ops.empty_ops.Erf&#39;&gt;, &#39;Expand&#39;: &lt;class &#39;engine.compile.ops.empty_ops.Expand&#39;&gt;, &#39;Fill&#39;: &lt;class &#39;engine.compile.ops.empty_ops.Fill&#39;&gt;, &#39;FlatMapDataset&#39;: &lt;class &#39;engine.compile.ops.empty_ops.FlatMapDataset&#39;&gt;, &#39;Identity&#39;: &lt;class &#39;engine.compile.ops.empty_ops.Identity&#39;&gt;, &#39;InnerProduct&#39;: &lt;class &#39;engine.compile.ops.empty_ops.InnerProduct&#39;&gt;, &#39;Input&#39;: &lt;class &#39;engine.compile.ops.empty_ops.Input&#39;&gt;, &#39;LayerNorm&#39;: &lt;class &#39;engine.compile.ops.empty_ops.LayerNorm&#39;&gt;, &#39;LessEqual&#39;: &lt;class &#39;engine.compile.ops.empty_ops.LessEqual&#39;&gt;, &#39;MakeIterator&#39;: &lt;class &#39;engine.compile.ops.empty_ops.MakeIterator&#39;&gt;, &#39;MatMulWithBiasAdd&#39;: &lt;class &#39;engine.compile.ops.empty_ops.MatMulWithBiasAdd&#39;&gt;, &#39;MatMulWithBiasGelu&#39;: &lt;class &#39;engine.compile.ops.empty_ops.MatMulWithBiasGelu&#39;&gt;, &#39;MatMulWithBiasTanh&#39;: &lt;class &#39;engine.compile.ops.empty_ops.MatMulWithBiasTanh&#39;&gt;, &#39;MatMulWithBias&#39;: &lt;class &#39;engine.compile.ops.empty_ops.MatMulWithBias&#39;&gt;, &#39;Mul&#39;: &lt;class &#39;engine.compile.ops.empty_ops.Mul&#39;&gt;, &#39;NonZero&#39;: &lt;class &#39;engine.compile.ops.empty_ops.NonZero&#39;&gt;, &#39;Output&#39;: &lt;class &#39;engine.compile.ops.empty_ops.Output&#39;&gt;, &#39;PaddingSequence&#39;: &lt;class &#39;engine.compile.ops.empty_ops.PaddingSequence&#39;&gt;, &#39;Pow&#39;: &lt;class &#39;engine.compile.ops.empty_ops.Pow&#39;&gt;, 
 ...}
</pre></div>
</div>
<p>These ops can be roughly divided into two categories, the one is without attributes, like <code class="docutils literal notranslate"><span class="pre">Mul</span></code>, the other one is with attributes, for example,  <code class="docutils literal notranslate"><span class="pre">Reshape</span></code> has the attributes <code class="docutils literal notranslate"><span class="pre">dst_shape</span></code>. You can look through the <code class="docutils literal notranslate"><span class="pre">engine.executor</span></code> for more info about the <code class="docutils literal notranslate"><span class="pre">Engine</span></code> ops’ attribute settings.</p>
<p>Assume the <code class="docutils literal notranslate"><span class="pre">Sqrt</span></code> and <code class="docutils literal notranslate"><span class="pre">ReduceMean</span></code> in <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> pattern is  new op_types for <code class="docutils literal notranslate"><span class="pre">engine.compile</span></code>.  Here are the examples that show how to register them.</p>
<p><code class="docutils literal notranslate"><span class="pre">Sqrt</span></code> has not attributes. You can add this op class in <a class="reference external" href="https://github.com/intel/neural-compressor/blob/master/engine/compile/ops/empty_ops.py"><code class="docutils literal notranslate"><span class="pre">engine.compile.ops.empty_ops</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># register the &#39;Sqrt&#39; class in OPERATORS</span>
<span class="nd">@operator_registry</span><span class="p">(</span><span class="n">operator_type</span><span class="o">=</span><span class="s1">&#39;Sqrt&#39;</span><span class="p">)</span>
<span class="c1"># all ops class will inherit the father class &#39;Operator&#39;</span>
<span class="k">class</span> <span class="nc">Sqrt</span><span class="p">(</span><span class="n">Operator</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ReduceMean</span></code> has <code class="docutils literal notranslate"><span class="pre">keep_dims</span></code> and <code class="docutils literal notranslate"><span class="pre">axis</span></code> two attributes, you need to set them by extracting the node from the origin model.</p>
<p>Create a python file (for example, name can be <code class="docutils literal notranslate"><span class="pre">reduce_mean.py</span></code>) in <a class="reference external" href="https://github.com/intel/neural-compressor/tree/master/engine/compile/ops"><code class="docutils literal notranslate"><span class="pre">engine.compile.ops</span></code></a> and add the <code class="docutils literal notranslate"><span class="pre">ReduceMean</span></code> op class.</p>
<p>In this <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> pattern, the <code class="docutils literal notranslate"><span class="pre">ReduceMean</span></code> node in origin onnx model just has <code class="docutils literal notranslate"><span class="pre">axes</span></code> value which is a list, that is the value of <code class="docutils literal notranslate"><span class="pre">axis</span></code> attribute comes from.  The <code class="docutils literal notranslate"><span class="pre">keep_dims</span></code> attribute is <code class="docutils literal notranslate"><span class="pre">False</span></code> by default in <code class="docutils literal notranslate"><span class="pre">engine.executor</span></code>, so if the <code class="docutils literal notranslate"><span class="pre">ReduceMean</span></code> node has the <code class="docutils literal notranslate"><span class="pre">keep_dims</span></code> attribute, you should extract and set it. Otherwise, you can just ignore it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">.op</span> <span class="kn">import</span> <span class="n">Operator</span><span class="p">,</span> <span class="n">operator_registry</span>
<span class="kn">from</span> <span class="nn">.tensor</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">..graph_utils</span> <span class="kn">import</span> <span class="n">list2str</span>

<span class="nd">@operator_registry</span><span class="p">(</span><span class="n">operator_type</span><span class="o">=</span><span class="s1">&#39;ReduceMean&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ReduceMean</span><span class="p">(</span><span class="n">Operator</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="c1"># rewrite the &#39;set_attr&#39; function to set the attributes</span>
    <span class="k">def</span> <span class="nf">set_attr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">framework</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
        <span class="c1"># other frameworks may also have the &#39;ReduceMean&#39; op_type</span>
        <span class="k">if</span> <span class="n">framework</span> <span class="o">==</span> <span class="s1">&#39;onnxruntime&#39;</span><span class="p">:</span>
            <span class="c1"># if node has &#39;keep_dims&#39; attribute in origin model</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">axis</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ints</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_attr</span><span class="p">[</span><span class="s1">&#39;keep_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">i</span><span class="p">)</span>
            <span class="c1"># if node has not &#39;keep_dims&#39; attribute in origin model</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
               <span class="n">axis</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ints</span>
            <span class="c1"># in this &#39;LayerNorm&#39; pattern, the axis just have on element in a list</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_attr</span><span class="p">[</span><span class="s1">&#39;axis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># if the axis list have several element, change the list to string</span>
            <span class="c1"># for example, [1, 2, 3] --&gt; &#39;1,2,3&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_attr</span><span class="p">[</span><span class="s1">&#39;axis&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">list2str</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
</pre></div>
</div>
<p>After adding the two op classes, you can use the <code class="docutils literal notranslate"><span class="pre">OPERATORS</span></code> to check whether them be added successfully or not. Please do not forget reinstall the <code class="docutils literal notranslate"><span class="pre">Neural_Compressor</span></code> in local for making your code changes effective.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># enter into the &lt;nerual_compressor&gt; floder</span>
<span class="nb">cd</span> &lt;you_work_dir&gt;/neural_compressor/
<span class="c1"># reinstall the neural_compressor locally</span>
python setup.py install
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># check your code changes</span>
<span class="kn">from</span> <span class="nn">engine.compile.ops.op</span> <span class="kn">import</span> <span class="n">OPERATORS</span>
<span class="s1">&#39;Sqrt&#39;</span> <span class="ow">and</span> <span class="s1">&#39;ReduceMean&#39;</span> <span class="ow">in</span> <span class="n">OPERATORS</span>
</pre></div>
</div>
<p>If nothing wrong, the output result should be <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
</div>
<div class="section" id="set-the-pattern-mapping-config-and-register-the-pattern">
<h2>Set the pattern mapping config and register the pattern;<a class="headerlink" href="#set-the-pattern-mapping-config-and-register-the-pattern" title="Permalink to this headline">¶</a></h2>
<p>In <code class="docutils literal notranslate"><span class="pre">Engine</span></code>, we treat the pattern fusion as the process of pattern mapping: from a group nodes to another group nodes. In this step, you need to supply a config for <code class="docutils literal notranslate"><span class="pre">pattern_mapping</span></code> function and register your pattern, in order to make sure that the <code class="docutils literal notranslate"><span class="pre">engine.compile</span></code> to implement pattern fusion correctly.</p>
<ul>
<li><p>Create a python file (for example, name can be <code class="docutils literal notranslate"><span class="pre">layer_norm.py</span></code>) in <a class="reference external" href="https://github.com/intel/neural-compressor/tree/master/engine/compile/sub_graph"><code class="docutils literal notranslate"><span class="pre">engine.compile.sub_graph</span></code></a> and add the <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> pattern mapping config.</p>
<p>For the above <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> pattern, the config example can be like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># LayerNorm in distil_bert_base</span>
<span class="n">pattern_mapping_config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;LayerNorm&#39;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
    <span class="s1">&#39;patterns&#39;</span><span class="p">:</span> <span class="p">{</span>
                 <span class="s1">&#39;in&#39;</span><span class="p">:</span> <span class="p">[[(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;ReduceMean&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Sub&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;Pow&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;ReduceMean&#39;</span><span class="p">),</span> 
                        <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;Add&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;Sqrt&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;Div&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="s1">&#39;Mul&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;Add&#39;</span><span class="p">)]],</span>
                 <span class="s1">&#39;out&#39;</span><span class="p">:</span> <span class="p">[[(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;LayerNorm&#39;</span><span class="p">)]]</span>
                 <span class="p">},</span>
     <span class="s1">&#39;search_mode&#39;</span><span class="p">:</span> <span class="s1">&#39;op_type&#39;</span><span class="p">,</span>
     <span class="s1">&#39;node_names&#39;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="mi">0</span><span class="p">:</span> <span class="mi">8</span>
                   <span class="p">},</span>
     <span class="s1">&#39;input_tensors&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="mi">0</span><span class="p">:</span> <span class="p">[[{</span>
                            <span class="mi">0</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="p">},</span> <span class="p">{</span>
                            <span class="mi">7</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="p">},</span> <span class="p">{</span>
                            <span class="mi">8</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="p">}],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="mi">3</span><span class="p">]]</span>
                       <span class="p">},</span>
     <span class="s1">&#39;output_tensors&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="mi">0</span><span class="p">:</span> <span class="p">[[{</span>
                            <span class="mi">8</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="p">}],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">]]</span>
                    <span class="p">},</span>
     <span class="s1">&#39;returns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span>
     <span class="p">},</span>
  <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The dict in the config will guide the <code class="docutils literal notranslate"><span class="pre">pattern_mapping</span></code> function how to find all the group nodes that belong to <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> pattern in intermediate graph and how to replace them with new pattern. We use this config to store many dicts because different models (even same model) could have different representations for a certain pattern. If you want to delve into it, pleas see  <a class="reference external" href="https://github.com/intel/neural-compressor/tree/master/engine/docs/pattern_recognition.md">pattern_recognize</a> and <a class="reference external" href="https://github.com/intel/neural-compressor/tree/master/engine/docs/graph_fusion.md">graph_fusion</a> docs for more details.</p>
</li>
<li><p>Register the <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> pattern</p>
<p>Like the node op_type, the new pattern also need to be registered. You can check the existing pattern classes by the commands below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">engine.compile.sub_graph.pattern</span> <span class="kn">import</span> <span class="n">PATTERNS</span>
<span class="k">print</span><span class="p">(</span><span class="n">PATTERNS</span><span class="p">)</span>
</pre></div>
</div>
<p>The print result will show all registered patterns, for example:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">{</span><span class="s1">&#39;AddEmbeddings&#39;</span>: &lt;class <span class="s1">&#39;engine.compile.sub_graph.add_embeddings.AddEmbeddings&#39;</span>&gt;, <span class="s1">&#39;AttentionReshape&#39;</span>: &lt;class <span class="s1">&#39;engine.compile.sub_graph.attention_reshape.AttentionReshape&#39;</span>&gt;, <span class="s1">&#39;Gelu&#39;</span>: &lt;class <span class="s1">&#39;engine.compile.sub_graph.gelu.Gelu&#39;</span>&gt;, <span class="s1">&#39;InputData&#39;</span>: &lt;class <span class="s1">&#39;engine.compile.sub_graph.input_data.InputData&#39;</span>&gt;, <span class="s1">&#39;InputFile&#39;</span>: &lt;class <span class="s1">&#39;engine.compile.sub_graph.input_file.InputFile&#39;</span>&gt;, <span class="s1">&#39;LastLayerShape&#39;</span>: &lt;class <span class="s1">&#39;engine.compile.sub_graph.last_layer_shape.LastLayerShape&#39;</span>&gt;, ...<span class="o">}</span>
</pre></div>
</div>
<p>In order to complete the <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> pattern registration, write a related classes in the python file you created before and put the pattern mapping config in.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">.pattern</span> <span class="kn">import</span> <span class="n">Pattern</span><span class="p">,</span> <span class="n">pattern_registry</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span><span class="p">,</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">graph_utils</span> <span class="k">as</span> <span class="n">util</span>

<span class="nd">@pattern_registry</span><span class="p">(</span><span class="n">pattern_type</span><span class="o">=</span><span class="s1">&#39;LayerNorm&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">Pattern</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>

        <span class="n">pattern_mapping_config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;LayerNorm&#39;</span><span class="p">:</span> <span class="p">[</span>        
                <span class="c1"># LayerNorm in distil_bert_base</span>
                <span class="p">{</span>
                    <span class="s1">&#39;patterns&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s1">&#39;in&#39;</span><span class="p">:</span> <span class="p">[[(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;ReduceMean&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Sub&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;Pow&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;ReduceMean&#39;</span><span class="p">),</span> 
                                <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;Add&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;Sqrt&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;Div&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="s1">&#39;Mul&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;Add&#39;</span><span class="p">)]],</span>
                        <span class="s1">&#39;out&#39;</span><span class="p">:</span> <span class="p">[[(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;LayerNorm&#39;</span><span class="p">)]]</span>
                    <span class="p">},</span>
                    <span class="s1">&#39;search_mode&#39;</span><span class="p">:</span> <span class="s1">&#39;op_type&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;node_names&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="mi">0</span><span class="p">:</span> <span class="mi">8</span>
                    <span class="p">},</span>
                    <span class="s1">&#39;input_tensors&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="mi">0</span><span class="p">:</span> <span class="p">[[{</span>
                            <span class="mi">0</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="p">},</span> <span class="p">{</span>
                            <span class="mi">7</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="p">},</span> <span class="p">{</span>
                            <span class="mi">8</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="p">}],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="mi">3</span><span class="p">]]</span>
                    <span class="p">},</span>
                    <span class="s1">&#39;output_tensors&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="mi">0</span><span class="p">:</span> <span class="p">[[{</span>
                            <span class="mi">8</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="p">}],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">]]</span>
                    <span class="p">},</span>
                    <span class="s1">&#39;returns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span>
                <span class="p">},</span>
            <span class="p">]</span>
        <span class="p">}</span>     
</pre></div>
</div>
<p>After save this python file, you can check it by retrieving the <code class="docutils literal notranslate"><span class="pre">PATTERNS</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">engine.compile.sub_graph.pattern</span> <span class="kn">import</span> <span class="n">PATTERNS</span>
<span class="s1">&#39;LayerNorm&#39;</span> <span class="ow">in</span> <span class="n">PATTERNS</span>
</pre></div>
</div>
<p>If nothing wrong, the output result should be <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</li>
</ul>
</div>
<div class="section" id="fuse-pattern-and-set-attributes-of-new-pattern-after-fusion">
<h2>Fuse pattern and set attributes of new pattern after fusion<a class="headerlink" href="#fuse-pattern-and-set-attributes-of-new-pattern-after-fusion" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p>Define the pattern fusion order</p>
<p>Fuse pattern should follow specific order if a model has multiple patterns. For example, if the model has A pattern (nodes: a–&gt;b) and B pattern (nodes: a–&gt;b–&gt;c), and B pattern is actually equivalent to A pattern + c node. So you should fuse A pattern first, then B pattern (more info and details please see the <a class="reference external" href="https://github.com/intel/neural-compressor/tree/master/engine/docs/graph_fusion.md">graph_fusion</a>).</p>
<p>There is a list called <code class="docutils literal notranslate"><span class="pre">supported_patterns</span></code> in <a class="reference external" href="https://github.com/intel/neural-compressor/blob/master/engine/compile/sub_graph/pattern.py"><code class="docutils literal notranslate"><span class="pre">engine.compile.sub_graph.pattern</span></code></a>. It control the order of pattern fusion. You need to add your customized pattern name (the <code class="docutils literal notranslate"><span class="pre">pattern_type</span></code> you register in step 2) into <code class="docutils literal notranslate"><span class="pre">supported_patterns</span></code> at appropriate location (If a pattern does not influence other patterns, you can put it at arbitrary location).</p>
<p>For example, change the <code class="docutils literal notranslate"><span class="pre">supported_patterns</span></code> like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">supported_patterns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;InputData&#39;</span><span class="p">,</span>
    <span class="s1">&#39;A pattern&#39;</span>
    <span class="o">...</span>
    <span class="s1">&#39;LayerNorm&#39;</span><span class="p">,</span>
    <span class="s1">&#39;B pattern&#39;</span><span class="p">,</span>
    <span class="o">...</span>
    <span class="s1">&#39;OutputData&#39;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</li>
<li><p>Replace the pattern with new pattern</p>
<p>According to the pattern mapping dict in step 2, add these two lines below to get the intermediate graph after pattern fusion.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># get the above LayerNorm pattern dict</span>
<span class="n">pattern_dict</span> <span class="o">=</span> <span class="n">pattern_mapping_config</span><span class="p">[</span><span class="s1">&#39;LayerNorm&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># get the intermediate graph (model) after fuse LayerNorm pattern</span>
<span class="c1"># new_node_name and ret_old_nodes are used for set attributes later</span>
<span class="n">model</span><span class="p">,</span> <span class="n">new_node_names</span><span class="p">,</span> <span class="n">ret_old_nodes</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">pattern_mapping</span><span class="p">(</span><span class="s1">&#39;LayerNorm&#39;</span><span class="p">,</span> <span class="n">pattern_dict</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Set the attributes of new pattern</p>
<p>Every new pattern generated after fusion could have their own attributes (when we talk about pattern attribute, it stands for the operator’s attributes in the pattern, which defined by <code class="docutils literal notranslate"><span class="pre">engine.executor</span></code> ). As for <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> pattern, the above 9 nodes are fused to one node with op_type <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code>. This operation has an attribute <code class="docutils literal notranslate"><span class="pre">epsilon</span></code> in <code class="docutils literal notranslate"><span class="pre">engine.executor</span></code>, which  is a value added to the denominator for numerical stability.</p>
<p>We recommend to write a <code class="docutils literal notranslate"><span class="pre">_set_attr</span></code> function and call it after pattern mapping to set the nodes’ attributes. Here is the example for <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> pattern.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_set_attr</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">node_names</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">attr</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
    <span class="c1"># set the `epsilon` attribute</span>
    <span class="n">attr</span><span class="p">[</span><span class="s1">&#39;epsilon&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">epsilon</span><span class="p">)</span>
    <span class="n">ln_node_idx</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_node_id</span><span class="p">(</span><span class="n">node_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1"># make the LayerNorm node in model have the </span>
    <span class="n">model</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ln_node_idx</span><span class="p">]</span><span class="o">.</span><span class="n">attr</span> <span class="o">=</span> <span class="n">attr</span>
<span class="c1"># LayerNorm pattern mapping</span>
<span class="n">pattern_dict</span> <span class="o">=</span> <span class="n">pattern_mapping_config</span><span class="p">[</span><span class="s1">&#39;LayerNorm&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">model</span><span class="p">,</span> <span class="n">new_node_names</span><span class="p">,</span> <span class="n">ret_old_nodes</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">pattern_mapping</span><span class="p">(</span><span class="s1">&#39;LayerNorm&#39;</span><span class="p">,</span> <span class="n">pattern_dict</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="c1"># if the model has the above LayerNorm pattern</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_node_names</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># set the LayerNorm node attribute</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_node_names</span><span class="p">)):</span>
        <span class="c1"># get the epsilon value from the ret_old_nodes</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="n">ret_old_nodes</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">data</span>
        <span class="n">_set_attr</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">new_node_names</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</li>
</ul>
<p>Here gives the complete code of the <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> pattern config, pattern fusion and attributes setting.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">.pattern</span> <span class="kn">import</span> <span class="n">Pattern</span><span class="p">,</span> <span class="n">pattern_registry</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span><span class="p">,</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">graph_utils</span> <span class="k">as</span> <span class="n">util</span>

<span class="nd">@pattern_registry</span><span class="p">(</span><span class="n">pattern_type</span><span class="o">=</span><span class="s1">&#39;LayerNorm&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">Pattern</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>

        <span class="n">pattern_mapping_config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;LayerNorm&#39;</span><span class="p">:</span> <span class="p">[</span>        
                <span class="c1"># LayerNorm in distil_bert_base</span>
                <span class="p">{</span>
                    <span class="s1">&#39;patterns&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="s1">&#39;in&#39;</span><span class="p">:</span> <span class="p">[[(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;ReduceMean&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Sub&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;Pow&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;ReduceMean&#39;</span><span class="p">),</span> 
                                <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;Add&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;Sqrt&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;Div&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="s1">&#39;Mul&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;Add&#39;</span><span class="p">)]],</span>
                        <span class="s1">&#39;out&#39;</span><span class="p">:</span> <span class="p">[[(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;LayerNorm&#39;</span><span class="p">)]]</span>
                    <span class="p">},</span>
                    <span class="s1">&#39;search_mode&#39;</span><span class="p">:</span> <span class="s1">&#39;op_type&#39;</span><span class="p">,</span>
                    <span class="s1">&#39;node_names&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="mi">0</span><span class="p">:</span> <span class="mi">8</span>
                    <span class="p">},</span>
                    <span class="s1">&#39;input_tensors&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="mi">0</span><span class="p">:</span> <span class="p">[[{</span>
                            <span class="mi">0</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="p">},</span> <span class="p">{</span>
                            <span class="mi">7</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="p">},</span> <span class="p">{</span>
                            <span class="mi">8</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="p">}],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="mi">3</span><span class="p">]]</span>
                    <span class="p">},</span>
                    <span class="s1">&#39;output_tensors&#39;</span><span class="p">:</span> <span class="p">{</span>
                        <span class="mi">0</span><span class="p">:</span> <span class="p">[[{</span>
                            <span class="mi">8</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="p">}],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">]]</span>
                    <span class="p">},</span>
                    <span class="s1">&#39;returns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span>
                <span class="p">},</span>
            <span class="p">]</span>
        <span class="p">}</span>     
        
        <span class="c1"># general LayerNorm node attribute setting function</span>
        <span class="k">def</span> <span class="nf">_set_attr</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">node_names</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
            <span class="n">attr</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="n">attr</span><span class="p">[</span><span class="s1">&#39;epsilon&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">epsilon</span><span class="p">)</span>
            <span class="n">ln_node_idx</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_node_id</span><span class="p">(</span><span class="n">node_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">model</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">ln_node_idx</span><span class="p">]</span><span class="o">.</span><span class="n">attr</span> <span class="o">=</span> <span class="n">attr</span>
        <span class="c1"># use for-loop beacuse you may add other LayerNorm pattern mapping dict </span>
        <span class="c1"># when meeting other different models</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pattern_mapping_config</span><span class="p">[</span><span class="s1">&#39;LayerNorm&#39;</span><span class="p">])):</span>
            <span class="c1"># replace all the LayerNorm patttern in the model</span>
            <span class="n">pattern_dict</span> <span class="o">=</span> <span class="n">pattern_mapping_config</span><span class="p">[</span><span class="s1">&#39;LayerNorm&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">new_node_names</span><span class="p">,</span> <span class="n">ret_old_nodes</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">pattern_mapping</span><span class="p">(</span><span class="s1">&#39;LayerNorm&#39;</span><span class="p">,</span> <span class="n">pattern_dict</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_node_names</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># set the LayerNorm node attribute</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_node_names</span><span class="p">)):</span>
                    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">ret_old_nodes</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input_tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">data</span>
                    <span class="n">_set_attr</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">new_node_names</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">model</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">model</span>
        <span class="c1"># if a model has not any LayerNorm pattern in the pattern_mapping config,return</span>
        <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>After finishing these three steps in <code class="docutils literal notranslate"><span class="pre">engine.compile</span></code>, reinstall <code class="docutils literal notranslate"><span class="pre">Neural_Compressor</span></code> and then use <code class="docutils literal notranslate"><span class="pre">prepare_ir</span></code> function would compile your model with the customized pattern.</p>
<blockquote>
<div><p><strong>NOTE</strong>:</p>
<ol class="simple">
<li><p>The pattern mapping function just support pattern after fusion is sequence for now, like [a–&gt;b–&gt;c] or [a]. So if the customized  pattern after fusion is too complicated, you had better decompose it.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">engine.executor</span></code> may have not the operators’ implementation of customized pattern after fusion, you need to add them in <code class="docutils literal notranslate"><span class="pre">engine.executor</span></code> if this condition happens.</p></li>
</ol>
</div></blockquote>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Intel® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>