Search.setIndex({"docnames": [".github/pull_request_template", "README", "SECURITY", "api-documentation/api-reference", "api-documentation/apis", "api-documentation/benchmark-api", "api-documentation/objective-api", "api-documentation/pruning-api", "api-documentation/quantization-api", "docker/README", "docs/CODE_OF_CONDUCT", "docs/FX", "docs/NAS", "docs/PTQ", "docs/QAT", "docs/adaptor", "docs/api-introduction", "docs/backend_quant", "docs/bench", "docs/benchmark", "docs/contributions", "docs/dataloader", "docs/dataset", "docs/design", "docs/distillation", "docs/distillation_quantization", "docs/distributed", "docs/doclist", "docs/dynamic_quantization", "docs/examples_readme", "docs/faq", "docs/framework_yaml", "docs/getting_started", "docs/graph_optimization", "docs/incompatible_changes", "docs/infrastructure", "docs/installation_guide", "docs/legal_information", "docs/metric", "docs/mixed_precision", "docs/model", "docs/model_conversion", "docs/objective", "docs/orchestration", "docs/platform_configuration", "docs/pruning", "docs/publication_list", "docs/pythonic_style", "docs/quantization", "docs/quantization_mixed_precision", "docs/reference_examples", "docs/releases_info", "docs/sigopt_strategy", "docs/tensorboard", "docs/transform", "docs/tuning_strategies", "docs/user_yaml", "docs/validated_model_list", "docs/welcome", "examples/README", "examples/helloworld/README", "examples/helloworld/tf_example1/README", "examples/helloworld/tf_example2/README", "examples/helloworld/tf_example3/README", "examples/helloworld/tf_example4/README", "examples/helloworld/tf_example5/README", "examples/helloworld/tf_example6/README", "examples/helloworld/tf_example7/README", "examples/helloworld/tf_example8/README", "examples/mxnet/image_recognition/cnn_models/quantization/ptq/README", "examples/mxnet/language_translation/bert/quantization/ptq/README", "examples/mxnet/object_detection/ssd_models/quantization/ptq/README", "examples/notebook/perf_fp32_int8_tf/README", "examples/notebook/pytorch/alexnet_fashion_mnist/README", "examples/notebook/tensorflow/alexnet_mnist/README", "examples/notebook/usage_example", "examples/onnxrt/README", "examples/onnxrt/body_analysis/onnx_model_zoo/emotion_ferplus/quantization/ptq/README", "examples/onnxrt/body_analysis/onnx_model_zoo/ultraface/quantization/ptq/README", "examples/onnxrt/image_recognition/mobilenet_v2/quantization/ptq/README", "examples/onnxrt/image_recognition/mobilenet_v3/quantization/ptq/readme", "examples/onnxrt/image_recognition/onnx_model_zoo/alexnet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/arcface/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/caffenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/densenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/efficientnet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/fcn/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/googlenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/inception/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/mnist/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/mobilenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/resnet50/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/shufflenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/squeezenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/vgg16/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/zfnet/quantization/ptq/README", "examples/onnxrt/image_recognition/resnet50/quantization/ptq/README", "examples/onnxrt/image_recognition/unet/quantization/ptq/readme", "examples/onnxrt/image_recognition/vgg16/quantization/ptq/README", "examples/onnxrt/nlp/bert/quantization/ptq/README", "examples/onnxrt/nlp/distilbert/quantization/ptq/readme", "examples/onnxrt/nlp/huggingface_model/question_answering/quantization/ptq/README", "examples/onnxrt/nlp/huggingface_model/text_classification/quantization/ptq/README", "examples/onnxrt/nlp/mobilebert/quantization/ptq/readme", "examples/onnxrt/nlp/onnx_model_zoo/BiDAF/quantization/ptq/README", "examples/onnxrt/nlp/onnx_model_zoo/bert-squad/quantization/ptq/readme", "examples/onnxrt/nlp/onnx_model_zoo/gpt2/quantization/ptq/readme", "examples/onnxrt/nlp/onnx_model_zoo/mobilebert/quantization/ptq/readme", "examples/onnxrt/nlp/roberta/quantization/ptq/readme", "examples/onnxrt/object_detection/onnx_model_zoo/DUC/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/faster_rcnn/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/mask_rcnn/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/ssd/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/ssd_mobilenet_v1/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/tiny_yolov3/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/yolov3/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/yolov4/quantization/ptq/README", "examples/onnxrt/object_detection/ssd_mobilenet_v1/quantization/ptq/readme", "examples/onnxrt/object_detection/ssd_mobilenet_v2/quantization/ptq/readme", "examples/pytorch/diffusion_model/diffusers/textual_inversion/README", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/3DUnet_README", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/README", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/data_format_inference", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/dataset_conversion", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/extending_nnunet", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/inference_example_Prostate", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/setting_up_paths", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/training_example_Hippocampus", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/nnunet/experiment_planning/alternative_experiment_planning/readme", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/readme", "examples/pytorch/image_recognition/CNN-2/distillation/eager/README", "examples/pytorch/image_recognition/MobileNetV2-0.35/distillation/eager/README", "examples/pytorch/image_recognition/VGG-8/distillation/eager/README", "examples/pytorch/image_recognition/efficientnet/quantization/ptq/eager/Efficientnet_README", "examples/pytorch/image_recognition/efficientnet/quantization/ptq/eager/README", "examples/pytorch/image_recognition/mnist/README", "examples/pytorch/image_recognition/peleenet/quantization/ptq/eager/PeleeNet_README", "examples/pytorch/image_recognition/peleenet/quantization/ptq/eager/README", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/README", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/ResNest_README", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/ablation", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/scripts/gluon/README", "examples/pytorch/image_recognition/se_resnext/quantization/ptq/eager/README", "examples/pytorch/image_recognition/se_resnext/quantization/ptq/eager/SE_ResNext_README", "examples/pytorch/image_recognition/torchvision_models/distillation/eager/README", "examples/pytorch/image_recognition/torchvision_models/optimization_pipeline/prune_and_ptq/eager/README", "examples/pytorch/image_recognition/torchvision_models/optimization_pipeline/qat_during_prune/eager/README", "examples/pytorch/image_recognition/torchvision_models/pruning/magnitude/eager/README", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/eager/README", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/fx/README", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/ipex/README", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/eager/README", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/eager/distributed/README", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/fx/README", "examples/pytorch/image_recognition/torchvision_models/self_distillation/eager/README", "examples/pytorch/nlp/blendcnn/distillation/eager/README", "examples/pytorch/nlp/blendcnn/quantization/ptq/eager/README", "examples/pytorch/nlp/huggingface_models/common/CODE_OF_CONDUCT", "examples/pytorch/nlp/huggingface_models/common/CONTRIBUTING", "examples/pytorch/nlp/huggingface_models/common/ISSUES", "examples/pytorch/nlp/huggingface_models/common/README", "examples/pytorch/nlp/huggingface_models/common/docs/README", "examples/pytorch/nlp/huggingface_models/common/docs/source/add_new_model", "examples/pytorch/nlp/huggingface_models/common/docs/source/benchmarks", "examples/pytorch/nlp/huggingface_models/common/docs/source/bertology", "examples/pytorch/nlp/huggingface_models/common/docs/source/community", "examples/pytorch/nlp/huggingface_models/common/docs/source/contributing", "examples/pytorch/nlp/huggingface_models/common/docs/source/converting_tensorflow_models", "examples/pytorch/nlp/huggingface_models/common/docs/source/custom_datasets", "examples/pytorch/nlp/huggingface_models/common/docs/source/examples", "examples/pytorch/nlp/huggingface_models/common/docs/source/glossary", "examples/pytorch/nlp/huggingface_models/common/docs/source/index", "examples/pytorch/nlp/huggingface_models/common/docs/source/installation", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/file_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/generation_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/modeling_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/pipelines_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/tokenization_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/trainer_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/callback", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/configuration", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/feature_extractor", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/logging", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/model", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/optimizer_schedules", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/output", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/pipelines", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/processors", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/tokenizer", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/trainer", "examples/pytorch/nlp/huggingface_models/common/docs/source/migration", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/albert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/auto", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bart", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/barthez", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bertgeneration", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bertweet", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/blenderbot", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/blenderbot_small", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bort", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/camembert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/convbert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/ctrl", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/deberta", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/deberta_v2", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/dialogpt", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/distilbert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/dpr", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/electra", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/encoderdecoder", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/flaubert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/fsmt", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/funnel", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/gpt", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/gpt2", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/herbert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/ibert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/layoutlm", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/led", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/longformer", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/lxmert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/marian", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mbart", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mobilebert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mpnet", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mt5", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/pegasus", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/phobert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/prophetnet", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/rag", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/reformer", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/retribert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/roberta", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/squeezebert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/t5", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/tapas", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/transformerxl", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/wav2vec2", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlm", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlmprophetnet", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlmroberta", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlnet", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_sharing", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_summary", "examples/pytorch/nlp/huggingface_models/common/docs/source/multilingual", "examples/pytorch/nlp/huggingface_models/common/docs/source/notebooks", "examples/pytorch/nlp/huggingface_models/common/docs/source/perplexity", "examples/pytorch/nlp/huggingface_models/common/docs/source/philosophy", "examples/pytorch/nlp/huggingface_models/common/docs/source/preprocessing", "examples/pytorch/nlp/huggingface_models/common/docs/source/pretrained_models", "examples/pytorch/nlp/huggingface_models/common/docs/source/quicktour", "examples/pytorch/nlp/huggingface_models/common/docs/source/serialization", "examples/pytorch/nlp/huggingface_models/common/docs/source/task_summary", "examples/pytorch/nlp/huggingface_models/common/docs/source/testing", "examples/pytorch/nlp/huggingface_models/common/docs/source/tokenizer_summary", "examples/pytorch/nlp/huggingface_models/common/docs/source/training", "examples/pytorch/nlp/huggingface_models/common/examples/README", "examples/pytorch/nlp/huggingface_models/common/examples/benchmarking/README", "examples/pytorch/nlp/huggingface_models/common/examples/language-modeling/README", "examples/pytorch/nlp/huggingface_models/common/examples/multiple-choice/README", "examples/pytorch/nlp/huggingface_models/common/examples/question-answering/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/adversarial/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/bert-loses-patience/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/bertabs/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/deebert/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/distillation/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/longform-qa/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/lxmert/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/mlm_wwm/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/mm-imdb/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/movement-pruning/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/performer/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/pplm/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/rag/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/seq2seq-distillation/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/seq2seq-distillation/precomputed_pseudo_labels", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/zero-shot-distillation/README", "examples/pytorch/nlp/huggingface_models/common/examples/seq2seq/README", "examples/pytorch/nlp/huggingface_models/common/examples/text-classification/README", "examples/pytorch/nlp/huggingface_models/common/examples/text-generation/README", "examples/pytorch/nlp/huggingface_models/common/examples/token-classification/README", "examples/pytorch/nlp/huggingface_models/common/model_cards/README", "examples/pytorch/nlp/huggingface_models/common/model_cards/google/tapas-base/README", "examples/pytorch/nlp/huggingface_models/common/notebooks/README", "examples/pytorch/nlp/huggingface_models/common/scripts/tatoeba/README", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_example_script/README", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/ADD_NEW_MODEL_PROPOSAL_TEMPLATE", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/README", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/{{cookiecutter.lowercase_modelname}}", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/open_model_proposals/ADD_BIG_BIRD", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/open_model_proposals/README", "examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/eager/README", "examples/pytorch/nlp/huggingface_models/question-answering/distillation/eager/README", "examples/pytorch/nlp/huggingface_models/question-answering/optimization_pipeline/prune_once_for_all/fx/README", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/group_lasso/eager/README", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/pattern_lock/eager/README", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/pytorch_pruner/eager/README", "examples/pytorch/nlp/huggingface_models/question-answering/quantization/ptq_static/fx/README", "examples/pytorch/nlp/huggingface_models/question-answering/quantization/ptq_static/ipex/README", "examples/pytorch/nlp/huggingface_models/summarization/quantization/ptq_dynamic/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/distillation/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/optimization_pipeline/distillation_for_quantization/fx/README", "examples/pytorch/nlp/huggingface_models/text-classification/optimization_pipeline/prune_once_for_all/fx/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/gradient_sensitivity/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/magnitude/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/pattern_lock/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/pytorch_pruner/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning_while_distillation/group_lasso/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning_while_distillation/group_lasso/eager/bert-mini/README", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_dynamic/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_dynamic/fx/README", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/fx/README", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/qat/fx/README", "examples/pytorch/nlp/huggingface_models/translation/quantization/ptq_dynamic/eager/README", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/MASKRCNN_README", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/README", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/ABSTRACTIONS", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/INSTALL", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/MODEL_ZOO", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/README", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/TROUBLESHOOTING", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/maskrcnn_benchmark/data/README", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/maskrcnn_benchmark/utils/README", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/fx/README", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/fx/upscale_coco/README", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/ipex/README", "examples/pytorch/object_detection/ssd_resnet34/quantization/qat/fx/README", "examples/pytorch/object_detection/yolo_v3/quantization/ptq/eager/README", "examples/pytorch/object_detection/yolo_v3/quantization/ptq/eager/YOLOV3_README", "examples/pytorch/recommendation/dlrm/quantization/ptq/eager/README", "examples/pytorch/recommendation/dlrm/quantization/ptq/fx/README", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/CODE_OF_CONDUCT", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/CONTRIBUTING", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/README", "examples/pytorch/speech_recognition/rnnt/quantization/ptq_dynamic/eager/README", "examples/pytorch/speech_recognition/torchaudio_models/quantization/ptq_dynamic/eager/README", "examples/tensorflow/image_recognition/SavedModel/quantization/ptq/README", "examples/tensorflow/image_recognition/ViT/pruning/magnitude/README", "examples/tensorflow/image_recognition/inception_v3/pruning/magnitude/README", "examples/tensorflow/image_recognition/keras_models/inception_resnet_v2/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/inception_v3/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/mnist/quantization/qat/README", "examples/tensorflow/image_recognition/keras_models/mobilenet_v2/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/resnet101/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/resnet50/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/resnet50_fashion/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/resnetv2_101/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/resnetv2_50/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/vgg16/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/vgg19/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/xception/quantization/ptq/README", "examples/tensorflow/image_recognition/resnet_v2/pruning/magnitude/README", "examples/tensorflow/image_recognition/resnet_v2/quantization/qat/README", "examples/tensorflow/image_recognition/tensorflow_models/distillation/README", "examples/tensorflow/image_recognition/tensorflow_models/quantization/ptq/README", "examples/tensorflow/image_recognition/tensorflow_models/quantization/ptq/slim/README", "examples/tensorflow/nlp/bert_base_mrpc/quantization/ptq/README", "examples/tensorflow/nlp/bert_large_squad/quantization/ptq/README", "examples/tensorflow/nlp/bert_large_squad_model_zoo/quantization/ptq/README", "examples/tensorflow/nlp/distilbert_base/quantization/ptq/README", "examples/tensorflow/nlp/transformer_lt/quantization/ptq/README", "examples/tensorflow/nlp/transformer_lt_mlperf/quantization/ptq/README", "examples/tensorflow/object_detection/tensorflow_models/quantization/ptq/README", "examples/tensorflow/object_detection/yolo_v3/quantization/ptq/README", "examples/tensorflow/oob_models/quantization/ptq/README", "examples/tensorflow/recommendation/wide_deep_large_ds/quantization/ptq/README", "examples/tensorflow/semantic_image_segmentation/3dunet-mlperf/quantization/ptq/README", "examples/tensorflow/semantic_image_segmentation/deeplab/quantization/ptq/README", "examples/tensorflow/style_transfer/arbitrary_style_transfer/quantization/ptq/README", "index", "neural_coder/README", "neural_coder/docs/IntelCPU_PerformanceSetting", "neural_coder/docs/PythonAPI", "neural_coder/docs/PythonLauncher", "neural_coder/docs/Quantization", "neural_coder/docs/SupportMatrix", "neural_coder/extensions/neural_compressor_ext_lab/CHANGELOG", "neural_coder/extensions/neural_compressor_ext_lab/DEVELOP", "neural_coder/extensions/neural_compressor_ext_lab/README", "neural_coder/extensions/neural_compressor_ext_lab/RELEASE", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/CHANGELOG", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/DEVELOP", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/RELEASE", "neural_compressor/conf/README", "neural_compressor/ux/components/benchmark/README", "neural_compressor/ux/components/configuration_wizard/README", "neural_compressor/ux/components/db_manager/README", "neural_compressor/ux/gui/README", "neural_compressor/ux/web/README"], "filenames": [".github/pull_request_template.md", "README.md", "SECURITY.md", "api-documentation/api-reference.rst", "api-documentation/apis.rst", "api-documentation/benchmark-api.rst", "api-documentation/objective-api.rst", "api-documentation/pruning-api.rst", "api-documentation/quantization-api.rst", "docker/README.md", "docs/CODE_OF_CONDUCT.md", "docs/FX.md", "docs/NAS.md", "docs/PTQ.md", "docs/QAT.md", "docs/adaptor.md", "docs/api-introduction.md", "docs/backend_quant.md", "docs/bench.md", "docs/benchmark.md", "docs/contributions.md", "docs/dataloader.md", "docs/dataset.md", "docs/design.md", "docs/distillation.md", "docs/distillation_quantization.md", "docs/distributed.md", "docs/doclist.rst", "docs/dynamic_quantization.md", "docs/examples_readme.md", "docs/faq.md", "docs/framework_yaml.md", "docs/getting_started.md", "docs/graph_optimization.md", "docs/incompatible_changes.md", "docs/infrastructure.md", "docs/installation_guide.md", "docs/legal_information.md", "docs/metric.md", "docs/mixed_precision.md", "docs/model.md", "docs/model_conversion.md", "docs/objective.md", "docs/orchestration.md", "docs/platform_configuration.md", "docs/pruning.md", "docs/publication_list.md", "docs/pythonic_style.md", "docs/quantization.md", "docs/quantization_mixed_precision.md", "docs/reference_examples.md", "docs/releases_info.md", "docs/sigopt_strategy.md", "docs/tensorboard.md", "docs/transform.md", "docs/tuning_strategies.md", "docs/user_yaml.md", "docs/validated_model_list.md", "docs/welcome.md", "examples/README.md", "examples/helloworld/README.md", "examples/helloworld/tf_example1/README.md", "examples/helloworld/tf_example2/README.md", "examples/helloworld/tf_example3/README.md", "examples/helloworld/tf_example4/README.md", "examples/helloworld/tf_example5/README.md", "examples/helloworld/tf_example6/README.md", "examples/helloworld/tf_example7/README.md", "examples/helloworld/tf_example8/README.md", "examples/mxnet/image_recognition/cnn_models/quantization/ptq/README.md", "examples/mxnet/language_translation/bert/quantization/ptq/README.md", "examples/mxnet/object_detection/ssd_models/quantization/ptq/README.md", "examples/notebook/perf_fp32_int8_tf/README.md", "examples/notebook/pytorch/alexnet_fashion_mnist/README.md", "examples/notebook/tensorflow/alexnet_mnist/README.md", "examples/notebook/usage_example.md", "examples/onnxrt/README.md", "examples/onnxrt/body_analysis/onnx_model_zoo/emotion_ferplus/quantization/ptq/README.md", "examples/onnxrt/body_analysis/onnx_model_zoo/ultraface/quantization/ptq/README.md", "examples/onnxrt/image_recognition/mobilenet_v2/quantization/ptq/README.md", "examples/onnxrt/image_recognition/mobilenet_v3/quantization/ptq/readme.md", "examples/onnxrt/image_recognition/onnx_model_zoo/alexnet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/arcface/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/caffenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/densenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/efficientnet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/fcn/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/googlenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/inception/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/mnist/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/mobilenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/resnet50/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/shufflenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/squeezenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/vgg16/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/zfnet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/resnet50/quantization/ptq/README.md", "examples/onnxrt/image_recognition/unet/quantization/ptq/readme.md", "examples/onnxrt/image_recognition/vgg16/quantization/ptq/README.md", "examples/onnxrt/nlp/bert/quantization/ptq/README.md", "examples/onnxrt/nlp/distilbert/quantization/ptq/readme.md", "examples/onnxrt/nlp/huggingface_model/question_answering/quantization/ptq/README.md", "examples/onnxrt/nlp/huggingface_model/text_classification/quantization/ptq/README.md", "examples/onnxrt/nlp/mobilebert/quantization/ptq/readme.md", "examples/onnxrt/nlp/onnx_model_zoo/BiDAF/quantization/ptq/README.md", "examples/onnxrt/nlp/onnx_model_zoo/bert-squad/quantization/ptq/readme.md", "examples/onnxrt/nlp/onnx_model_zoo/gpt2/quantization/ptq/readme.md", "examples/onnxrt/nlp/onnx_model_zoo/mobilebert/quantization/ptq/readme.md", "examples/onnxrt/nlp/roberta/quantization/ptq/readme.md", "examples/onnxrt/object_detection/onnx_model_zoo/DUC/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/faster_rcnn/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/mask_rcnn/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/ssd/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/ssd_mobilenet_v1/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/tiny_yolov3/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/yolov3/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/yolov4/quantization/ptq/README.md", "examples/onnxrt/object_detection/ssd_mobilenet_v1/quantization/ptq/readme.md", "examples/onnxrt/object_detection/ssd_mobilenet_v2/quantization/ptq/readme.md", "examples/pytorch/diffusion_model/diffusers/textual_inversion/README.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/3DUnet_README.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/README.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/data_format_inference.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/dataset_conversion.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/extending_nnunet.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/inference_example_Prostate.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/setting_up_paths.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/training_example_Hippocampus.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/nnunet/experiment_planning/alternative_experiment_planning/readme.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/readme.md", "examples/pytorch/image_recognition/CNN-2/distillation/eager/README.md", "examples/pytorch/image_recognition/MobileNetV2-0.35/distillation/eager/README.md", "examples/pytorch/image_recognition/VGG-8/distillation/eager/README.md", "examples/pytorch/image_recognition/efficientnet/quantization/ptq/eager/Efficientnet_README.md", "examples/pytorch/image_recognition/efficientnet/quantization/ptq/eager/README.md", "examples/pytorch/image_recognition/mnist/README.md", "examples/pytorch/image_recognition/peleenet/quantization/ptq/eager/PeleeNet_README.md", "examples/pytorch/image_recognition/peleenet/quantization/ptq/eager/README.md", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/README.md", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/ResNest_README.md", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/ablation.md", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/scripts/gluon/README.md", "examples/pytorch/image_recognition/se_resnext/quantization/ptq/eager/README.md", "examples/pytorch/image_recognition/se_resnext/quantization/ptq/eager/SE_ResNext_README.md", "examples/pytorch/image_recognition/torchvision_models/distillation/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/optimization_pipeline/prune_and_ptq/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/optimization_pipeline/qat_during_prune/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/pruning/magnitude/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/fx/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/ipex/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/eager/distributed/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/fx/README.md", "examples/pytorch/image_recognition/torchvision_models/self_distillation/eager/README.md", "examples/pytorch/nlp/blendcnn/distillation/eager/README.md", "examples/pytorch/nlp/blendcnn/quantization/ptq/eager/README.md", "examples/pytorch/nlp/huggingface_models/common/CODE_OF_CONDUCT.md", "examples/pytorch/nlp/huggingface_models/common/CONTRIBUTING.md", "examples/pytorch/nlp/huggingface_models/common/ISSUES.md", "examples/pytorch/nlp/huggingface_models/common/README.md", "examples/pytorch/nlp/huggingface_models/common/docs/README.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/add_new_model.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/benchmarks.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/bertology.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/community.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/contributing.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/converting_tensorflow_models.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/custom_datasets.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/examples.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/glossary.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/index.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/installation.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/file_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/generation_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/modeling_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/pipelines_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/tokenization_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/trainer_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/callback.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/configuration.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/feature_extractor.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/logging.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/model.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/optimizer_schedules.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/output.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/pipelines.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/processors.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/tokenizer.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/trainer.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/migration.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/albert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/auto.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bart.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/barthez.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bertgeneration.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bertweet.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/blenderbot.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/blenderbot_small.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bort.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/camembert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/convbert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/ctrl.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/deberta.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/deberta_v2.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/dialogpt.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/distilbert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/dpr.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/electra.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/encoderdecoder.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/flaubert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/fsmt.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/funnel.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/gpt.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/gpt2.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/herbert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/ibert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/layoutlm.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/led.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/longformer.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/lxmert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/marian.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mbart.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mobilebert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mpnet.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mt5.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/pegasus.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/phobert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/prophetnet.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/rag.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/reformer.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/retribert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/roberta.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/squeezebert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/t5.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/tapas.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/transformerxl.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/wav2vec2.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlm.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlmprophetnet.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlmroberta.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlnet.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_sharing.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_summary.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/multilingual.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/notebooks.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/perplexity.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/philosophy.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/preprocessing.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/pretrained_models.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/quicktour.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/serialization.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/task_summary.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/testing.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/tokenizer_summary.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/training.rst", "examples/pytorch/nlp/huggingface_models/common/examples/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/benchmarking/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/language-modeling/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/multiple-choice/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/question-answering/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/adversarial/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/bert-loses-patience/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/bertabs/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/deebert/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/distillation/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/longform-qa/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/lxmert/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/mlm_wwm/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/mm-imdb/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/movement-pruning/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/performer/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/pplm/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/rag/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/seq2seq-distillation/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/seq2seq-distillation/precomputed_pseudo_labels.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/zero-shot-distillation/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/seq2seq/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/text-classification/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/text-generation/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/token-classification/README.md", "examples/pytorch/nlp/huggingface_models/common/model_cards/README.md", "examples/pytorch/nlp/huggingface_models/common/model_cards/google/tapas-base/README.md", "examples/pytorch/nlp/huggingface_models/common/notebooks/README.md", "examples/pytorch/nlp/huggingface_models/common/scripts/tatoeba/README.md", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_example_script/README.md", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/ADD_NEW_MODEL_PROPOSAL_TEMPLATE.md", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/README.md", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/{{cookiecutter.lowercase_modelname}}.rst", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/open_model_proposals/ADD_BIG_BIRD.md", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/open_model_proposals/README.md", "examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/eager/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/distillation/eager/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/optimization_pipeline/prune_once_for_all/fx/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/group_lasso/eager/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/pattern_lock/eager/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/pytorch_pruner/eager/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/quantization/ptq_static/fx/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/quantization/ptq_static/ipex/README.md", "examples/pytorch/nlp/huggingface_models/summarization/quantization/ptq_dynamic/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/distillation/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/optimization_pipeline/distillation_for_quantization/fx/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/optimization_pipeline/prune_once_for_all/fx/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/gradient_sensitivity/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/magnitude/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/pattern_lock/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/pytorch_pruner/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning_while_distillation/group_lasso/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning_while_distillation/group_lasso/eager/bert-mini/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_dynamic/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_dynamic/fx/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/fx/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/qat/fx/README.md", "examples/pytorch/nlp/huggingface_models/translation/quantization/ptq_dynamic/eager/README.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/MASKRCNN_README.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/README.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/ABSTRACTIONS.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/INSTALL.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/MODEL_ZOO.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/README.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/TROUBLESHOOTING.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/maskrcnn_benchmark/data/README.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/maskrcnn_benchmark/utils/README.md", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/fx/README.md", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/fx/upscale_coco/README.md", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/ipex/README.md", "examples/pytorch/object_detection/ssd_resnet34/quantization/qat/fx/README.md", "examples/pytorch/object_detection/yolo_v3/quantization/ptq/eager/README.md", "examples/pytorch/object_detection/yolo_v3/quantization/ptq/eager/YOLOV3_README.md", "examples/pytorch/recommendation/dlrm/quantization/ptq/eager/README.md", "examples/pytorch/recommendation/dlrm/quantization/ptq/fx/README.md", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/CODE_OF_CONDUCT.md", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/CONTRIBUTING.md", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/README.md", "examples/pytorch/speech_recognition/rnnt/quantization/ptq_dynamic/eager/README.md", "examples/pytorch/speech_recognition/torchaudio_models/quantization/ptq_dynamic/eager/README.md", "examples/tensorflow/image_recognition/SavedModel/quantization/ptq/README.md", "examples/tensorflow/image_recognition/ViT/pruning/magnitude/README.md", "examples/tensorflow/image_recognition/inception_v3/pruning/magnitude/README.md", "examples/tensorflow/image_recognition/keras_models/inception_resnet_v2/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/inception_v3/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/mnist/quantization/qat/README.md", "examples/tensorflow/image_recognition/keras_models/mobilenet_v2/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/resnet101/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/resnet50/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/resnet50_fashion/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/resnetv2_101/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/resnetv2_50/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/vgg16/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/vgg19/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/xception/quantization/ptq/README.md", "examples/tensorflow/image_recognition/resnet_v2/pruning/magnitude/README.md", "examples/tensorflow/image_recognition/resnet_v2/quantization/qat/README.md", "examples/tensorflow/image_recognition/tensorflow_models/distillation/README.md", "examples/tensorflow/image_recognition/tensorflow_models/quantization/ptq/README.md", "examples/tensorflow/image_recognition/tensorflow_models/quantization/ptq/slim/README.md", "examples/tensorflow/nlp/bert_base_mrpc/quantization/ptq/README.md", "examples/tensorflow/nlp/bert_large_squad/quantization/ptq/README.md", "examples/tensorflow/nlp/bert_large_squad_model_zoo/quantization/ptq/README.md", "examples/tensorflow/nlp/distilbert_base/quantization/ptq/README.md", "examples/tensorflow/nlp/transformer_lt/quantization/ptq/README.md", "examples/tensorflow/nlp/transformer_lt_mlperf/quantization/ptq/README.md", "examples/tensorflow/object_detection/tensorflow_models/quantization/ptq/README.md", "examples/tensorflow/object_detection/yolo_v3/quantization/ptq/README.md", "examples/tensorflow/oob_models/quantization/ptq/README.md", "examples/tensorflow/recommendation/wide_deep_large_ds/quantization/ptq/README.md", "examples/tensorflow/semantic_image_segmentation/3dunet-mlperf/quantization/ptq/README.md", "examples/tensorflow/semantic_image_segmentation/deeplab/quantization/ptq/README.md", "examples/tensorflow/style_transfer/arbitrary_style_transfer/quantization/ptq/README.md", "index.rst", "neural_coder/README.md", "neural_coder/docs/IntelCPU_PerformanceSetting.md", "neural_coder/docs/PythonAPI.md", "neural_coder/docs/PythonLauncher.md", "neural_coder/docs/Quantization.md", "neural_coder/docs/SupportMatrix.md", "neural_coder/extensions/neural_compressor_ext_lab/CHANGELOG.md", "neural_coder/extensions/neural_compressor_ext_lab/DEVELOP.md", "neural_coder/extensions/neural_compressor_ext_lab/README.md", "neural_coder/extensions/neural_compressor_ext_lab/RELEASE.md", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/CHANGELOG.md", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/DEVELOP.md", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/RELEASE.md", "neural_compressor/conf/README.md", "neural_compressor/ux/components/benchmark/README.md", "neural_compressor/ux/components/configuration_wizard/README.md", "neural_compressor/ux/components/db_manager/README.md", "neural_compressor/ux/gui/README.md", "neural_compressor/ux/web/README.md"], "titles": ["Type of Change", "Intel\u00ae Neural Compressor", "Security Policy", "API Reference", "APIs", "Benchmark", "Objective", "Pruning", "Quantization", "build <code class=\"docutils literal notranslate\"><span class=\"pre\">Neural</span> <span class=\"pre\">Compressor(INC)</span></code> Containers:", "Contributor Covenant Code of Conduct", "FX", "Neural Architecture Search", "PTQ", "Quantization-aware Training", "Adaptor", "API Documentation", "Quantization Support Matrix", "Intel\u00ae Neural Compressor Bench", "Benchmarking", "Contribution Guidelines", "DataLoader", "Dataset", "Design", "Distillation", "Distillation for Quantization", "Distributed Training and Inference (Evaluation)", "Developer Documentation", "Dynamic Quantization", "Examples", "Frequently Asked Questions", "Framework YAML Configuration Files", "Getting Started", "Graph Optimization", "Incompatible changes between v1.2 and v1.1", "Infrastructure of Intel\u00ae Neural Compressor", "Installation", "Legal Information", "Metrics", "Mixed Precision", "Model", "Model Conversion", "Objective", "Optimization Orchestration", "SYSTEM CONFIGURATION", "Pruning", "Full Publications/Events (44)", "Pythonic Style Access for Configurations", "Quantization", "Turn ON Auto Mixed Precision during Quantization", "Reference Examples", "Release", "SigOpt Strategy", "TensorBoard", "Transform", "Tuning Strategies", "User YAML Configuration Files", "Validated Models", "Introduction to Intel\u00ae Neural Compressor", "Examples", "Hello World Examples", "tf_example1 example", "tf_example2 example", "tf_example3 example", "tf_example4 example", "tf_example5 example", "tf_example6 example", "tf_example7 example", "tf_example8 example", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Performance of FP32 Vs. INT8 ResNet50 Model", "Intel\u00ae Neural Compressor Sample for PyTorch*", "Intel\u00ae Neural Compressor Sample for TensorFlow*", "Usage Example", "ONNX model quantization", "Evaluate performance of ONNX Runtime(Emotion FERPlus)", "Evaluate performance of ONNX Runtime(Ultra-lightweight face detection)", "Evaluate performance of ONNX Runtime(Mobilenet v2)", "Evaluate performance of ONNX Runtime(Mobilenet v3)", "Evaluate performance of ONNX Runtime(Alexnet)", "Evaluate performance of ONNX Runtime(ArcFace)", "Evaluate performance of ONNX Runtime(Caffenet)", "Evaluate performance of ONNX Runtime(Densenet)", "Evaluate performance of ONNX Runtime(EfficientNet-Lite4)", "Evaluate performance of ONNX Runtime(FCN)", "Evaluate performance of ONNX Runtime(Googlenet)", "Evaluate performance of ONNX Runtime(Inception)", "Evaluate performance of ONNX Runtime(MNIST)", "Evaluate performance of ONNX Runtime(Mobilenet)", "Evaluate performance of ONNX Runtime(ResNet 50)", "Evaluate performance of ONNX Runtime(Shufflenet)", "Evaluate performance of ONNX Runtime(Squeezenet)", "Evaluate performance of ONNX Runtime(VGG16)", "Evaluate performance of ONNX Runtime(ZFNet)", "Evaluate performance of ONNX Runtime(ResNet 50)", "Evaluate performance of ONNX Runtime(unet)", "Evaluate performance of ONNX Runtime(VGG16)", "Evaluate performance of ONNX Runtime(BERT)", "Evaluate performance of ONNX Runtime(DistilBERT)", "Evaluate performance of ONNX Runtime(Huggingface Question Answering)", "Evaluate performance of ONNX Runtime(Huggingface Text Classification)", "Evaluate performance of ONNX Runtime(MobileBERT)", "Evaluate performance of ONNX Runtime(BiDAF)", "Evaluate performance of ONNX Runtime(BERT)", "Evaluate performance of ONNX Runtime(GPT2)", "Evaluate performance of ONNX Runtime(MobileBERT)", "Evaluate performance of ONNX Runtime(RoBERTa)", "Evaluate performance of ONNX Runtime(ResNet101-DUC)", "Evaluate performance of ONNX Runtime(Faster R-CNN)", "Evaluate performance of ONNX Runtime(Mask R-CNN)", "Evaluate performance of ONNX Runtime(SSD)", "Evaluate performance of ONNX Runtime(SSD Mobilenet v1)", "Evaluate performance of ONNX Runtime(Tiny-YOLOv3)", "Evaluate performance of ONNX Runtime(yolov3)", "Evaluate performance of ONNX Runtime(YOLOv4)", "Evaluate performance of ONNX Runtime(SSD Mobilenet v1)", "Evaluate performance of ONNX Runtime(SSD Mobilenet v2)", "A example using Textual Inversion method to personalize text2image", "MLPerf Inference Benchmarks for Medical Image 3D Segmentation", "Introduction", "Data format for Inference", "Dataset conversion instructions", "Extending/Changing nnU-Net", "Example: inference with pretrained nnU-Net models", "Setting up Paths", "Example: 3D U-Net training on the Hippocampus dataset", "&lt;no title&gt;", "nnU-Net", "CIFAR100 Distillation Example", "CIFAR10 Distillation Example", "CIFAR100 Distillation Example", "(Generic) EfficientNets for PyTorch", "Step-by-Step", "Distributed MNIST Example", "PeleeNet", "Step-by-Step", "Step-by-Step", "ResNeSt", "Pretrained Models", "Train ResNeSt with MXNet Gluon", "Step-by-Step", "Pretrained models for Pytorch (Work in progress)", "Prepare dataset", "Step-by-Step", "Step-by-Step", "Prepare an environment", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "distributed example on QAT", "Step-by-Step", "Prepare requirements", "Step-by-Step", "Step-by-Step", "Contributor Covenant Code of Conduct", "How to contribute to transformers?", "How To Request Support", "Online demos", "Generating the documentation", "How to add a model to \ud83e\udd17 Transformers?", "Benchmarks", "BERTology", "Community", "&lt;no title&gt;", "Converting Tensorflow Checkpoints", "Fine-tuning with custom datasets", "&lt;no title&gt;", "Glossary", "Transformers", "Installation", "General Utilities", "Utilities for Generation", "Custom Layers and Utilities", "Utilities for pipelines", "Utilities for Tokenizers", "Utilities for Trainer", "Callbacks", "Configuration", "Feature Extractor", "Logging", "Models", "Optimization", "Model outputs", "Pipelines", "Processors", "Tokenizer", "Trainer", "Migrating from previous packages", "ALBERT", "Auto Classes", "BART", "BARThez", "BERT", "BertGeneration", "Bertweet", "Blenderbot", "Blenderbot Small", "BORT", "CamemBERT", "ConvBERT", "CTRL", "DeBERTa", "DeBERTa-v2", "DialoGPT", "DistilBERT", "DPR", "ELECTRA", "Encoder Decoder Models", "FlauBERT", "FSMT", "Funnel Transformer", "OpenAI GPT", "OpenAI GPT2", "herBERT", "I-BERT", "LayoutLM", "LED", "Longformer", "LXMERT", "MarianMT", "MBart and MBart-50", "MobileBERT", "MPNet", "MT5", "Pegasus", "PhoBERT", "ProphetNet", "RAG", "Reformer", "RetriBERT", "RoBERTa", "SqueezeBERT", "T5", "TAPAS", "Transformer XL", "Wav2Vec2", "XLM", "XLM-ProphetNet", "XLM-RoBERTa", "XLNet", "Model sharing and uploading", "Summary of the models", "Multi-lingual models", "&lt;no title&gt;", "Perplexity of fixed-length models", "Philosophy", "Preprocessing data", "Pretrained models", "Quick tour", "Exporting transformers models", "Summary of the tasks", "Testing", "Summary of the tokenizers", "Training and fine-tuning", "Examples", "\ud83e\udd17 Benchmark results", "Language model training", "Multiple Choice", "SQuAD", "Research projects", "Adversarial evaluation of model performances", "Patience-based Early Exit", "Text Summarization with Pretrained Encoders", "DeeBERT: Early Exiting for *BERT", "Distil*", "Long Form Question Answering", "LXMERT DEMO", "Whole Word Mask Language Model", "MM-IMDb", "Movement Pruning: Adaptive Sparsity by Fine-Tuning", "Performer fine-tuning", "Plug and Play Language Models: a Simple Approach to Controlled Text Generation", "Intro", "Sequence to Sequence Training and Evaluation", "Saved Pseudo-Labels", "Zero-shot classifier distillation", "Sequence to Sequence Training and Evaluation", "Text classification examples", "Language generation", "Token classification", "\ud83d\udd25 Model cards now live inside each huggingface.co model repo \ud83d\udd25", "TAPAS base model", "\ud83e\udd17 Transformers Notebooks", "Upload converted models", "How to add a new example script in \ud83e\udd17 Transformers", "<strong>TEMPLATE</strong>", "Using <code class=\"docutils literal notranslate\"><span class=\"pre\">cookiecutter</span></code> to generate models", "{{cookiecutter.modelname}}", "How to add BigBird to \ud83e\udd17 Transformers?", "&lt;no title&gt;", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Pytorch Pruner", "Step-by-Step", "Step by step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Prepare dataset", "Step-by-Step", "Pytorch Pruner", "\u201cPruning while distillation\u201d step by step", "Notice", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "1. Problem", "Step-by-Step", "Abstractions", "Installation", "Model Zoo and Baselines", "Faster R-CNN and Mask R-CNN in PyTorch 1.0", "Troubleshooting", "Setting Up Datasets", "Utility functions", "Step-by-Step", "Upscaled COCO Dataset", "SSD-ResNet34 Inference", "Step-by-Step", "Step-by-Step", "PyTorch-YOLOv3", "Step-by-Step", "Step-by-Step", "Code of Conduct", "Contributing to DLRM", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Run pretraining", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Prerequisite", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Intel\u00ae Neural Compressor Documentation", "Neural Coder", "Intel CPU Platforms: Best Performance Setting", "Neural Coder as Python API", "Python Launcher", "Neural Coder for Quantization", "Supported Optimization Features", "Changelog", "neural_compressor_ext_lab", "Intel\u00ae Neural Compressor as JupyterLab Extension", "Making a new release of neural_compressor_ext_lab", "Changelog", "neural_compressor_ext_lab_alibaba", "Making a new release of neural_compressor_ext_lab_alibaba", "Introduction", "Execute benchmark endpoint", "Configuration for predefined models", "Database migration", "Gui", "Intel\u00ae Neural Compressor Bench"], "terms": {"featur": [0, 13, 19, 20, 21, 23, 24, 33, 39, 40, 46, 51, 54, 124, 159, 162, 163, 164, 168, 170, 172, 179, 186, 187, 189, 190, 193, 197, 203, 214, 215, 218, 221, 228, 244, 251, 256, 257, 261, 282, 284, 288, 291, 298, 308, 340, 341, 354, 355, 373, 375, 376, 386], "bug": [0, 20, 121, 159, 162, 168, 172, 189, 222, 236, 254, 255, 267, 276, 288, 291, 335], "fix": [0, 20, 22, 27, 55, 133, 143, 158, 159, 160, 162, 168, 171, 172, 184, 189, 236, 237, 244, 252, 254, 267, 276, 288, 289, 291, 375], "document": [0, 4, 17, 26, 28, 39, 51, 54, 69, 70, 71, 119, 129, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 155, 156, 158, 159, 160, 162, 165, 167, 168, 170, 171, 174, 182, 185, 189, 190, 200, 201, 206, 214, 218, 219, 220, 222, 227, 230, 241, 242, 243, 244, 250, 251, 252, 253, 254, 255, 257, 265, 276, 278, 287, 288, 289, 291, 293, 294, 295, 296, 297, 299, 300, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 315, 316, 318, 326, 329, 330, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 382, 385], "valid": [0, 9, 12, 15, 22, 24, 31, 35, 37, 45, 48, 51, 59, 69, 71, 73, 74, 78, 79, 80, 81, 83, 84, 85, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 123, 127, 129, 133, 134, 136, 151, 158, 168, 254, 259, 267, 270, 276, 279, 282, 317, 326, 357, 358, 362, 365, 369, 391], "other": [0, 10, 11, 16, 18, 20, 28, 31, 33, 35, 37, 40, 42, 44, 45, 48, 54, 55, 57, 69, 72, 75, 76, 101, 102, 123, 124, 125, 126, 129, 134, 136, 137, 138, 142, 143, 156, 157, 158, 159, 160, 162, 168, 170, 171, 179, 183, 186, 189, 190, 193, 198, 199, 200, 210, 211, 212, 213, 216, 220, 222, 227, 230, 231, 234, 235, 236, 238, 243, 248, 251, 252, 253, 254, 255, 256, 267, 271, 275, 276, 277, 278, 279, 280, 284, 288, 291, 311, 320, 324, 338, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 386], "api": [0, 14, 21, 33, 35, 41, 51, 52, 55, 59, 60, 66, 68, 75, 133, 148, 149, 150, 159, 160, 165, 171, 186, 189, 190, 193, 200, 236, 243, 248, 249, 251, 254, 257, 259, 270, 278, 282, 289, 291, 296, 298, 308, 311, 312, 314, 315, 317, 318, 319, 320, 335, 358, 372, 377, 378, 387, 391], "detail": [0, 1, 10, 20, 31, 34, 38, 39, 45, 51, 52, 53, 55, 57, 71, 73, 74, 79, 96, 98, 99, 100, 103, 108, 113, 117, 118, 134, 137, 138, 142, 144, 145, 146, 148, 150, 151, 154, 156, 158, 159, 160, 161, 162, 163, 170, 186, 189, 190, 205, 221, 226, 236, 241, 244, 245, 249, 250, 251, 252, 254, 256, 257, 272, 282, 284, 286, 300, 322, 330, 332, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 356, 357, 361, 366, 367, 368, 369, 370, 373], "jira": 0, "ticket": 0, "xxx": [0, 22, 24, 73, 74, 125, 127, 129, 161, 254, 326], "trigger": [0, 33, 151, 158, 273, 330], "reproduc": [0, 20, 69, 70, 71, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 155, 156, 158, 159, 160, 162, 190, 211, 214, 248, 272, 276, 288, 291, 293, 294, 295, 297, 299, 300, 301, 302, 304, 305, 307, 311, 312, 313, 314, 315, 316, 318, 326, 329, 330, 332, 333, 335, 336, 337, 338, 340, 341, 344, 348, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "includ": [0, 1, 10, 15, 18, 20, 22, 27, 32, 36, 37, 38, 45, 48, 49, 53, 55, 58, 59, 60, 73, 74, 119, 120, 123, 124, 133, 134, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 153, 157, 158, 159, 160, 161, 162, 164, 168, 172, 181, 186, 187, 189, 190, 195, 205, 213, 216, 218, 228, 241, 242, 244, 247, 252, 253, 254, 255, 256, 257, 267, 271, 278, 280, 285, 288, 289, 291, 298, 308, 319, 323, 338, 364, 373, 374, 377, 381], "hardwar": [0, 15, 24, 33, 35, 39, 44, 45, 46, 47, 72, 158, 189, 200, 252, 272, 280, 388], "inform": [0, 1, 2, 4, 10, 15, 20, 24, 28, 31, 40, 45, 49, 51, 53, 56, 57, 69, 70, 119, 124, 125, 126, 129, 134, 136, 137, 138, 142, 150, 156, 157, 158, 159, 160, 162, 163, 164, 165, 168, 170, 171, 174, 182, 185, 189, 201, 203, 205, 206, 210, 215, 218, 220, 221, 225, 231, 235, 239, 241, 244, 251, 252, 253, 254, 257, 259, 266, 267, 272, 274, 280, 284, 288, 291, 295, 300, 303, 304, 319, 322, 357, 358, 364, 365, 372, 382, 385], "ani": [0, 10, 11, 18, 20, 21, 26, 72, 73, 74, 120, 123, 124, 126, 129, 157, 158, 159, 160, 161, 162, 163, 165, 167, 168, 172, 186, 189, 190, 210, 217, 221, 236, 243, 244, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 262, 270, 272, 278, 279, 280, 283, 284, 285, 288, 291, 317, 335, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 376, 390], "librari": [0, 1, 16, 17, 27, 32, 36, 58, 119, 129, 158, 159, 160, 161, 162, 163, 165, 167, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 186, 187, 188, 189, 190, 218, 222, 231, 243, 244, 245, 248, 251, 252, 253, 254, 255, 256, 257, 259, 261, 262, 267, 268, 270, 272, 279, 280, 281, 282, 287, 288, 289, 291, 325, 381], "introduc": [0, 15, 27, 31, 45, 48, 51, 190, 194, 195, 207, 208, 211, 212, 216, 219, 220, 223, 225, 226, 229, 230, 231, 235, 236, 240, 244, 254, 255, 284, 319], "remov": [0, 10, 13, 19, 20, 33, 45, 53, 69, 70, 71, 133, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 157, 158, 159, 161, 162, 227, 233, 236, 243, 244, 249, 250, 253, 254, 255, 273, 276, 288, 291, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 322, 330, 332, 333, 336, 337, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 380, 384, 391], "an": [1, 3, 10, 12, 13, 14, 15, 16, 19, 20, 21, 23, 28, 33, 38, 39, 42, 52, 53, 54, 55, 58, 59, 61, 64, 65, 66, 68, 69, 73, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 129, 133, 136, 139, 140, 143, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 172, 174, 184, 185, 186, 187, 189, 190, 192, 193, 194, 196, 198, 199, 200, 204, 205, 209, 210, 211, 216, 217, 218, 219, 220, 221, 222, 223, 224, 227, 229, 231, 235, 236, 239, 240, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 261, 263, 265, 267, 272, 274, 275, 276, 278, 279, 280, 282, 283, 284, 287, 288, 291, 296, 298, 305, 308, 309, 311, 312, 314, 315, 319, 322, 357, 358, 360, 373, 375, 376, 386], "open": [1, 10, 16, 18, 20, 30, 58, 73, 74, 124, 126, 129, 157, 158, 159, 160, 161, 162, 165, 168, 171, 172, 198, 199, 200, 206, 208, 217, 218, 230, 232, 244, 252, 253, 258, 283, 285, 288, 291, 322, 335, 367, 382, 385], "sourc": [1, 11, 16, 37, 41, 58, 72, 73, 74, 119, 120, 121, 126, 143, 150, 158, 159, 160, 162, 165, 171, 187, 189, 200, 203, 212, 217, 222, 223, 233, 250, 251, 252, 257, 269, 276, 277, 279, 280, 288, 289, 291, 317, 318, 320, 335, 357, 362, 363, 364, 380, 382, 384, 385, 390, 391], "popular": [1, 15, 16, 22, 24, 45, 48, 55, 58, 75, 160, 162, 224, 236, 253, 255, 288, 291], "compress": [1, 24, 35, 42, 43, 45, 48, 58, 59, 160, 171, 200, 213, 224, 247, 267, 272, 327], "techniqu": [1, 13, 14, 35, 43, 45, 47, 48, 56, 59, 191, 204, 205, 218, 231, 234, 235, 244, 267, 270, 276, 373], "all": [1, 10, 11, 13, 14, 15, 16, 18, 20, 21, 22, 26, 31, 32, 33, 36, 43, 44, 45, 46, 48, 49, 54, 55, 123, 124, 125, 127, 133, 134, 137, 138, 139, 142, 143, 148, 151, 156, 157, 158, 159, 160, 161, 162, 163, 164, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 182, 183, 185, 186, 187, 188, 189, 190, 195, 201, 202, 206, 209, 212, 213, 215, 219, 220, 222, 226, 227, 229, 235, 236, 238, 240, 242, 244, 245, 248, 249, 251, 253, 255, 256, 257, 259, 265, 267, 270, 272, 275, 276, 277, 279, 284, 285, 286, 288, 289, 291, 296, 319, 321, 322, 323, 330, 331, 332, 340, 341, 354, 373, 381, 382, 385], "mainstream": 1, "deep": [1, 15, 16, 17, 21, 32, 35, 36, 39, 46, 48, 55, 58, 59, 73, 74, 124, 129, 143, 160, 162, 170, 171, 195, 213, 244, 253, 256, 288, 291, 368, 373, 376, 377, 381], "learn": [1, 15, 16, 17, 21, 22, 27, 32, 34, 35, 36, 39, 45, 46, 48, 53, 55, 58, 73, 74, 75, 124, 129, 143, 157, 159, 162, 168, 170, 171, 189, 190, 191, 194, 198, 199, 202, 203, 205, 207, 208, 209, 211, 214, 218, 221, 233, 235, 236, 237, 238, 239, 241, 242, 243, 244, 248, 251, 255, 256, 259, 264, 267, 272, 276, 284, 288, 291, 309, 322, 359, 373, 376, 377, 381, 382, 385], "framework": [1, 15, 16, 17, 18, 21, 22, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 45, 46, 48, 54, 55, 56, 57, 58, 62, 69, 70, 71, 75, 76, 120, 121, 124, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 160, 162, 163, 170, 171, 208, 217, 218, 221, 235, 238, 244, 248, 252, 253, 256, 288, 291, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 378, 387, 388], "tensorflow": [1, 13, 15, 16, 18, 24, 26, 27, 29, 31, 32, 33, 35, 36, 37, 39, 40, 41, 45, 46, 47, 48, 52, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 72, 75, 96, 117, 118, 120, 133, 134, 137, 138, 139, 142, 143, 158, 160, 161, 162, 163, 165, 170, 171, 172, 179, 181, 183, 189, 192, 197, 228, 243, 248, 249, 251, 252, 253, 254, 257, 288, 289, 290, 291, 378, 387, 388, 391], "pytorch": [1, 11, 15, 16, 24, 26, 28, 29, 31, 32, 35, 36, 39, 40, 45, 46, 47, 48, 51, 55, 56, 58, 69, 79, 80, 96, 98, 120, 121, 129, 136, 141, 142, 145, 146, 148, 154, 155, 158, 160, 161, 162, 163, 165, 167, 170, 171, 172, 179, 181, 183, 185, 189, 192, 203, 206, 212, 215, 217, 222, 236, 243, 248, 249, 251, 252, 253, 254, 257, 258, 267, 272, 275, 282, 284, 288, 289, 290, 291, 294, 297, 300, 302, 305, 306, 307, 310, 315, 319, 320, 321, 323, 326, 328, 329, 332, 333, 336, 337, 338, 357, 358, 365, 370, 373, 377, 378, 388], "mxnet": [1, 15, 16, 29, 31, 32, 35, 39, 40, 47, 55, 56, 58, 134, 137, 138, 139, 142, 143, 357, 358, 365, 370, 388, 391], "formerli": [1, 32, 58, 171, 253], "known": [1, 45, 53, 55, 58, 162, 171, 189, 224, 253, 255, 270, 275, 288, 291], "low": [1, 14, 15, 16, 19, 22, 26, 27, 39, 46, 48, 55, 58, 73, 74, 119, 124, 126, 160, 162, 171, 187, 241, 280, 288, 291], "precis": [1, 14, 15, 16, 17, 18, 19, 25, 26, 27, 31, 35, 46, 47, 48, 55, 58, 73, 74, 119, 120, 121, 129, 162, 190, 217, 230, 244, 251, 252, 254, 256, 275, 276, 284, 288, 291, 296, 330, 331, 373, 377, 378, 387], "optim": [1, 12, 13, 14, 16, 24, 26, 27, 31, 32, 35, 36, 37, 40, 44, 45, 46, 47, 48, 49, 52, 53, 55, 56, 58, 61, 65, 66, 68, 70, 72, 73, 74, 79, 96, 98, 124, 133, 151, 153, 158, 160, 165, 168, 171, 195, 200, 224, 227, 229, 231, 233, 234, 236, 240, 244, 254, 256, 272, 284, 298, 308, 315, 326, 329, 337, 355, 357, 358, 360, 361, 363, 365, 367, 368, 370, 373, 375, 376, 381, 387], "tool": [1, 11, 15, 21, 33, 37, 46, 48, 58, 64, 80, 96, 107, 129, 134, 158, 162, 163, 172, 208, 243, 244, 248, 249, 252, 253, 254, 256, 272, 288, 291, 311, 313, 318, 322, 324, 357, 358, 360, 367, 380, 384], "i": [1, 4, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 153, 156, 157, 159, 161, 162, 163, 164, 167, 168, 170, 171, 172, 174, 179, 181, 182, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 261, 262, 263, 264, 265, 266, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 315, 316, 317, 318, 319, 320, 322, 323, 324, 329, 330, 331, 332, 333, 335, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 374, 376, 377, 380, 381, 382, 384, 385, 389], "run": [1, 14, 15, 18, 20, 26, 27, 30, 31, 33, 39, 45, 46, 48, 51, 52, 53, 55, 56, 58, 79, 89, 96, 98, 99, 100, 103, 106, 108, 119, 120, 123, 124, 125, 126, 127, 130, 131, 132, 133, 158, 159, 161, 163, 167, 171, 189, 207, 217, 220, 234, 236, 243, 247, 252, 259, 261, 262, 265, 266, 267, 270, 272, 274, 275, 276, 277, 278, 284, 285, 286, 287, 289, 293, 299, 301, 306, 311, 312, 313, 314, 316, 320, 322, 324, 331, 369, 375, 376, 377, 380, 381, 382, 384, 385, 389], "which": [1, 10, 12, 14, 15, 16, 18, 19, 20, 21, 22, 24, 26, 28, 31, 32, 33, 35, 38, 39, 40, 41, 43, 45, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 69, 70, 71, 73, 74, 75, 119, 121, 123, 124, 125, 126, 129, 134, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 163, 165, 168, 170, 172, 179, 183, 186, 187, 188, 189, 190, 191, 194, 195, 200, 202, 203, 205, 207, 209, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 224, 225, 227, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 259, 261, 263, 264, 265, 266, 267, 270, 272, 275, 276, 278, 279, 280, 284, 287, 288, 289, 291, 293, 295, 298, 299, 301, 304, 308, 311, 312, 313, 314, 316, 318, 319, 320, 322, 323, 330, 332, 333, 336, 340, 344, 348, 354, 355, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 376, 381], "deliv": [1, 46, 58], "unifi": [1, 15, 16, 21, 34, 35, 40, 58, 160, 171, 211, 226, 235, 244, 248, 252], "interfac": [1, 12, 16, 27, 35, 48, 51, 58, 75, 133, 134, 137, 138, 142, 143, 145, 146, 148, 156, 167, 252, 254, 256, 332, 333, 336, 365, 390], "across": [1, 16, 23, 45, 58, 129, 163, 187, 215, 218, 230, 244, 253, 289], "network": [1, 12, 13, 18, 24, 25, 46, 48, 58, 73, 74, 104, 127, 129, 136, 139, 143, 154, 160, 162, 170, 171, 209, 213, 224, 234, 252, 255, 256, 272, 284, 288, 291, 298, 308, 319, 331], "technologi": [1, 44, 58, 73, 74, 162, 234, 253, 288, 291], "prune": [1, 3, 26, 27, 31, 35, 43, 46, 48, 56, 58, 75, 147, 164, 183, 248, 296, 298, 308], "knowledg": [1, 25, 35, 40, 56, 58, 59, 162, 165, 194, 198, 199, 207, 218, 224, 230, 244, 267, 288, 291, 298, 308], "distil": [1, 35, 43, 56, 58, 159, 160, 171, 193, 198, 207, 215, 227, 244, 250, 253, 272, 277, 295, 298, 300, 304, 308, 362], "thi": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 28, 31, 33, 35, 37, 38, 39, 40, 41, 45, 48, 49, 51, 52, 53, 54, 55, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 145, 146, 148, 149, 150, 151, 153, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 185, 187, 188, 189, 190, 192, 193, 194, 196, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 224, 225, 226, 227, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 261, 262, 263, 264, 265, 266, 267, 268, 270, 272, 274, 275, 276, 277, 278, 279, 280, 282, 284, 287, 288, 289, 291, 293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 315, 316, 318, 320, 322, 323, 324, 325, 326, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 374, 376, 377, 380, 382, 384, 385, 390], "automat": [1, 11, 16, 18, 22, 27, 35, 39, 43, 54, 55, 58, 70, 72, 124, 125, 129, 134, 137, 138, 142, 145, 146, 148, 156, 158, 161, 162, 170, 172, 192, 206, 231, 235, 236, 243, 248, 249, 251, 253, 257, 278, 280, 284, 288, 291, 298, 308, 313, 330, 332, 333, 336, 348, 373, 376, 377, 380, 381, 382, 384, 385, 389, 390], "accuraci": [1, 12, 13, 14, 16, 18, 19, 21, 25, 26, 27, 28, 32, 33, 38, 39, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 133, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 195, 208, 217, 231, 234, 236, 239, 241, 256, 272, 278, 280, 293, 299, 301, 308, 309, 313, 316, 318, 322, 328, 330, 332, 333, 336, 340, 344, 354, 357, 358, 359, 360, 362, 364, 365, 368, 370, 371, 387], "driven": [1, 16, 39, 42, 53, 58, 252], "tune": [1, 11, 14, 15, 16, 18, 21, 22, 26, 27, 28, 32, 35, 37, 39, 42, 45, 46, 49, 51, 52, 53, 56, 58, 61, 63, 65, 66, 67, 73, 74, 75, 100, 103, 108, 119, 121, 142, 143, 148, 160, 162, 165, 171, 172, 184, 193, 194, 195, 196, 200, 206, 207, 210, 211, 212, 214, 218, 219, 221, 222, 224, 225, 227, 230, 235, 238, 243, 244, 248, 249, 250, 251, 252, 253, 257, 259, 264, 266, 267, 270, 275, 276, 278, 279, 282, 284, 285, 288, 291, 295, 300, 303, 304, 328, 338, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 363, 365, 366, 368, 369, 386, 391], "strategi": [1, 15, 26, 27, 35, 46, 47, 48, 49, 51, 56, 58, 69, 70, 71, 124, 134, 137, 138, 142, 148, 149, 150, 151, 153, 162, 168, 171, 198, 199, 221, 244, 247, 249, 253, 257, 272, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 365, 370, 376, 391], "help": [1, 13, 16, 21, 32, 40, 55, 58, 63, 71, 72, 73, 74, 124, 129, 143, 158, 159, 162, 163, 164, 170, 172, 191, 208, 221, 227, 234, 251, 253, 254, 262, 264, 267, 273, 275, 276, 280, 288, 291, 311, 322, 365, 371, 373, 377, 391], "user": [1, 11, 12, 13, 15, 24, 28, 31, 33, 35, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 51, 53, 54, 55, 58, 59, 60, 61, 63, 65, 66, 72, 73, 74, 75, 76, 119, 121, 123, 126, 129, 133, 145, 146, 148, 158, 159, 160, 161, 162, 163, 168, 171, 172, 190, 197, 203, 206, 209, 220, 234, 243, 248, 253, 254, 273, 280, 287, 288, 291, 299, 312, 313, 314, 315, 326, 348, 373, 375, 376, 377, 381, 386, 388], "quickli": [1, 16, 55, 58, 158, 159, 160, 162, 172, 248, 251, 253, 254, 276, 288, 289, 291], "find": [1, 12, 15, 16, 18, 45, 52, 53, 55, 58, 123, 124, 126, 129, 136, 148, 149, 155, 156, 159, 160, 162, 170, 172, 189, 205, 230, 233, 236, 244, 251, 253, 254, 255, 258, 259, 264, 266, 267, 272, 273, 276, 279, 282, 285, 287, 288, 291, 374, 380, 384], "out": [1, 11, 16, 20, 22, 47, 48, 58, 73, 74, 126, 129, 143, 158, 159, 160, 162, 163, 168, 170, 171, 172, 190, 209, 213, 214, 216, 235, 236, 239, 244, 247, 249, 251, 254, 257, 272, 274, 278, 279, 281, 288, 291, 298, 308, 322, 373, 376, 380, 381, 382, 384, 385, 390], "best": [1, 10, 12, 14, 16, 20, 32, 36, 42, 48, 54, 55, 58, 69, 70, 71, 123, 133, 134, 137, 138, 148, 149, 151, 153, 155, 156, 157, 158, 159, 161, 162, 167, 171, 189, 191, 194, 198, 199, 216, 218, 221, 228, 233, 234, 236, 238, 239, 243, 254, 255, 264, 270, 276, 287, 288, 291, 318, 322, 330, 357, 359, 360, 362, 363, 364, 365, 371, 373, 377], "It": [1, 13, 15, 16, 18, 19, 24, 33, 45, 48, 52, 55, 56, 58, 62, 63, 72, 104, 123, 124, 126, 129, 134, 137, 138, 139, 142, 143, 145, 146, 148, 149, 156, 158, 159, 160, 161, 162, 170, 172, 179, 186, 187, 189, 191, 193, 195, 200, 201, 203, 204, 205, 206, 207, 208, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 223, 224, 230, 233, 234, 235, 236, 237, 239, 241, 243, 244, 245, 249, 251, 252, 253, 254, 255, 259, 261, 264, 265, 267, 270, 272, 276, 278, 279, 280, 282, 284, 288, 289, 291, 294, 295, 297, 302, 303, 304, 307, 311, 319, 330, 331, 332, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 377, 381], "also": [1, 12, 13, 15, 18, 19, 20, 21, 24, 32, 33, 35, 38, 42, 43, 45, 48, 49, 55, 58, 61, 63, 65, 66, 75, 119, 123, 124, 125, 126, 127, 129, 133, 134, 137, 138, 142, 145, 146, 148, 149, 151, 156, 157, 158, 159, 160, 161, 162, 168, 170, 174, 181, 182, 183, 185, 189, 190, 191, 193, 194, 196, 200, 203, 209, 212, 216, 218, 219, 220, 221, 231, 236, 237, 241, 243, 244, 247, 249, 251, 252, 253, 254, 255, 256, 259, 265, 266, 272, 275, 276, 278, 279, 280, 285, 286, 288, 291, 293, 295, 296, 298, 301, 303, 304, 308, 311, 312, 313, 314, 315, 319, 322, 326, 330, 331, 332, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 376, 380, 381, 384, 390], "implement": [1, 14, 16, 19, 21, 22, 51, 53, 55, 56, 58, 62, 75, 119, 120, 121, 124, 129, 133, 134, 136, 137, 138, 139, 142, 145, 146, 148, 151, 153, 156, 160, 162, 165, 168, 170, 171, 177, 179, 180, 183, 188, 189, 190, 200, 201, 202, 203, 205, 208, 209, 217, 231, 233, 237, 241, 244, 252, 256, 264, 267, 275, 283, 287, 288, 289, 291, 298, 299, 308, 309, 312, 313, 314, 321, 322, 330, 331, 332, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "differ": [1, 10, 11, 12, 13, 16, 18, 20, 21, 22, 24, 26, 29, 32, 33, 34, 35, 38, 40, 41, 42, 45, 48, 53, 54, 55, 58, 122, 123, 125, 129, 133, 143, 157, 159, 162, 163, 168, 170, 187, 189, 190, 193, 198, 211, 212, 215, 216, 220, 221, 223, 227, 230, 233, 234, 235, 236, 239, 241, 244, 245, 247, 251, 252, 253, 254, 255, 256, 258, 259, 261, 264, 266, 267, 273, 275, 279, 280, 281, 284, 285, 288, 289, 291, 298, 308, 311, 319, 321, 380, 384], "weight": [1, 13, 14, 15, 16, 17, 18, 25, 27, 31, 34, 38, 42, 45, 47, 48, 53, 55, 56, 57, 58, 61, 75, 79, 96, 98, 119, 125, 126, 129, 137, 148, 149, 155, 156, 158, 162, 164, 165, 167, 168, 171, 174, 184, 189, 190, 192, 193, 198, 204, 205, 231, 243, 248, 251, 253, 254, 256, 265, 267, 272, 273, 276, 288, 291, 298, 299, 308, 309, 311, 312, 314, 315, 321, 332, 333, 336, 359, 360, 362, 363, 364, 365, 386], "algorithm": [1, 12, 15, 24, 31, 35, 45, 48, 53, 55, 56, 58, 61, 124, 129, 162, 170, 200, 236, 249, 255, 288, 291, 295, 298, 303, 304, 305, 308, 322, 357, 358, 365, 377, 381], "gener": [1, 15, 18, 21, 24, 33, 38, 39, 42, 44, 45, 46, 48, 49, 53, 54, 55, 58, 60, 62, 68, 73, 74, 119, 121, 124, 129, 148, 149, 159, 160, 165, 171, 185, 187, 193, 194, 195, 196, 198, 199, 202, 203, 206, 207, 209, 210, 214, 215, 216, 219, 222, 223, 224, 227, 229, 230, 234, 235, 236, 237, 239, 240, 242, 244, 245, 251, 252, 254, 255, 257, 270, 275, 276, 278, 284, 285, 287, 306, 319, 322, 326, 328, 335, 344, 348, 357, 359, 360, 362, 363, 364, 365, 368, 371, 373, 376, 380, 382, 384, 385, 389, 390], "predefin": [1, 58, 168, 251, 391], "sparsiti": [1, 16, 22, 27, 35, 45, 57, 58, 295, 296, 297, 298, 304, 307, 308, 309], "goal": [1, 43, 48, 55, 58, 143, 162, 215, 236, 248, 249, 251, 253, 288, 291], "from": [1, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 24, 25, 26, 29, 30, 33, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 61, 62, 63, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 98, 101, 102, 104, 105, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 133, 134, 137, 138, 139, 140, 142, 147, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 174, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 261, 263, 264, 265, 266, 267, 272, 273, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 288, 289, 290, 291, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 324, 326, 328, 329, 330, 331, 332, 333, 335, 336, 337, 339, 357, 358, 359, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 375, 376, 377, 388, 389], "teacher": [1, 24, 25, 57, 58, 59, 130, 131, 132, 144, 154, 171, 224, 235, 244, 267, 272, 278, 295, 298, 303, 304, 308, 309, 356], "student": [1, 22, 24, 25, 57, 58, 59, 130, 131, 132, 244, 267, 276, 278, 288, 309], "critic": [1, 10, 20, 182], "ai": [1, 27, 46, 49, 59, 133, 160, 168, 171, 250, 252, 311, 373], "compon": [1, 12, 16, 20, 21, 26, 27, 37, 43, 44, 75, 124, 133, 162, 221, 222, 227, 254, 275, 288, 291, 373, 387, 390], "oneapi": [1, 27, 32, 36, 46], "analyt": [1, 27, 32, 36, 46], "toolkit": [1, 11, 27, 32, 36, 46, 129, 139, 141, 189, 212, 373], "visit": [1, 57, 119, 139, 141, 296], "onlin": [1, 10, 20, 52, 157, 216, 266, 331], "websit": [1, 32, 36, 73, 74, 129, 243, 250, 265, 280, 283, 365, 366], "http": [1, 9, 10, 13, 18, 22, 32, 33, 36, 37, 51, 58, 61, 63, 64, 65, 66, 68, 73, 74, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 125, 129, 133, 134, 136, 137, 138, 139, 142, 143, 145, 146, 148, 150, 151, 154, 155, 156, 157, 158, 159, 160, 162, 164, 168, 172, 187, 189, 194, 202, 204, 205, 212, 223, 243, 250, 253, 254, 257, 265, 266, 272, 274, 275, 276, 277, 279, 282, 286, 288, 289, 291, 296, 300, 301, 302, 305, 317, 320, 322, 323, 324, 326, 329, 330, 331, 332, 335, 337, 338, 357, 358, 360, 361, 363, 364, 365, 366, 367, 368, 370, 371, 377, 382, 385, 390, 391], "github": [1, 13, 18, 20, 22, 29, 32, 36, 37, 51, 58, 64, 73, 74, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 121, 124, 129, 133, 143, 150, 154, 158, 162, 168, 172, 189, 193, 198, 202, 204, 205, 212, 220, 222, 223, 227, 229, 231, 235, 236, 240, 243, 252, 253, 254, 257, 264, 265, 272, 274, 276, 283, 284, 286, 288, 289, 291, 296, 317, 320, 322, 323, 324, 329, 331, 335, 357, 360, 361, 363, 364, 365, 366, 367, 368, 370, 377, 382, 385], "io": [1, 21, 66, 129, 168, 172, 254, 296, 360, 361], "version": [1, 9, 10, 11, 15, 18, 20, 31, 32, 36, 37, 44, 46, 55, 69, 70, 71, 78, 79, 96, 98, 101, 102, 119, 121, 129, 133, 142, 143, 149, 150, 153, 157, 158, 159, 160, 162, 163, 165, 170, 171, 172, 187, 189, 190, 201, 205, 207, 211, 213, 215, 217, 224, 228, 236, 244, 247, 248, 251, 252, 253, 254, 257, 261, 262, 267, 270, 272, 276, 284, 286, 288, 291, 296, 298, 300, 308, 317, 318, 320, 321, 322, 323, 326, 328, 329, 332, 333, 336, 337, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 380, 382, 384, 385, 388, 389, 390], "3": [1, 13, 14, 22, 24, 26, 31, 32, 33, 38, 39, 42, 45, 47, 48, 50, 54, 55, 57, 58, 59, 79, 96, 98, 100, 106, 108, 119, 120, 121, 123, 125, 129, 133, 136, 139, 142, 143, 158, 160, 163, 167, 168, 171, 172, 189, 200, 204, 205, 214, 218, 222, 223, 234, 236, 237, 238, 239, 241, 244, 250, 252, 254, 256, 257, 260, 261, 264, 267, 271, 272, 274, 276, 277, 278, 279, 280, 282, 284, 286, 288, 291, 293, 294, 295, 297, 299, 300, 301, 302, 303, 304, 305, 307, 308, 311, 312, 313, 314, 316, 319, 321, 331, 373, 375, 380, 384, 386, 388, 390, 391], "7": [1, 19, 21, 30, 31, 32, 33, 36, 48, 51, 55, 58, 60, 65, 66, 99, 100, 106, 119, 129, 133, 134, 136, 137, 138, 139, 142, 143, 148, 149, 150, 162, 172, 189, 195, 200, 202, 204, 205, 224, 234, 236, 244, 252, 261, 264, 267, 272, 277, 288, 289, 291, 293, 296, 298, 303, 320, 321, 322, 331, 360, 387, 391], "8": [1, 9, 11, 13, 14, 31, 32, 36, 42, 46, 57, 58, 59, 81, 89, 100, 103, 106, 108, 129, 132, 133, 136, 139, 143, 149, 150, 151, 153, 160, 162, 163, 170, 171, 189, 204, 205, 215, 227, 237, 238, 241, 244, 250, 251, 252, 257, 261, 263, 264, 267, 272, 275, 276, 277, 288, 291, 295, 296, 298, 315, 318, 321, 322, 323, 326, 329, 331, 367, 386, 390], "9": [1, 11, 13, 14, 32, 36, 45, 47, 56, 57, 67, 73, 74, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 103, 105, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 131, 133, 136, 155, 156, 162, 189, 198, 199, 204, 205, 208, 214, 223, 231, 239, 241, 245, 250, 251, 253, 254, 264, 267, 272, 276, 280, 288, 291, 298, 303, 304, 308, 317, 320, 321, 323, 331, 390, 391], "10": [1, 13, 18, 22, 32, 36, 47, 50, 54, 59, 63, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 124, 129, 130, 133, 139, 141, 143, 151, 154, 162, 163, 168, 182, 187, 189, 206, 231, 245, 250, 251, 252, 253, 255, 261, 265, 272, 274, 276, 277, 278, 280, 284, 288, 291, 296, 298, 299, 300, 301, 302, 308, 316, 319, 320, 321, 322, 326, 328, 333, 362, 364, 391], "releas": [1, 16, 32, 36, 59, 72, 73, 74, 123, 125, 139, 159, 160, 167, 171, 172, 187, 194, 196, 201, 202, 203, 204, 205, 206, 216, 233, 234, 235, 241, 245, 252, 267, 270, 272, 284, 320, 322, 372, 377, 380, 384], "binari": [1, 30, 38, 58, 170, 236, 256, 317, 382, 385], "stabl": [1, 18, 36, 46, 97, 119, 134, 137, 138, 142, 145, 146, 148, 150, 151, 156, 300, 330, 332], "basic": [1, 35, 36, 47, 52, 69, 70, 71, 75, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 158, 162, 182, 189, 224, 236, 244, 254, 264, 288, 291, 293, 299, 301, 306, 311, 312, 313, 314, 316, 318, 323, 330, 332, 333, 336, 357, 358, 365, 370, 391], "pip": [1, 18, 26, 30, 32, 36, 51, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 119, 121, 124, 129, 130, 131, 132, 134, 135, 137, 138, 139, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 161, 162, 167, 171, 189, 190, 214, 250, 254, 257, 262, 265, 267, 269, 272, 274, 276, 286, 287, 288, 289, 291, 293, 294, 295, 296, 297, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 311, 312, 313, 314, 315, 316, 318, 320, 326, 328, 329, 330, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 380, 382, 384, 385], "Or": [1, 71, 73, 74, 162, 243, 257, 288, 291, 318], "full": [1, 16, 18, 22, 30, 32, 36, 37, 124, 125, 126, 127, 158, 159, 160, 168, 188, 189, 190, 213, 217, 223, 225, 227, 231, 236, 243, 248, 250, 253, 254, 267, 278, 296, 322, 334], "nightli": [1, 18, 36, 276, 320], "git": [1, 18, 32, 36, 64, 97, 121, 124, 129, 139, 143, 150, 158, 159, 162, 172, 189, 243, 254, 257, 265, 274, 283, 286, 288, 289, 291, 296, 317, 320, 324, 329, 331, 357, 365, 366, 367, 370], "clone": [1, 18, 32, 36, 64, 97, 119, 121, 124, 129, 143, 150, 158, 159, 162, 172, 189, 243, 247, 252, 257, 265, 274, 276, 286, 288, 289, 291, 296, 317, 320, 324, 328, 357, 366, 367, 370, 380, 384], "com": [1, 9, 10, 13, 18, 20, 22, 32, 33, 36, 37, 51, 52, 57, 58, 61, 64, 65, 66, 68, 73, 74, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 121, 125, 129, 133, 139, 143, 150, 154, 158, 159, 162, 172, 189, 202, 204, 205, 212, 243, 253, 254, 257, 265, 272, 274, 275, 276, 282, 286, 288, 289, 291, 296, 300, 317, 320, 322, 323, 324, 329, 331, 335, 357, 360, 361, 363, 364, 365, 366, 367, 368, 370, 371, 373, 377], "cd": [1, 18, 26, 32, 36, 62, 97, 100, 103, 108, 121, 129, 134, 137, 138, 139, 141, 142, 143, 145, 146, 148, 149, 150, 151, 153, 155, 156, 158, 159, 162, 172, 189, 243, 257, 265, 274, 276, 286, 288, 289, 291, 293, 296, 299, 301, 306, 311, 312, 313, 314, 315, 316, 317, 318, 320, 322, 324, 326, 328, 329, 330, 331, 332, 333, 336, 337, 338, 357, 358, 359, 360, 361, 363, 365, 366, 367, 368, 370, 371], "r": [1, 18, 32, 36, 44, 48, 57, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 119, 130, 131, 132, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 159, 160, 168, 170, 171, 197, 203, 228, 231, 241, 253, 254, 257, 262, 267, 269, 272, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 306, 307, 309, 311, 312, 313, 314, 315, 316, 317, 318, 326, 328, 329, 330, 331, 332, 333, 336, 337, 338, 340, 341, 357, 358, 362, 365, 366, 368, 370, 371], "txt": [1, 18, 22, 32, 36, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 105, 107, 119, 120, 121, 130, 131, 132, 134, 135, 137, 138, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 159, 161, 167, 243, 257, 262, 263, 265, 267, 269, 270, 272, 275, 276, 278, 282, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 306, 307, 309, 310, 311, 312, 313, 314, 315, 316, 318, 326, 328, 329, 330, 331, 332, 333, 336, 337, 338, 340, 341, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 391], "test": [1, 11, 18, 20, 36, 57, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 123, 125, 129, 133, 136, 139, 143, 155, 156, 160, 161, 162, 163, 168, 171, 172, 187, 189, 195, 218, 222, 234, 236, 238, 242, 247, 259, 263, 267, 270, 275, 276, 278, 280, 282, 288, 289, 291, 318, 322, 330, 335, 338, 340, 354, 365, 366, 371, 391], "pypi": [1, 9, 18, 36, 189, 382, 385], "org": [1, 9, 10, 18, 36, 63, 96, 117, 118, 121, 133, 134, 137, 138, 142, 145, 146, 148, 151, 155, 156, 157, 160, 162, 164, 194, 222, 223, 243, 250, 253, 266, 274, 275, 296, 305, 320, 323, 324, 326, 330, 332, 337, 338, 357, 358, 365, 367, 370, 371, 382, 385], "simpl": [1, 13, 18, 36, 52, 55, 79, 96, 98, 100, 103, 108, 113, 117, 118, 125, 129, 159, 161, 162, 168, 186, 189, 195, 208, 215, 218, 224, 248, 252, 253, 254, 255, 256, 257, 267, 272, 273, 276, 285, 288, 291, 322], "more": [1, 2, 12, 13, 14, 18, 22, 24, 26, 32, 33, 35, 36, 38, 39, 42, 43, 45, 49, 55, 57, 58, 70, 71, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 123, 125, 126, 129, 133, 136, 150, 158, 159, 161, 162, 163, 168, 170, 171, 172, 185, 189, 190, 202, 203, 205, 206, 207, 209, 210, 213, 215, 218, 220, 222, 227, 230, 231, 235, 236, 239, 241, 247, 249, 251, 252, 253, 254, 255, 257, 259, 261, 264, 267, 272, 274, 275, 276, 278, 280, 282, 283, 284, 285, 286, 295, 298, 300, 303, 304, 308, 322, 331, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 382, 385, 390], "method": [1, 11, 12, 13, 14, 19, 21, 24, 25, 27, 28, 38, 43, 45, 48, 49, 54, 55, 73, 74, 76, 124, 126, 129, 133, 139, 143, 158, 160, 162, 167, 168, 170, 171, 172, 174, 177, 179, 180, 182, 183, 187, 188, 189, 190, 191, 192, 203, 207, 208, 209, 216, 217, 218, 220, 223, 225, 234, 235, 236, 237, 238, 239, 242, 243, 244, 248, 249, 251, 252, 253, 254, 255, 259, 261, 264, 267, 268, 276, 278, 285, 288, 291, 293, 298, 301, 308, 311, 312, 313, 314, 316, 319, 358, 391], "can": [1, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 24, 26, 27, 28, 31, 32, 33, 35, 36, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 52, 53, 54, 55, 56, 59, 62, 68, 69, 70, 71, 73, 74, 75, 76, 79, 96, 98, 119, 123, 124, 125, 126, 127, 128, 133, 143, 148, 149, 150, 151, 155, 156, 159, 160, 161, 162, 163, 165, 167, 168, 170, 171, 172, 174, 179, 182, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 263, 264, 265, 266, 267, 268, 270, 272, 273, 275, 276, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 293, 298, 300, 301, 308, 309, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 324, 326, 334, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 375, 376, 377, 380, 381, 382, 384, 385, 386, 390], "found": [1, 16, 39, 55, 59, 71, 124, 125, 127, 128, 129, 133, 158, 159, 162, 163, 168, 173, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 235, 236, 237, 239, 240, 241, 242, 243, 251, 253, 254, 261, 265, 276, 278, 284, 288, 291, 309, 320, 322, 324, 357, 358, 362, 364, 376, 391], "guid": [1, 22, 24, 27, 32, 36, 73, 74, 79, 96, 98, 99, 100, 103, 108, 126, 129, 160, 168, 172, 189, 256, 373], "pleas": [1, 2, 9, 12, 14, 15, 18, 22, 25, 26, 36, 38, 39, 42, 45, 49, 51, 52, 65, 66, 70, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 129, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 156, 158, 159, 160, 162, 170, 172, 187, 189, 206, 220, 243, 252, 253, 254, 258, 264, 266, 267, 272, 274, 276, 279, 280, 283, 285, 288, 291, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 316, 318, 322, 323, 326, 330, 332, 333, 334, 335, 336, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 356, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 376], "check": [1, 13, 14, 18, 20, 26, 33, 36, 129, 136, 150, 158, 160, 161, 162, 165, 168, 170, 172, 189, 190, 194, 239, 244, 247, 249, 253, 254, 261, 272, 274, 275, 282, 288, 291, 300, 320, 322, 323, 326, 337, 357, 374, 376, 382, 385, 389, 390], "our": [1, 12, 13, 119, 123, 124, 129, 136, 139, 143, 158, 159, 160, 162, 168, 170, 171, 172, 174, 185, 190, 191, 194, 196, 197, 198, 199, 207, 208, 209, 211, 212, 214, 217, 218, 219, 220, 221, 230, 233, 235, 236, 237, 239, 241, 245, 247, 249, 251, 252, 253, 255, 256, 257, 259, 266, 267, 270, 272, 273, 275, 276, 278, 279, 281, 282, 288, 289, 291, 298, 308, 311, 312, 313, 314, 315, 321, 322, 326, 329, 337, 359, 360, 362, 363, 364, 365], "faq": [1, 10, 20, 157, 280], "A": [1, 12, 13, 21, 29, 31, 32, 38, 40, 45, 46, 54, 55, 56, 129, 133, 136, 139, 143, 148, 149, 157, 158, 160, 161, 162, 163, 165, 167, 168, 170, 171, 174, 181, 187, 188, 189, 190, 191, 193, 197, 203, 208, 219, 220, 223, 226, 232, 233, 236, 238, 243, 244, 245, 247, 248, 249, 253, 254, 255, 256, 270, 275, 276, 278, 281, 288, 291, 322, 331, 360, 361, 380, 381, 384], "exampl": [1, 9, 10, 11, 16, 18, 20, 22, 27, 28, 34, 35, 41, 49, 51, 54, 55, 58, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 126, 133, 139, 140, 145, 146, 147, 148, 155, 157, 158, 159, 160, 161, 162, 163, 164, 167, 168, 169, 170, 171, 172, 174, 179, 182, 185, 186, 189, 190, 197, 198, 200, 201, 203, 209, 210, 212, 214, 215, 216, 218, 223, 228, 231, 233, 236, 241, 242, 243, 244, 245, 248, 249, 250, 251, 252, 253, 254, 255, 256, 259, 260, 261, 263, 265, 267, 270, 272, 275, 276, 277, 279, 281, 282, 284, 288, 289, 291, 294, 295, 296, 297, 299, 302, 303, 304, 305, 306, 307, 310, 312, 313, 314, 319, 322, 323, 324, 328, 338, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 371, 372, 373, 374, 375, 376, 386, 388], "prepar": [1, 13, 14, 22, 26, 48, 60, 70, 72, 75, 160, 168, 171, 181, 188, 236, 256, 362], "fp32": [1, 15, 27, 31, 32, 38, 39, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 59, 69, 70, 71, 73, 74, 119, 120, 121, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 217, 227, 280, 293, 299, 301, 303, 311, 312, 313, 314, 316, 318, 326, 330, 332, 333, 336, 337, 344, 357, 358, 359, 360, 362, 363, 364, 365, 367, 370, 371, 378, 386, 387, 391], "wget": [1, 33, 61, 63, 65, 66, 68, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 168, 275, 276, 286, 296, 300, 301, 302, 326, 337, 338, 357, 358, 360, 361, 363, 365, 366, 368, 370, 371], "storag": [1, 33, 38, 61, 65, 66, 68, 105, 107, 357, 360, 361, 363, 365, 367, 368, 371], "googleapi": [1, 33, 61, 65, 66, 68, 105, 107, 357, 360, 361, 363, 365, 367, 368, 371], "v1_6": [1, 33, 61, 65, 66, 68, 357, 368], "mobilenet_v1_1": [1, 61, 65, 66, 68, 75, 357], "0_224_frozen": [1, 61, 65, 66, 68, 75, 357], "pb": [1, 16, 26, 33, 40, 53, 57, 59, 60, 61, 65, 66, 67, 68, 73, 74, 75, 96, 117, 118, 133, 357, 358, 361, 362, 363, 364, 367, 370, 371, 387, 388, 391], "import": [1, 11, 12, 13, 14, 16, 19, 21, 22, 24, 26, 33, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 53, 54, 61, 62, 63, 65, 66, 67, 69, 70, 71, 75, 76, 79, 96, 98, 119, 126, 129, 133, 134, 137, 138, 139, 140, 142, 143, 148, 149, 150, 151, 153, 156, 159, 160, 162, 163, 164, 167, 168, 170, 171, 172, 174, 182, 185, 189, 190, 193, 197, 198, 199, 216, 218, 222, 223, 227, 228, 233, 236, 243, 244, 245, 247, 249, 251, 252, 253, 254, 255, 256, 265, 267, 276, 278, 284, 286, 288, 293, 298, 299, 301, 308, 311, 312, 313, 314, 315, 316, 318, 319, 322, 326, 329, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 373, 375, 377], "tf": [1, 13, 18, 26, 40, 49, 54, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 120, 129, 133, 158, 160, 162, 168, 172, 189, 208, 243, 248, 249, 251, 252, 253, 254, 256, 257, 280, 288, 291, 357, 358, 360, 361, 365, 366, 367, 370], "neural_compressor": [1, 11, 12, 14, 16, 19, 21, 22, 24, 26, 33, 34, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 51, 54, 55, 56, 61, 63, 65, 66, 67, 69, 70, 71, 75, 76, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 298, 308, 315, 318, 326, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 387], "experiment": [1, 11, 12, 14, 19, 22, 24, 26, 33, 39, 40, 41, 42, 43, 45, 47, 49, 51, 54, 61, 63, 65, 67, 69, 70, 71, 75, 76, 97, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 171, 189, 225, 228, 229, 240, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 321, 330, 332, 333, 336, 358], "common": [1, 10, 14, 16, 19, 20, 21, 22, 24, 26, 27, 32, 33, 34, 36, 40, 41, 45, 48, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 75, 124, 126, 134, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 153, 157, 158, 162, 168, 170, 177, 180, 183, 188, 189, 213, 216, 226, 231, 247, 248, 254, 255, 256, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 317, 318, 322, 323, 330, 332, 333, 336, 357, 359, 362, 363, 364, 365, 370], "dataset": [1, 12, 14, 15, 16, 19, 21, 26, 27, 28, 32, 33, 38, 48, 55, 56, 57, 59, 60, 62, 64, 67, 68, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 130, 131, 132, 135, 143, 154, 158, 159, 160, 162, 165, 171, 187, 189, 193, 194, 208, 215, 216, 218, 219, 221, 225, 226, 227, 229, 233, 234, 235, 236, 240, 244, 247, 250, 251, 253, 254, 256, 257, 259, 261, 263, 265, 266, 267, 268, 270, 271, 273, 275, 277, 278, 279, 280, 284, 286, 288, 291, 293, 298, 299, 300, 308, 311, 312, 313, 314, 316, 342, 343, 345, 346, 349, 350, 353, 354, 386, 388], "dummi": [1, 18, 22, 33, 38, 59, 60, 64, 68, 72, 97, 162, 256, 288, 291, 367, 391], "shape": [1, 18, 22, 31, 33, 54, 68, 124, 129, 161, 162, 168, 245, 251, 288, 291, 299, 312, 314, 391], "1": [1, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 28, 31, 32, 33, 38, 39, 42, 43, 44, 45, 47, 48, 50, 51, 53, 54, 55, 56, 58, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 125, 129, 130, 131, 133, 136, 139, 143, 147, 154, 158, 159, 160, 161, 163, 168, 170, 172, 179, 185, 187, 189, 195, 200, 202, 203, 204, 205, 209, 215, 218, 220, 222, 223, 224, 229, 231, 234, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 261, 264, 267, 272, 274, 275, 276, 277, 278, 280, 282, 284, 289, 294, 295, 298, 300, 302, 304, 307, 308, 319, 321, 323, 324, 328, 331, 374, 386, 387, 388, 391], "224": [1, 19, 21, 22, 26, 33, 54, 55, 56, 61, 63, 65, 66, 68, 75, 79, 96, 98, 120, 133, 134, 137, 138, 139, 141, 142, 143, 148, 149, 150, 357, 358, 373, 386, 391], "calib_dataload": [1, 16, 21, 22, 34, 38, 48, 62, 64, 68, 69, 70, 71, 75, 151, 156, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 359, 362, 363, 364, 365], "dataload": [1, 15, 16, 18, 22, 26, 33, 34, 38, 39, 41, 48, 53, 54, 55, 56, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 75, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 168, 189, 236, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 331, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 386, 388], "fit": [1, 11, 14, 16, 21, 22, 24, 26, 34, 38, 40, 42, 43, 45, 48, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 75, 124, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 158, 162, 168, 189, 253, 256, 259, 288, 289, 291, 293, 299, 301, 312, 314, 316, 318, 330, 332, 333, 336, 357, 359, 360, 362, 363, 364, 365, 370, 371], "search": [1, 35, 38, 46, 53, 55, 133, 158, 159, 172, 189, 200, 251, 254, 255, 288, 373, 381], "jupyt": [1, 162, 257, 288, 291, 320, 380, 381, 384], "lab": [1, 143, 251, 380, 381, 382, 384, 385], "manag": [1, 133, 162, 188, 189, 223, 237, 254, 288, 291, 373, 381], "one": [1, 12, 15, 16, 18, 21, 24, 25, 26, 31, 32, 33, 35, 36, 38, 39, 42, 43, 45, 47, 48, 51, 54, 55, 72, 75, 119, 122, 123, 125, 126, 127, 129, 133, 139, 143, 145, 146, 158, 159, 160, 162, 163, 168, 170, 172, 179, 182, 185, 192, 195, 200, 206, 209, 212, 213, 214, 215, 218, 221, 222, 223, 225, 227, 229, 230, 231, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 257, 259, 261, 265, 267, 272, 275, 276, 277, 278, 279, 280, 284, 287, 288, 291, 293, 296, 298, 308, 311, 313, 331, 357, 359, 360, 362, 363, 364, 365, 371, 373, 376, 377, 380, 381, 384], "click": [1, 18, 35, 46, 53, 158, 159, 161, 162, 288, 291, 373, 381], "12": [1, 9, 18, 32, 50, 70, 77, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 105, 107, 109, 110, 111, 112, 114, 115, 139, 143, 150, 155, 156, 159, 162, 167, 214, 227, 241, 250, 252, 255, 261, 267, 272, 276, 280, 288, 291, 295, 297, 300, 308, 338, 370, 391], "0": [1, 11, 13, 14, 16, 18, 19, 21, 22, 24, 26, 28, 31, 32, 37, 38, 39, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 58, 59, 60, 62, 67, 70, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 125, 127, 129, 130, 131, 132, 133, 134, 136, 137, 138, 141, 142, 143, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 167, 170, 171, 172, 185, 187, 189, 190, 195, 196, 197, 200, 202, 204, 205, 218, 220, 221, 222, 223, 224, 227, 228, 231, 236, 237, 238, 243, 244, 245, 247, 248, 249, 251, 252, 253, 254, 256, 257, 260, 263, 264, 265, 267, 272, 274, 275, 276, 277, 278, 279, 284, 286, 288, 291, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 307, 308, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 323, 327, 328, 330, 331, 332, 333, 336, 339, 344, 358, 359, 360, 362, 363, 364, 365, 369, 370, 371, 374, 380, 384, 386, 391], "onnxruntim": [1, 15, 28, 35, 47, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 171], "raw": [1, 38, 55, 71, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 122, 123, 125, 126, 127, 129, 134, 137, 138, 139, 142, 145, 146, 148, 149, 150, 151, 153, 168, 203, 238, 247, 255, 257, 259, 270, 284, 293, 324, 332, 333, 336, 338, 357, 358, 360, 366], "main": [1, 13, 26, 48, 70, 71, 75, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 130, 131, 132, 134, 137, 138, 145, 146, 147, 148, 149, 150, 151, 153, 159, 162, 172, 179, 182, 188, 190, 212, 244, 249, 254, 255, 266, 282, 288, 291, 318, 319, 322, 326, 329, 340, 341, 354, 358, 363, 375, 377], "vision": [1, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 109, 110, 111, 112, 113, 114, 115, 116, 136, 143, 160, 171, 213, 221, 234, 253, 317, 320, 340, 375], "classif": [1, 24, 38, 46, 59, 69, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 134, 136, 137, 138, 142, 148, 149, 150, 151, 153, 156, 160, 161, 162, 165, 170, 171, 190, 193, 197, 209, 211, 213, 214, 218, 221, 234, 235, 236, 238, 239, 244, 245, 250, 251, 256, 257, 284, 285, 288, 291, 299, 311, 312, 313, 314, 315, 317, 318, 340, 377], "resnet": [1, 26, 33, 57, 59, 69, 138, 139, 142, 148, 244, 331, 342, 355, 358, 365, 367], "resnet50": [1, 13, 26, 32, 33, 48, 52, 57, 59, 71, 86, 91, 96, 143, 144, 145, 146, 147, 152, 154, 317, 347, 348, 365, 367, 373, 375], "v1": [1, 9, 16, 26, 38, 40, 51, 52, 57, 59, 62, 69, 71, 75, 88, 91, 97, 104, 119, 133, 187, 195, 216, 224, 247, 250, 259, 267, 270, 272, 291, 293, 294, 295, 296, 300, 302, 304, 339, 360, 361, 365, 367], "inc_bench": [1, 18], "xeon": [1, 32, 33, 37, 39, 44, 46, 48, 49, 50, 57, 72, 73, 74], "scalabl": [1, 32, 33, 39, 44, 46, 48, 49, 50, 57, 73, 74, 213, 243, 283], "skylak": [1, 32], "cascad": [1, 32, 33, 124, 139], "lake": [1, 32, 33, 39, 46], "cooper": [1, 32, 39, 165, 311], "icelak": [1, 32], "futur": [1, 32, 35, 39, 41, 125, 129, 158, 159, 160, 162, 170, 171, 172, 229, 235, 236, 240, 243, 244, 267, 276, 278, 280, 284, 288, 291], "code": [1, 11, 15, 16, 21, 22, 24, 26, 27, 32, 34, 35, 37, 38, 42, 43, 45, 46, 47, 48, 52, 53, 54, 55, 61, 67, 72, 75, 76, 119, 120, 121, 124, 129, 133, 139, 145, 146, 158, 159, 160, 162, 163, 168, 171, 172, 173, 174, 175, 176, 177, 178, 179, 186, 189, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 239, 240, 241, 242, 243, 244, 248, 249, 252, 253, 254, 256, 257, 261, 265, 266, 267, 268, 270, 272, 274, 276, 280, 286, 288, 289, 291, 317, 322, 323, 325, 331, 340, 341, 354, 373, 375, 376, 377, 381, 389], "name": [1, 9, 11, 13, 18, 19, 22, 26, 28, 31, 32, 33, 37, 38, 40, 44, 51, 52, 53, 55, 56, 57, 64, 66, 69, 70, 71, 75, 76, 79, 96, 98, 122, 123, 124, 125, 129, 130, 131, 132, 133, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 158, 159, 160, 161, 162, 163, 168, 171, 186, 189, 190, 192, 197, 201, 209, 216, 225, 228, 229, 236, 240, 243, 244, 249, 251, 252, 256, 257, 267, 273, 275, 278, 279, 280, 282, 286, 289, 290, 291, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 320, 324, 330, 331, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 367, 368, 370, 371, 374, 380, 384, 390, 391], "sapphir": [1, 32], "rapid": [1, 32], "data": [1, 13, 15, 18, 21, 22, 26, 27, 28, 31, 32, 33, 36, 38, 39, 48, 49, 52, 53, 54, 55, 59, 69, 70, 72, 76, 77, 78, 82, 97, 99, 100, 102, 103, 108, 121, 123, 124, 125, 126, 127, 139, 142, 143, 147, 159, 160, 162, 163, 168, 170, 171, 174, 185, 187, 189, 198, 199, 201, 203, 204, 205, 206, 209, 212, 213, 214, 215, 217, 220, 227, 231, 233, 235, 236, 238, 239, 241, 243, 245, 247, 248, 250, 251, 252, 253, 254, 255, 256, 261, 270, 272, 275, 278, 279, 280, 285, 287, 288, 291, 293, 295, 296, 301, 302, 303, 304, 306, 311, 313, 322, 324, 327, 328, 330, 331, 332, 333, 336, 357, 358, 359, 360, 361, 363, 364, 367, 368, 369, 387, 391], "center": [1, 2, 54, 55, 143, 217], "flex": 1, "seri": [1, 54, 69, 134, 138, 142, 148, 149, 150, 151, 153, 156, 157, 216, 221, 357], "amd": [1, 35, 57], "arm": [1, 35, 57, 217], "nvidia": [1, 35, 45, 48, 57, 120, 129, 136, 189, 276, 280, 296, 317, 320, 321], "refer": [1, 4, 9, 14, 15, 16, 19, 22, 25, 26, 32, 34, 37, 38, 39, 42, 45, 47, 48, 51, 54, 55, 72, 73, 74, 75, 79, 96, 98, 99, 100, 103, 105, 107, 108, 113, 117, 118, 119, 120, 123, 124, 127, 129, 134, 135, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 156, 158, 159, 160, 172, 189, 200, 201, 203, 206, 220, 233, 241, 244, 250, 253, 255, 257, 261, 265, 267, 270, 276, 280, 286, 287, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 316, 318, 322, 323, 329, 330, 332, 333, 336, 362, 366, 368, 370, 373, 376], "list": [1, 13, 15, 17, 31, 32, 42, 47, 49, 53, 55, 69, 70, 120, 123, 129, 133, 139, 140, 142, 143, 155, 156, 159, 160, 161, 162, 163, 168, 170, 173, 174, 175, 176, 177, 178, 179, 187, 189, 190, 220, 222, 231, 236, 248, 249, 250, 251, 253, 257, 258, 264, 267, 272, 275, 278, 285, 286, 288, 291, 293, 294, 295, 297, 298, 299, 301, 302, 303, 304, 305, 307, 308, 311, 312, 313, 314, 315, 316, 319, 322, 323, 326, 329, 332, 333, 336, 337, 340, 341, 344, 348, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 373, 376, 380, 381, 384], "o": [1, 13, 20, 32, 44, 73, 74, 125, 129, 141, 148, 149, 158, 168, 189, 220, 222, 223, 224, 231, 253, 254, 279, 286, 300, 318, 319, 337, 357], "cento": [1, 32], "4": [1, 10, 13, 15, 19, 20, 21, 30, 31, 32, 35, 36, 38, 44, 45, 50, 54, 55, 57, 58, 70, 97, 119, 120, 121, 122, 123, 127, 129, 132, 133, 134, 136, 137, 138, 140, 142, 143, 150, 158, 159, 163, 179, 189, 195, 202, 204, 205, 209, 212, 214, 217, 224, 234, 236, 238, 239, 244, 250, 251, 252, 253, 255, 261, 264, 265, 267, 272, 275, 276, 278, 279, 280, 288, 291, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 308, 316, 320, 321, 323, 331, 335, 386, 387, 391], "ubuntu": [1, 44, 72, 126, 129, 141, 189], "20": [1, 14, 32, 44, 50, 54, 56, 57, 61, 63, 68, 75, 127, 133, 143, 182, 208, 242, 250, 255, 259, 267, 271, 277, 280, 296, 302, 303, 319, 321, 322, 359, 391], "04": [1, 32, 44, 57, 119, 123, 133, 139, 143, 251, 274, 280, 367, 391], "2": [1, 9, 13, 14, 15, 17, 22, 24, 26, 31, 32, 33, 35, 37, 38, 39, 42, 43, 44, 45, 48, 50, 51, 54, 55, 58, 59, 60, 73, 74, 102, 106, 120, 121, 122, 123, 129, 130, 131, 132, 133, 136, 143, 147, 159, 160, 163, 164, 165, 170, 171, 172, 174, 185, 189, 195, 196, 197, 198, 199, 200, 204, 205, 206, 214, 215, 217, 218, 220, 221, 222, 224, 227, 228, 231, 233, 236, 238, 241, 242, 245, 248, 250, 251, 252, 253, 254, 255, 260, 261, 264, 266, 267, 270, 272, 274, 276, 277, 278, 281, 282, 284, 289, 294, 295, 297, 298, 300, 306, 319, 321, 322, 323, 331, 373, 387, 391], "11": [1, 18, 33, 38, 39, 50, 77, 78, 79, 80, 82, 85, 96, 98, 104, 107, 114, 117, 118, 129, 133, 139, 143, 162, 163, 189, 241, 276, 280, 288, 291, 296, 300, 318, 321, 336], "6": [1, 13, 18, 31, 32, 48, 57, 58, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 129, 133, 136, 142, 143, 155, 156, 160, 162, 163, 172, 193, 195, 204, 205, 222, 224, 249, 250, 253, 254, 257, 261, 264, 267, 272, 275, 276, 277, 280, 284, 288, 291, 293, 294, 295, 296, 297, 299, 301, 302, 304, 305, 307, 308, 311, 312, 313, 314, 316, 321, 323, 332, 337, 367, 370, 386], "note": [1, 9, 12, 13, 16, 18, 19, 26, 27, 28, 31, 32, 33, 45, 48, 50, 53, 55, 56, 57, 58, 61, 63, 65, 66, 69, 70, 71, 73, 74, 75, 106, 119, 120, 121, 123, 125, 127, 129, 133, 134, 137, 138, 139, 142, 143, 145, 146, 148, 150, 151, 156, 158, 161, 162, 168, 170, 171, 187, 199, 214, 218, 220, 231, 236, 244, 247, 249, 251, 252, 253, 254, 255, 256, 259, 261, 267, 272, 276, 277, 278, 279, 282, 288, 291, 293, 295, 299, 300, 301, 304, 311, 312, 313, 314, 316, 320, 323, 326, 328, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 363, 364, 365, 366, 367, 368, 369, 370, 371, 376, 380, 384, 386], "set": [1, 9, 10, 12, 13, 14, 16, 18, 19, 20, 21, 22, 26, 31, 33, 34, 35, 38, 39, 47, 48, 52, 55, 56, 58, 61, 63, 67, 68, 69, 70, 71, 73, 74, 75, 125, 127, 129, 133, 134, 136, 137, 138, 140, 142, 148, 149, 150, 151, 153, 157, 158, 159, 162, 163, 165, 168, 170, 172, 182, 187, 189, 190, 194, 206, 208, 216, 219, 220, 222, 223, 225, 230, 231, 234, 236, 237, 238, 242, 244, 247, 249, 251, 252, 253, 254, 255, 256, 257, 264, 265, 267, 272, 275, 276, 277, 278, 280, 282, 284, 288, 291, 293, 295, 298, 299, 300, 301, 304, 308, 309, 311, 312, 313, 314, 316, 317, 318, 319, 322, 327, 328, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 371, 373, 375], "variabl": [1, 18, 58, 79, 96, 98, 124, 129, 143, 158, 163, 172, 182, 189, 252, 257, 276, 280, 282, 330], "tf_enable_onednn_opt": [1, 18], "enabl": [1, 13, 18, 26, 27, 33, 39, 44, 45, 46, 49, 58, 59, 60, 61, 63, 67, 75, 129, 133, 148, 152, 160, 189, 190, 194, 206, 219, 237, 242, 252, 254, 255, 257, 272, 275, 298, 306, 308, 339, 342, 343, 345, 346, 347, 349, 350, 351, 352, 353, 373, 376, 377], "onednn": [1, 17, 58], "you": [1, 11, 14, 16, 18, 19, 20, 21, 22, 26, 27, 32, 36, 37, 38, 51, 52, 53, 55, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 101, 105, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 136, 139, 141, 143, 148, 149, 155, 156, 159, 160, 161, 162, 164, 167, 168, 171, 173, 174, 175, 176, 177, 178, 179, 182, 185, 187, 189, 190, 192, 193, 198, 205, 207, 212, 214, 218, 220, 222, 223, 225, 227, 229, 231, 233, 235, 236, 240, 243, 244, 245, 248, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 264, 265, 266, 267, 268, 270, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 289, 293, 296, 298, 300, 301, 306, 308, 309, 311, 312, 313, 314, 318, 320, 322, 323, 326, 328, 334, 335, 340, 341, 354, 357, 358, 359, 360, 361, 365, 370, 371, 373, 374, 376, 380, 384, 386, 390], "ar": [1, 3, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 31, 32, 34, 35, 37, 38, 39, 42, 43, 44, 45, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 65, 66, 69, 73, 74, 75, 76, 120, 121, 123, 124, 125, 126, 127, 128, 129, 133, 134, 137, 138, 139, 142, 143, 145, 146, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 173, 174, 175, 176, 177, 178, 179, 182, 183, 185, 186, 187, 188, 189, 192, 193, 194, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 227, 228, 230, 231, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 253, 255, 256, 257, 259, 262, 266, 267, 272, 273, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 288, 289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 331, 337, 339, 357, 358, 362, 364, 365, 368, 369, 370, 371, 373, 374, 376, 381], "us": [1, 10, 11, 12, 13, 14, 15, 16, 18, 20, 22, 24, 25, 26, 27, 28, 31, 32, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 145, 146, 148, 149, 150, 151, 152, 153, 156, 157, 158, 159, 161, 163, 164, 165, 167, 170, 172, 173, 174, 175, 176, 177, 178, 179, 182, 184, 185, 186, 187, 188, 189, 191, 192, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 248, 250, 253, 254, 255, 256, 257, 259, 261, 262, 263, 264, 265, 266, 268, 270, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 285, 287, 293, 294, 295, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 309, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 325, 326, 327, 328, 330, 331, 332, 333, 335, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 373, 375, 376, 380, 382, 384, 385, 386, 389, 390, 391], "v2": [1, 13, 26, 57, 59, 92, 102, 133, 136, 148, 149, 160, 168, 171, 187, 195, 204, 224, 243, 250, 252, 264, 277, 296, 339, 342, 345, 355, 358, 365, 367, 377], "default": [1, 15, 18, 19, 21, 22, 28, 31, 35, 38, 41, 42, 47, 49, 52, 54, 55, 56, 59, 60, 61, 63, 66, 69, 70, 71, 75, 82, 119, 124, 126, 127, 129, 133, 134, 137, 138, 142, 143, 148, 149, 150, 151, 153, 156, 158, 161, 162, 163, 172, 179, 182, 189, 198, 214, 227, 235, 236, 237, 249, 251, 252, 253, 254, 256, 257, 261, 266, 267, 275, 276, 278, 279, 288, 291, 293, 296, 299, 301, 311, 312, 313, 314, 316, 318, 320, 322, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 376, 380, 384], "420": [1, 35, 133], "perform": [1, 12, 14, 15, 16, 18, 19, 21, 23, 25, 27, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 55, 56, 57, 59, 60, 65, 66, 67, 73, 74, 120, 121, 129, 134, 137, 138, 139, 142, 148, 149, 150, 151, 153, 154, 160, 170, 171, 172, 187, 189, 191, 193, 197, 198, 199, 200, 201, 202, 204, 205, 206, 207, 209, 213, 214, 216, 217, 222, 223, 226, 227, 230, 231, 233, 236, 237, 241, 242, 244, 248, 252, 253, 254, 255, 261, 264, 267, 272, 275, 276, 278, 295, 304, 319, 324, 327, 328, 330, 331, 339, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 360, 362, 364, 370, 373, 377, 381, 387, 389], "speedup": [1, 35, 48, 217, 234, 257, 272, 275, 276, 278, 280, 295, 304], "geomean": [1, 35], "2x": [1, 35, 44, 136, 168, 257, 280, 322], "up": [1, 13, 16, 18, 26, 31, 32, 33, 35, 46, 47, 48, 52, 54, 56, 59, 73, 74, 124, 158, 159, 162, 165, 168, 170, 188, 189, 193, 215, 217, 219, 235, 236, 237, 244, 247, 252, 253, 254, 255, 256, 264, 267, 280, 284, 288, 291, 311, 312, 314, 315, 322, 327, 382, 385], "vnni": [1, 35, 47, 48, 72, 73, 74], "while": [1, 14, 15, 18, 21, 33, 35, 39, 47, 48, 59, 124, 129, 159, 160, 162, 164, 168, 170, 172, 189, 190, 191, 194, 196, 198, 199, 202, 203, 207, 209, 214, 217, 218, 221, 223, 224, 231, 234, 236, 238, 244, 247, 252, 254, 255, 259, 261, 267, 272, 275, 276, 277, 278, 288, 291, 322, 323, 358, 373, 376, 389], "minim": [1, 24, 38, 45, 48, 55, 124, 133, 159, 189, 214, 254, 272, 276, 277, 331, 365, 380, 384], "loss": [1, 13, 14, 24, 25, 26, 28, 32, 38, 39, 45, 48, 55, 56, 69, 70, 71, 73, 74, 124, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 161, 168, 170, 171, 174, 185, 189, 190, 191, 196, 207, 220, 223, 231, 235, 236, 244, 247, 251, 255, 256, 257, 259, 267, 272, 274, 293, 298, 299, 301, 308, 309, 311, 312, 313, 314, 316, 318, 330, 331, 332, 333, 336, 354, 357, 358, 359, 365, 366, 370], "over": [1, 13, 14, 35, 38, 47, 55, 73, 74, 129, 133, 143, 160, 162, 170, 171, 189, 194, 203, 206, 207, 209, 223, 225, 231, 236, 238, 241, 242, 244, 245, 247, 250, 253, 254, 255, 259, 267, 276, 278, 288, 291, 317, 319, 322, 391], "30": [1, 14, 19, 21, 32, 35, 50, 54, 57, 134, 138, 139, 140, 143, 147, 148, 149, 150, 153, 158, 171, 182, 198, 199, 218, 248, 250, 253, 265, 274, 276, 284, 309, 322, 367, 391], "sampl": [1, 12, 16, 21, 22, 27, 35, 48, 54, 55, 56, 57, 59, 61, 62, 63, 75, 119, 124, 129, 134, 137, 138, 142, 148, 149, 150, 156, 159, 162, 174, 209, 212, 227, 244, 253, 255, 259, 266, 274, 275, 284, 288, 291, 299, 312, 314, 318, 326, 331, 357, 358, 365, 368, 370, 391], "avail": [1, 3, 4, 10, 18, 32, 35, 44, 52, 55, 59, 60, 127, 129, 139, 157, 158, 161, 162, 163, 167, 168, 170, 171, 186, 187, 188, 189, 190, 194, 196, 198, 199, 201, 204, 205, 209, 211, 213, 215, 216, 218, 222, 234, 235, 236, 239, 241, 244, 245, 247, 250, 253, 254, 256, 257, 259, 261, 265, 267, 275, 276, 278, 281, 284, 285, 288, 291, 292, 321, 322, 380, 384], "here": [1, 9, 11, 13, 14, 16, 18, 22, 26, 31, 32, 38, 42, 45, 48, 51, 52, 55, 59, 69, 70, 71, 119, 122, 123, 124, 125, 126, 127, 129, 133, 134, 137, 138, 139, 142, 143, 148, 149, 150, 151, 153, 156, 158, 159, 160, 161, 162, 163, 167, 168, 170, 172, 174, 179, 182, 185, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 235, 236, 237, 239, 240, 241, 242, 243, 244, 245, 248, 249, 250, 251, 252, 253, 254, 255, 257, 258, 259, 261, 263, 267, 273, 275, 276, 277, 278, 279, 280, 282, 284, 285, 288, 289, 290, 291, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 319, 321, 322, 323, 324, 330, 332, 333, 335, 336, 357, 358, 359, 360, 363, 364, 365, 369, 370, 371, 376, 382, 385], "overview": [1, 161, 168, 171], "transform": [1, 11, 16, 19, 21, 22, 24, 25, 26, 27, 45, 46, 49, 53, 55, 56, 59, 61, 63, 65, 66, 75, 100, 103, 106, 108, 134, 137, 138, 142, 143, 148, 149, 150, 159, 161, 164, 165, 168, 170, 173, 174, 182, 185, 189, 193, 195, 196, 197, 198, 201, 203, 205, 206, 207, 209, 211, 212, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 226, 227, 228, 231, 234, 235, 236, 239, 241, 242, 243, 245, 248, 249, 250, 251, 253, 255, 256, 257, 261, 262, 265, 267, 268, 272, 274, 276, 278, 279, 281, 284, 286, 289, 299, 300, 303, 312, 313, 314, 315, 319, 322, 340, 357, 358, 360, 364, 370, 371, 373, 376, 377, 386], "metric": [1, 12, 15, 16, 18, 19, 21, 26, 27, 33, 39, 52, 53, 55, 56, 57, 59, 60, 61, 63, 65, 66, 69, 70, 71, 75, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 189, 247, 256, 257, 267, 275, 276, 280, 293, 299, 301, 303, 311, 312, 313, 314, 316, 318, 330, 331, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 391], "object": [1, 3, 11, 12, 13, 16, 18, 19, 21, 22, 27, 30, 38, 39, 40, 43, 47, 48, 54, 55, 59, 62, 75, 79, 86, 96, 98, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 136, 159, 161, 162, 163, 168, 170, 174, 179, 184, 185, 186, 189, 190, 193, 195, 203, 206, 211, 213, 214, 215, 216, 221, 223, 224, 229, 233, 234, 235, 236, 239, 240, 244, 249, 251, 253, 254, 256, 259, 284, 288, 291, 298, 308, 317, 318, 319, 322, 330, 332, 333, 336, 359, 360, 362, 363, 364, 365, 367, 391], "dive": [1, 31, 32, 160, 162, 247, 288, 291], "mix": [1, 15, 27, 35, 129, 202, 244, 251, 253, 256, 276, 373, 377, 378], "orchestr": [1, 35], "benchmark": [1, 3, 21, 27, 33, 40, 41, 55, 56, 57, 59, 60, 65, 66, 67, 72, 124, 129, 134, 137, 138, 142, 150, 155, 156, 171, 187, 191, 194, 196, 200, 205, 207, 208, 209, 214, 216, 224, 226, 229, 235, 240, 241, 244, 252, 267, 272, 280, 285, 300, 306, 320, 323, 324, 328, 338, 344, 354, 357, 368, 369, 373, 375, 381], "distribut": [1, 13, 24, 32, 36, 48, 51, 55, 129, 139, 159, 171, 189, 251, 253, 267, 275, 276, 277, 278, 295, 304, 318, 322, 340, 341, 354, 382, 385], "train": [1, 12, 13, 15, 16, 17, 22, 24, 25, 27, 33, 35, 39, 41, 43, 45, 46, 55, 56, 57, 59, 60, 67, 73, 74, 79, 96, 98, 119, 120, 121, 123, 124, 125, 126, 130, 131, 132, 133, 134, 135, 137, 138, 142, 143, 145, 146, 147, 148, 149, 150, 153, 155, 156, 158, 159, 160, 162, 163, 164, 165, 167, 168, 170, 171, 172, 179, 189, 190, 191, 193, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 214, 215, 216, 218, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 248, 250, 251, 252, 253, 255, 260, 263, 265, 266, 268, 270, 272, 275, 277, 278, 282, 285, 287, 288, 291, 294, 295, 296, 297, 298, 302, 303, 304, 307, 308, 324, 325, 327, 341, 344, 359, 364, 365, 366, 368, 373, 377, 391], "convers": [1, 15, 27, 39, 48, 49, 106, 125, 160, 161, 162, 165, 167, 171, 181, 187, 190, 198, 199, 206, 209, 236, 250, 252, 286, 288, 291, 344], "tensorboard": [1, 15, 27, 55, 130, 131, 132, 148, 149, 179, 189, 256, 257], "coder": [1, 35, 46, 376, 381], "advanc": [1, 10, 20, 21, 32, 48, 55, 56, 61, 63, 134, 136, 137, 138, 142, 157, 161, 188, 255, 257, 266, 348, 357, 358, 365, 370], "topic": [1, 274], "adaptor": [1, 27, 35, 49, 51, 53, 55, 358, 363], "fast": [1, 46, 129, 133, 140, 168, 171, 188, 189, 207, 216, 222, 244, 248, 254, 261, 264, 267, 282, 321, 322, 331], "approach": [1, 11, 12, 24, 28, 35, 46, 47, 55, 56, 59, 76, 151, 153, 159, 160, 163, 171, 172, 189, 198, 199, 209, 211, 214, 217, 223, 224, 233, 235, 236, 239, 242, 244, 247, 253, 254, 267, 272, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318], "achiev": [1, 16, 27, 38, 43, 45, 46, 48, 53, 55, 129, 162, 189, 193, 202, 204, 205, 211, 214, 217, 218, 219, 220, 221, 224, 225, 227, 229, 230, 231, 233, 234, 235, 236, 237, 238, 240, 241, 242, 244, 254, 272, 276, 288, 291, 331], "signific": [1, 13, 46, 48, 188, 194, 196, 233, 234, 241, 254, 272, 278], "speed": [1, 13, 32, 33, 46, 48, 59, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 136, 139, 159, 163, 165, 188, 189, 191, 219, 244, 252, 254, 264, 278], "sota": [1, 46, 227, 236], "nov": [1, 46], "2022": [1, 57, 73, 74, 391], "person": [1, 10, 20, 46, 157, 159, 162, 198, 199, 236, 251, 253, 280, 288, 291, 321], "diffus": [1, 46, 97, 119], "few": [1, 18, 46, 55, 129, 158, 159, 160, 162, 164, 171, 172, 183, 189, 190, 220, 222, 237, 242, 244, 245, 247, 248, 253, 254, 256, 267, 272, 273, 280, 286, 288, 291, 319, 323], "shot": [1, 12, 35, 45, 46, 59, 267, 298, 308, 322], "fine": [1, 14, 22, 45, 46, 48, 100, 103, 108, 119, 129, 143, 159, 160, 162, 165, 171, 172, 184, 190, 193, 194, 195, 196, 200, 206, 207, 210, 211, 212, 214, 218, 219, 221, 222, 224, 225, 227, 230, 235, 238, 243, 244, 248, 249, 250, 251, 252, 253, 254, 257, 259, 264, 266, 267, 270, 275, 276, 278, 279, 282, 284, 285, 288, 291, 293, 294, 295, 297, 300, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 323, 374], "meet": [1, 9, 11, 33, 42, 46, 47, 48, 53, 55, 69, 70, 71, 134, 137, 138, 142, 148, 149, 150, 266, 289, 293, 299, 301, 311, 312, 313, 314, 316, 318, 332, 333, 336, 357, 358, 365, 370], "innov": [1, 46], "oct": [1, 46, 160, 193, 194], "infer": [1, 13, 14, 15, 16, 17, 21, 24, 27, 33, 39, 42, 45, 46, 48, 53, 55, 59, 62, 69, 71, 72, 73, 74, 96, 121, 139, 160, 162, 163, 171, 186, 189, 195, 201, 207, 211, 217, 218, 224, 228, 231, 242, 244, 245, 248, 251, 253, 256, 258, 263, 265, 266, 275, 278, 285, 287, 288, 291, 318, 321, 326, 327, 329, 336, 337, 357, 362, 363, 364, 365, 370], "acceler": [1, 24, 45, 46, 49, 55, 59, 72, 73, 74, 129, 224, 252, 266, 340, 341, 354, 373], "new": [1, 16, 19, 20, 26, 27, 39, 46, 48, 51, 52, 54, 56, 61, 63, 65, 66, 69, 73, 74, 119, 124, 126, 134, 137, 138, 139, 142, 143, 159, 160, 162, 163, 164, 165, 168, 170, 172, 183, 188, 189, 190, 191, 193, 194, 195, 196, 202, 204, 205, 208, 209, 211, 212, 216, 218, 219, 220, 222, 226, 229, 235, 236, 239, 240, 243, 244, 248, 250, 251, 253, 254, 255, 257, 270, 276, 278, 288, 289, 291, 322, 331, 357, 358, 365, 370, 381, 390, 391], "plug": [1, 46, 129, 264], "wa": [1, 15, 18, 46, 55, 124, 126, 129, 143, 157, 159, 160, 162, 168, 187, 189, 190, 191, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 248, 249, 251, 252, 253, 254, 255, 259, 261, 263, 276, 280, 284, 288, 290, 291, 362, 368, 390], "cover": [1, 12, 16, 20, 34, 46, 75, 124, 129, 133, 226, 235, 250, 251, 254, 282], "twitter": [1, 46, 158, 165, 168], "linkedin": [1, 46], "develop": [1, 11, 16, 20, 36, 39, 46, 48, 49, 52, 58, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 124, 126, 129, 133, 137, 138, 142, 156, 159, 160, 162, 164, 165, 171, 189, 196, 206, 213, 217, 231, 252, 254, 280, 285, 288, 291, 298, 308, 320, 332, 372, 373, 377], "zone": [1, 46, 123, 125], "hug": [1, 46, 119, 159, 160, 162, 165, 168, 172, 193, 206, 214, 215, 248, 252, 253, 255, 283, 284, 288, 291, 362], "face": [1, 10, 20, 46, 51, 59, 60, 66, 82, 119, 159, 160, 162, 165, 168, 172, 193, 206, 214, 215, 248, 252, 253, 283, 284, 288, 291, 323, 362, 373, 375], "successfulli": [1, 11, 26, 46, 73, 74, 162, 218, 254, 257, 288, 291, 309, 359], "land": [1, 46], "gcp": [1, 46], "aw": [1, 46, 57, 180, 183, 188], "azur": [1, 46], "marketplac": [1, 46], "One": [1, 16, 18, 21, 26, 35, 45, 46, 59, 158, 163, 164, 168, 189, 237, 244, 251, 254, 255, 272, 282], "No": [1, 30, 44, 46, 72, 125, 137, 138, 142, 151, 156, 157, 158, 159, 161, 162, 193, 223, 257, 288, 291, 332], "solut": [1, 15, 16, 30, 46, 55, 189, 217, 223, 255, 322, 323, 377, 381], "pat": [1, 46, 391], "keynot": [1, 46], "intelon": [1, 46], "sep": [1, 46, 168, 170, 196, 207, 225, 236, 249, 252, 253, 278, 284], "alibaba": [1, 46, 378, 384, 385], "cloud": [1, 46, 72, 73, 74, 190, 279, 284, 357], "better": [1, 14, 16, 25, 38, 39, 45, 46, 48, 52, 55, 72, 75, 128, 129, 133, 159, 162, 164, 191, 197, 200, 204, 205, 224, 225, 231, 234, 236, 237, 242, 244, 247, 251, 255, 261, 267, 276, 288, 291, 313, 321, 328, 331], "product": [1, 16, 27, 35, 39, 44, 46, 48, 52, 55, 160, 162, 171, 172, 231, 244, 248, 267, 276, 288, 291, 373, 390], "effici": [1, 12, 21, 24, 43, 46, 133, 136, 154, 160, 162, 170, 171, 195, 202, 204, 205, 208, 209, 211, 213, 217, 224, 231, 234, 236, 239, 244, 249, 252, 278, 285, 288, 291, 303, 322, 373], "text": [1, 37, 46, 54, 57, 59, 104, 105, 126, 148, 149, 159, 160, 161, 162, 165, 168, 170, 171, 183, 187, 193, 195, 196, 197, 201, 203, 206, 209, 210, 211, 213, 214, 215, 218, 221, 223, 224, 225, 226, 228, 231, 232, 234, 235, 236, 237, 242, 244, 245, 247, 249, 250, 251, 252, 255, 257, 259, 267, 270, 275, 278, 279, 281, 282, 284, 285, 288, 289, 291, 299, 311, 312, 313, 314, 315, 332, 333, 334, 336, 377], "view": [1, 13, 16, 18, 20, 29, 32, 51, 58, 245, 256, 329], "contribut": [1, 10, 129, 157, 160, 162, 166, 172, 221, 244, 288, 289, 291, 372], "guidelin": [1, 2, 158, 159, 160, 372], "legal": [1, 372], "secur": [1, 44, 46, 157, 253, 335], "polici": [1, 10, 20, 33, 44, 56], "we": [1, 10, 11, 13, 14, 15, 16, 20, 21, 26, 31, 32, 33, 38, 41, 42, 43, 45, 47, 48, 52, 53, 55, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 97, 105, 107, 119, 123, 124, 125, 126, 129, 134, 137, 138, 139, 142, 148, 149, 150, 151, 153, 156, 157, 158, 159, 160, 161, 162, 164, 168, 170, 171, 172, 174, 185, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 259, 261, 264, 265, 266, 267, 270, 272, 275, 276, 278, 280, 282, 283, 285, 287, 288, 291, 293, 295, 296, 298, 299, 300, 301, 303, 304, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 326, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 375, 382, 385], "activ": [1, 13, 14, 15, 17, 18, 25, 27, 28, 31, 32, 44, 47, 48, 53, 55, 56, 61, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 129, 133, 160, 162, 172, 189, 190, 231, 244, 251, 254, 257, 269, 272, 288, 291, 299, 320, 335, 357, 358, 359, 360, 365], "send": [1, 20, 129, 158, 159, 249, 251, 275, 279], "your": [1, 18, 19, 20, 22, 26, 37, 52, 53, 55, 60, 119, 123, 124, 125, 126, 127, 129, 136, 141, 143, 154, 158, 159, 160, 161, 165, 167, 168, 171, 172, 182, 189, 207, 220, 225, 233, 236, 239, 245, 248, 249, 251, 252, 253, 254, 256, 257, 258, 259, 261, 262, 264, 265, 268, 270, 273, 277, 279, 280, 282, 283, 285, 286, 287, 289, 296, 298, 308, 317, 318, 320, 323, 324, 326, 328, 331, 332, 333, 335, 336, 337, 357, 358, 359, 360, 361, 370, 371, 373, 374, 375, 376, 380, 381, 382, 384, 385], "resum": [1, 141, 295, 304], "inc": [1, 14, 46, 47, 51, 59, 73, 74, 119, 136, 253, 298, 308, 309, 313, 373, 378, 389], "maintain": [1, 10, 20, 40, 45, 51, 59, 158, 159, 160, 162, 198, 199, 213, 257, 262, 288, 291, 335, 373, 382, 385], "interest": [1, 10, 20, 53, 162, 209, 236, 252, 253, 256, 267, 278, 284, 285], "issu": [2, 10, 18, 20, 36, 48, 53, 124, 129, 133, 143, 157, 160, 162, 172, 189, 190, 193, 198, 201, 212, 216, 220, 222, 223, 227, 229, 230, 231, 235, 236, 240, 252, 254, 279, 283, 288, 291, 322, 323], "intel": [2, 3, 10, 12, 15, 16, 20, 23, 24, 25, 27, 29, 31, 32, 33, 36, 37, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 55, 56, 59, 60, 61, 62, 65, 66, 68, 102, 145, 146, 148, 149, 151, 153, 155, 295, 296, 297, 300, 304, 307, 315, 318, 326, 329, 330, 337, 338, 340, 354, 373, 376, 378], "For": [2, 9, 10, 11, 13, 14, 15, 18, 20, 25, 26, 31, 33, 35, 45, 49, 53, 55, 56, 57, 70, 71, 72, 119, 123, 124, 126, 129, 134, 135, 136, 137, 138, 139, 141, 142, 143, 145, 146, 147, 148, 149, 151, 153, 156, 157, 158, 159, 160, 161, 162, 163, 168, 170, 171, 179, 182, 189, 192, 196, 197, 206, 213, 218, 219, 220, 223, 230, 231, 234, 235, 236, 243, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 261, 267, 270, 272, 274, 275, 276, 277, 278, 279, 280, 283, 284, 288, 291, 293, 296, 298, 300, 301, 303, 308, 313, 315, 316, 321, 322, 323, 330, 332, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 366, 367, 368, 369, 370, 371, 373, 374, 376], "how": [2, 13, 15, 16, 18, 19, 20, 22, 24, 26, 27, 34, 45, 48, 54, 55, 56, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 119, 124, 125, 127, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 160, 161, 165, 168, 170, 171, 172, 182, 189, 193, 218, 219, 223, 234, 236, 243, 247, 249, 251, 252, 253, 255, 256, 257, 259, 261, 275, 279, 280, 284, 285, 293, 296, 301, 303, 309, 311, 316, 318, 319, 322, 323, 324, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 381, 382, 385], "work": [2, 16, 21, 24, 45, 49, 51, 53, 72, 73, 74, 119, 124, 126, 129, 133, 136, 158, 159, 160, 164, 168, 170, 189, 190, 193, 194, 198, 199, 200, 207, 208, 209, 217, 219, 220, 221, 227, 231, 234, 235, 239, 244, 247, 248, 249, 251, 252, 253, 254, 255, 257, 261, 262, 264, 270, 276, 277, 282, 289, 298, 308, 322, 335, 365, 366, 382, 385], "resolv": [2, 159, 162, 237, 254, 286, 288, 291], "see": [2, 10, 11, 13, 18, 20, 33, 37, 41, 45, 53, 57, 70, 71, 72, 73, 74, 123, 124, 125, 126, 127, 129, 133, 143, 157, 158, 159, 160, 161, 162, 165, 167, 168, 170, 172, 174, 179, 185, 186, 188, 189, 190, 193, 198, 203, 210, 212, 215, 218, 219, 220, 222, 223, 225, 226, 227, 229, 231, 235, 236, 240, 242, 243, 244, 247, 249, 250, 251, 252, 253, 254, 255, 256, 272, 276, 278, 279, 284, 288, 291, 322, 323, 380, 381, 384, 386], "handl": [2, 11, 16, 21, 75, 124, 129, 133, 158, 162, 168, 170, 171, 179, 187, 189, 190, 245, 249, 256, 288, 291], "read": [3, 22, 27, 49, 52, 119, 123, 126, 129, 159, 161, 162, 168, 170, 179, 181, 189, 213, 234, 244, 254, 275, 276, 288, 291, 298, 308, 309, 327, 334], "introduct": [3, 168, 171, 244, 251], "neural": [3, 11, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 46, 48, 51, 53, 54, 55, 56, 59, 61, 62, 63, 67, 72, 75, 76, 104, 121, 133, 136, 145, 146, 148, 154, 155, 160, 170, 171, 196, 198, 199, 200, 204, 205, 206, 213, 223, 230, 234, 237, 244, 248, 252, 255, 256, 284, 294, 295, 296, 297, 300, 302, 303, 304, 305, 307, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 361, 367, 368, 369, 376, 378, 380, 382, 384, 385], "compressor": [3, 11, 12, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 45, 46, 48, 51, 53, 54, 55, 56, 59, 61, 62, 63, 67, 72, 75, 76, 121, 145, 146, 148, 155, 294, 295, 296, 297, 300, 302, 303, 304, 305, 307, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 361, 367, 368, 369, 373, 376, 378, 380, 382, 384, 385], "The": [3, 4, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 45, 47, 48, 49, 51, 53, 54, 55, 56, 57, 60, 61, 62, 63, 65, 66, 69, 70, 71, 72, 73, 74, 75, 79, 96, 98, 100, 103, 108, 113, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 133, 134, 136, 137, 138, 139, 142, 143, 145, 146, 148, 149, 150, 151, 153, 156, 157, 158, 160, 161, 162, 163, 167, 168, 170, 171, 172, 174, 179, 180, 183, 184, 185, 187, 188, 189, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 259, 261, 263, 264, 265, 266, 267, 270, 272, 274, 275, 276, 278, 279, 280, 282, 284, 286, 288, 289, 290, 291, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 306, 307, 311, 312, 313, 314, 315, 316, 317, 318, 319, 321, 322, 327, 328, 329, 330, 331, 332, 333, 336, 338, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 369, 370, 371, 374, 376, 380, 381, 382, 384, 385, 390, 391], "follow": [3, 4, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 27, 28, 31, 32, 33, 36, 37, 38, 40, 41, 43, 45, 47, 48, 53, 55, 60, 61, 64, 65, 66, 72, 73, 74, 75, 79, 96, 98, 100, 103, 108, 113, 117, 118, 119, 120, 122, 123, 125, 126, 127, 129, 130, 131, 132, 135, 139, 141, 143, 145, 146, 152, 155, 156, 157, 158, 159, 160, 161, 162, 163, 170, 171, 172, 174, 179, 182, 187, 189, 191, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 247, 249, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 263, 264, 265, 267, 268, 270, 272, 275, 276, 278, 279, 280, 282, 284, 286, 287, 288, 289, 290, 291, 292, 295, 296, 298, 300, 304, 315, 319, 320, 321, 322, 323, 324, 327, 329, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 380, 384], "quantiz": [3, 13, 15, 18, 19, 21, 22, 26, 27, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 51, 53, 54, 55, 56, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 103, 106, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 156, 217, 238, 272, 295, 304, 317, 318, 328, 329, 330, 332, 333, 336, 338, 355, 358, 373, 376, 378, 381, 386, 391], "inc_ver": 9, "must": [9, 11, 16, 32, 33, 36, 54, 55, 75, 106, 122, 123, 124, 125, 126, 127, 129, 143, 158, 160, 162, 163, 168, 172, 189, 228, 231, 236, 244, 252, 253, 254, 256, 276, 278, 280, 282, 284, 286, 288, 291, 317, 357, 358], "publish": [9, 10, 20, 37, 39, 136, 157, 160, 233, 266, 267, 275], "project": [9, 10, 20, 46, 52, 55, 158, 159, 187, 189, 205, 209, 220, 231, 232, 252, 254, 257, 331, 334, 335, 372, 390], "histori": [9, 55, 340, 370, 391], "python": [9, 11, 16, 18, 20, 22, 26, 32, 36, 49, 54, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 76, 80, 96, 97, 100, 101, 102, 103, 106, 107, 108, 117, 118, 119, 121, 123, 124, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 162, 163, 171, 172, 188, 189, 190, 214, 218, 248, 254, 257, 259, 260, 261, 263, 264, 265, 267, 270, 271, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 286, 288, 289, 291, 298, 300, 308, 315, 320, 322, 323, 324, 326, 327, 328, 330, 332, 337, 340, 341, 342, 343, 344, 345, 346, 349, 350, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 369, 370, 371, 381, 387, 391], "python3": [9, 70, 120, 129, 143, 172, 254, 267, 282, 298, 308, 331], "image_nam": [9, 22], "image_tag": 9, "docker": [9, 120, 317], "arg": [9, 11, 12, 13, 16, 21, 22, 24, 26, 40, 45, 48, 53, 54, 62, 71, 75, 133, 142, 151, 156, 161, 163, 168, 187, 189, 190, 222, 254, 256, 275, 276, 298, 299, 308, 311, 312, 314, 318, 320, 336, 357, 358, 362, 363, 364, 365, 370, 371, 377], "f": [9, 13, 24, 26, 48, 121, 125, 129, 150, 155, 156, 162, 168, 222, 251, 253, 254, 256, 267, 276, 282, 288, 291, 296, 300, 340], "dockerfil": 9, "t": [9, 11, 13, 15, 18, 19, 21, 24, 26, 39, 45, 55, 56, 57, 59, 61, 63, 65, 66, 69, 72, 119, 123, 124, 125, 127, 129, 134, 137, 138, 141, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 158, 159, 161, 162, 168, 170, 172, 174, 185, 187, 189, 190, 193, 207, 209, 212, 214, 220, 222, 225, 233, 236, 243, 244, 245, 247, 248, 249, 251, 253, 254, 255, 256, 261, 270, 275, 276, 282, 283, 287, 288, 289, 291, 293, 295, 304, 313, 317, 320, 330, 331, 332, 333, 335, 336, 357, 358, 363, 364, 370, 371, 391], "inc_branch": 9, "branch": [9, 158, 162, 243, 254, 272, 276, 288, 291, 335, 362], "otherwis": [9, 10, 20, 22, 47, 54, 129, 157, 159, 162, 179, 244, 254, 256, 259, 276, 288, 289, 291, 298, 308, 348, 382, 385, 391], "fail": [9, 11, 73, 74, 129, 159, 162, 189, 276, 288, 291, 323], "If": [9, 11, 16, 18, 20, 22, 26, 33, 36, 37, 38, 39, 42, 43, 48, 52, 53, 54, 55, 71, 72, 73, 74, 75, 119, 120, 123, 124, 125, 126, 129, 136, 158, 159, 160, 161, 162, 168, 170, 172, 189, 190, 193, 198, 212, 214, 222, 223, 227, 229, 240, 243, 244, 247, 248, 249, 251, 252, 253, 254, 256, 257, 258, 259, 262, 264, 265, 267, 272, 274, 275, 276, 278, 279, 280, 285, 288, 289, 291, 300, 309, 311, 322, 323, 335, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 381, 382, 385, 391], "devel": 9, "doe": [9, 13, 14, 22, 28, 38, 51, 54, 55, 123, 129, 142, 151, 153, 158, 162, 164, 168, 170, 225, 227, 241, 243, 244, 249, 252, 253, 254, 255, 272, 275, 276, 277, 278, 288, 289, 291, 293, 299, 301, 311, 312, 313, 314, 316, 326, 332, 333, 336], "tag": [9, 53, 159, 168, 197, 201, 228, 243, 249, 251, 257, 276, 279, 282, 283, 284, 287, 357], "requir": [9, 12, 13, 14, 15, 16, 18, 19, 21, 25, 26, 31, 33, 36, 39, 40, 44, 48, 51, 53, 55, 56, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 119, 121, 123, 124, 125, 126, 127, 129, 130, 131, 132, 134, 135, 137, 138, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 156, 158, 159, 160, 161, 162, 163, 167, 168, 170, 179, 186, 189, 196, 198, 199, 200, 203, 209, 213, 214, 219, 221, 222, 236, 241, 245, 247, 248, 249, 250, 252, 253, 254, 257, 262, 267, 269, 270, 272, 274, 276, 278, 279, 284, 286, 288, 289, 291, 293, 294, 295, 296, 297, 299, 300, 301, 302, 303, 304, 305, 306, 307, 310, 311, 312, 313, 314, 315, 316, 318, 322, 324, 326, 328, 329, 330, 332, 333, 336, 337, 338, 357, 358, 365, 366, 368, 369, 370, 371, 381, 391], "describ": [9, 15, 18, 31, 53, 71, 129, 134, 137, 138, 145, 146, 148, 149, 150, 151, 153, 155, 156, 158, 161, 162, 189, 193, 212, 226, 227, 231, 243, 253, 255, 272, 276, 284, 288, 291, 296, 300, 317, 318, 324, 330, 338, 366], "doc": [9, 38, 45, 134, 137, 138, 142, 145, 146, 148, 151, 156, 158, 161, 162, 165, 168, 170, 189, 236, 244, 279, 286, 288, 289, 291, 330, 332, 382, 385], "engin": [9, 159, 162, 189, 218, 248, 288, 291], "commandlin": 9, "modifi": [9, 11, 16, 18, 19, 26, 31, 56, 61, 63, 65, 66, 124, 129, 134, 137, 138, 142, 143, 158, 160, 174, 189, 226, 233, 244, 252, 253, 266, 276, 278, 286, 289, 320, 322, 327, 357, 358, 370, 371], "so": [9, 11, 15, 28, 30, 35, 38, 48, 49, 53, 54, 55, 69, 70, 71, 72, 97, 119, 121, 122, 123, 124, 125, 127, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 159, 160, 161, 162, 163, 168, 170, 172, 174, 182, 185, 189, 191, 192, 195, 196, 200, 203, 206, 214, 215, 220, 221, 224, 230, 231, 234, 235, 236, 238, 243, 244, 247, 248, 250, 251, 252, 253, 254, 255, 256, 270, 276, 278, 279, 280, 282, 283, 284, 285, 288, 289, 291, 293, 299, 301, 311, 312, 313, 314, 316, 318, 320, 322, 326, 328, 334, 357, 358, 371, 374, 376, 386], "met": [9, 12, 31, 39, 48, 53, 55, 124, 151, 153, 254, 330], "replac": [9, 11, 13, 26, 33, 51, 129, 143, 161, 162, 168, 189, 190, 193, 202, 204, 205, 209, 219, 220, 231, 234, 243, 244, 249, 251, 253, 255, 259, 261, 279, 284, 288, 291, 329, 331], "imag": [9, 13, 14, 18, 22, 26, 33, 47, 53, 54, 57, 59, 61, 63, 65, 66, 71, 72, 73, 75, 78, 79, 80, 81, 83, 84, 85, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 119, 122, 123, 124, 125, 129, 133, 134, 136, 137, 138, 139, 142, 143, 145, 146, 148, 149, 150, 151, 153, 160, 165, 170, 171, 218, 221, 244, 250, 271, 317, 318, 319, 322, 324, 326, 327, 339, 340, 357, 358, 360, 365, 367, 369, 370, 371, 391], "grep": [9, 72, 162, 189, 254, 282, 288, 291, 323], "5c0dc1371312": 9, "5": [9, 13, 15, 22, 31, 32, 38, 44, 47, 54, 56, 57, 58, 59, 70, 73, 74, 100, 103, 108, 119, 121, 123, 125, 127, 129, 136, 141, 143, 168, 189, 195, 200, 212, 215, 222, 224, 231, 236, 237, 239, 243, 250, 251, 253, 254, 255, 256, 257, 260, 261, 264, 265, 267, 271, 272, 274, 275, 276, 277, 280, 284, 286, 288, 291, 294, 295, 296, 298, 302, 304, 305, 307, 308, 309, 313, 315, 321, 327, 331, 337, 340, 391], "minut": [9, 238, 254, 259, 276], "ago": 9, "76gb": 9, "303de7f7c38d": 9, "36": [9, 50, 57, 133, 139, 250, 321, 326, 391], "61gb": 9, "In": [10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 24, 26, 33, 38, 41, 42, 43, 45, 48, 49, 52, 53, 54, 55, 63, 69, 70, 71, 73, 74, 75, 119, 126, 129, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 156, 158, 159, 161, 162, 163, 164, 168, 170, 182, 189, 190, 192, 194, 196, 204, 205, 206, 207, 208, 209, 211, 213, 214, 216, 217, 218, 219, 220, 221, 224, 225, 226, 229, 231, 234, 235, 236, 239, 240, 242, 243, 244, 248, 249, 251, 252, 253, 254, 255, 256, 257, 259, 266, 267, 272, 276, 279, 283, 284, 288, 291, 293, 295, 299, 301, 304, 310, 311, 312, 313, 314, 316, 318, 319, 321, 322, 330, 331, 332, 333, 335, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 378, 380, 381, 384], "foster": [10, 20, 201], "welcom": [10, 20, 157, 158, 172, 243, 335, 372], "environ": [10, 18, 20, 55, 58, 119, 129, 157, 158, 159, 160, 163, 172, 182, 189, 236, 243, 252, 257, 258, 276, 282, 289, 320, 357, 358, 380, 384, 388], "make": [10, 11, 13, 15, 18, 20, 21, 31, 38, 48, 49, 55, 65, 66, 110, 111, 112, 113, 114, 115, 116, 119, 120, 121, 123, 124, 125, 126, 127, 129, 157, 158, 159, 160, 161, 162, 163, 168, 170, 172, 188, 189, 198, 199, 200, 201, 203, 214, 219, 220, 225, 236, 239, 241, 244, 245, 247, 251, 252, 253, 254, 255, 256, 257, 259, 264, 269, 270, 275, 276, 278, 279, 287, 289, 319, 320, 326, 331, 335, 357, 358, 359, 360, 361, 364, 365, 376, 380, 384], "particip": [10, 20, 129, 157, 212, 334], "commun": [10, 18, 20, 129, 143, 157, 158, 159, 160, 162, 163, 171, 189, 200, 211, 243, 244, 251, 252, 253, 256, 258, 275, 278, 288, 291], "harass": [10, 20, 157], "free": [10, 16, 20, 38, 42, 52, 75, 124, 157, 162, 172, 251, 253, 276, 277, 288, 289, 291, 322, 377, 381], "experi": [10, 16, 20, 52, 55, 124, 157, 159, 160, 162, 165, 189, 197, 202, 205, 207, 209, 211, 212, 222, 229, 236, 238, 240, 242, 244, 252, 254, 267, 272, 274, 275, 276, 288, 291, 303, 322, 340, 373], "everyon": [10, 20, 157, 158, 160, 162, 171, 243, 288, 291], "regardless": [10, 20, 157, 254], "ag": [10, 20, 157, 236, 278, 284], "bodi": [10, 20, 59, 157, 251, 323, 387, 391], "size": [10, 13, 18, 19, 20, 21, 22, 26, 30, 33, 42, 45, 50, 54, 55, 56, 57, 65, 66, 71, 120, 124, 129, 133, 134, 137, 138, 139, 141, 142, 143, 147, 148, 149, 150, 157, 163, 168, 170, 185, 189, 191, 198, 199, 200, 205, 207, 209, 211, 215, 218, 220, 224, 227, 231, 233, 236, 244, 245, 247, 250, 251, 252, 253, 254, 255, 256, 261, 263, 264, 265, 272, 273, 278, 280, 284, 299, 309, 311, 312, 314, 315, 318, 319, 322, 326, 327, 328, 329, 337, 359, 360, 362, 364, 366, 369, 386, 391], "disabl": [10, 20, 157, 249, 254], "ethnic": [10, 20, 157], "sex": [10, 20, 157], "characterist": [10, 20, 157, 162, 288, 291], "gender": [10, 20, 157], "ident": [10, 13, 20, 24, 33, 123, 143, 157, 162, 189, 193, 209, 222, 240, 254, 276, 288, 291, 298, 308], "express": [10, 20, 157, 252, 254, 284, 298, 308, 386], "level": [10, 13, 20, 55, 157, 160, 162, 168, 182, 211, 213, 218, 219, 220, 233, 237, 244, 254, 270, 272, 288, 291], "educ": [10, 20, 157, 160, 171, 248], "socio": [10, 20, 157], "econom": [10, 20, 157], "statu": [10, 20, 42, 157, 243, 253, 254, 323, 391], "nation": [10, 20, 157, 211, 223], "appear": [10, 18, 20, 143, 157, 158, 253, 255, 284, 289, 298, 308, 381], "race": [10, 20, 157, 191, 204, 205, 233, 257], "religion": [10, 20, 157], "sexual": [10, 20, 157], "orient": [10, 20, 157, 252], "behavior": [10, 15, 16, 20, 24, 31, 40, 53, 55, 56, 133, 143, 157, 158, 179, 189, 203, 249, 252, 254, 279, 289, 386], "creat": [10, 12, 15, 16, 20, 22, 28, 32, 33, 40, 41, 48, 52, 53, 55, 61, 63, 64, 65, 66, 68, 73, 74, 121, 123, 124, 126, 133, 158, 159, 160, 161, 162, 167, 168, 170, 172, 189, 192, 193, 195, 196, 206, 214, 215, 223, 235, 236, 243, 245, 248, 249, 250, 251, 252, 253, 254, 255, 256, 258, 263, 267, 275, 283, 284, 285, 289, 296, 319, 320, 322, 331, 335, 357, 358, 360, 361, 380, 382, 384, 385, 389], "posit": [10, 18, 20, 38, 157, 159, 160, 162, 168, 171, 172, 191, 195, 203, 204, 205, 206, 207, 214, 215, 218, 222, 224, 225, 227, 234, 236, 237, 241, 242, 244, 251, 253, 270, 274, 275, 288, 291, 373], "inclus": [10, 20, 157], "languag": [10, 20, 46, 59, 99, 100, 101, 102, 103, 105, 106, 107, 108, 157, 160, 161, 165, 168, 170, 171, 174, 186, 187, 191, 193, 194, 195, 196, 197, 200, 201, 202, 203, 204, 205, 206, 207, 209, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 233, 234, 235, 236, 237, 239, 240, 241, 242, 244, 247, 250, 251, 252, 255, 256, 257, 263, 264, 267, 272, 273, 276, 278, 279, 280, 284, 285, 286, 295, 304, 306, 364, 391], "Being": [10, 20, 157], "respect": [10, 20, 25, 31, 45, 56, 129, 157, 158, 162, 163, 200, 204, 205, 221, 223, 229, 240, 244, 253, 254, 275, 288, 291, 331, 359], "viewpoint": [10, 20, 157], "gracefulli": [10, 20, 157, 263], "accept": [10, 18, 20, 39, 119, 129, 157, 161, 162, 168, 170, 190, 238, 249, 251, 275, 288, 291, 319, 335], "construct": [10, 19, 20, 22, 26, 55, 70, 71, 75, 151, 157, 213, 255, 278], "focus": [10, 15, 20, 33, 157, 159, 171, 191, 223, 236, 254], "what": [10, 18, 20, 123, 124, 129, 157, 158, 159, 160, 161, 162, 164, 168, 170, 171, 187, 189, 190, 234, 236, 243, 244, 249, 251, 253, 254, 255, 273, 276, 279, 288, 291, 320, 322, 334], "show": [10, 13, 18, 19, 20, 24, 26, 32, 45, 55, 73, 74, 75, 119, 123, 129, 136, 161, 162, 163, 168, 191, 194, 197, 198, 199, 203, 204, 205, 206, 207, 208, 211, 217, 218, 219, 221, 223, 224, 225, 228, 229, 233, 236, 238, 239, 240, 241, 243, 249, 251, 252, 253, 255, 256, 261, 272, 285, 288, 291, 296, 322, 331, 357, 365, 371, 374, 388, 391], "empathi": [10, 20, 157, 198, 199], "toward": [10, 14, 20, 24, 154, 157, 189, 272], "member": [10, 15, 20, 157, 161, 162, 222, 243, 289, 365], "unaccept": [10, 20, 157], "imageri": [10, 20, 157], "unwelcom": [10, 20, 157], "attent": [10, 20, 24, 139, 157, 160, 162, 164, 165, 171, 174, 183, 185, 190, 196, 202, 203, 204, 205, 215, 219, 221, 224, 229, 234, 235, 236, 237, 240, 242, 248, 249, 251, 252, 253, 261, 288, 291, 309], "troll": [10, 20, 157], "insult": [10, 20, 157], "derogatori": [10, 20, 157], "comment": [10, 20, 22, 38, 54, 157, 159, 162, 206, 253, 276, 280, 288, 291], "polit": [10, 20, 157], "attack": [10, 20, 157], "public": [10, 20, 64, 123, 142, 157, 158, 159, 161, 162, 171, 197, 200, 228, 236, 288, 291, 293, 313, 322, 335, 382, 385], "privat": [10, 20, 157, 159, 160, 172, 233], "physic": [10, 20, 157, 362, 364], "electron": [10, 20], "address": [10, 18, 20, 39, 46, 157, 158, 159, 160, 189, 191, 201, 219, 220, 225, 254, 266, 295, 304], "without": [10, 11, 16, 18, 20, 21, 24, 26, 33, 38, 45, 46, 47, 48, 55, 61, 68, 72, 74, 129, 143, 157, 158, 159, 160, 161, 163, 168, 190, 195, 205, 216, 217, 223, 236, 237, 241, 244, 248, 251, 252, 253, 254, 255, 257, 267, 272, 275, 276, 278, 291, 295, 304, 322, 359, 371, 391], "explicit": [10, 20, 157, 159, 203, 230, 254], "permiss": [10, 20, 157, 159], "could": [10, 16, 20, 25, 33, 41, 43, 45, 48, 55, 69, 70, 71, 73, 74, 121, 124, 134, 137, 138, 142, 143, 145, 146, 148, 149, 150, 151, 153, 156, 157, 158, 159, 162, 189, 207, 210, 236, 244, 247, 248, 251, 254, 255, 270, 275, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 318, 324, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "reason": [10, 20, 21, 53, 55, 129, 157, 159, 161, 162, 189, 221, 237, 243, 252, 254, 255, 276, 284, 288, 291, 322], "consid": [10, 11, 20, 21, 24, 55, 123, 129, 136, 157, 158, 159, 168, 170, 185, 201, 234, 244, 255, 256, 264, 272, 274, 278, 284, 296, 322], "inappropri": [10, 20, 157], "profession": [10, 20, 157], "clarifi": [10, 20, 157], "expect": [10, 16, 20, 27, 30, 48, 55, 75, 123, 129, 159, 160, 162, 163, 168, 170, 171, 172, 190, 218, 223, 227, 236, 242, 249, 251, 253, 254, 256, 259, 275, 276, 288, 289, 291, 324, 331, 334], "take": [10, 12, 16, 20, 21, 24, 31, 45, 48, 49, 54, 55, 56, 121, 126, 127, 157, 159, 162, 163, 167, 168, 170, 179, 189, 190, 203, 215, 225, 227, 234, 235, 244, 248, 249, 251, 253, 254, 255, 256, 259, 265, 276, 277, 284, 288, 291, 295, 303, 304, 311, 368, 386], "appropri": [10, 20, 126, 157, 170, 198, 199, 220, 236, 245, 253, 255, 357, 358], "fair": [10, 20, 157, 212, 216], "correct": [10, 13, 18, 20, 124, 125, 126, 127, 129, 158, 161, 162, 168, 189, 190, 209, 235, 239, 241, 253, 254, 256, 288, 291, 344, 373], "action": [10, 20, 33, 157, 158, 179, 244, 254, 334, 382, 385], "instanc": [10, 11, 12, 15, 18, 20, 32, 50, 55, 56, 57, 65, 66, 124, 143, 157, 160, 161, 162, 170, 172, 174, 182, 185, 192, 235, 243, 244, 248, 249, 251, 255, 256, 257, 272, 275, 278, 288, 291, 310, 319, 322, 387, 391], "have": [10, 13, 16, 18, 20, 21, 26, 31, 37, 38, 39, 42, 45, 48, 73, 74, 119, 123, 124, 125, 126, 128, 129, 133, 134, 137, 138, 139, 141, 142, 145, 146, 148, 156, 157, 158, 159, 160, 161, 162, 163, 164, 167, 168, 170, 171, 172, 174, 185, 189, 190, 191, 193, 194, 196, 197, 198, 200, 201, 202, 207, 211, 217, 218, 220, 223, 225, 230, 231, 233, 234, 236, 237, 239, 243, 244, 245, 247, 249, 251, 252, 253, 254, 255, 256, 257, 259, 261, 264, 266, 267, 270, 272, 275, 276, 277, 278, 279, 280, 282, 283, 288, 289, 291, 293, 298, 308, 309, 319, 322, 323, 326, 331, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373], "right": [10, 11, 18, 20, 21, 54, 129, 157, 159, 160, 162, 170, 171, 189, 191, 193, 195, 203, 206, 214, 215, 218, 224, 231, 234, 235, 236, 237, 243, 244, 247, 251, 253, 254, 255, 276, 288, 291, 320, 326, 337], "edit": [10, 11, 20, 129, 157, 158, 159, 171, 189, 254, 283, 289, 315, 326, 329, 337], "reject": [10, 20, 157], "commit": [10, 20, 121, 157, 158, 159, 161, 162, 172, 243, 254, 272, 276, 283, 288, 291], "wiki": [10, 20, 157, 236, 270, 275], "align": [10, 20, 54, 123, 157, 188, 221], "ban": [10, 20], "temporarili": [10, 20, 126], "perman": [10, 20, 126, 253], "thei": [10, 19, 20, 24, 31, 38, 42, 45, 72, 73, 74, 120, 123, 124, 128, 129, 133, 157, 158, 159, 160, 161, 162, 168, 170, 171, 172, 179, 187, 188, 189, 190, 193, 198, 199, 209, 211, 218, 221, 222, 224, 231, 236, 243, 244, 245, 247, 249, 251, 252, 253, 254, 255, 257, 262, 270, 272, 276, 277, 283, 284, 288, 289, 291, 317, 319, 369, 376], "deem": [10, 20, 157, 253], "threaten": [10, 20, 157], "offens": [10, 20, 157], "harm": [10, 20, 157], "appli": [10, 14, 18, 20, 43, 45, 48, 49, 52, 55, 56, 129, 136, 150, 151, 153, 157, 160, 162, 170, 171, 200, 205, 211, 224, 236, 244, 247, 249, 251, 253, 255, 256, 267, 278, 288, 291, 295, 298, 304, 308, 321, 359, 360, 362, 363, 364, 365, 371, 373], "both": [10, 12, 14, 15, 20, 21, 25, 47, 48, 72, 129, 145, 160, 161, 162, 163, 168, 170, 172, 187, 188, 189, 195, 196, 202, 206, 209, 217, 220, 221, 223, 230, 235, 236, 237, 243, 244, 249, 251, 252, 253, 254, 255, 256, 259, 261, 265, 270, 275, 276, 280, 288, 289, 291, 298, 308, 317, 323, 357, 365, 370], "within": [10, 11, 20, 39, 46, 123, 157, 159, 170, 172, 206, 215, 220, 253, 254, 357, 380, 384], "space": [10, 12, 15, 20, 21, 45, 48, 55, 56, 61, 63, 124, 129, 134, 137, 138, 142, 143, 157, 158, 159, 188, 193, 208, 238, 244, 255, 335, 357, 358, 365, 370], "when": [10, 12, 14, 16, 18, 20, 21, 22, 28, 33, 45, 48, 54, 55, 69, 75, 123, 124, 125, 134, 137, 138, 142, 143, 155, 156, 157, 158, 159, 160, 161, 162, 163, 168, 170, 172, 174, 183, 185, 188, 189, 190, 191, 193, 198, 199, 208, 209, 219, 221, 230, 231, 234, 236, 237, 238, 243, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 264, 267, 270, 272, 275, 276, 278, 287, 288, 291, 298, 299, 308, 331, 357, 358, 365, 369, 370, 380, 381, 384, 389, 391], "individu": [10, 12, 20, 157, 162, 170, 244, 254, 272, 283, 288, 291], "repres": [10, 20, 22, 48, 55, 76, 143, 157, 170, 171, 204, 205, 218, 220, 221, 231, 235, 244, 245, 249, 251, 252, 255, 319], "its": [10, 12, 18, 20, 21, 24, 37, 38, 39, 44, 45, 52, 54, 55, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 123, 124, 129, 134, 158, 159, 160, 161, 162, 168, 170, 172, 189, 194, 202, 204, 205, 207, 219, 220, 222, 223, 226, 231, 236, 242, 243, 244, 247, 248, 249, 251, 252, 253, 255, 257, 266, 274, 275, 276, 278, 279, 283, 288, 291, 298, 303, 308, 324, 363, 364, 380, 384], "offici": [10, 18, 20, 32, 38, 58, 73, 74, 79, 96, 98, 133, 157, 159, 160, 162, 172, 189, 206, 220, 248, 264, 276, 281, 285, 288, 291, 296, 309, 317, 363, 365, 366], "e": [10, 20, 24, 26, 33, 55, 124, 129, 133, 143, 157, 158, 159, 160, 161, 162, 163, 170, 171, 172, 181, 188, 189, 190, 196, 216, 217, 218, 219, 220, 221, 222, 223, 225, 227, 234, 235, 236, 239, 242, 244, 247, 249, 250, 251, 253, 254, 255, 263, 267, 274, 275, 276, 283, 284, 286, 288, 289, 291, 294, 295, 297, 302, 303, 304, 307, 320, 323, 324, 373, 376, 377, 380, 384], "mail": [10, 20, 157, 253, 257, 265], "post": [10, 13, 14, 15, 16, 20, 25, 26, 27, 32, 35, 36, 43, 53, 55, 59, 120, 145, 157, 158, 159, 162, 168, 189, 207, 231, 232, 247, 251, 252, 253, 268, 272, 283, 288, 291, 303, 373, 377, 391], "via": [10, 20, 26, 33, 35, 52, 124, 133, 150, 154, 157, 160, 162, 163, 171, 179, 189, 190, 197, 203, 213, 221, 224, 235, 236, 253, 254, 257, 277, 284, 288, 291, 300, 315, 324, 326, 329, 337, 357, 370, 373, 390], "social": [10, 20, 157, 234], "media": [10, 20, 126, 141, 157, 366], "account": [10, 20, 52, 55, 73, 74, 157, 158, 162, 165, 170, 243, 251, 255, 288, 291, 357, 358], "act": [10, 20, 157, 158], "appoint": [10, 20, 157], "offlin": [10, 20, 48, 120, 157], "event": [10, 20, 53, 157], "represent": [10, 20, 25, 42, 48, 124, 143, 160, 164, 170, 171, 187, 191, 195, 207, 208, 209, 211, 213, 221, 238, 241, 244, 245, 251, 252, 255, 261, 280, 284], "mai": [10, 16, 20, 21, 30, 37, 39, 44, 46, 48, 123, 126, 129, 143, 148, 149, 157, 158, 159, 161, 172, 189, 190, 209, 236, 243, 244, 247, 248, 253, 254, 257, 259, 261, 264, 265, 270, 273, 276, 286, 289, 311, 317, 323, 380, 384], "further": [10, 20, 39, 40, 159, 161, 191, 211, 213, 221, 234, 236, 253, 266, 267, 272, 282, 322, 373, 381], "defin": [10, 12, 13, 14, 15, 18, 20, 22, 24, 31, 35, 38, 42, 43, 45, 48, 52, 53, 55, 56, 63, 70, 71, 75, 124, 145, 146, 160, 162, 163, 168, 170, 183, 189, 209, 220, 236, 238, 245, 247, 251, 253, 254, 255, 256, 259, 260, 264, 280, 282, 288, 291, 298, 308, 358, 362, 364, 388], "abus": [10, 20, 157], "report": [10, 18, 20, 52, 73, 74, 133, 139, 143, 157, 158, 159, 179, 182, 189, 233, 236, 247, 267, 272, 276, 280, 322], "contact": [10, 20, 51, 52, 160, 162, 172, 262, 288, 291], "mlp": [10, 20], "mlpc": [10, 20], "dl": [10, 16, 20, 32, 34, 46, 73, 74, 254, 275, 357, 375], "complaint": [10, 20, 157], "review": [10, 20, 157, 158, 162, 171, 216, 244, 288, 291], "investig": [10, 20, 157, 159, 164, 207, 230, 248, 253, 267], "result": [10, 12, 13, 16, 18, 19, 20, 21, 24, 26, 28, 33, 35, 37, 38, 42, 45, 46, 48, 52, 53, 54, 55, 57, 62, 65, 66, 69, 70, 71, 75, 120, 121, 123, 124, 125, 126, 129, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 155, 156, 159, 160, 161, 162, 163, 167, 168, 170, 191, 193, 194, 195, 196, 197, 198, 199, 209, 211, 216, 217, 218, 219, 220, 221, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 239, 240, 243, 244, 247, 248, 251, 252, 253, 255, 256, 257, 260, 263, 265, 266, 267, 270, 272, 276, 278, 280, 282, 288, 291, 293, 294, 295, 296, 297, 299, 300, 301, 302, 304, 305, 307, 311, 312, 313, 314, 315, 316, 318, 322, 324, 326, 327, 329, 330, 332, 333, 336, 337, 338, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 376, 377], "necessari": [10, 12, 16, 20, 40, 52, 55, 67, 75, 125, 127, 158, 161, 162, 170, 207, 219, 221, 252, 265, 288, 291, 295, 304, 322, 365], "circumst": [10, 20, 47], "team": [10, 20, 49, 160, 162, 171, 283, 284, 288, 289, 291], "oblig": [10, 20, 157, 159], "confidenti": [10, 18, 20], "regard": [10, 20, 49, 160, 162, 172, 189, 190, 224, 234, 236, 288, 291], "incid": [10, 20, 157], "specif": [10, 12, 13, 15, 18, 20, 24, 28, 31, 32, 34, 38, 39, 40, 42, 47, 56, 69, 70, 71, 73, 74, 122, 123, 124, 129, 133, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 158, 159, 160, 162, 164, 165, 167, 168, 170, 171, 172, 185, 189, 190, 200, 203, 207, 212, 216, 228, 243, 244, 247, 249, 251, 252, 253, 255, 256, 257, 262, 267, 272, 279, 288, 291, 293, 294, 295, 297, 299, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 316, 318, 319, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 373, 375, 376, 381], "separ": [10, 16, 18, 20, 34, 37, 43, 47, 75, 120, 123, 129, 147, 158, 159, 162, 163, 168, 170, 189, 207, 209, 220, 225, 233, 236, 244, 247, 252, 253, 255, 264, 275, 278, 282, 288, 291, 369, 391], "who": [10, 20, 158, 159, 236, 248, 252, 253, 275], "do": [10, 16, 18, 20, 22, 26, 31, 33, 35, 38, 42, 49, 51, 55, 61, 62, 63, 70, 71, 97, 124, 125, 126, 127, 133, 134, 137, 138, 142, 143, 145, 146, 148, 151, 156, 159, 161, 162, 168, 170, 171, 174, 185, 188, 189, 190, 192, 236, 243, 245, 247, 249, 251, 252, 253, 254, 255, 256, 257, 267, 272, 276, 277, 278, 279, 288, 289, 291, 298, 303, 308, 309, 320, 322, 323, 330, 332, 335, 348, 359, 367, 382, 385], "good": [10, 20, 28, 48, 55, 124, 129, 143, 158, 159, 162, 164, 189, 198, 199, 207, 209, 213, 231, 247, 253, 254, 267, 288, 291, 331, 359], "faith": [10, 20], "temporari": [10, 20], "repercuss": [10, 20], "determin": [10, 13, 20, 28, 124, 129, 157, 168, 241, 244, 253, 255, 264, 278, 284, 298, 308], "": [10, 12, 13, 19, 20, 24, 26, 27, 28, 31, 32, 33, 35, 36, 39, 43, 44, 45, 46, 47, 48, 51, 52, 56, 72, 73, 74, 75, 79, 96, 98, 119, 129, 136, 137, 138, 142, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 170, 171, 172, 174, 179, 180, 183, 185, 188, 189, 190, 191, 194, 195, 196, 198, 200, 201, 203, 204, 205, 206, 207, 209, 211, 212, 214, 215, 217, 218, 219, 220, 222, 224, 227, 231, 233, 234, 236, 237, 239, 241, 243, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 262, 265, 267, 270, 276, 277, 278, 279, 280, 282, 283, 284, 288, 289, 291, 293, 295, 298, 299, 301, 304, 308, 309, 311, 312, 313, 314, 316, 318, 321, 322, 324, 331, 332, 333, 335, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 376, 380, 384], "leadership": [10, 20], "adapt": [10, 20, 119, 124, 126, 129, 143, 157, 160, 162, 164, 189, 194, 221, 230, 237, 243, 244, 251, 253, 288, 291], "www": [10, 22, 57, 121, 157, 160, 187, 205, 266, 324, 338], "html": [10, 121, 133, 134, 137, 138, 142, 145, 146, 148, 151, 155, 156, 157, 159, 161, 279, 296, 323, 330, 332, 382, 385], "answer": [10, 20, 54, 57, 59, 104, 157, 158, 159, 160, 162, 165, 170, 171, 186, 187, 193, 195, 208, 214, 216, 219, 221, 224, 232, 235, 236, 242, 244, 245, 249, 250, 251, 257, 261, 272, 275, 284, 285, 287, 288, 291, 296], "question": [10, 15, 20, 36, 54, 57, 59, 124, 157, 158, 159, 160, 162, 165, 170, 171, 186, 187, 189, 193, 195, 208, 214, 216, 219, 221, 224, 229, 232, 233, 235, 236, 240, 242, 244, 245, 249, 250, 251, 257, 261, 270, 272, 275, 284, 285, 287, 288, 291, 296, 373], "about": [10, 18, 20, 21, 28, 49, 57, 73, 74, 104, 124, 127, 129, 157, 158, 159, 160, 162, 163, 168, 171, 186, 189, 200, 205, 222, 227, 233, 234, 235, 236, 243, 247, 251, 252, 259, 275, 277, 278, 284, 287, 288, 289, 290, 291, 321], "nn": [11, 13, 14, 16, 40, 45, 53, 133, 143, 151, 153, 160, 162, 190, 222, 248, 251, 253, 256, 288, 291], "modul": [11, 13, 14, 18, 19, 24, 35, 38, 40, 47, 49, 53, 133, 137, 142, 143, 148, 149, 151, 153, 159, 160, 162, 171, 182, 184, 190, 230, 244, 248, 251, 252, 256, 272, 288, 291, 298, 308, 313, 358, 386, 390], "With": [11, 14, 15, 21, 42, 45, 46, 48, 57, 73, 74, 143, 162, 163, 171, 197, 213, 214, 215, 228, 242, 244, 247, 255, 256, 275, 278, 281, 288, 291, 298, 308, 376, 380, 384], "convert": [11, 13, 14, 16, 27, 33, 39, 41, 48, 49, 54, 61, 63, 65, 66, 73, 74, 77, 78, 80, 86, 96, 104, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 123, 125, 127, 129, 143, 162, 168, 170, 171, 172, 187, 188, 189, 209, 222, 227, 235, 236, 243, 244, 248, 249, 251, 252, 253, 255, 256, 267, 272, 288, 291, 322, 337, 344, 357, 358, 365, 366, 370], "torch": [11, 13, 14, 16, 26, 39, 40, 45, 48, 53, 79, 96, 98, 119, 121, 129, 133, 138, 140, 143, 151, 153, 155, 156, 158, 159, 161, 162, 168, 172, 185, 189, 190, 197, 216, 227, 228, 236, 245, 247, 248, 251, 252, 253, 254, 256, 257, 261, 267, 275, 276, 277, 288, 291, 293, 295, 296, 299, 301, 304, 311, 312, 313, 314, 316, 319, 322, 326, 330, 336, 337, 373], "graphmodul": [11, 49], "insert": [11, 13, 35, 48, 49, 53, 163, 189, 244, 278, 290, 313, 322, 332, 344, 373], "quant": [11, 13, 48, 272, 313, 344], "dequant": [11, 13, 53, 313, 344], "oper": [11, 13, 18, 42, 48, 54, 55, 124, 126, 129, 134, 137, 138, 142, 145, 146, 148, 151, 156, 162, 172, 207, 213, 217, 219, 220, 231, 234, 236, 244, 252, 272, 288, 291, 319, 327, 330, 332], "symbolic_trac": 11, "fake": [11, 14, 48, 371], "valu": [11, 13, 14, 18, 21, 22, 28, 31, 38, 42, 45, 47, 48, 54, 55, 56, 61, 63, 69, 75, 123, 124, 129, 134, 137, 138, 139, 142, 143, 148, 149, 156, 158, 161, 162, 164, 170, 172, 174, 182, 185, 187, 189, 190, 203, 215, 220, 221, 231, 236, 245, 249, 251, 252, 253, 254, 272, 274, 278, 279, 288, 291, 298, 308, 311, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 374, 391], "call": [11, 12, 15, 16, 18, 21, 34, 45, 48, 53, 54, 55, 72, 73, 74, 124, 129, 143, 159, 160, 161, 162, 163, 164, 168, 170, 171, 190, 194, 195, 200, 207, 209, 211, 229, 234, 235, 236, 240, 244, 247, 249, 251, 253, 254, 255, 256, 267, 276, 278, 279, 286, 288, 291, 348, 365, 377], "proxi": [11, 270, 284], "fed": [11, 170, 187, 235, 244, 248, 249, 251, 252, 256, 278], "model": [11, 12, 14, 15, 16, 19, 21, 22, 24, 25, 26, 27, 28, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 48, 51, 52, 53, 54, 56, 58, 59, 60, 71, 73, 74, 75, 107, 119, 123, 124, 126, 127, 130, 131, 132, 134, 136, 138, 145, 146, 147, 151, 153, 154, 164, 165, 167, 168, 174, 175, 176, 180, 181, 184, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 248, 249, 254, 255, 256, 257, 258, 264, 265, 266, 267, 273, 275, 276, 277, 278, 279, 280, 281, 282, 285, 287, 292, 295, 298, 300, 303, 304, 308, 309, 310, 325, 330, 338, 355, 373, 376, 381, 386, 387], "record": [11, 13, 22, 52, 53, 55, 61, 63, 65, 66, 75, 96, 158, 200, 252, 279, 326, 337, 357, 358, 360, 361, 365, 366], "Then": [11, 16, 18, 33, 125, 126, 127, 160, 162, 209, 224, 229, 240, 243, 249, 251, 253, 254, 255, 256, 257, 265, 270, 276, 278, 288, 291, 322, 360, 361, 380, 382, 384, 385], "get": [11, 18, 19, 21, 22, 35, 36, 53, 55, 58, 63, 69, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 125, 127, 139, 140, 148, 149, 150, 151, 158, 159, 161, 162, 167, 168, 172, 174, 179, 182, 185, 188, 189, 193, 236, 243, 244, 249, 253, 255, 256, 276, 278, 280, 284, 285, 286, 288, 291, 293, 299, 300, 301, 313, 317, 318, 320, 322, 340, 341, 344, 354, 355, 357, 358, 362, 364, 367, 371, 374, 390], "sure": [11, 13, 18, 65, 66, 110, 111, 112, 113, 114, 115, 116, 119, 123, 124, 125, 126, 127, 129, 158, 159, 160, 161, 162, 163, 167, 168, 188, 189, 236, 239, 243, 251, 254, 255, 257, 259, 270, 275, 279, 289, 320, 326, 335, 357, 358, 359, 360, 361, 364, 365], "backend": [11, 16, 17, 26, 28, 34, 35, 47, 48, 54, 56, 120, 121, 134, 137, 138, 142, 149, 150, 153, 160, 192, 251, 254, 300, 315, 318, 326, 329, 331, 333, 336, 357, 358, 365, 370, 377], "pytorch_fx": [11, 47, 299, 312, 314, 333], "conf": [11, 12, 14, 16, 19, 21, 24, 33, 34, 55, 64, 67, 69, 70, 71, 75, 76, 121, 137, 138, 142, 144, 147, 148, 149, 150, 151, 153, 154, 293, 299, 301, 306, 311, 312, 313, 314, 315, 316, 318, 326, 329, 330, 331, 332, 333, 336, 337, 356, 371], "yaml": [11, 14, 15, 16, 22, 24, 28, 33, 34, 38, 41, 42, 45, 47, 53, 54, 55, 64, 68, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 144, 145, 146, 147, 148, 152, 154, 294, 295, 296, 297, 302, 303, 304, 305, 306, 307, 309, 315, 322, 326, 329, 337, 356, 386, 387, 391], "usual": [11, 14, 21, 24, 43, 48, 161, 162, 170, 172, 174, 185, 191, 195, 203, 206, 214, 215, 220, 222, 224, 231, 234, 236, 243, 244, 248, 249, 251, 253, 254, 255, 256, 257, 276, 280, 283, 284, 288, 291, 295, 304], "_": [11, 13, 14, 15, 16, 17, 24, 26, 28, 31, 33, 38, 39, 40, 42, 45, 48, 49, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 99, 100, 103, 108, 110, 111, 112, 113, 114, 115, 116, 120, 122, 123, 124, 125, 126, 127, 129, 133, 134, 137, 138, 142, 143, 147, 148, 149, 150, 151, 153, 155, 156, 157, 161, 231, 256, 257, 263, 266, 275, 276, 277, 278, 279, 280, 288, 291, 293, 294, 295, 296, 297, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 318, 322, 323, 324, 326, 329, 330, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 377, 380, 382, 384, 385, 386, 387], "shown": [11, 12, 18, 24, 33, 38, 42, 43, 55, 72, 129, 163, 198, 199, 202, 206, 210, 230, 236, 244, 247, 252, 253, 254, 257, 269, 340, 341, 354, 362, 364, 381], "below": [11, 12, 14, 15, 16, 17, 20, 24, 26, 33, 34, 38, 42, 43, 45, 47, 48, 53, 55, 69, 70, 71, 73, 74, 75, 119, 123, 124, 129, 134, 136, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 155, 156, 158, 167, 168, 171, 174, 182, 185, 187, 188, 189, 190, 244, 247, 249, 251, 252, 253, 254, 256, 258, 259, 265, 270, 272, 275, 276, 279, 280, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 311, 312, 313, 314, 316, 318, 324, 330, 331, 332, 333, 336, 338, 357, 358, 359, 360, 361, 362, 363, 364, 365, 370, 373, 380, 381, 384], "eval": [11, 13, 14, 53, 69, 70, 71, 133, 134, 137, 138, 141, 142, 143, 148, 149, 150, 151, 153, 156, 168, 227, 252, 256, 260, 266, 276, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 329, 330, 332, 333, 336, 357, 358, 359, 360, 361, 362, 363, 364, 365, 368, 370, 371, 373], "q_model": [11, 14, 16, 21, 22, 26, 34, 38, 40, 41, 42, 48, 62, 69, 70, 71, 75, 134, 137, 138, 142, 148, 149, 151, 153, 156, 293, 301, 311, 312, 313, 314, 315, 316, 318, 330, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371], "save": [11, 12, 13, 15, 16, 33, 34, 39, 40, 41, 45, 48, 60, 62, 65, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 123, 124, 125, 126, 129, 141, 151, 162, 163, 167, 179, 180, 183, 188, 190, 196, 205, 209, 210, 213, 231, 243, 244, 248, 251, 254, 255, 256, 264, 266, 271, 275, 276, 278, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 327, 333, 336, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 358, 359, 360, 362, 363, 364, 366, 370, 376, 380, 384, 388], "tuned_checkpoint": [11, 151, 293, 313, 315, 318], "return": [11, 12, 13, 14, 16, 22, 26, 38, 39, 40, 42, 48, 53, 55, 62, 69, 70, 71, 75, 134, 137, 138, 142, 148, 149, 151, 153, 156, 159, 160, 162, 168, 170, 174, 179, 185, 187, 189, 190, 218, 221, 236, 247, 249, 251, 253, 254, 256, 275, 282, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 318, 319, 322, 323, 330, 333, 336, 340, 357, 359, 360, 362, 363, 364, 365, 371, 391], "now": [11, 12, 22, 26, 33, 41, 47, 54, 55, 119, 125, 127, 129, 133, 158, 159, 160, 161, 162, 167, 168, 171, 172, 189, 197, 201, 205, 228, 231, 243, 245, 249, 251, 253, 254, 255, 256, 267, 276, 278, 280, 288, 291, 293, 306, 311, 317, 322, 323, 360, 365], "support": [11, 12, 13, 16, 18, 19, 27, 28, 32, 33, 41, 46, 49, 52, 55, 57, 58, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 123, 126, 129, 133, 134, 137, 138, 142, 147, 148, 149, 150, 151, 153, 156, 158, 160, 163, 171, 172, 189, 219, 222, 227, 245, 248, 249, 252, 254, 257, 265, 267, 275, 278, 284, 293, 295, 298, 301, 304, 305, 306, 308, 311, 316, 318, 319, 322, 323, 330, 331, 332, 333, 336, 337, 339, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 376, 381, 386], "auto": [11, 27, 148, 158, 159, 171, 190, 223, 235, 242, 244, 251, 253, 254, 281, 289, 328, 367, 373, 374, 376], "avoid": [11, 53, 157, 158, 159, 189, 225, 244, 267, 326], "log": [11, 18, 52, 53, 55, 120, 141, 159, 168, 171, 179, 181, 189, 190, 205, 231, 243, 247, 254, 255, 256, 260, 261, 273, 276, 308, 317, 320, 329], "output": [11, 13, 14, 15, 16, 18, 21, 24, 26, 31, 33, 34, 38, 40, 45, 47, 48, 53, 54, 55, 56, 70, 72, 73, 74, 75, 79, 80, 96, 98, 107, 117, 118, 120, 122, 124, 125, 129, 133, 143, 147, 148, 149, 151, 153, 160, 162, 163, 164, 168, 170, 171, 188, 189, 196, 197, 201, 204, 205, 216, 222, 227, 228, 231, 235, 238, 241, 244, 245, 247, 250, 251, 252, 253, 255, 256, 263, 267, 275, 278, 284, 288, 291, 293, 297, 298, 299, 305, 307, 308, 311, 313, 324, 327, 357, 358, 359, 360, 362, 363, 364, 365, 371, 388, 391], "symbol": [11, 16, 40, 162, 170, 249, 251, 255, 288, 291, 320], "trace": [11, 162, 243, 288, 291, 326, 336, 378], "info": [11, 18, 20, 33, 40, 71, 73, 74, 75, 162, 182, 236, 252, 254, 258, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 363, 364], "entir": [11, 13, 14, 16, 45, 123, 129, 168, 170, 194, 217, 247, 253, 254, 284, 298, 308, 317, 364, 386], "conduct": [11, 158, 194, 196, 224, 229, 240, 244, 376], "combin": [11, 15, 28, 35, 43, 46, 49, 54, 55, 69, 134, 137, 138, 142, 146, 156, 159, 165, 170, 189, 195, 196, 199, 207, 212, 219, 220, 221, 222, 230, 235, 244, 251, 254, 255, 272, 276, 284, 357, 358, 365, 370], "imper": [11, 134, 137, 138, 142, 145, 146, 148, 156, 330, 332], "control": [11, 16, 18, 44, 55, 129, 158, 160, 161, 171, 203, 242, 243, 244, 249, 272, 275, 276, 282, 386], "flow": [11, 12, 159], "therefor": [11, 14, 48, 51, 123, 125, 126, 129, 158, 162, 170, 189, 196, 202, 203, 206, 209, 213, 214, 215, 219, 224, 231, 234, 236, 237, 244, 252, 253, 254, 255, 259, 279, 288, 291, 298, 308, 309], "int8": [11, 14, 15, 17, 18, 22, 25, 27, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 61, 64, 65, 66, 68, 73, 74, 121, 150, 151, 156, 217, 252, 293, 300, 303, 311, 312, 314, 315, 326, 328, 329, 332, 333, 336, 337, 360, 361, 362, 364, 376, 378, 381, 387, 391], "consist": [11, 16, 18, 20, 55, 125, 128, 158, 160, 161, 162, 189, 190, 191, 198, 199, 204, 205, 206, 216, 219, 220, 221, 228, 236, 237, 243, 244, 248, 253, 255, 267, 275, 276, 283, 288, 291, 327, 335], "lot": [11, 28, 129, 158, 159, 189, 244, 251, 267, 284, 286, 291, 322], "higher": [11, 14, 16, 24, 38, 39, 45, 48, 52, 75, 142, 149, 153, 202, 217, 224, 244, 247, 253, 254, 276, 278, 293, 294, 295, 296, 297, 299, 300, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 316, 321, 323, 326, 329, 332, 333, 336, 337, 357, 358, 365, 366, 367, 370], "between": [11, 13, 15, 16, 19, 24, 27, 33, 35, 38, 48, 51, 52, 54, 55, 133, 143, 160, 162, 163, 168, 170, 171, 172, 177, 188, 190, 200, 218, 221, 223, 224, 225, 233, 234, 241, 242, 243, 244, 247, 248, 251, 252, 253, 254, 255, 256, 259, 267, 276, 288, 291, 311], "don": [11, 18, 55, 72, 123, 124, 142, 158, 159, 161, 162, 168, 172, 174, 185, 187, 189, 190, 207, 214, 220, 225, 233, 236, 243, 245, 247, 248, 251, 254, 255, 256, 270, 276, 283, 287, 288, 289, 291, 293, 313, 331, 363, 364, 371], "need": [11, 14, 15, 16, 18, 19, 21, 22, 24, 26, 35, 39, 42, 45, 47, 48, 49, 51, 54, 55, 56, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 133, 134, 137, 138, 139, 142, 143, 148, 149, 150, 151, 153, 155, 156, 158, 159, 160, 161, 162, 167, 168, 170, 172, 179, 189, 190, 202, 207, 214, 218, 220, 225, 233, 235, 236, 243, 244, 248, 249, 251, 252, 253, 254, 255, 256, 259, 262, 265, 270, 272, 273, 275, 276, 278, 280, 282, 286, 287, 288, 289, 291, 293, 295, 299, 301, 304, 309, 311, 312, 313, 314, 315, 316, 318, 320, 322, 323, 326, 327, 329, 330, 332, 333, 335, 336, 337, 340, 341, 354, 357, 358, 359, 360, 361, 365, 370, 371, 373, 374, 377, 380, 381, 382, 384, 385], "becaus": [11, 45, 48, 54, 55, 70, 71, 72, 123, 124, 125, 126, 129, 158, 159, 162, 168, 170, 174, 185, 189, 209, 244, 247, 249, 252, 253, 255, 256, 270, 276, 277, 288, 289, 291, 293, 322, 327, 363, 364, 365, 371, 386], "As": [11, 18, 21, 24, 28, 45, 55, 69, 71, 75, 122, 129, 133, 134, 137, 138, 142, 143, 148, 149, 150, 151, 153, 156, 158, 159, 162, 168, 189, 191, 195, 207, 209, 223, 235, 237, 244, 248, 249, 251, 252, 253, 254, 255, 257, 272, 276, 278, 284, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 317, 331, 340, 341, 354, 357, 358, 371, 381], "cannot": [11, 30, 53, 124, 129, 133, 159, 162, 179, 190, 203, 217, 224, 247, 326], "tensor": [11, 13, 22, 27, 45, 48, 51, 53, 54, 55, 57, 129, 161, 162, 168, 170, 181, 185, 197, 217, 220, 228, 236, 241, 245, 249, 251, 252, 253, 256, 267, 280, 288, 291, 319, 322, 323, 330, 359, 360, 363, 364, 365, 371], "iter": [11, 12, 14, 15, 21, 24, 45, 47, 53, 55, 56, 69, 71, 147, 153, 160, 162, 191, 247, 253, 272, 288, 291, 298, 308, 321, 322, 359, 360, 362, 364, 365, 367, 369, 370, 391], "might": [11, 18, 20, 55, 128, 158, 159, 162, 189, 236, 243, 249, 255, 256, 257, 276, 280, 283, 288, 291, 322, 323], "failur": [11, 159, 198, 199, 254], "sometim": [11, 45, 48, 129, 168, 170, 247, 249, 253, 278, 279], "order": [11, 16, 38, 45, 47, 53, 55, 63, 129, 158, 161, 162, 164, 168, 170, 172, 182, 187, 193, 206, 236, 242, 243, 244, 250, 252, 253, 259, 272, 276, 278, 288, 291, 319, 322, 335], "suggest": [11, 52, 243, 251, 283], "two": [11, 12, 16, 18, 19, 22, 24, 26, 31, 33, 38, 39, 43, 45, 48, 49, 52, 55, 56, 69, 70, 71, 76, 122, 125, 129, 134, 137, 138, 142, 145, 146, 148, 151, 153, 156, 159, 160, 161, 162, 163, 168, 170, 174, 185, 186, 187, 188, 189, 190, 191, 196, 197, 204, 205, 209, 210, 212, 221, 222, 228, 230, 231, 239, 241, 243, 244, 245, 248, 249, 251, 252, 253, 254, 255, 267, 272, 275, 276, 279, 282, 284, 288, 291, 293, 295, 301, 304, 311, 316, 319, 322, 326, 330, 332, 333, 336, 337, 340, 341, 354, 357, 358, 364, 365, 368, 370, 371], "preprocess": [11, 21, 26, 54, 120, 121, 124, 126, 127, 133, 160, 168, 171, 222, 251, 255, 276, 279, 282, 285, 287, 326, 357, 358, 364, 368, 369], "non": [11, 13, 44, 45, 55, 159, 165, 170, 200, 230, 236, 247, 249, 252, 254, 263, 272], "traceabl": 11, "class": [11, 12, 13, 16, 19, 21, 22, 24, 28, 33, 38, 42, 43, 53, 55, 56, 62, 71, 75, 123, 124, 129, 133, 143, 148, 149, 150, 157, 158, 159, 160, 161, 162, 163, 165, 168, 174, 177, 179, 180, 183, 184, 185, 187, 188, 189, 190, 198, 213, 218, 236, 243, 248, 249, 251, 252, 253, 254, 256, 257, 267, 278, 284, 288, 289, 291, 311, 312, 314, 315, 317, 318, 319, 322, 323, 330, 332, 333, 336, 357, 362, 363, 364, 365, 370, 390], "select": [11, 12, 18, 32, 35, 36, 48, 53, 55, 120, 125, 129, 133, 159, 162, 170, 207, 208, 220, 221, 236, 239, 242, 244, 248, 249, 253, 254, 270, 272, 275, 279, 289, 291, 298, 308, 319, 369, 388], "pass": [11, 13, 14, 15, 16, 19, 21, 22, 24, 26, 34, 38, 42, 45, 47, 48, 49, 55, 56, 62, 65, 66, 129, 134, 137, 138, 142, 143, 158, 160, 162, 163, 168, 170, 174, 185, 189, 190, 193, 221, 223, 230, 236, 244, 245, 247, 249, 251, 252, 253, 254, 256, 257, 273, 275, 276, 278, 279, 286, 288, 289, 291, 322, 326, 335, 357, 358, 369, 370], "them": [11, 16, 21, 31, 34, 43, 45, 55, 72, 75, 121, 123, 124, 125, 126, 128, 129, 143, 148, 149, 158, 159, 160, 161, 162, 168, 170, 172, 187, 188, 189, 190, 209, 214, 215, 230, 236, 243, 244, 248, 249, 250, 251, 253, 254, 255, 256, 257, 259, 262, 267, 270, 275, 276, 279, 280, 282, 284, 287, 288, 289, 291, 311, 312, 313, 314, 315, 323, 332, 333, 336, 365, 366], "dict": [11, 38, 47, 53, 55, 168, 190, 249, 391], "These": [11, 13, 16, 35, 125, 128, 129, 158, 160, 161, 170, 186, 187, 189, 203, 218, 221, 222, 233, 245, 252, 253, 254, 259, 270, 272, 276, 277, 280, 295, 303, 304], "function": [11, 12, 14, 15, 16, 18, 19, 21, 24, 34, 35, 36, 38, 39, 45, 48, 52, 53, 55, 61, 63, 65, 66, 69, 70, 71, 73, 74, 75, 124, 126, 129, 134, 137, 138, 143, 148, 149, 153, 156, 159, 161, 162, 168, 170, 171, 173, 174, 176, 177, 178, 189, 218, 231, 235, 244, 248, 251, 253, 254, 256, 276, 288, 291, 293, 299, 301, 309, 311, 312, 313, 314, 316, 318, 319, 322, 323, 326, 329, 330, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "conv2d": [11, 13, 31, 53, 298, 308, 365], "won": [11, 119, 159, 160, 189, 251, 254, 295, 304, 320], "detect": [11, 18, 59, 86, 96, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 136, 172, 189, 209, 244, 253, 254, 317, 318, 320, 321, 322, 330, 331, 365, 367, 373, 391], "maskrcnn": [11, 111, 318, 320, 323, 324, 365], "net": [11, 13, 70, 71, 123, 126, 128, 133, 139, 140, 160, 200, 248, 318, 357, 358], "py": [11, 12, 13, 15, 18, 26, 32, 36, 41, 48, 51, 53, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 89, 97, 100, 101, 102, 103, 106, 108, 119, 120, 121, 124, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 162, 163, 164, 167, 173, 182, 187, 189, 190, 203, 214, 215, 222, 227, 242, 243, 245, 252, 253, 254, 257, 259, 260, 261, 263, 264, 265, 267, 270, 271, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 286, 288, 289, 291, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 307, 308, 311, 312, 313, 314, 315, 316, 318, 320, 322, 324, 326, 327, 328, 329, 330, 331, 332, 333, 336, 337, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 375, 376, 377, 382, 385, 387, 391], "prepare_custom_config_dict": [11, 318], "non_traceable_module_class": [11, 318], "anchorgener": [11, 318], "rpnpostprocessor": [11, 318], "pooler": [11, 298, 308, 318], "postprocessor": [11, 318], "maskrcnnfpnfeatureextractor": [11, 318], "maskpostprocessor": [11, 318], "fpn": [11, 318, 321, 322, 365, 367], "rpnhead": [11, 318], "decor": [11, 12, 15, 55, 171, 254], "wrap": [11, 26, 189, 223, 243, 326, 382, 385], "untrac": 11, "part": [11, 21, 24, 32, 33, 36, 39, 45, 59, 75, 124, 125, 129, 159, 160, 162, 167, 168, 170, 171, 189, 190, 197, 201, 203, 218, 223, 228, 236, 243, 244, 248, 249, 251, 252, 253, 254, 255, 256, 257, 259, 265, 267, 270, 282, 283, 288, 291, 326, 337, 348, 357, 370, 382, 385], "like": [11, 12, 15, 18, 20, 24, 27, 28, 33, 35, 41, 43, 45, 48, 55, 69, 70, 71, 73, 74, 79, 96, 98, 100, 103, 108, 119, 120, 122, 123, 124, 125, 129, 133, 134, 137, 138, 139, 142, 148, 149, 151, 153, 156, 157, 158, 159, 160, 161, 162, 164, 168, 170, 172, 179, 188, 189, 190, 191, 193, 202, 203, 206, 207, 210, 211, 213, 217, 222, 224, 231, 232, 239, 242, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 258, 265, 270, 272, 275, 276, 278, 282, 284, 285, 288, 289, 291, 293, 295, 296, 299, 301, 304, 311, 312, 313, 314, 316, 318, 319, 322, 323, 330, 332, 333, 336, 358, 359, 360, 365, 376], "global": [11, 47, 55, 129, 133, 161, 202, 219, 220, 243, 244, 254, 291, 298, 308, 322], "want": [11, 15, 16, 18, 19, 22, 26, 38, 42, 43, 52, 53, 55, 71, 72, 75, 125, 129, 148, 149, 159, 160, 161, 162, 168, 171, 189, 192, 214, 222, 236, 243, 245, 247, 248, 251, 252, 253, 254, 265, 270, 273, 275, 276, 279, 283, 288, 291, 298, 308, 309, 311, 320, 322, 335, 340, 341, 354, 359, 360, 376], "move": [11, 47, 51, 133, 159, 160, 162, 171, 172, 247, 256, 257, 259, 265, 272, 276, 288, 291, 331, 357, 358], "keep": [11, 15, 51, 69, 70, 71, 129, 133, 134, 137, 138, 142, 145, 146, 147, 148, 149, 150, 151, 153, 156, 159, 162, 167, 172, 174, 190, 244, 252, 255, 256, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 318, 326, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "should": [11, 12, 13, 15, 16, 18, 22, 26, 38, 42, 48, 54, 55, 56, 61, 63, 65, 66, 75, 101, 105, 123, 124, 126, 127, 129, 134, 137, 138, 142, 147, 158, 159, 161, 162, 163, 170, 172, 179, 189, 190, 193, 196, 198, 199, 213, 214, 218, 220, 222, 223, 231, 235, 236, 241, 243, 244, 245, 247, 249, 251, 252, 253, 254, 255, 257, 259, 267, 270, 272, 276, 277, 278, 279, 280, 288, 289, 291, 293, 295, 296, 299, 301, 304, 306, 309, 311, 312, 313, 314, 316, 322, 323, 328, 331, 335, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 382, 385, 389], "try": [11, 48, 73, 74, 129, 143, 159, 162, 170, 189, 198, 243, 244, 252, 253, 254, 276, 281, 288, 291, 313, 323], "ssd": [11, 57, 59, 126, 326, 329, 331, 365, 367, 391], "resnet34": [11, 57, 59, 143, 144, 147, 154, 326, 329, 365, 367], "ptq": [11, 26, 27, 35, 48, 53, 59, 134, 137, 138, 142, 148, 149, 150, 151, 156, 318, 326, 328, 330, 332, 333, 336, 357, 358, 359, 360, 361, 363, 365, 366, 368, 370, 371], "r34": [11, 326], "def": [11, 12, 13, 14, 15, 16, 22, 24, 26, 38, 42, 45, 48, 53, 55, 62, 70, 71, 75, 151, 153, 161, 162, 168, 189, 218, 236, 254, 256, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 318, 322, 330, 332, 333, 336, 340, 357, 362, 363, 364, 365, 371], "bboxes_labels_scor": 11, "bbox": [11, 38, 139, 218, 318, 319, 324, 329, 365], "prob": [11, 253], "criteria": [11, 16, 27, 55], "45": [11, 32, 50, 57, 139, 160, 284, 323], "max_output": 11, "200": [11, 55, 57, 130, 131, 132, 133, 139, 143, 265, 277, 319, 358, 367], "box": [11, 16, 18, 38, 53, 54, 55, 129, 159, 160, 190, 218, 221, 235, 251, 257, 272, 278, 317, 319, 321, 322, 331, 373, 381], "label": [11, 16, 22, 38, 45, 54, 62, 75, 81, 83, 87, 88, 93, 95, 110, 111, 112, 113, 114, 115, 116, 120, 123, 129, 141, 160, 165, 168, 172, 185, 187, 189, 190, 196, 214, 220, 221, 223, 231, 235, 236, 238, 245, 247, 249, 251, 253, 256, 278, 280, 282, 284, 319, 322, 330, 331, 357, 358, 362, 363, 365, 391], "score": [11, 38, 42, 45, 52, 55, 129, 133, 160, 161, 164, 172, 174, 195, 202, 224, 241, 244, 247, 251, 253, 259, 261, 267, 272, 275, 276, 277, 278, 279, 298, 308, 319, 327, 333, 354, 363, 364], "zip": [11, 105, 107, 155, 156, 168, 236, 253, 302, 318, 324, 326, 360, 361], "split": [11, 54, 139, 162, 168, 170, 188, 190, 191, 193, 196, 222, 244, 245, 247, 249, 251, 253, 255, 259, 276, 282, 288, 291, 322, 362], "squeez": [11, 133, 236, 391], "dbox": 11, "dlabel": 11, "dscore": 11, "decode_singl": 11, "append": [11, 13, 42, 43, 125, 145, 146, 168, 235, 236, 247, 276, 332, 333, 336], "process": [12, 14, 15, 16, 18, 19, 21, 22, 24, 25, 26, 27, 33, 43, 45, 48, 53, 54, 55, 56, 58, 59, 61, 63, 65, 66, 73, 74, 75, 120, 124, 129, 136, 143, 151, 158, 159, 160, 162, 163, 167, 168, 170, 171, 181, 187, 189, 194, 195, 196, 201, 204, 205, 207, 211, 213, 214, 217, 219, 220, 224, 227, 231, 234, 235, 243, 244, 247, 249, 251, 252, 253, 254, 255, 259, 267, 270, 272, 275, 276, 279, 283, 284, 288, 291, 295, 298, 303, 304, 308, 309, 322, 330, 335, 357, 358, 391], "autom": [12, 129, 133, 158, 236, 373], "design": [12, 16, 45, 48, 72, 129, 159, 162, 165, 195, 202, 224, 226, 231, 233, 234, 236, 244, 248, 256, 288, 291, 311, 331, 376], "artifici": 12, "ann": 12, "ha": [12, 15, 18, 21, 27, 33, 35, 39, 47, 48, 49, 52, 58, 75, 121, 122, 123, 124, 125, 127, 129, 133, 134, 136, 137, 138, 142, 143, 145, 146, 148, 149, 150, 156, 158, 159, 160, 162, 165, 168, 170, 171, 172, 174, 182, 185, 189, 191, 196, 197, 198, 199, 204, 205, 207, 210, 211, 213, 216, 217, 222, 223, 224, 227, 231, 233, 234, 235, 236, 237, 238, 239, 242, 243, 244, 245, 247, 249, 251, 252, 253, 254, 255, 261, 266, 267, 270, 272, 275, 276, 278, 279, 280, 282, 284, 288, 289, 291, 300, 318, 319, 323, 324, 330, 331, 332, 334, 335, 357, 365, 374, 391], "been": [12, 16, 18, 24, 33, 39, 58, 129, 133, 143, 159, 160, 161, 162, 163, 165, 168, 170, 171, 172, 174, 185, 189, 194, 196, 201, 210, 211, 217, 218, 230, 234, 236, 243, 244, 249, 251, 252, 253, 254, 255, 267, 270, 272, 276, 278, 284, 288, 291, 323, 359, 369, 391], "par": [12, 194, 231, 236], "outperform": [12, 194, 197, 202, 208, 209, 211, 212, 213, 214, 219, 220, 225, 228, 230, 236, 238, 239, 241, 242, 244], "hand": [12, 18, 75, 129, 159, 171, 216, 248, 252], "simplest": [12, 24, 374], "launcher": [12, 16, 24, 45, 75, 189, 257], "configur": [12, 13, 15, 16, 18, 19, 22, 25, 27, 38, 42, 51, 54, 57, 61, 63, 65, 66, 76, 123, 124, 127, 133, 134, 137, 138, 142, 148, 149, 150, 156, 158, 161, 162, 163, 167, 171, 183, 190, 227, 236, 243, 248, 251, 252, 253, 254, 256, 257, 275, 277, 288, 289, 291, 294, 295, 297, 298, 302, 303, 304, 307, 308, 310, 311, 312, 314, 315, 318, 322, 324, 326, 329, 330, 337, 357, 358, 362, 364, 370, 375, 386], "agent": [12, 159], "path": [12, 13, 15, 16, 18, 19, 21, 22, 24, 26, 33, 34, 38, 40, 41, 45, 54, 55, 56, 63, 65, 66, 69, 71, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 125, 127, 133, 134, 137, 138, 142, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 156, 158, 162, 163, 167, 168, 172, 189, 190, 192, 243, 254, 260, 261, 263, 264, 265, 266, 270, 271, 275, 278, 288, 291, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 311, 313, 318, 320, 322, 324, 326, 327, 328, 329, 330, 331, 332, 333, 336, 338, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 356, 357, 358, 360, 361, 362, 363, 364, 365, 368, 369, 370, 371, 374, 377, 386, 387, 391], "syntax": [12, 16, 31, 161, 189, 278, 331], "dyna": [12, 35, 47], "section": [12, 18, 24, 45, 47, 56, 119, 124, 160, 161, 162, 163, 168, 171, 189, 236, 244, 245, 249, 250, 253, 256, 276, 282, 284, 288, 291, 321, 328], "option": [12, 16, 19, 21, 22, 28, 31, 33, 39, 54, 55, 56, 61, 63, 65, 66, 69, 71, 75, 82, 123, 125, 129, 134, 137, 138, 139, 141, 142, 151, 153, 156, 161, 163, 170, 174, 185, 189, 207, 236, 243, 249, 252, 254, 256, 257, 265, 267, 274, 275, 276, 278, 280, 322, 324, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 381], "search_algorithm": 12, "nsga2": 12, "seed": [12, 21, 28, 55, 56, 69, 70, 131, 134, 137, 138, 142, 156, 254, 263, 280, 282, 294, 295, 297, 302, 304, 305, 307, 308, 357, 358, 365, 370, 391], "42": [12, 44, 57, 133, 139, 140, 218, 249, 254, 263, 267, 277, 303, 307, 321, 391], "supernet": 12, "ofa_mbv3_d234_e346_k357_w1": 12, "acc": [12, 13, 32, 50, 53, 57, 70, 136, 143, 256, 272, 280, 293, 299, 301, 303, 311, 312, 313, 314, 316, 360], "mac": 12, "popul": [12, 129, 236, 276], "50": [12, 32, 33, 57, 59, 63, 119, 129, 139, 140, 141, 148, 149, 150, 151, 153, 160, 171, 182, 244, 250, 253, 254, 255, 264, 265, 274, 276, 309, 319, 321, 322, 326, 331, 350, 358, 360, 367, 370, 391], "num_ev": 12, "250": [12, 133, 143, 253], "results_csv_path": 12, "search_result": 12, "csv": [12, 18, 163, 236, 275, 280, 286, 368], "batch_siz": [12, 13, 16, 19, 21, 22, 26, 33, 34, 48, 61, 62, 63, 65, 66, 69, 70, 71, 75, 79, 96, 98, 134, 137, 138, 142, 148, 149, 150, 156, 161, 163, 168, 170, 236, 245, 265, 282, 295, 296, 299, 303, 304, 318, 330, 331, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 367, 368, 370, 371, 373, 386, 387, 391], "64": [12, 13, 32, 54, 57, 129, 133, 141, 143, 154, 168, 247, 250, 256, 267, 276, 280, 321, 331, 357, 360, 364, 391], "dataset_path": [12, 391], "imagenet": [12, 14, 32, 53, 54, 56, 57, 61, 63, 65, 66, 69, 75, 79, 80, 81, 83, 84, 85, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 133, 134, 137, 138, 142, 144, 145, 146, 147, 148, 149, 150, 151, 153, 321, 331, 356, 357, 358, 377], "ilsvrc2012": [12, 141], "nasconfig": 12, "argument": [12, 19, 24, 33, 75, 129, 133, 159, 163, 168, 170, 171, 186, 189, 198, 203, 215, 219, 231, 236, 249, 251, 253, 254, 256, 257, 267, 273, 275, 276, 278, 279, 295, 304, 322, 336, 365, 371], "config": [12, 18, 22, 24, 26, 33, 35, 40, 45, 47, 49, 53, 55, 59, 60, 65, 66, 67, 68, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 133, 144, 147, 148, 152, 154, 155, 158, 161, 162, 163, 167, 170, 189, 192, 219, 220, 231, 236, 243, 247, 251, 252, 253, 254, 276, 288, 291, 297, 300, 302, 305, 306, 307, 309, 310, 315, 322, 325, 326, 331, 356, 386, 387, 391], "under": [12, 13, 18, 22, 33, 37, 38, 43, 45, 48, 53, 55, 58, 71, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 123, 158, 159, 161, 162, 163, 170, 171, 189, 207, 222, 225, 242, 243, 252, 254, 261, 267, 274, 275, 276, 283, 285, 288, 291, 311, 322, 335, 359, 360, 362, 363, 364, 370, 373, 376, 377, 389], "file": [12, 15, 16, 18, 22, 26, 30, 33, 34, 37, 38, 40, 42, 45, 47, 53, 54, 55, 72, 76, 79, 96, 98, 105, 107, 120, 122, 123, 124, 125, 126, 129, 133, 148, 158, 159, 160, 161, 162, 163, 167, 168, 171, 172, 173, 180, 181, 183, 187, 188, 189, 190, 193, 198, 212, 218, 220, 222, 223, 227, 229, 231, 235, 236, 240, 252, 253, 259, 262, 263, 265, 266, 267, 270, 272, 275, 276, 278, 280, 282, 288, 289, 291, 294, 295, 296, 297, 302, 303, 304, 307, 310, 315, 320, 322, 324, 326, 327, 329, 331, 335, 337, 374, 382, 385, 386, 388, 389, 390], "input": [12, 15, 16, 18, 21, 22, 24, 26, 31, 33, 34, 38, 39, 40, 45, 47, 48, 53, 54, 56, 73, 74, 75, 79, 96, 98, 117, 118, 120, 122, 125, 129, 133, 141, 143, 158, 160, 161, 162, 167, 168, 171, 174, 183, 185, 187, 188, 189, 191, 195, 196, 197, 198, 201, 202, 203, 205, 206, 207, 209, 213, 214, 215, 218, 221, 223, 224, 225, 227, 228, 231, 234, 235, 236, 237, 238, 239, 241, 242, 244, 245, 247, 251, 253, 254, 255, 256, 259, 275, 276, 279, 284, 288, 291, 319, 327, 331, 357, 358, 359, 360, 362, 363, 364, 365, 369, 371, 373, 376, 387, 388, 391], "aim": [12, 21, 55, 160, 201, 227, 243, 275, 322, 373], "accord": [12, 15, 22, 26, 45, 49, 54, 55, 65, 66, 162, 170, 189, 193, 223, 227, 236, 247, 252, 253, 254, 255, 259, 288, 289, 291, 322, 340, 354, 388], "regist": [12, 15, 16, 19, 22, 26, 38, 42, 55, 61, 63, 65, 66, 69, 73, 74, 75, 119, 123, 134, 137, 138, 142, 254, 357, 358, 370], "__new__": 12, "self": [12, 13, 15, 16, 18, 22, 35, 38, 42, 52, 53, 55, 59, 62, 75, 124, 158, 160, 162, 165, 168, 170, 171, 189, 190, 191, 194, 202, 219, 221, 224, 229, 234, 236, 238, 240, 244, 254, 261, 284, 288, 291, 318, 322, 330, 332, 333, 336, 357, 358, 362, 363, 364, 365, 370], "conf_fname_or_obj": [12, 16], "kwarg": [12, 190, 318, 358], "current": [12, 13, 15, 16, 18, 26, 27, 28, 31, 38, 42, 45, 48, 55, 76, 124, 126, 129, 139, 143, 151, 159, 160, 162, 163, 171, 172, 182, 188, 189, 244, 245, 252, 253, 254, 255, 257, 267, 272, 278, 288, 289, 291, 292, 295, 298, 304, 308, 322, 324, 326, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 375, 387, 389], "built": [12, 15, 16, 19, 26, 27, 42, 54, 55, 56, 59, 60, 61, 63, 65, 66, 69, 75, 134, 136, 137, 138, 142, 148, 149, 150, 151, 153, 156, 158, 160, 161, 168, 170, 189, 205, 243, 248, 251, 256, 257, 272, 273, 276, 320, 328, 357, 358, 360, 370, 380, 384], "inherit": [12, 15, 21, 124, 162, 184, 187, 225, 227, 248, 254, 276, 288, 291], "base": [12, 15, 22, 25, 26, 27, 28, 31, 32, 44, 52, 53, 55, 57, 59, 70, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 123, 124, 125, 126, 127, 129, 133, 158, 160, 161, 162, 163, 165, 167, 168, 170, 171, 180, 183, 185, 187, 188, 189, 190, 192, 193, 194, 196, 197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 212, 213, 215, 216, 217, 219, 220, 224, 226, 228, 229, 230, 233, 234, 236, 240, 241, 242, 243, 245, 248, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 263, 266, 267, 270, 271, 272, 273, 275, 278, 280, 281, 282, 286, 288, 289, 291, 293, 294, 295, 297, 298, 302, 303, 304, 305, 306, 307, 308, 311, 313, 314, 317, 357, 358, 359, 364, 376, 377], "nasbas": 12, "own": [12, 18, 21, 22, 35, 38, 42, 52, 55, 73, 74, 119, 123, 124, 129, 133, 154, 159, 160, 163, 168, 170, 189, 190, 223, 236, 243, 248, 251, 253, 255, 256, 259, 268, 270, 276, 277, 278, 279, 280, 282, 285, 357, 358, 370, 371], "just": [12, 13, 14, 32, 33, 43, 48, 54, 55, 69, 70, 71, 119, 124, 129, 133, 134, 137, 138, 142, 148, 149, 151, 153, 156, 157, 159, 160, 162, 168, 172, 182, 188, 189, 190, 195, 198, 206, 207, 209, 210, 213, 220, 225, 229, 233, 236, 238, 240, 243, 244, 247, 248, 249, 251, 252, 254, 255, 256, 257, 262, 275, 276, 279, 280, 282, 288, 291, 293, 299, 311, 312, 313, 314, 318, 330, 332, 357, 365, 370, 371, 378, 381], "nas_registri": 12, "well": [12, 13, 22, 48, 51, 56, 69, 70, 71, 123, 124, 129, 137, 157, 158, 161, 162, 168, 175, 187, 189, 193, 194, 200, 201, 209, 211, 212, 219, 224, 233, 235, 236, 241, 244, 245, 247, 249, 252, 253, 255, 256, 267, 268, 270, 284, 288, 291, 293, 298, 299, 301, 303, 308, 311, 312, 313, 314, 316, 319, 322, 323, 332, 333, 336, 358, 365], "wai": [12, 18, 21, 22, 38, 43, 45, 48, 55, 56, 76, 124, 129, 137, 138, 142, 143, 156, 157, 159, 162, 168, 170, 172, 186, 188, 189, 194, 198, 199, 211, 220, 231, 236, 243, 244, 247, 248, 249, 251, 252, 254, 255, 276, 278, 284, 285, 287, 288, 291, 298, 308, 332, 365, 373, 374], "__init__": [12, 13, 15, 16, 22, 38, 42, 55, 62, 75, 159, 162, 168, 190, 236, 288, 289, 291, 318, 322, 330, 332, 333, 336, 362, 363, 364], "search_spac": 12, "none": [12, 13, 15, 16, 22, 38, 48, 53, 54, 55, 161, 162, 168, 174, 185, 231, 236, 249, 251, 254, 288, 291, 299, 311, 312, 314, 315, 318, 330, 332, 333, 336, 358, 391], "model_build": 12, "initi": [12, 13, 16, 21, 22, 33, 38, 39, 45, 55, 119, 120, 162, 196, 209, 210, 223, 230, 236, 243, 244, 248, 251, 252, 253, 255, 256, 267, 275, 284, 288, 291, 311, 312, 314, 315, 321, 326, 331, 359, 360, 363, 364], "select_model_arch": 12, "propos": [12, 15, 24, 39, 45, 129, 162, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 209, 211, 213, 214, 215, 216, 217, 218, 219, 221, 224, 225, 227, 228, 229, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 244, 253, 261, 272, 290, 292], "next": [12, 18, 39, 47, 55, 129, 161, 168, 170, 172, 189, 195, 203, 214, 215, 221, 229, 233, 236, 239, 240, 243, 244, 245, 249, 253, 254, 255, 265], "res_save_path": 12, "estim": [12, 13, 14, 55, 124, 129, 151, 153, 267, 288, 291, 359], "pragma": 12, "depend": [12, 20, 30, 31, 33, 47, 55, 121, 124, 129, 130, 131, 132, 133, 143, 158, 160, 161, 162, 189, 201, 202, 205, 214, 225, 228, 231, 236, 237, 242, 244, 245, 250, 253, 254, 255, 267, 272, 279, 288, 289, 291, 300, 320, 328, 332, 333, 336], "load_search_result": 12, "load": [12, 13, 21, 47, 48, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 129, 133, 139, 140, 143, 158, 160, 162, 167, 168, 180, 183, 187, 190, 193, 209, 210, 216, 243, 247, 248, 251, 253, 254, 256, 265, 275, 276, 278, 279, 287, 288, 291, 317, 322, 324, 362, 364, 371, 380, 384], "exist": [12, 16, 33, 38, 45, 55, 59, 123, 158, 159, 161, 162, 165, 187, 189, 194, 198, 199, 202, 209, 216, 243, 244, 251, 252, 254, 267, 272, 275, 276, 287, 288, 291, 326, 375], "dump_search_result": 12, "find_best_model_arch": 12, "pareto": 12, "front": 12, "setter": [12, 171], "callabl": [12, 190], "leverag": [12, 24, 33, 43, 48, 59, 76, 160, 165, 170, 171, 196, 203, 206, 207, 210, 211, 214, 215, 218, 225, 226, 239, 251, 252, 253, 257, 259, 270, 272, 282, 285, 322, 373], "grid": 12, "random": [12, 28, 47, 54, 56, 69, 134, 137, 138, 142, 156, 162, 244, 253, 263, 284, 288, 291, 357, 358, 365, 370, 391], "bayesian": [12, 37, 47], "given": [12, 21, 45, 54, 104, 124, 129, 159, 160, 163, 168, 171, 172, 187, 188, 192, 198, 199, 203, 209, 215, 235, 236, 243, 244, 248, 249, 251, 253, 254, 255, 266, 275, 278, 280, 283, 284, 288, 362], "evalu": [12, 13, 14, 15, 16, 21, 22, 24, 33, 34, 35, 38, 39, 41, 42, 45, 48, 52, 53, 55, 56, 61, 62, 63, 65, 66, 67, 69, 70, 71, 75, 120, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 160, 162, 165, 168, 171, 179, 187, 189, 190, 194, 198, 199, 206, 208, 211, 212, 216, 217, 219, 220, 230, 237, 241, 247, 252, 255, 256, 257, 259, 261, 264, 265, 266, 267, 278, 280, 288, 291, 293, 296, 299, 301, 306, 311, 312, 313, 314, 316, 318, 324, 330, 331, 332, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 360, 361, 362, 366, 367, 368, 369, 370, 373, 377, 381], "potenti": [12, 162, 189, 203, 237, 243, 251, 254, 275, 288, 291], "after": [12, 13, 14, 16, 18, 19, 21, 22, 24, 35, 38, 41, 42, 43, 45, 48, 49, 52, 53, 54, 55, 65, 66, 69, 70, 71, 73, 74, 124, 126, 129, 133, 134, 137, 138, 142, 148, 149, 150, 151, 153, 155, 156, 158, 159, 161, 162, 189, 210, 213, 221, 233, 236, 244, 252, 253, 254, 255, 256, 267, 276, 277, 278, 279, 284, 288, 291, 296, 318, 323, 326, 330, 332, 357, 359, 360, 362, 363, 364, 365, 370, 371, 380, 381, 384], "sever": [12, 13, 18, 24, 35, 39, 45, 47, 54, 56, 124, 126, 129, 133, 158, 159, 160, 161, 168, 170, 184, 186, 187, 188, 189, 190, 214, 215, 216, 218, 221, 224, 234, 236, 244, 249, 252, 253, 254, 255, 256, 266, 267, 274, 295, 298, 299, 304, 308, 311, 312, 313, 314, 315, 380, 384], "procedur": [12, 119, 162, 197, 247, 288, 291, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "lie": 12, "through": [12, 13, 16, 31, 32, 34, 35, 36, 38, 42, 43, 47, 52, 59, 119, 157, 158, 159, 162, 168, 172, 179, 189, 191, 206, 221, 223, 225, 227, 244, 249, 251, 252, 253, 255, 256, 257, 278, 284, 285, 288, 291, 335, 374], "basic_na": 12, "basicna": 12, "super": [12, 13, 14, 42, 162, 172, 243, 288, 291], "predictor": [12, 322], "predict": [12, 13, 16, 24, 38, 53, 54, 62, 63, 75, 120, 124, 125, 129, 133, 160, 161, 162, 165, 168, 170, 171, 174, 189, 193, 195, 203, 204, 205, 209, 213, 214, 215, 221, 224, 225, 229, 234, 236, 239, 240, 244, 245, 247, 249, 250, 251, 252, 253, 256, 263, 275, 278, 284, 288, 291, 322, 331, 357, 358], "4x": [12, 13, 48], "than": [12, 13, 14, 16, 22, 34, 38, 42, 43, 45, 48, 52, 54, 124, 125, 129, 133, 136, 139, 143, 158, 159, 160, 162, 163, 164, 167, 168, 170, 171, 172, 185, 189, 191, 193, 195, 197, 200, 202, 203, 206, 207, 209, 214, 215, 218, 222, 224, 230, 234, 236, 237, 239, 241, 242, 243, 244, 245, 247, 250, 251, 252, 253, 254, 255, 256, 259, 261, 267, 273, 275, 276, 277, 278, 280, 282, 284, 288, 291, 293, 300, 322, 331, 335, 357, 365], "typic": [12, 16, 25, 45, 69, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 159, 189, 193, 244, 247, 357, 358], "figur": [12, 45, 72, 73, 74, 129, 159, 162, 244, 266, 276, 284, 288, 291, 380, 381, 384], "first": [12, 13, 14, 15, 18, 22, 33, 36, 39, 47, 48, 49, 52, 53, 55, 56, 63, 69, 70, 71, 119, 123, 124, 127, 129, 134, 137, 138, 148, 149, 150, 151, 153, 156, 158, 159, 160, 161, 162, 163, 168, 170, 172, 179, 187, 189, 190, 194, 196, 197, 203, 204, 205, 206, 212, 213, 218, 219, 221, 222, 223, 224, 228, 231, 235, 236, 238, 241, 243, 244, 249, 251, 253, 254, 255, 256, 265, 267, 272, 276, 279, 284, 286, 288, 289, 291, 319, 320, 322, 357, 359, 360, 365, 371, 381, 382, 385], "phase": [12, 45, 48, 49, 55, 207, 252, 358], "small": [12, 14, 18, 55, 59, 129, 133, 159, 162, 171, 189, 191, 207, 208, 209, 215, 219, 232, 243, 244, 247, 250, 253, 267, 272, 273, 278, 279, 288, 291, 293, 295, 304, 340, 341, 354], "sub": [12, 19, 162, 168, 188, 189, 190, 242, 288, 291, 357, 358], "randomli": [12, 54, 55, 120, 129, 162, 170, 193, 209, 223, 236, 244, 253, 254, 256, 270, 275, 284, 288, 291, 317, 369], "measur": [12, 15, 16, 19, 24, 33, 38, 41, 50, 53, 55, 59, 60, 65, 66, 163, 198, 199, 201, 207, 227, 233, 254, 267, 331, 371], "provid": [12, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 32, 35, 36, 39, 40, 47, 48, 53, 56, 57, 61, 63, 65, 66, 69, 70, 71, 73, 74, 123, 124, 126, 129, 134, 137, 138, 142, 148, 149, 150, 151, 156, 157, 158, 159, 160, 161, 162, 167, 171, 172, 175, 176, 180, 183, 184, 188, 189, 190, 194, 198, 199, 203, 211, 216, 227, 230, 236, 244, 245, 247, 248, 249, 251, 252, 253, 254, 256, 257, 261, 263, 267, 275, 278, 280, 282, 285, 287, 288, 291, 293, 296, 298, 299, 301, 305, 308, 311, 312, 313, 314, 315, 316, 317, 318, 319, 322, 323, 330, 342, 343, 345, 346, 347, 349, 350, 351, 352, 353, 357, 358, 362, 363, 364, 370, 373, 375, 381], "inner": [12, 164, 284], "loop": [12, 14, 31, 52, 55, 160, 170, 179, 189, 236, 243, 247, 251, 254], "multi": [12, 21, 22, 35, 42, 45, 59, 135, 162, 165, 171, 187, 189, 191, 193, 198, 199, 216, 221, 235, 239, 240, 241, 244, 250, 253, 275, 276, 278, 280, 288, 291, 295, 304, 317, 340, 341, 354], "evolutionari": 12, "extens": [12, 15, 27, 31, 35, 39, 40, 46, 55, 56, 72, 134, 137, 138, 142, 158, 160, 161, 171, 189, 196, 216, 219, 223, 236, 239, 242, 252, 276, 300, 358, 377, 378, 382, 385], "cycl": [12, 21, 162, 288, 291], "continu": [12, 16, 45, 129, 157, 159, 162, 189, 194, 211, 253, 254, 276, 288, 291], "until": [12, 33, 55, 126, 151, 153, 162, 249, 254, 255, 276, 288, 291, 293, 330], "conclud": [12, 159], "count": [12, 13, 22, 124, 200, 236, 250, 253, 255, 267, 272], "create_acc_predictor": 12, "create_macs_predictor": 12, "create_latency_predictor": 12, "latenc": [12, 32, 33, 52, 55, 69, 71, 72, 73, 74, 126, 189, 217, 224, 326, 360], "mobilenetv3": [12, 133, 134], "static": [13, 14, 15, 35, 55, 57, 59, 161, 222, 227, 259, 313, 323, 373, 376, 377, 378, 381], "involv": [13, 157, 158, 159, 168, 170, 193, 236, 247, 253], "float": [13, 14, 17, 22, 28, 38, 47, 48, 54, 71, 119, 129, 161, 162, 190, 217, 236, 238, 252, 288, 291, 387], "int": [13, 22, 38, 45, 47, 54, 82, 129, 161, 168, 182, 218, 249, 251, 253, 298, 308], "feed": [13, 24, 168, 224, 235, 236, 244, 245, 249, 250, 251, 255, 365], "batch": [13, 14, 16, 18, 21, 24, 33, 45, 50, 54, 57, 65, 66, 75, 124, 129, 138, 141, 147, 151, 153, 163, 168, 170, 184, 185, 188, 189, 190, 193, 223, 227, 233, 236, 244, 245, 249, 251, 252, 256, 259, 261, 263, 264, 265, 270, 278, 280, 284, 298, 299, 308, 309, 311, 312, 314, 315, 318, 319, 322, 326, 328, 329, 331, 337, 359, 360, 362, 363, 364, 369, 391], "comput": [13, 14, 25, 27, 38, 39, 45, 48, 55, 73, 74, 120, 124, 129, 133, 136, 158, 160, 163, 164, 170, 171, 185, 188, 189, 191, 196, 202, 203, 204, 205, 207, 209, 213, 215, 234, 237, 244, 247, 249, 252, 253, 255, 265, 266, 267, 276, 277, 298, 308, 317, 322, 364, 373, 381], "done": [13, 14, 24, 41, 45, 48, 62, 69, 70, 71, 119, 124, 126, 129, 133, 134, 137, 138, 142, 145, 146, 148, 149, 151, 153, 156, 159, 160, 161, 162, 163, 168, 170, 172, 189, 190, 209, 220, 233, 235, 236, 237, 243, 244, 251, 252, 253, 254, 255, 276, 284, 288, 289, 291, 318, 322, 330, 332, 359, 360, 362, 363, 364, 365, 371], "observ": [13, 28, 52, 53, 55, 159, 202, 203, 214, 215, 234, 244, 254], "point": [13, 14, 17, 27, 28, 38, 48, 54, 55, 76, 120, 121, 123, 129, 158, 159, 162, 172, 189, 191, 195, 198, 199, 212, 217, 236, 249, 252, 254, 255, 272, 275, 276, 283, 288, 291, 320, 322, 326], "time": [13, 14, 26, 30, 42, 45, 46, 48, 52, 53, 54, 55, 72, 73, 74, 120, 126, 129, 133, 134, 136, 137, 138, 142, 148, 149, 150, 151, 153, 157, 158, 159, 160, 162, 163, 168, 170, 171, 172, 189, 191, 196, 200, 211, 217, 218, 220, 223, 229, 231, 236, 237, 238, 240, 241, 242, 243, 244, 245, 247, 249, 251, 253, 254, 255, 258, 267, 275, 276, 278, 279, 280, 288, 291, 317, 318, 321, 322, 326, 330, 331, 337, 359, 360, 362, 363, 364, 365, 376, 378, 380, 384, 391], "would": [13, 20, 33, 39, 48, 120, 123, 124, 129, 139, 158, 159, 161, 162, 168, 174, 185, 189, 200, 216, 231, 243, 244, 247, 249, 251, 252, 253, 254, 255, 256, 257, 258, 265, 275, 278, 279, 285, 286, 288, 291, 322, 365], "simpli": [13, 26, 40, 119, 124, 126, 129, 158, 162, 163, 168, 170, 247, 252, 254, 255, 256, 267, 272, 276, 288, 289, 291, 296, 322, 373, 376], "divid": [13, 55, 143, 231, 244, 255, 284, 322], "rang": [13, 14, 15, 22, 24, 26, 28, 45, 48, 54, 123, 143, 151, 153, 160, 161, 165, 168, 170, 189, 193, 195, 204, 205, 207, 208, 214, 219, 230, 236, 241, 247, 252, 253, 256, 278, 291, 298, 308, 332, 362, 365], "256": [13, 19, 21, 22, 26, 54, 55, 57, 69, 133, 134, 137, 138, 139, 142, 143, 147, 148, 149, 150, 159, 244, 250, 255, 276, 313, 386], "sophist": 13, "addit": [13, 18, 24, 33, 51, 124, 129, 133, 158, 160, 161, 162, 163, 164, 170, 171, 172, 186, 188, 189, 190, 194, 195, 205, 209, 213, 218, 223, 236, 244, 249, 250, 251, 253, 255, 257, 261, 272, 274, 276, 279, 282, 293, 301, 311, 312, 313, 314, 319, 322, 365, 381], "step": [13, 14, 18, 20, 24, 25, 26, 39, 45, 47, 49, 52, 53, 55, 119, 124, 125, 127, 129, 158, 161, 168, 171, 172, 174, 189, 190, 211, 229, 236, 240, 244, 247, 249, 251, 254, 255, 256, 257, 267, 276, 280, 284, 285, 298, 308, 322, 366, 382, 385, 389, 391], "allow": [13, 14, 18, 19, 24, 26, 28, 33, 38, 39, 47, 55, 56, 61, 63, 65, 66, 69, 123, 133, 134, 137, 138, 142, 143, 156, 157, 158, 159, 160, 162, 163, 168, 188, 189, 203, 214, 215, 216, 230, 231, 236, 243, 244, 247, 248, 251, 252, 253, 254, 255, 256, 275, 276, 280, 284, 288, 291, 317, 319, 357, 358, 365, 370], "u": [13, 124, 125, 138, 147, 157, 158, 159, 161, 162, 163, 168, 172, 205, 207, 249, 252, 254, 255, 256, 267, 283, 288, 291, 298, 299, 308, 311, 312, 314, 373], "instead": [13, 123, 124, 129, 158, 159, 160, 162, 163, 168, 171, 189, 190, 199, 200, 205, 209, 223, 229, 231, 234, 236, 240, 243, 244, 247, 249, 251, 252, 253, 254, 270, 288, 291, 374, 376], "back": [13, 129, 158, 159, 160, 171, 188, 190, 212, 243, 244, 249, 251, 255, 261, 275, 282, 283, 317], "everi": [13, 15, 45, 55, 126, 129, 148, 149, 158, 159, 160, 161, 162, 163, 170, 171, 190, 220, 231, 233, 234, 235, 236, 243, 253, 254, 255, 272, 276, 278, 283, 288, 291, 376, 380, 384], "pre": [13, 22, 24, 33, 39, 45, 46, 48, 53, 55, 57, 139, 156, 159, 160, 162, 163, 164, 165, 167, 168, 171, 189, 193, 195, 196, 197, 202, 203, 204, 205, 206, 207, 209, 210, 211, 214, 215, 218, 221, 223, 224, 225, 226, 227, 228, 229, 230, 235, 236, 238, 240, 242, 244, 250, 253, 255, 256, 259, 261, 265, 267, 272, 276, 278, 279, 284, 287, 288, 291, 294, 295, 297, 302, 303, 304, 307, 321, 322, 365], "notabl": [13, 194, 237], "modif": [13, 15, 21, 31, 124, 129, 133, 159, 168, 195, 222, 248, 251, 267, 276, 280, 322, 376], "floatfunct": 13, "quantstub": [13, 134, 137, 138, 142, 145, 146, 148, 151, 156, 330, 332], "dequantstub": [13, 134, 137, 138, 142, 145, 146, 148, 151, 156, 330, 332], "begin": [13, 24, 45, 55, 159, 161, 162, 168, 170, 188, 231, 243, 244, 252, 253, 254, 256, 288, 291, 298, 308], "end": [13, 14, 15, 24, 31, 32, 33, 36, 42, 45, 53, 54, 55, 59, 73, 74, 75, 106, 123, 125, 129, 151, 153, 158, 160, 161, 162, 168, 170, 172, 196, 206, 208, 217, 231, 236, 244, 245, 250, 252, 253, 254, 255, 256, 257, 265, 268, 288, 291, 298, 308, 354, 364, 381], "relu6": [13, 31], "relu": [13, 31, 53, 134, 137, 138, 142, 148, 151, 156, 330, 332], "_make_divis": 13, "v": [13, 33, 56, 59, 73, 74, 124, 129, 141, 151, 158, 160, 170, 171, 204, 205, 225, 234, 237, 242, 254, 278, 280, 282, 291, 301, 316, 317, 320, 326, 337], "divisor": 13, "min_valu": 13, "taken": [13, 129, 194, 247, 331, 362], "origin": [13, 22, 33, 45, 48, 54, 56, 70, 71, 129, 133, 143, 158, 159, 160, 167, 168, 170, 188, 189, 191, 193, 195, 196, 197, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 221, 222, 223, 224, 225, 226, 228, 231, 233, 235, 236, 237, 239, 241, 242, 248, 249, 250, 252, 253, 254, 265, 266, 267, 270, 272, 274, 278, 282, 283, 284, 293, 294, 297, 299, 301, 302, 305, 307, 309, 311, 312, 313, 314, 316, 319, 324, 326, 332, 333, 336, 365, 376], "repo": [13, 22, 29, 58, 61, 63, 65, 66, 119, 139, 158, 160, 162, 172, 189, 222, 227, 243, 254, 257, 264, 274, 276, 286, 287, 288, 291, 332, 333, 335, 336, 357, 358, 380, 382, 384, 385], "ensur": [13, 18, 26, 28, 48, 54, 75, 79, 96, 98, 123, 124, 126, 129, 162, 163, 168, 189, 216, 231, 252, 254, 255, 288, 289, 291, 296, 332, 333, 335, 336], "layer": [13, 15, 21, 25, 35, 45, 51, 55, 131, 148, 149, 162, 165, 170, 171, 189, 190, 191, 195, 196, 200, 204, 205, 209, 213, 217, 219, 220, 221, 222, 223, 227, 231, 234, 235, 244, 250, 252, 253, 254, 255, 256, 266, 267, 272, 276, 288, 291, 296, 298, 308, 331, 357], "channel": [13, 15, 32, 35, 36, 45, 54, 57, 59, 123, 125, 143, 157, 160, 172, 190, 212, 373, 378, 391], "number": [13, 14, 18, 22, 26, 28, 38, 45, 48, 52, 54, 55, 59, 65, 66, 69, 71, 74, 124, 125, 129, 143, 158, 160, 162, 168, 170, 171, 189, 190, 191, 198, 199, 208, 218, 220, 227, 231, 236, 244, 247, 248, 249, 251, 252, 253, 254, 255, 256, 266, 272, 275, 278, 284, 288, 291, 295, 299, 304, 312, 314, 319, 321, 322, 331, 332, 333, 336, 362, 364, 391], "divis": [13, 253], "seen": [13, 15, 124, 159, 236, 243, 249, 253, 255, 278, 284], "blob": [13, 80, 329, 363, 364, 377], "master": [13, 129, 133, 162, 172, 212, 254, 272, 276, 288, 291, 295, 304, 320, 329, 335, 363, 364, 366, 368], "research": [13, 37, 129, 133, 136, 143, 160, 161, 162, 165, 172, 194, 198, 199, 201, 205, 206, 208, 209, 211, 216, 230, 244, 248, 251, 257, 274, 276, 288, 291, 322, 357, 370], "slim": [13, 40, 59, 60, 63, 133, 143, 357, 358, 370], "mobilenet": [13, 52, 57, 59, 71, 75, 133, 136, 148, 149, 339, 345, 356, 365], "param": [13, 15, 40, 55, 70, 133, 141, 189, 254, 256, 264, 291, 391], "new_v": 13, "max": [13, 17, 18, 48, 54, 55, 143, 247, 249, 250, 277, 282, 298, 308, 359, 362, 365, 391], "round": [13, 14, 17, 28, 48, 251, 253, 340], "down": [13, 159, 162, 170, 225, 247, 252, 254, 255, 272, 288, 291, 303, 381], "go": [13, 31, 47, 54, 119, 158, 159, 160, 161, 162, 168, 170, 172, 189, 222, 236, 243, 244, 249, 288, 291, 331, 335, 382, 385, 390], "convbnrelu": 13, "sequenti": [13, 43, 55, 133, 160, 165, 171, 213, 236, 242, 244], "in_plan": 13, "out_plan": 13, "kernel_s": 13, "stride": [13, 54, 234, 247], "group": [13, 35, 45, 53, 54, 55, 57, 59, 160, 168, 171, 191, 222, 234, 236, 244, 251, 253, 254, 255, 256, 298, 308, 309, 391], "pad": [13, 22, 54, 133, 165, 168, 170, 171, 181, 191, 195, 203, 206, 214, 215, 219, 222, 224, 227, 234, 235, 236, 237, 251, 252, 253, 256, 277, 319], "bia": [13, 53, 124, 162, 243, 256, 276, 288, 291], "fals": [13, 14, 15, 16, 21, 22, 31, 38, 42, 47, 48, 53, 54, 55, 56, 66, 75, 133, 143, 150, 156, 162, 163, 168, 189, 190, 196, 197, 222, 236, 249, 253, 254, 256, 257, 265, 288, 290, 291, 298, 299, 308, 312, 314, 315, 318, 326, 328, 329, 330, 336, 337, 362, 380, 384, 391], "batchnorm2d": 13, "momentum": [13, 35, 45, 56, 59, 124, 143, 298, 308, 317], "inplac": [13, 14], "invertedresidu": 13, "inp": 13, "oup": 13, "expand_ratio": 13, "assert": [13, 42, 159, 162, 193, 227, 254, 288, 291, 336, 337], "hidden_dim": [13, 251], "use_res_connect": 13, "pw": 13, "extend": [13, 62, 75, 170, 189, 206, 223, 236, 239, 248], "dw": 13, "linear": [13, 24, 143, 162, 189, 190, 209, 244, 250, 288, 291, 298, 308, 332], "conv": [13, 47, 133, 134, 137, 138, 142, 148, 151, 156, 298, 308, 330, 331, 371], "add": [13, 18, 20, 22, 26, 31, 33, 38, 41, 42, 52, 53, 55, 61, 64, 65, 66, 119, 126, 129, 133, 134, 137, 138, 142, 143, 145, 146, 148, 149, 151, 156, 158, 161, 168, 170, 171, 189, 190, 196, 236, 244, 247, 248, 249, 250, 253, 254, 257, 258, 264, 273, 274, 275, 277, 280, 289, 315, 319, 322, 326, 329, 330, 331, 332, 335, 337, 340, 341, 354, 357, 359, 360, 362, 363, 364, 365, 370, 371, 382, 385], "skip_add": 13, "forward": [13, 14, 47, 48, 53, 159, 162, 163, 168, 190, 193, 198, 218, 220, 223, 224, 231, 235, 236, 247, 250, 252, 256, 275, 278, 288, 291], "x": [13, 24, 26, 40, 45, 48, 53, 54, 72, 74, 79, 96, 98, 129, 133, 136, 161, 168, 170, 171, 189, 197, 222, 223, 231, 236, 244, 247, 254, 255, 321, 327, 331, 357, 358, 365, 366, 370], "els": [13, 53, 124, 159, 168, 172, 227, 236, 290, 298, 299, 308, 311, 312, 314, 315, 318, 336, 359, 376], "num_class": [13, 143, 370], "1000": [13, 33, 55, 56, 143, 159, 168, 189, 190, 218, 222, 231, 254, 276, 278, 298, 357, 360], "width_mult": 13, "inverted_residual_set": 13, "round_nearest": 13, "width": [13, 26, 48, 54, 56, 61, 63, 65, 66, 75, 143, 218, 319, 322, 331, 357, 358, 391], "multipli": [13, 28, 322], "adjust": [13, 14, 48, 158, 159, 162, 168, 189, 244, 254, 279, 287, 288, 291, 295, 304], "each": [13, 14, 15, 16, 18, 21, 22, 24, 28, 31, 42, 43, 45, 52, 53, 54, 55, 75, 120, 122, 123, 124, 125, 126, 129, 143, 148, 149, 158, 159, 160, 161, 162, 163, 164, 168, 170, 171, 174, 183, 185, 187, 189, 192, 204, 205, 209, 213, 214, 218, 220, 221, 222, 227, 229, 231, 235, 236, 240, 243, 244, 247, 248, 249, 250, 251, 252, 253, 255, 262, 266, 267, 272, 275, 276, 278, 279, 284, 288, 289, 291, 295, 298, 304, 308, 319, 322, 331, 357, 381], "amount": [13, 129, 158, 159, 196, 203, 209, 211, 215, 221, 238, 272, 340, 341, 354], "structur": [13, 35, 45, 48, 53, 57, 59, 123, 126, 127, 129, 161, 162, 168, 174, 185, 188, 203, 224, 236, 288, 291, 319, 322, 324, 327], "multipl": [13, 16, 22, 43, 52, 55, 58, 59, 79, 96, 98, 123, 129, 159, 162, 165, 168, 184, 196, 200, 201, 208, 213, 219, 221, 222, 223, 228, 231, 236, 239, 243, 244, 245, 251, 253, 254, 255, 257, 265, 272, 275, 278, 279, 288, 291, 299, 312, 314, 319, 322], "turn": [13, 38, 126, 129, 145, 146, 159, 162, 168, 198, 199, 206, 227, 236, 278, 288, 291, 381], "off": [13, 49, 148, 149, 159, 168, 170, 189, 227, 241, 254], "block": [13, 35, 42, 45, 129, 133, 160, 170, 202, 213, 214, 244, 248, 250, 259, 272, 291, 322], "input_channel": 13, "32": [13, 16, 26, 34, 45, 50, 57, 61, 65, 66, 69, 70, 71, 73, 74, 75, 123, 129, 133, 143, 156, 163, 171, 236, 250, 252, 253, 256, 264, 267, 276, 277, 278, 280, 282, 284, 302, 303, 304, 305, 307, 308, 313, 315, 319, 331, 359, 391], "last_channel": 13, "1280": [13, 245, 250], "c": [13, 18, 22, 30, 32, 36, 119, 129, 133, 136, 158, 159, 160, 172, 189, 222, 243, 244, 252, 253, 254, 257, 264, 272, 274, 276, 277, 284, 320, 322, 323, 338, 365], "n": [13, 22, 24, 32, 45, 54, 133, 136, 158, 160, 162, 168, 170, 171, 206, 223, 229, 231, 234, 240, 244, 247, 254, 255, 256, 257, 278, 288, 291, 298, 308, 324, 360], "16": [13, 33, 45, 50, 57, 123, 133, 143, 168, 200, 218, 227, 239, 247, 250, 255, 256, 260, 261, 267, 272, 276, 278, 280, 296, 298, 308, 309, 311, 312, 314, 328, 331, 358, 360, 361, 370, 391], "24": [13, 32, 50, 55, 57, 133, 152, 170, 218, 250, 261, 276, 280, 360, 361, 391], "96": [13, 32, 57, 133, 143, 253, 280], "160": [13, 120, 133], "320": [13, 78, 133, 139, 331], "onli": [13, 15, 16, 19, 21, 26, 31, 33, 36, 39, 47, 53, 55, 56, 61, 64, 65, 66, 68, 69, 70, 71, 75, 120, 122, 123, 124, 125, 126, 127, 129, 134, 137, 138, 139, 142, 143, 146, 148, 149, 150, 151, 153, 156, 158, 159, 161, 162, 163, 167, 168, 170, 172, 173, 174, 175, 176, 177, 178, 179, 182, 185, 187, 189, 190, 193, 194, 199, 202, 209, 213, 216, 217, 219, 220, 221, 222, 223, 230, 231, 236, 237, 239, 242, 243, 244, 245, 247, 249, 251, 252, 253, 255, 256, 257, 261, 264, 267, 272, 275, 276, 278, 279, 282, 284, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 317, 318, 322, 324, 330, 332, 333, 335, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 376], "element": [13, 22, 35, 38, 45, 168, 170, 174, 185, 190, 244, 251, 256, 267, 298, 308, 319], "assum": [13, 15, 31, 73, 74, 139, 141, 158, 167, 220, 244, 255, 256, 276, 279, 288, 291, 322, 324], "know": [13, 26, 51, 72, 121, 123, 124, 125, 126, 127, 129, 158, 159, 162, 171, 187, 207, 243, 244, 254, 255, 283, 284, 288, 291], "len": [13, 16, 22, 26, 45, 54, 62, 71, 75, 151, 168, 170, 190, 236, 253, 318, 332, 363, 364], "rais": [13, 45, 158, 233, 252, 254, 299, 312, 314], "valueerror": [13, 30, 159, 254, 299, 312, 314], "empti": [13, 168, 189, 244, 254, 276, 282, 374], "got": [13, 30, 33, 53, 159, 253, 279], "format": [13, 16, 22, 24, 26, 38, 39, 40, 41, 48, 58, 61, 63, 65, 66, 123, 125, 126, 127, 129, 139, 151, 158, 159, 162, 165, 167, 168, 171, 209, 218, 222, 223, 226, 235, 236, 249, 252, 254, 256, 275, 276, 279, 282, 288, 291, 293, 299, 301, 309, 311, 312, 313, 314, 315, 316, 319, 327, 339, 342, 343, 345, 346, 347, 349, 350, 351, 352, 353, 357, 358, 360, 365, 373], "build": [13, 15, 18, 27, 36, 40, 55, 59, 73, 74, 119, 120, 121, 150, 160, 165, 168, 170, 171, 189, 190, 198, 199, 202, 204, 205, 207, 221, 233, 243, 244, 248, 249, 251, 253, 254, 275, 298, 300, 308, 311, 317, 320, 322, 323, 325, 362, 369, 380, 382, 384, 385], "invert": [13, 224], "residu": [13, 124, 162, 170, 231, 244, 288, 291], "output_channel": 13, "last": [13, 18, 39, 48, 55, 141, 143, 159, 162, 171, 172, 189, 212, 227, 244, 247, 249, 253, 254, 267, 288, 291, 331, 373, 378, 381], "classifi": [13, 22, 24, 133, 143, 156, 160, 165, 168, 170, 234, 244, 249, 251, 253, 264, 284, 298, 307, 308, 359], "dropout": [13, 162, 190, 250, 251, 276, 288, 291], "m": [13, 24, 33, 57, 72, 73, 74, 80, 82, 86, 96, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 125, 129, 133, 136, 150, 158, 159, 160, 162, 170, 171, 189, 198, 199, 214, 224, 232, 243, 249, 254, 255, 257, 261, 267, 272, 276, 277, 279, 288, 289, 291, 295, 298, 300, 304, 308, 317, 322, 326, 331, 360, 376, 382, 385, 389], "isinst": 13, "init": [13, 22, 38, 42, 133, 150, 162, 189, 288, 291, 296, 298, 308, 359], "kaiming_normal_": 13, "mode": [13, 15, 18, 19, 33, 35, 48, 49, 69, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 133, 150, 151, 153, 156, 158, 162, 190, 249, 252, 254, 256, 275, 280, 288, 291, 299, 300, 312, 313, 314, 315, 319, 322, 326, 328, 329, 332, 333, 336, 337, 338, 339, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 359, 360, 362, 364, 367, 368, 369, 370, 380, 384, 387, 391], "fan_out": 13, "zeros_": 13, "elif": [13, 168], "ones_": 13, "normal_": 13, "01": [13, 28, 47, 52, 55, 56, 57, 69, 70, 71, 75, 133, 134, 137, 138, 142, 143, 148, 149, 150, 151, 153, 156, 168, 189, 251, 256, 274, 293, 297, 299, 301, 303, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 363, 364, 365, 367, 370, 371, 391], "mean": [13, 14, 16, 19, 21, 26, 28, 31, 38, 45, 48, 54, 55, 56, 69, 70, 71, 72, 120, 121, 129, 133, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 158, 162, 168, 174, 185, 189, 190, 202, 209, 219, 220, 231, 235, 236, 244, 247, 248, 249, 251, 252, 253, 254, 255, 256, 284, 288, 291, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 322, 323, 330, 332, 333, 336, 357, 358, 360, 364, 365, 370, 374, 386], "fuse": [13, 14, 53, 134, 137, 138, 142, 148, 151, 156, 221, 251, 252, 330, 332], "bn": [13, 57, 134, 137, 138, 142, 143, 148, 151, 156, 330], "prior": [13, 55, 129, 198, 199, 207, 219, 220, 236], "chang": [13, 20, 21, 26, 30, 38, 53, 54, 55, 121, 126, 133, 137, 138, 142, 158, 159, 160, 161, 162, 171, 172, 179, 182, 195, 205, 209, 213, 214, 231, 236, 243, 244, 251, 252, 254, 261, 267, 272, 273, 278, 286, 288, 289, 291, 311, 315, 322, 326, 329, 331, 332, 335, 337, 357, 358, 365, 370, 373, 380, 381, 384, 389, 390], "numer": [13, 14, 17, 32, 39, 46, 170, 252, 284], "fuse_model": [13, 14, 134, 138, 142, 148, 149, 151, 153, 330], "type": [13, 15, 18, 22, 27, 31, 35, 39, 45, 48, 54, 56, 59, 82, 123, 124, 126, 129, 143, 158, 159, 161, 162, 163, 168, 174, 185, 189, 220, 236, 243, 244, 248, 251, 252, 253, 254, 255, 263, 275, 288, 291, 298, 308, 309, 319, 321, 322, 330, 364], "fuse_modul": [13, 332], "true": [13, 14, 22, 26, 31, 38, 42, 47, 48, 49, 53, 54, 55, 56, 70, 79, 96, 98, 124, 133, 139, 140, 148, 149, 150, 156, 161, 162, 163, 168, 170, 174, 185, 189, 193, 196, 219, 222, 223, 227, 236, 243, 247, 249, 251, 252, 253, 254, 256, 265, 278, 288, 291, 311, 312, 314, 315, 317, 318, 323, 326, 328, 329, 332, 333, 336, 337, 340, 341, 354, 357, 373, 374, 375, 391], "idx": [13, 16, 22, 168, 236, 318, 322], "str": [13, 22, 38, 47, 53, 54, 143, 161, 236, 254], "averagemet": 13, "store": [13, 16, 34, 75, 79, 96, 98, 123, 125, 126, 127, 129, 162, 168, 170, 230, 231, 244, 248, 252, 253, 256, 272, 275, 288, 291, 319, 322, 327, 390], "averag": [13, 24, 38, 42, 45, 55, 129, 168, 216, 220, 223, 236, 241, 244, 247, 256, 267, 284, 317], "fmt": 13, "reset": [13, 38, 62, 75, 126, 254, 365], "val": [13, 42, 61, 69, 71, 109, 129, 134, 137, 138, 141, 142, 145, 146, 148, 149, 150, 151, 153, 168, 236, 275, 276, 280, 357, 358, 365, 370], "avg": [13, 14, 48], "sum": [13, 24, 62, 75, 161, 231, 236, 247, 278, 284, 301, 316], "updat": [13, 16, 18, 21, 38, 44, 45, 55, 62, 75, 110, 111, 112, 114, 115, 116, 129, 133, 143, 144, 147, 150, 159, 162, 168, 172, 230, 243, 251, 254, 256, 262, 267, 276, 288, 291, 293, 296, 299, 301, 311, 312, 313, 314, 316, 322, 323, 331, 335, 356, 374, 381, 388, 389], "__str__": 13, "fmtstr": 13, "__dict__": [13, 143], "target": [13, 14, 21, 22, 24, 26, 39, 45, 53, 54, 56, 69, 70, 71, 124, 125, 129, 134, 137, 138, 141, 142, 148, 149, 150, 151, 153, 158, 161, 162, 170, 212, 222, 223, 235, 242, 244, 247, 252, 253, 267, 275, 276, 279, 288, 291, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 365, 370, 391], "topk": [13, 19, 21, 26, 38, 61, 63, 65, 66, 69, 75, 134, 137, 138, 142, 148, 149, 150, 151, 153, 190, 253, 272, 357, 358, 370, 391], "k": [13, 38, 45, 69, 134, 136, 137, 138, 142, 148, 149, 150, 151, 153, 156, 231, 234, 235, 244, 247, 253, 254, 275, 278, 301, 316, 357, 358], "top": [13, 38, 54, 57, 69, 133, 134, 136, 137, 138, 142, 148, 149, 150, 151, 153, 156, 160, 208, 236, 244, 248, 250, 251, 253, 254, 255, 256, 257, 262, 272, 284, 340, 357, 358], "specifi": [13, 18, 25, 26, 28, 31, 38, 42, 47, 48, 54, 55, 56, 69, 70, 71, 122, 123, 124, 125, 126, 127, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 157, 158, 161, 163, 168, 172, 189, 190, 222, 243, 245, 247, 249, 251, 252, 254, 256, 275, 276, 279, 293, 294, 295, 297, 299, 301, 302, 303, 304, 307, 311, 312, 313, 314, 316, 318, 327, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 376, 386], "no_grad": [13, 197, 228, 247, 336, 373], "maxk": 13, "pred": [13, 38, 256], "eq": 13, "expand_a": 13, "re": [13, 33, 55, 158, 159, 160, 161, 162, 168, 172, 189, 203, 209, 213, 215, 236, 243, 244, 247, 251, 252, 253, 254, 259, 275, 278, 287, 288, 289, 291, 320, 365], "correct_k": 13, "keepdim": 13, "mul_": 13, "100": [13, 21, 22, 26, 33, 34, 47, 48, 54, 55, 56, 57, 61, 63, 64, 69, 71, 75, 123, 133, 134, 137, 138, 142, 151, 159, 160, 168, 170, 171, 187, 190, 235, 238, 241, 244, 245, 247, 250, 251, 253, 256, 271, 276, 293, 298, 308, 309, 319, 331, 337, 340, 357, 358, 359, 360, 362, 363, 364, 365, 369, 370, 391], "criterion": [13, 14, 24, 33, 45, 48, 55, 56, 151, 153, 298, 308, 357, 370, 391], "data_load": [13, 14, 15], "neval_batch": [13, 14], "top1": [13, 14, 48], "2f": [13, 14], "top5": [13, 14], "cnt": [13, 14, 24, 151, 153], "acc1": 13, "acc5": 13, "print": [13, 14, 18, 24, 26, 38, 55, 62, 72, 73, 74, 119, 120, 126, 129, 143, 146, 151, 153, 159, 162, 163, 168, 170, 172, 179, 196, 198, 222, 236, 245, 249, 251, 253, 254, 266, 288, 291, 318, 340, 354, 360], "load_model": [13, 69], "model_fil": [13, 120, 369], "state_dict": [13, 26, 53], "load_state_dict": 13, "cpu": [13, 14, 20, 32, 35, 39, 44, 46, 47, 49, 53, 58, 71, 73, 74, 121, 147, 148, 149, 150, 155, 156, 158, 162, 163, 168, 172, 189, 200, 227, 254, 275, 288, 291, 293, 295, 299, 301, 304, 311, 312, 313, 314, 316, 322, 330, 332, 333, 336, 358, 373], "print_size_of_model": 13, "temp": 13, "p": [13, 18, 123, 124, 140, 141, 143, 155, 156, 160, 171, 189, 194, 254, 255, 256, 267, 302, 317, 320, 322, 324, 360, 361], "mb": [13, 163, 222], "getsiz": 13, "1e6": 13, "num_calibration_batch": 13, "mymodel": [13, 158], "saved_model_dir": 13, "float_model_fil": 13, "start": [13, 36, 53, 54, 58, 62, 122, 123, 124, 127, 129, 160, 161, 162, 165, 167, 168, 189, 193, 196, 203, 222, 227, 234, 235, 236, 243, 244, 250, 252, 253, 254, 255, 267, 273, 275, 276, 285, 288, 291, 298, 308, 320, 387, 389, 391], "min": [13, 17, 18, 48, 54, 143, 160, 171, 208, 222, 247, 261, 280, 322, 331], "per": [13, 15, 16, 18, 33, 44, 49, 57, 71, 127, 129, 133, 147, 168, 230, 236, 241, 247, 251, 253, 256, 259, 267, 275, 276, 278, 317, 322, 331, 362, 364, 365, 391], "qconfig": [13, 14, 53, 299], "default_qconfig": [13, 299], "calibr": [13, 15, 16, 21, 34, 35, 48, 55, 56, 61, 63, 67, 69, 70, 71, 75, 76, 121, 134, 137, 138, 142, 148, 149, 150, 151, 156, 293, 299, 301, 311, 312, 313, 314, 316, 318, 326, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 371, 386], "fusion": [13, 15, 31, 134, 137, 138, 142, 145, 146, 148, 151, 156, 196, 330, 332], "data_loader_test": [13, 14], "num_eval_batch": [13, 14], "d": [13, 14, 24, 34, 73, 74, 158, 159, 160, 164, 171, 172, 189, 231, 235, 244, 253, 254, 266, 274, 275, 276, 279, 282, 284, 302, 317, 318, 332, 363, 368], "eval_batch_s": [13, 14, 276, 359], "functool": 13, "partial": [13, 48, 250, 284], "minmaxobserv": 13, "reduce_rang": [13, 47], "dtype": [13, 21, 22, 31, 47, 53, 54, 55, 56, 120, 141, 168, 251, 253, 299, 359, 360, 365, 373, 386, 391], "qint8": 13, "qscheme": 13, "per_tensor_symmetr": 13, "convrelu2d": 13, "activation_post_process": [13, 53], "min_val": 13, "max_val": 13, "quantizedconvrelu2d": 13, "scale": [13, 14, 17, 28, 48, 54, 76, 133, 139, 143, 160, 162, 164, 171, 189, 191, 197, 198, 199, 203, 206, 207, 209, 215, 218, 219, 220, 221, 223, 225, 226, 228, 229, 234, 235, 236, 240, 241, 244, 248, 252, 267, 274, 278, 288, 291, 303, 319, 331], "15583468973636627": 13, "zero_point": [13, 252], "quantizedconv2d": 13, "19358506798744202": 13, "74": [13, 32, 50, 57, 133, 143, 267, 280, 331], "631847": 13, "300": [13, 21, 133, 134, 136, 138, 148, 149, 150, 265, 293, 299, 301, 311, 312, 313, 314, 315, 316, 322, 329], "67": [13, 57, 133, 236, 267, 280, 303], "significantli": [13, 39, 45, 139, 189, 202, 204, 205, 212, 214, 221, 233, 241, 244, 280], "lower": [13, 17, 25, 45, 46, 48, 54, 75, 160, 171, 189, 191, 202, 213, 218, 222, 224, 232, 238, 244, 250, 276, 278, 321, 327], "62": [13, 50, 57, 133, 139, 224, 267], "same": [13, 15, 19, 21, 22, 24, 26, 31, 44, 47, 48, 53, 54, 55, 72, 73, 74, 122, 123, 124, 129, 133, 143, 158, 159, 160, 162, 167, 168, 170, 171, 187, 189, 191, 197, 200, 201, 209, 213, 220, 222, 223, 225, 227, 229, 230, 231, 233, 235, 240, 241, 243, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 257, 259, 261, 265, 267, 270, 275, 276, 279, 280, 288, 291, 295, 296, 304, 311, 312, 314, 315, 319, 321, 322, 323, 327, 360, 361, 376, 380, 384], "nevertheless": [13, 14], "did": [13, 129, 159, 267, 276, 284], "reduc": [13, 15, 16, 21, 25, 39, 46, 48, 49, 55, 56, 61, 63, 73, 74, 129, 134, 137, 138, 142, 159, 160, 170, 171, 189, 207, 213, 220, 225, 227, 231, 244, 252, 253, 254, 255, 272, 274, 276, 280, 322, 357, 358, 365, 370], "almost": [13, 162, 189, 218, 248, 255, 288, 291, 322], "decreas": [13, 253, 272, 274], "improv": [13, 16, 20, 33, 45, 48, 49, 55, 57, 72, 129, 133, 143, 151, 154, 158, 159, 160, 162, 171, 189, 191, 195, 198, 199, 200, 201, 202, 204, 205, 212, 213, 214, 216, 221, 223, 228, 231, 233, 236, 237, 239, 241, 244, 253, 254, 255, 261, 264, 272, 276, 278, 288, 291, 322, 373], "repeat": [13, 55, 168, 191, 250, 255, 256, 386], "exercis": [13, 159], "recommend": [13, 15, 16, 21, 31, 45, 47, 55, 59, 72, 73, 74, 124, 129, 142, 150, 161, 162, 163, 168, 189, 227, 231, 234, 235, 249, 250, 252, 256, 287, 288, 291, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 316, 322, 332, 333, 336, 337, 357, 358, 365, 366, 367, 368, 370, 381, 391], "x86": [13, 39, 133, 357], "basi": [13, 129, 253, 254], "histogram": [13, 27, 53, 148, 149, 257], "collect": [13, 48, 53, 55, 160, 168, 218, 236, 254, 275, 284, 306, 311, 312, 314, 315], "pick": [13, 124, 160, 171, 236, 243, 251, 254, 255, 382, 385], "paramet": [13, 14, 16, 18, 21, 22, 26, 28, 35, 38, 45, 48, 52, 54, 55, 56, 67, 76, 79, 96, 98, 129, 133, 136, 151, 153, 159, 162, 163, 168, 170, 189, 190, 191, 198, 199, 200, 202, 203, 205, 207, 215, 221, 223, 224, 227, 230, 231, 236, 239, 244, 245, 248, 250, 252, 254, 256, 257, 260, 267, 275, 276, 280, 288, 291, 296, 298, 308, 322, 365, 381, 387, 391], "manner": [13, 24, 40], "per_channel_quantized_model": 13, "get_default_qconfig": 13, "fbgemm": [13, 14, 17, 121], "jit": [13, 53, 133, 162, 252, 288, 291, 337, 373, 378], "script": [13, 26, 35, 46, 60, 61, 63, 65, 66, 70, 71, 73, 74, 97, 99, 100, 102, 103, 106, 108, 119, 120, 121, 125, 129, 133, 138, 139, 147, 158, 160, 162, 164, 167, 171, 187, 189, 193, 203, 209, 214, 215, 227, 236, 243, 251, 252, 253, 254, 256, 257, 259, 260, 261, 265, 266, 267, 270, 271, 272, 275, 278, 281, 286, 288, 291, 296, 300, 306, 317, 318, 322, 327, 328, 337, 344, 348, 357, 358, 359, 360, 361, 363, 365, 366, 369, 370, 371, 373, 375, 378, 381], "scripted_quantized_model_fil": 13, "histogramobserv": 13, "perchannelminmaxobserv": 13, "per_channel_symmetr": 13, "76": [13, 32, 57, 133, 140, 143, 221, 261, 272, 277, 331], "increas": [13, 23, 35, 72, 73, 74, 129, 159, 165, 170, 189, 191, 231, 244, 253, 255, 274, 276, 373], "qat": [14, 25, 26, 27, 35, 41, 48, 59, 151, 153, 295, 303, 304, 315, 329, 355], "simul": [14, 278], "dure": [14, 27, 39, 40, 42, 43, 45, 48, 53, 56, 59, 69, 70, 72, 124, 125, 126, 127, 129, 134, 137, 138, 143, 148, 149, 151, 153, 156, 157, 160, 162, 168, 170, 188, 189, 190, 207, 214, 217, 231, 236, 237, 244, 245, 249, 252, 254, 256, 259, 275, 278, 288, 291, 298, 303, 308, 309, 318, 322, 323, 330, 365, 371], "backward": [14, 16, 24, 26, 45, 48, 51, 151, 153, 163, 168, 190, 196, 236, 244, 256, 298, 308], "mimic": [14, 48, 253, 289], "still": [14, 48, 49, 129, 158, 159, 162, 189, 220, 230, 231, 235, 236, 238, 243, 244, 247, 249, 251, 252, 253, 254, 257, 259, 261, 272, 276, 282, 288, 291, 331], "thu": [14, 48, 73, 74, 129, 158, 159, 162, 170, 188, 189, 202, 221, 225, 234, 244, 252, 254, 255, 267, 272, 278, 288, 291, 319, 322, 362, 391], "made": [14, 15, 48, 51, 121, 143, 158, 159, 161, 162, 190, 204, 205, 234, 236, 239, 253, 254, 280, 288, 291, 315, 326, 329, 331, 337], "fact": [14, 48, 158, 165, 189, 248, 277, 344], "ultim": [14, 48], "yield": [14, 48, 55, 162, 170, 234, 236, 247, 253, 260, 261, 280, 288, 291, 318, 330, 332, 333, 336, 362, 365], "either": [14, 39, 43, 47, 48, 123, 158, 159, 161, 162, 163, 168, 170, 179, 180, 183, 188, 189, 190, 201, 212, 223, 232, 243, 244, 248, 251, 253, 254, 256, 275, 276, 282, 283, 288, 289, 291, 376], "dynam": [14, 15, 21, 24, 27, 35, 46, 57, 59, 100, 101, 102, 103, 105, 107, 108, 160, 165, 171, 202, 216, 244, 252, 259, 266, 293, 301, 311, 312, 313, 314, 316, 373, 376, 377, 378, 381], "training_func_for_nc": [14, 151, 153], "epoch": [14, 16, 24, 26, 45, 56, 70, 129, 130, 131, 132, 141, 151, 153, 168, 236, 244, 256, 259, 261, 276, 280, 296, 298, 308, 317, 331, 337, 359], "sgd": [14, 47, 56, 151, 153, 317], "lr": [14, 26, 70, 124, 130, 131, 132, 141, 147, 151, 153, 168, 189, 190, 236, 256, 321], "0001": [14, 47, 122, 123, 125, 151, 153, 317, 367, 391], "nepoch": [14, 24, 151, 153], "train_load": [14, 26, 151, 153, 168], "zero_grad": [14, 24, 26, 45, 151, 153, 168, 236, 298, 308], "break": [14, 24, 26, 153, 159, 161, 162, 190, 236, 247, 254, 267, 288, 291, 293, 301, 311, 313, 316], "freez": [14, 45, 151, 153, 272, 357, 373], "disable_observ": [14, 151, 153], "norm": [14, 151, 153], "varianc": [14, 151, 153], "intrins": [14, 137, 138, 142, 151, 153, 156, 332], "freeze_bn_stat": [14, 151, 153], "get_default_qat_qconfig": 14, "final": [14, 16, 42, 45, 48, 51, 55, 129, 155, 156, 159, 162, 189, 213, 216, 219, 233, 241, 243, 244, 250, 251, 254, 256, 257, 276, 280, 288, 291, 293, 301, 311, 313, 316, 319, 357, 366, 374], "alreadi": [14, 15, 18, 22, 35, 119, 124, 126, 127, 129, 158, 159, 162, 163, 172, 189, 194, 197, 228, 236, 243, 249, 254, 256, 264, 267, 275, 288, 291, 313, 335, 359, 360, 382, 385], "hook": [14, 24, 45, 53, 363], "prepare_qat": 14, "high": [14, 22, 32, 36, 46, 55, 124, 126, 129, 133, 158, 160, 171, 187, 198, 199, 224, 227, 241, 244, 272, 279, 280], "accur": [14, 163, 165, 234, 276, 331], "switch": [14, 53, 133, 248, 251, 276, 279, 286, 373], "match": [14, 24, 28, 122, 124, 129, 133, 147, 159, 160, 162, 168, 189, 190, 193, 221, 233, 252, 272, 275, 279, 280, 288, 291, 309, 322], "zero": [14, 17, 45, 54, 55, 76, 236, 252, 267, 319, 331], "num_train_batch": 14, "train_one_epoch": 14, "qat_model": 14, "devic": [14, 24, 45, 47, 58, 136, 162, 163, 168, 171, 207, 224, 227, 234, 247, 256, 272, 278, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 318, 322, 328, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 374], "quantized_model": [14, 61, 63, 64, 65, 66, 68, 75, 148, 149, 318], "q_func": [14, 15, 16, 55, 151, 153], "eval_dataload": [14, 16, 21, 34, 55, 62, 69, 70, 71, 75, 148, 151, 153, 299, 312, 314, 332, 359, 365], "val_load": [14, 48, 151, 153], "timeout": [14, 28, 47, 52, 55, 56, 69, 70, 71, 75, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 391], "constrain": [14, 69, 70, 71, 134, 137, 138, 148, 149, 151, 153, 156, 207, 252, 318, 330, 357, 365, 371], "71": [14, 32, 57, 136, 143, 148, 149, 261, 280], "close": [14, 123, 126, 129, 133, 162, 206, 244, 248, 252, 253, 276, 278, 280, 288, 291], "debug": [14, 18, 27, 55, 129, 159, 162, 163, 182, 380, 384], "analyz": [14, 45, 52, 53, 198, 199, 203, 251, 306], "limit": [14, 20, 24, 27, 45, 53, 134, 137, 138, 142, 145, 146, 148, 156, 159, 160, 171, 189, 190, 191, 198, 199, 201, 219, 220, 224, 225, 230, 235, 237, 238, 242, 243, 244, 247, 248, 259, 285, 299, 330, 332], "sinc": [14, 24, 28, 38, 43, 133, 159, 160, 162, 167, 168, 170, 172, 174, 185, 187, 189, 194, 213, 220, 222, 225, 236, 243, 244, 247, 249, 251, 254, 255, 275, 276, 278, 286, 288, 291, 309, 381], "actual": [14, 26, 129, 189, 236, 244, 288, 291, 365], "arithmet": [14, 31, 217], "easili": [14, 15, 42, 45, 124, 129, 159, 160, 162, 165, 168, 182, 203, 231, 248, 251, 252, 254, 256, 257, 259, 270, 272, 282, 285, 288, 291, 322, 376], "relat": [14, 56, 61, 63, 65, 66, 134, 137, 138, 142, 148, 149, 150, 151, 153, 158, 170, 171, 189, 236, 244, 248, 254, 257, 279, 318, 330, 332, 357, 358, 363, 364, 373], "onnx": [15, 16, 27, 29, 31, 32, 35, 39, 40, 46, 47, 48, 58, 120, 133, 171, 285, 378, 388], "runtim": [15, 16, 27, 28, 29, 31, 32, 35, 47, 48, 58, 252, 280, 360, 361, 378], "bridg": [15, 35, 253], "vanilla": [15, 35, 194, 237], "10004": [15, 24, 31, 35, 39, 43, 47, 56], "complet": [15, 18, 55, 56, 57, 129, 143, 151, 160, 161, 162, 165, 189, 190, 223, 227, 244, 251, 253, 254, 256, 267, 287, 288, 289, 291, 330, 335, 357, 370], "subclass": [15, 55, 168, 174, 179, 185, 189, 254], "packag": [15, 16, 18, 30, 32, 36, 51, 55, 129, 133, 139, 140, 142, 171, 172, 187, 189, 254, 257, 275, 289, 293, 300, 301, 311, 312, 313, 314, 322, 323, 362], "adaptor_registri": 15, "abc": [15, 53, 55, 391], "abcadaptor": 15, "framework_specific_info": 15, "tune_cfg": 15, "postprocess": [15, 16, 19, 21, 53, 54, 75, 121, 125, 129, 276, 360], "query_fw_cap": [15, 55], "query_fused_pattern": 15, "awar": [15, 16, 25, 26, 27, 35, 39, 41, 43, 57, 59, 146, 151, 153, 159, 163, 186, 214, 272, 295, 298, 303, 304, 308], "he": [15, 139, 160, 171, 189, 204, 205, 236, 275, 317], "intersect": [15, 38], "graph": [15, 16, 22, 24, 26, 27, 34, 38, 40, 48, 49, 53, 62, 63, 70, 71, 252, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 373, 387], "decid": [15, 28, 51, 55, 69, 134, 137, 138, 142, 156, 159, 162, 163, 244, 288, 291, 322, 357, 358, 365, 370], "besid": [15, 20, 24, 43, 162, 227, 254, 276, 288, 291], "op": [15, 18, 31, 33, 39, 48, 49, 51, 53, 55, 56, 62, 134, 137, 138, 142, 145, 146, 148, 149, 151, 156, 326, 330, 332, 362, 364, 386, 391], "sequenc": [15, 22, 31, 54, 133, 160, 161, 165, 170, 171, 174, 193, 194, 196, 202, 203, 206, 209, 210, 212, 213, 214, 215, 219, 220, 223, 227, 229, 230, 231, 234, 235, 236, 237, 240, 242, 245, 247, 249, 251, 252, 254, 256, 259, 267, 275, 278, 280, 284, 291, 362], "past": [15, 129, 159, 162, 190, 194, 203, 215, 254, 288, 291], "abov": [15, 19, 33, 45, 73, 74, 119, 121, 123, 124, 125, 126, 127, 129, 133, 148, 151, 155, 156, 159, 161, 162, 163, 168, 172, 189, 231, 236, 244, 247, 249, 252, 253, 254, 255, 256, 257, 261, 276, 279, 280, 288, 291, 323, 326, 337, 344, 360, 361, 386, 389], "hidden": [15, 45, 126, 164, 170, 174, 191, 209, 213, 221, 237, 244, 248, 250, 251, 253, 267, 276], "corner": [15, 54, 159, 218], "effect": [15, 45, 124, 129, 162, 165, 193, 200, 209, 210, 214, 218, 219, 235, 236, 239, 272, 285, 288, 291], "mainten": [15, 162, 288, 291], "difficult": [15, 159, 162, 288, 291], "correspond": [15, 16, 31, 45, 47, 48, 52, 55, 124, 125, 129, 162, 163, 168, 170, 182, 185, 188, 189, 218, 235, 236, 238, 243, 244, 249, 253, 254, 255, 270, 275, 276, 278, 279, 280, 283, 284, 288, 291, 298, 308, 331, 348], "abil": [15, 21, 31, 162, 230, 247, 288, 291], "clear": [15, 31, 38, 288, 291, 335], "fragment": [15, 189, 237], "field": [15, 16, 18, 19, 26, 28, 33, 55, 56, 69, 70, 71, 124, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 164, 194, 236, 244, 252, 293, 299, 301, 311, 312, 313, 314, 316, 318, 322, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "enumer": [15, 26, 45, 53, 168, 236, 298, 308, 318, 333], "scenario": [15, 16, 18, 19, 24, 33, 45, 120], "doesn": [15, 19, 21, 26, 56, 61, 63, 65, 66, 69, 72, 134, 137, 138, 142, 158, 159, 162, 193, 207, 209, 212, 220, 225, 233, 244, 254, 261, 276, 282, 288, 291, 357, 358, 370], "bf16": [15, 31, 33, 39, 49, 55, 73, 74, 119, 378, 381, 391], "granular": [15, 31, 35, 45, 55, 56, 61, 276, 359, 360, 362, 363, 364, 374], "scheme": [15, 21, 31, 55, 56, 123, 124, 193, 194, 212, 216, 217, 233, 237], "semant": [15, 31, 214, 221, 232, 236, 370], "pattern": [15, 22, 31, 35, 43, 47, 57, 59, 134, 137, 138, 142, 148, 151, 156, 157, 242, 254, 275, 295, 297, 298, 304, 307, 308, 330, 332], "abstract": [15, 16, 34, 75, 160, 161, 162, 171, 187, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 248, 253, 265, 288, 290, 291, 331], "querybackendcap": 15, "tensorflowqueri": 15, "look": [15, 31, 38, 42, 56, 122, 123, 124, 129, 159, 161, 162, 163, 164, 168, 172, 185, 189, 235, 244, 251, 252, 255, 257, 267, 272, 275, 276, 284, 288, 291, 295, 304, 331], "microsoft": [15, 160, 171, 189, 204, 205, 236, 250, 293, 317], "mla": [15, 17], "kernel": [15, 44, 45, 55, 124, 129], "becom": [15, 75, 162, 190, 191, 207, 211, 244, 253, 255, 272, 288, 291], "integr": [15, 18, 69, 70, 71, 119, 121, 124, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 160, 162, 165, 171, 222, 242, 254, 273, 288, 291, 318, 330, 357], "explor": [15, 129, 160, 168, 171, 230, 235, 244, 249, 252, 272, 296, 360, 361], "attribut": [15, 16, 31, 34, 39, 47, 56, 143, 162, 174, 185, 188, 203, 221, 227, 245, 251, 253, 256, 288, 291, 319, 391], "whether": [15, 22, 38, 54, 79, 96, 98, 124, 129, 159, 168, 171, 209, 236, 253, 254, 257, 275, 278, 284, 288], "qlinear": [15, 57, 378], "qdq": [15, 35, 48, 59, 79, 80, 81, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 103, 105, 107, 108, 110, 111, 112, 113, 117, 118], "integ": [15, 27, 48, 55, 123, 129, 161, 162, 168, 188, 190, 217, 236, 249, 251, 252, 254, 274, 288, 291, 295, 304], "qtype": 15, "choic": [15, 18, 22, 38, 124, 125, 126, 127, 129, 143, 162, 165, 182, 190, 198, 199, 213, 233, 244, 253, 254, 257, 262, 276, 288, 291], "float32": [15, 19, 22, 48, 54, 62, 75, 133, 141, 162, 251, 252, 288, 291, 391], "uint8": [15, 17, 22, 31, 47, 48, 54, 55, 56], "node": [15, 18, 26, 53, 73, 74, 129, 135, 147, 189, 267, 275, 278, 295, 304, 340, 341, 354], "exclud": [15, 254], "three": [15, 18, 21, 33, 36, 39, 43, 48, 49, 52, 53, 55, 123, 125, 126, 127, 129, 134, 137, 138, 142, 148, 149, 150, 156, 160, 161, 163, 167, 168, 171, 197, 216, 221, 222, 227, 230, 236, 244, 248, 249, 255, 266, 280, 291, 310, 318, 330, 331, 357, 358, 381], "onnxrt": [15, 100, 103, 108, 391], "onnxrt_qlinearopsadaptor": 15, "dump_elapsed_tim": 15, "recov": [15, 25, 213, 274, 276], "q_config": 15, "inspect_tensor": 15, "op_list": [15, 53], "iteration_list": 15, "inspect_typ": 15, "save_to_disk": 15, "save_path": [15, 40, 270, 276], "quantization_cfg": 15, "set_tensor": 15, "tensor_dict": 15, "input_graph": [15, 357, 358, 363, 365, 366, 370], "fp32_baselin": 15, "diagnosis_help": 15, "fp32_model": [15, 21, 69, 149, 156, 318, 387], "int8_model": [15, 156], "deploi": [16, 24, 55, 58, 62, 159, 170, 189, 224, 234, 291, 370], "recip": [16, 27, 55, 160, 171, 198, 199, 230], "memori": [16, 21, 25, 27, 39, 42, 45, 48, 55, 124, 129, 133, 163, 170, 189, 191, 202, 217, 220, 230, 231, 237, 244, 247, 252, 255, 258, 261, 272, 275, 276, 278, 322, 332, 333, 336, 373], "usag": [16, 18, 22, 26, 27, 29, 32, 33, 38, 41, 42, 47, 54, 69, 70, 71, 73, 74, 99, 100, 103, 108, 134, 135, 137, 138, 142, 148, 149, 150, 151, 153, 156, 160, 163, 170, 171, 189, 196, 200, 201, 203, 214, 215, 233, 241, 245, 253, 254, 269, 281, 293, 301, 309, 311, 315, 316, 318, 326, 330, 332, 333, 336, 337, 357, 358, 359, 360, 361, 365, 366, 370, 371, 373], "intend": [16, 20, 126, 127, 129, 160, 161, 193, 223, 244], "cross": [16, 34, 55, 123, 127, 129, 159, 160, 162, 165, 171, 187, 196, 221, 235, 239, 241, 244, 247, 250, 256, 280, 288, 291, 317], "compat": [16, 26, 32, 40, 51, 62, 125, 127, 129, 133, 143, 162, 189, 196, 256, 272, 278, 288, 291, 323, 365, 382, 385], "locat": [16, 19, 26, 48, 51, 54, 55, 56, 61, 63, 65, 66, 71, 120, 121, 123, 124, 125, 126, 129, 134, 137, 138, 142, 159, 161, 162, 168, 172, 189, 253, 254, 263, 280, 282, 288, 291, 322, 332, 333, 336, 348, 357, 358, 359, 360, 361, 363, 365, 366, 369, 370, 371, 374, 380, 384], "major": [16, 34, 48, 124, 162, 216, 288, 291], "concept": [16, 34, 52, 119, 171, 207, 221], "those": [16, 24, 33, 34, 43, 45, 48, 55, 133, 157, 158, 159, 160, 162, 163, 170, 171, 172, 173, 174, 175, 176, 177, 178, 182, 185, 187, 189, 202, 218, 244, 245, 248, 249, 251, 252, 253, 254, 255, 259, 261, 262, 276, 277, 282, 284, 288, 291, 335, 357, 370], "case": [16, 18, 19, 21, 24, 26, 31, 34, 38, 42, 45, 46, 48, 54, 56, 59, 69, 70, 71, 75, 101, 122, 123, 124, 125, 126, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 158, 159, 160, 162, 163, 168, 170, 172, 189, 190, 192, 193, 197, 198, 199, 209, 216, 217, 231, 236, 243, 244, 245, 249, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 261, 265, 267, 273, 280, 282, 283, 284, 288, 289, 291, 293, 295, 299, 301, 304, 311, 312, 313, 314, 316, 318, 322, 330, 332, 333, 335, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 376], "whose": [16, 34, 45, 55, 162, 168, 254, 255, 256, 279, 288, 291], "style": [16, 20, 22, 34, 59, 133, 161, 162, 165, 171, 203, 218, 235, 244, 278, 288, 289, 291, 322, 324], "rather": [16, 34, 159, 160, 162, 168, 170, 171, 191, 195, 203, 206, 209, 214, 215, 224, 234, 236, 244, 247, 254, 259, 272, 273, 275, 288, 291, 335, 357], "refin": [16, 34, 82, 129, 254, 270], "__call__": [16, 21, 143, 161, 162, 188, 223, 249, 252, 253, 256, 288, 291], "properti": [16, 37, 44, 73, 74, 124, 129, 171, 252, 311, 391], "user_postprocess": 16, "eval_func": [16, 19, 21, 22, 26, 39, 48, 55, 56, 61, 63, 65, 66, 69, 70, 71, 134, 137, 138, 142, 148, 156, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 362, 363, 364, 365, 370, 371], "templat": [16, 18, 55, 69, 70, 71, 124, 134, 137, 138, 145, 146, 148, 149, 150, 151, 153, 156, 158, 159, 160, 161, 162, 243, 278, 287, 289, 291, 318, 323, 330, 358], "understand": [16, 48, 53, 124, 159, 160, 162, 164, 165, 170, 171, 187, 190, 194, 195, 196, 200, 202, 207, 209, 211, 213, 214, 216, 218, 221, 225, 234, 235, 236, 239, 241, 242, 244, 251, 253, 267, 280, 284, 288, 291, 306, 334], "most": [16, 18, 39, 45, 48, 55, 69, 70, 71, 124, 126, 129, 133, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 158, 159, 160, 162, 170, 173, 174, 175, 176, 177, 178, 182, 186, 188, 189, 194, 201, 203, 207, 211, 214, 219, 220, 221, 225, 244, 245, 247, 249, 252, 253, 254, 255, 262, 276, 284, 288, 291, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 322, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "helloworld": [16, 22, 54, 75], "__getitem__": [16, 19, 21, 22, 62, 75, 168, 236, 322, 363, 364], "singl": [16, 22, 45, 75, 125, 129, 133, 136, 157, 160, 161, 162, 163, 168, 170, 171, 189, 190, 193, 205, 206, 213, 218, 232, 236, 244, 248, 249, 252, 254, 255, 259, 261, 265, 267, 275, 278, 280, 288, 291, 295, 298, 304, 308, 329], "tupl": [16, 22, 38, 45, 54, 79, 96, 98, 161, 168, 174, 185, 197, 221, 228, 231, 236, 251, 267, 319, 323], "collat": [16, 256], "custom_metr": [16, 34], "mini": [16, 57, 59, 75, 233, 298, 308, 309, 310], "calcul": [16, 22, 38, 42, 45, 48, 52, 55, 56, 62, 76, 171, 217, 231, 252, 256, 275, 276, 311], "invok": [16, 75, 134, 137, 138, 142, 145, 146, 148, 156, 254, 332], "onc": [16, 18, 21, 46, 119, 126, 129, 133, 143, 158, 159, 161, 162, 167, 209, 231, 243, 244, 249, 251, 253, 254, 255, 259, 267, 272, 275, 282, 288, 289, 291, 317, 335], "scalar": [16, 38, 39, 48, 75, 123, 235], "accuracy_criterion": [16, 28, 42, 47, 52, 55, 56, 67, 69, 70, 71, 75, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371], "higher_is_bett": [16, 38, 42, 56, 75], "line": [16, 18, 26, 35, 53, 61, 64, 65, 66, 126, 127, 129, 133, 145, 146, 158, 159, 160, 162, 167, 168, 171, 172, 189, 190, 197, 206, 228, 252, 253, 254, 257, 259, 267, 275, 276, 277, 278, 279, 280, 283, 286, 288, 289, 291, 335, 340, 341, 354, 357, 364, 371, 373, 376, 377], "cal_dl": 16, "dir": [16, 22, 30, 34, 70, 121, 134, 137, 138, 139, 141, 142, 145, 146, 148, 149, 150, 151, 153, 156, 254, 260, 271, 293, 299, 301, 306, 311, 313, 320, 331, 338, 359, 362, 364], "kera": [16, 26, 40, 59, 60, 62, 74, 75, 143, 160, 168, 189, 248, 251, 256, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 378], "frozen": [16, 18, 40, 60, 73, 74, 256, 257, 362, 370], "checkpoint": [16, 40, 59, 60, 64, 129, 133, 160, 165, 171, 193, 196, 198, 199, 209, 210, 213, 215, 219, 223, 226, 234, 236, 239, 243, 244, 245, 248, 250, 252, 253, 261, 267, 272, 273, 275, 284, 289, 293, 299, 311, 313, 328, 357, 358, 359, 370], "gluon": [16, 40], "hybirdblock": 16, "instanti": [16, 43, 124, 162, 163, 168, 179, 186, 188, 189, 190, 192, 196, 248, 251, 252, 253, 256, 287, 288, 291], "custom": [16, 24, 27, 45, 52, 59, 60, 69, 70, 71, 75, 123, 124, 127, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 158, 159, 160, 161, 162, 163, 165, 171, 179, 189, 227, 236, 253, 254, 259, 270, 275, 282, 285, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 373, 391], "directli": [16, 38, 47, 48, 53, 59, 124, 129, 133, 158, 159, 160, 162, 163, 170, 171, 189, 190, 192, 196, 202, 205, 213, 231, 243, 244, 247, 249, 251, 253, 254, 255, 266, 267, 272, 283, 288, 291, 358, 375], "execut": [16, 18, 24, 26, 27, 33, 39, 43, 45, 48, 57, 72, 73, 74, 79, 96, 98, 129, 130, 131, 132, 134, 135, 137, 138, 142, 145, 146, 148, 156, 162, 189, 243, 252, 254, 257, 265, 288, 291, 311, 330, 332, 360, 361, 374, 380, 381, 384, 390], "contain": [16, 21, 22, 24, 35, 38, 45, 53, 55, 120, 123, 124, 125, 126, 129, 133, 158, 162, 163, 168, 170, 171, 172, 174, 185, 187, 188, 189, 190, 209, 215, 221, 236, 243, 244, 251, 252, 253, 254, 256, 257, 262, 265, 267, 268, 272, 274, 275, 276, 279, 282, 288, 289, 291, 298, 308, 315, 317, 319, 320, 325, 326, 329, 337, 362, 369], "hyper": [16, 56, 248, 260, 276, 280], "reserv": [16, 203], "special": [16, 32, 38, 42, 75, 161, 162, 168, 170, 171, 188, 189, 196, 223, 224, 244, 249, 251, 253, 254, 255, 261, 282, 288, 291], "had": [16, 190, 249, 254], "leav": [16, 123, 129, 189, 231, 253, 254, 381], "scaler": 16, "some": [16, 18, 28, 32, 36, 38, 42, 45, 48, 49, 53, 55, 123, 124, 129, 133, 145, 146, 148, 149, 158, 159, 160, 161, 162, 164, 170, 171, 172, 179, 189, 191, 193, 194, 198, 200, 202, 209, 215, 227, 236, 241, 243, 244, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 262, 276, 279, 280, 282, 283, 285, 288, 291, 306, 310, 311, 319, 322, 331, 357, 389], "effort": [16, 61, 124, 129, 162, 252, 288, 291], "on_epoch_begin": [16, 45], "on_step_begin": [16, 45, 298, 308], "batch_id": [16, 362], "on_step_end": [16, 45], "on_epoch_end": [16, 24, 45], "proof": [16, 207], "magnitud": [16, 35, 45, 57, 59, 252, 272, 278, 298, 306, 308, 340, 341, 354], "To": [16, 18, 20, 26, 39, 47, 49, 51, 56, 59, 72, 73, 74, 75, 89, 106, 113, 117, 118, 124, 126, 129, 133, 143, 158, 160, 161, 162, 163, 164, 167, 168, 170, 172, 182, 189, 190, 191, 206, 207, 213, 216, 218, 219, 220, 221, 223, 224, 235, 236, 242, 243, 244, 249, 251, 255, 256, 257, 259, 262, 265, 267, 270, 272, 275, 276, 278, 279, 280, 282, 286, 287, 288, 291, 295, 304, 324, 331, 344, 357, 358, 365, 375, 380, 382, 384, 385, 390], "b_dataload": [16, 19, 41, 359], "symmetr": [17, 48, 54, 220, 244], "asymmetr": [17, 48], "ab": [17, 48, 133, 164, 194, 223, 274, 275, 276, 305], "rmin": 17, "rmax": 17, "web": [18, 27, 53, 162, 215, 234, 244, 288, 291], "applic": [18, 46, 53, 54, 129, 158, 159, 162, 201, 210, 216, 218, 234, 244, 249, 253, 254, 272, 288, 291, 342, 343, 345, 346, 347, 349, 350, 351, 352, 353, 373], "easier": [18, 46, 129, 158, 160, 162, 163, 236, 243, 254, 288, 291, 380, 384], "gui": [18, 35, 36, 283], "conda": [18, 30, 32, 36, 51, 129, 133, 171, 190, 257, 296, 300, 320, 323, 328, 374, 381], "forg": [18, 30, 32, 36, 190, 257], "setup": [18, 31, 32, 36, 120, 121, 133, 134, 138, 142, 143, 150, 159, 161, 162, 172, 182, 189, 190, 233, 235, 236, 243, 249, 254, 257, 279, 284, 286, 288, 291, 293, 296, 313, 320, 321, 324, 382, 385], "server": [18, 72, 120, 248], "command": [18, 26, 33, 60, 70, 72, 73, 74, 100, 103, 108, 113, 117, 118, 119, 124, 125, 126, 127, 129, 130, 131, 132, 135, 152, 158, 159, 160, 161, 162, 163, 167, 172, 189, 243, 249, 251, 252, 254, 257, 259, 262, 267, 272, 275, 276, 277, 278, 279, 280, 282, 283, 286, 287, 288, 289, 291, 295, 296, 300, 304, 323, 324, 326, 331, 332, 333, 336, 337, 357, 358, 376, 380, 384, 387, 389], "sign": [18, 48, 52], "tl": [18, 129], "certif": 18, "instruct": [18, 24, 27, 32, 36, 39, 46, 47, 48, 61, 63, 65, 66, 71, 73, 74, 125, 127, 129, 133, 134, 137, 138, 145, 146, 148, 149, 150, 151, 153, 155, 156, 159, 162, 171, 189, 227, 249, 276, 279, 286, 288, 291, 300, 318, 320, 322, 323, 329, 330, 335, 338, 357, 358, 364, 365, 382, 385], "access": [18, 119, 125, 126, 133, 143, 159, 162, 164, 168, 174, 179, 185, 188, 189, 190, 219, 221, 230, 243, 244, 248, 253, 254, 256, 272, 275, 278, 283, 288, 291, 322, 348, 382, 385], "ui": [18, 254, 283], "13": [18, 32, 50, 57, 59, 132, 133, 143, 162, 229, 240, 241, 280, 288, 291, 321, 391], "5000": [18, 261, 391], "token": [18, 22, 38, 52, 54, 55, 119, 158, 160, 161, 165, 171, 174, 183, 185, 187, 193, 195, 196, 197, 198, 200, 203, 204, 205, 206, 207, 209, 212, 213, 214, 215, 216, 218, 219, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 239, 240, 242, 243, 244, 245, 247, 248, 250, 252, 253, 254, 256, 257, 259, 261, 267, 270, 275, 276, 278, 284, 285, 289, 296, 299, 311, 312, 314, 315, 362], "338174d13706855fc6924cec7b3a8ae8": 18, "trust": [18, 159, 391], "browser": [18, 159, 161, 380, 384], "listen": [18, 198, 199], "port": [18, 129, 222, 276, 331], "firewal": 18, "8080": 18, "cert": 18, "kei": [18, 53, 124, 129, 168, 170, 174, 185, 189, 190, 203, 211, 215, 220, 227, 231, 233, 234, 236, 241, 244, 249, 251, 261, 273, 279, 293, 298, 301, 308, 311, 313, 316, 322], "path_to_cert": 18, "crt": 18, "path_to_private_kei": 18, "encrypt": 18, "insecur": 18, "connect": [18, 45, 52, 158, 162, 221, 234, 252, 272, 288, 291, 298, 308], "machin": [18, 32, 36, 46, 53, 141, 160, 170, 171, 187, 193, 196, 198, 199, 223, 239, 244, 250, 252, 254, 255, 374], "local": [18, 52, 72, 73, 74, 124, 143, 158, 159, 161, 162, 171, 172, 180, 183, 188, 189, 202, 205, 219, 220, 229, 240, 243, 244, 248, 251, 252, 254, 288, 291, 298, 308, 313, 318, 320, 323, 380, 384], "whole": [18, 28, 48, 57, 59, 69, 71, 75, 120, 121, 129, 159, 162, 170, 202, 216, 230, 244, 250, 253, 254, 257, 261, 288, 291, 299, 300], "internet": [18, 22, 158], "expos": [18, 160, 171, 248], "forfeit": 18, "client": [18, 73, 74, 286], "extern": [18, 157, 190, 218, 252, 254, 275, 324], "threat": 18, "button": [18, 35, 158, 159, 162, 243, 288, 291, 381], "pop": [18, 168, 189], "choos": [18, 32, 35, 51, 55, 56, 69, 73, 74, 123, 129, 134, 137, 138, 139, 148, 149, 150, 151, 153, 158, 159, 160, 162, 171, 236, 255, 256, 264, 273, 276, 288, 289, 291, 298, 308, 357, 358, 370], "second": [18, 28, 42, 55, 56, 69, 70, 71, 73, 74, 123, 129, 134, 137, 138, 142, 156, 159, 160, 161, 162, 168, 170, 179, 187, 189, 196, 204, 205, 213, 222, 234, 236, 244, 249, 251, 252, 254, 255, 267, 277, 279, 280, 284, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 321, 326, 332, 333, 336, 337, 357, 358, 365, 370, 380, 384, 391], "possibl": [18, 28, 33, 43, 49, 55, 69, 120, 124, 129, 134, 137, 138, 142, 143, 148, 151, 156, 158, 159, 160, 162, 189, 207, 216, 231, 241, 248, 249, 253, 254, 255, 257, 267, 276, 278, 288, 291, 319, 322, 323, 330, 332, 335], "domain": [18, 45, 55, 59, 129, 159, 160, 171, 198, 199, 206, 208, 212, 215, 216, 230, 232, 244, 253, 388], "recognit": [18, 26, 53, 59, 61, 63, 65, 66, 82, 134, 137, 138, 142, 148, 149, 150, 151, 153, 160, 168, 171, 186, 197, 201, 216, 228, 238, 249, 251, 282, 339, 357, 358, 367, 370, 391], "finish": [18, 55, 73, 74, 127, 129, 155, 156, 162, 275, 276, 288, 289, 291, 381], "chosen": [18, 120, 143], "download": [18, 22, 32, 33, 36, 51, 58, 63, 69, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 125, 126, 127, 129, 134, 137, 138, 139, 142, 143, 145, 146, 148, 149, 150, 151, 153, 155, 156, 158, 160, 167, 168, 180, 183, 188, 214, 227, 248, 249, 251, 254, 263, 265, 266, 275, 276, 277, 279, 296, 300, 306, 318, 322, 324, 326, 328, 332, 333, 336, 337, 338, 339, 348, 357, 358, 364, 367, 370, 371, 391], "synthet": [18, 284], "collaps": 18, "plu": [18, 160, 189, 248, 251, 254, 276], "icon": [18, 159], "unfold": [18, 159], "On": [18, 48, 75, 129, 158, 160, 162, 212, 224, 239, 244, 248, 252, 253, 254, 255, 259, 264, 267, 270, 276, 288, 291], "left": [18, 54, 162, 191, 193, 195, 203, 206, 214, 215, 218, 224, 231, 234, 235, 236, 237, 244, 247, 251, 253, 254, 255, 284, 288, 291, 326, 337, 381], "side": [18, 22, 54, 159, 162, 222, 251, 288, 291, 381], "panel": [18, 382, 385], "navig": [18, 190, 331, 390], "previou": [18, 51, 53, 55, 123, 129, 159, 161, 162, 170, 171, 189, 197, 205, 214, 215, 217, 220, 221, 223, 225, 229, 231, 236, 238, 239, 240, 241, 244, 251, 254, 255, 256, 257, 267, 276, 280, 288, 291, 389], "trash": 18, "visibl": [18, 129, 157, 189, 205, 245, 253, 319], "cursor": 18, "prompt": [18, 26, 119, 244, 251, 253, 289], "confirm": [18, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 197], "revers": [18, 231, 244, 255], "bottom": [18, 126, 161], "There": [18, 24, 31, 35, 38, 39, 56, 73, 74, 76, 126, 129, 143, 158, 159, 162, 163, 164, 172, 186, 189, 192, 193, 223, 236, 244, 251, 254, 266, 267, 276, 288, 291, 357, 358, 371, 373], "even": [18, 45, 129, 161, 162, 172, 189, 190, 217, 252, 253, 254, 256, 264, 267, 272, 275, 277, 278, 288, 291, 322], "exit": [18, 28, 33, 39, 55, 56, 69, 126, 134, 137, 138, 142, 156, 253, 293, 301, 311, 313, 316, 317, 323, 357, 358, 365, 370, 371], "yet": [18, 129, 159, 162, 170, 172, 179, 200, 244, 253, 254, 265, 279, 283, 288, 291, 382, 385], "pencil": 18, "light": [18, 25, 207, 242, 267, 276], "blue": [18, 123, 129, 279], "color": [18, 123, 125, 143], "That": [18, 21, 159, 162, 168, 189, 198, 222, 243, 244, 251, 254, 276, 288, 291, 322], "indic": [18, 19, 30, 53, 124, 158, 159, 161, 168, 170, 207, 220, 225, 233, 236, 244, 248, 249, 253, 262, 275], "befor": [18, 20, 21, 22, 24, 26, 30, 31, 33, 42, 45, 48, 52, 53, 55, 58, 119, 122, 126, 129, 134, 137, 138, 142, 143, 145, 146, 148, 151, 156, 158, 159, 160, 161, 162, 163, 170, 172, 189, 190, 235, 244, 247, 249, 251, 254, 255, 259, 266, 267, 275, 276, 288, 291, 293, 301, 306, 311, 312, 313, 314, 319, 326, 330, 332, 362, 364, 382, 385], "row": [18, 45, 159, 236, 277, 331], "arrow": 18, "checkbox": [18, 119], "column": [18, 45, 168, 236, 275, 279, 280, 282, 303], "compar": [18, 21, 25, 33, 38, 48, 52, 53, 55, 59, 72, 73, 74, 124, 129, 133, 136, 148, 149, 159, 162, 191, 193, 201, 204, 205, 207, 209, 213, 217, 220, 225, 229, 230, 235, 236, 240, 242, 243, 247, 252, 267, 276, 284, 288, 291, 321, 331, 365], "chart": [18, 48, 52, 53], "core": [18, 37, 44, 50, 57, 65, 66, 120, 121, 158, 162, 163, 217, 251, 254, 257, 275, 280, 284, 288, 291, 325, 362, 364, 380, 384, 391], "ad": [18, 33, 39, 53, 75, 129, 133, 158, 160, 162, 163, 164, 168, 170, 183, 188, 189, 196, 207, 212, 223, 236, 243, 244, 249, 251, 253, 254, 255, 270, 275, 284, 287, 288, 291, 326, 335, 337, 365, 376, 382, 385, 391], "fill": [18, 52, 54, 162, 171, 245, 251, 252, 253, 276, 287, 288, 289, 291], "link": [18, 22, 57, 59, 101, 105, 120, 121, 129, 139, 158, 159, 161, 162, 172, 203, 222, 243, 244, 257, 265, 267, 274, 275, 276, 277, 283, 288, 290, 291, 296, 300, 318, 320, 321, 326, 340, 354, 357, 380, 384], "highlight": [18, 162, 168, 233, 285, 288, 291], "thread": [18, 21, 44, 129, 159, 254, 362, 364, 391], "form": [18, 24, 124, 165, 168, 184, 202, 218, 232, 235, 236, 244, 255, 284], "bar": [18, 73, 74, 158, 159], "offer": [18, 22, 160, 162, 186, 253, 255, 288, 291], "conveni": [18, 129, 168, 243, 256, 276, 278, 319], "easi": [18, 21, 46, 48, 52, 124, 125, 127, 129, 136, 159, 160, 162, 186, 187, 188, 219, 220, 243, 248, 251, 252, 253, 254, 255, 256, 273, 288, 291, 335, 358], "request": [18, 21, 48, 124, 129, 157, 162, 254, 258, 283, 285, 288, 291, 300, 391], "variat": [18, 124, 189], "mse": [18, 38, 47, 51, 142, 293, 299, 301, 309, 312, 313, 314, 316, 332, 333, 336, 391], "wise": [18, 21, 35, 45, 53, 55, 56, 59, 61, 63, 134, 137, 138, 142, 143, 254, 298, 308, 357, 358, 365, 370, 386], "summari": [18, 20, 44, 53, 124, 129, 158, 159, 160, 162, 171, 186, 190, 196, 213, 227, 247, 250, 251, 254, 256, 259, 265, 276, 279, 288, 290, 291, 323, 382, 385], "present": [18, 46, 72, 123, 124, 126, 160, 162, 191, 197, 206, 213, 220, 221, 223, 226, 228, 229, 233, 235, 236, 240, 241, 250, 251, 253, 255, 256, 257, 272, 288, 291, 322, 331, 362], "assign": [18, 26, 39, 47, 129, 162, 168, 188, 189, 193, 212, 222, 223, 227, 229, 231, 240, 254, 288, 291, 295, 304], "inspect": [18, 51, 53, 161, 179, 189], "yellow": [18, 254], "warn": [18, 182, 227, 249, 254, 276], "remind": [18, 162, 288, 291], "dialog": [18, 165, 206], "organ": [18, 56, 160, 162, 168, 171, 234, 243, 257, 259, 283, 288, 291], "cryptographi": 18, "flask": 18, "socketio": 18, "alwai": [19, 38, 45, 122, 124, 125, 143, 158, 159, 160, 161, 162, 163, 171, 189, 235, 247, 248, 252, 254, 255, 276, 288, 291, 331], "map": [19, 22, 26, 38, 45, 48, 61, 63, 65, 66, 69, 71, 110, 111, 112, 113, 114, 115, 116, 123, 124, 129, 134, 137, 138, 139, 142, 168, 188, 202, 235, 244, 252, 253, 276, 298, 308, 317, 327, 331, 357, 358, 365, 370, 380, 384], "f1": [19, 26, 38, 52, 57, 61, 63, 65, 66, 69, 70, 134, 137, 138, 142, 195, 224, 241, 256, 261, 267, 272, 275, 280, 293, 298, 299, 301, 303, 308, 311, 312, 313, 314, 315, 316, 330, 357, 358, 370], "imagefold": [19, 21, 22, 26, 134, 137, 138, 142, 148, 149, 150, 386], "root": [19, 21, 22, 26, 38, 55, 56, 63, 75, 134, 137, 138, 142, 148, 149, 150, 158, 161, 163, 252, 254, 326, 335, 348, 357, 358, 360, 370, 386, 391], "resiz": [19, 21, 22, 54, 55, 61, 63, 134, 137, 138, 142, 143, 148, 149, 150, 183, 319], "centercrop": [19, 21, 54, 55, 134, 137, 138, 142, 148, 149, 150], "totensor": [19, 21, 54, 134, 137, 138, 142, 148, 149, 150, 386], "normal": [19, 21, 42, 54, 124, 133, 134, 137, 138, 142, 143, 148, 149, 150, 160, 162, 172, 181, 189, 197, 217, 218, 231, 254, 256, 278, 288, 291, 322, 386], "485": [19, 21, 57, 134, 137, 138, 142, 143, 148, 149, 150, 386], "456": [19, 21, 133, 134, 137, 138, 142, 143, 148, 149, 150, 386, 391], "406": [19, 21, 134, 137, 138, 142, 143, 148, 149, 150, 386], "std": [19, 21, 54, 133, 134, 137, 138, 142, 148, 149, 150, 323, 386], "229": [19, 21, 134, 137, 138, 142, 143, 148, 149, 150, 386], "225": [19, 21, 134, 137, 138, 142, 143, 148, 149, 150, 326, 386], "cores_per_inst": [19, 21, 33, 47, 65, 66, 134, 137, 138, 142, 148, 149, 150, 357, 358, 359, 360, 370, 387, 391], "num_of_inst": [19, 21, 33, 47, 65, 66, 134, 137, 138, 142, 148, 149, 150, 357, 358, 359, 360, 370], "flexibl": [19, 24, 45, 252, 253], "enough": [19, 48, 129, 158, 159, 162, 170, 244, 288, 291], "__iter__": [19, 21, 318, 330, 332, 333, 336, 362, 365], "postprocess_cl": 19, "metric_cl": 19, "benchmarkconf": 19, "lpot": [19, 33, 46, 51, 75], "pylint": 20, "flake8": [20, 158], "autopep8": 20, "clean": [20, 161, 162, 235, 238, 245, 250, 288, 291, 320, 323, 337, 338], "unit": [20, 129, 217, 223, 255], "motiv": [20, 158, 162, 219, 220, 288, 291], "explan": [20, 157, 275], "regress": [20, 162, 221, 235, 242, 244, 264, 281, 288, 291], "bring": [20, 48, 123, 126, 127, 133, 381], "submit": [20, 162, 254, 288, 291, 335], "page": [20, 136, 158, 160, 161, 162, 165, 168, 172, 173, 174, 175, 176, 177, 178, 185, 189, 200, 206, 215, 233, 239, 243, 244, 245, 251, 253, 255, 266, 272, 275, 282, 287, 288, 291, 335], "reach": [20, 45, 55, 158, 244, 249, 255, 259, 261, 267, 272, 282, 298, 308], "safe": [20, 129, 243, 249, 252, 254, 276, 335], "collabor": 20, "adher": [20, 129, 334], "often": [21, 24, 43, 45, 123, 125, 129, 159, 162, 170, 191, 233, 242, 244, 249, 251, 253, 254, 255, 276, 288, 291], "encount": [21, 158, 189, 323], "larg": [21, 24, 57, 59, 124, 129, 133, 143, 160, 162, 164, 168, 170, 171, 191, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 214, 215, 217, 219, 221, 223, 225, 227, 228, 229, 230, 231, 234, 236, 240, 241, 242, 244, 245, 247, 248, 250, 252, 253, 254, 255, 256, 257, 264, 266, 267, 272, 273, 275, 276, 277, 278, 279, 284, 288, 291, 294, 296, 299, 302, 303, 312, 360, 361, 368], "consum": [21, 162, 254, 288, 291], "previous": [21, 163, 190, 203, 215, 233, 237, 245, 251, 252, 253, 255, 280], "constant": [21, 31, 54, 79, 96, 98, 119, 160, 171, 226, 251, 252, 272, 291, 308], "lack": [21, 159, 162, 257, 288, 291], "faster": [21, 23, 46, 57, 59, 115, 129, 139, 158, 160, 162, 171, 172, 189, 200, 207, 217, 224, 231, 234, 237, 244, 247, 250, 252, 264, 267, 276, 277, 278, 288, 291, 331, 362, 365, 367], "dataloadermodul": 21, "hard": [21, 124, 159, 162, 168, 189, 288, 291], "anoth": [21, 24, 41, 54, 55, 123, 124, 159, 160, 161, 162, 165, 170, 187, 189, 236, 243, 244, 248, 249, 251, 252, 253, 254, 255, 265, 279, 280, 288, 291, 380, 384], "treat": [21, 75, 129, 162, 231, 247, 255, 288, 291], "third": [21, 151, 160, 161, 163, 189, 236, 318, 330], "eas": [21, 32, 36, 46, 75, 283], "advantag": [21, 47, 136, 162, 203, 225, 252, 288, 291], "intern": [21, 160, 162, 170, 179, 248, 254, 264, 284, 288, 291, 317, 319, 322, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "hold": [21, 158, 188, 231, 252, 279, 319], "fetch": [21, 158, 162, 253, 265, 288, 291], "index": [21, 38, 62, 75, 161, 168, 188, 190, 230, 232, 236, 249, 251, 253, 267, 275, 291, 319, 331, 363, 364], "__len__": [21, 22, 62, 75, 168, 236, 362, 363, 364], "life": 21, "give": [21, 55, 124, 125, 129, 157, 159, 162, 168, 189, 198, 199, 243, 244, 247, 248, 249, 251, 253, 254, 255, 259, 270, 288, 291, 320, 357, 358], "compos": [21, 54, 143, 267, 291], "togeth": [21, 24, 32, 36, 53, 54, 160, 168, 170, 171, 187, 202, 227, 236, 244, 250, 251, 253, 255, 297, 305, 307, 375], "serial": [21, 162, 275, 288, 291], "launch": [21, 39, 119, 120, 129, 159, 189, 256, 257, 261, 267, 273, 276, 277, 280, 289, 295, 304, 322, 369], "__next__": 21, "constraint": [21, 52, 55, 56, 61, 63, 134, 137, 138, 142, 247, 357, 358, 359, 360, 362, 363, 364, 365, 370], "sampling_s": [21, 55, 56, 61, 63, 75, 134, 137, 138, 142, 148, 149, 150, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 386, 391], "mani": [21, 32, 36, 55, 56, 61, 63, 119, 123, 124, 129, 133, 134, 137, 138, 142, 159, 160, 161, 162, 163, 168, 189, 192, 198, 204, 205, 211, 215, 217, 222, 223, 226, 233, 234, 235, 236, 239, 244, 249, 250, 253, 254, 270, 284, 288, 291, 322, 357, 358, 365, 370, 386], "randomresizedcrop": [21, 54, 134, 137, 138, 142, 148, 149, 150, 386], "randomhorizontalflip": [21, 54, 134, 137, 138, 142, 148, 149, 150, 386], "calib_data": [21, 70, 342, 343, 345, 346, 349, 350, 353], "mx": [21, 71], "imagerecordit": 21, "path_imgrec": 21, "label_width": 21, "preprocess_thread": 21, "data_nthread": 21, "data_shap": [21, 71], "label_nam": 21, "rand_crop": 21, "rand_mirror": 21, "shuffl": [21, 48, 168, 193, 254, 256, 330], "shuffle_dataset": 21, "shuffle_chunk_se": 21, "shuffle_se": 21, "data_layer_typ": 21, "ctx": [21, 71], "combine_mean_std": 21, "industri": [22, 38, 252], "mnist": [22, 26, 59, 73, 74, 344], "filter": [22, 35, 45, 53, 55, 59, 160, 171, 212, 213, 241, 244, 253, 254, 277, 282, 284, 391], "directori": [22, 26, 30, 53, 69, 70, 71, 119, 126, 129, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 156, 159, 161, 162, 168, 172, 180, 183, 188, 189, 190, 251, 253, 256, 263, 266, 275, 276, 279, 288, 291, 293, 296, 299, 301, 306, 311, 312, 313, 314, 316, 318, 324, 327, 330, 332, 333, 335, 336, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 380, 382, 384, 385, 389, 390], "bool": [22, 38, 47, 54, 323], "subset": [22, 129, 200, 209, 238, 357, 358, 391], "condit": [22, 37, 54, 55, 160, 171, 193, 195, 203, 227, 230, 244, 247, 254, 281], "put": [22, 24, 45, 155, 156, 159, 161, 165, 168, 170, 189, 190, 219, 235, 244, 254, 256, 265, 267, 278, 289, 365, 371], "again": [22, 33, 49, 129, 162, 163, 172, 189, 231, 236, 249, 253, 254, 255, 279, 288, 291, 323], "npz": [22, 129], "manual": [22, 72, 124, 134, 137, 138, 142, 145, 146, 148, 151, 156, 158, 254, 322, 323, 330, 332, 373, 377, 381], "ensp": [22, 38, 54], "fashionmnist": [22, 348], "idx1": 22, "ubyt": 22, "gz": [22, 63, 117, 118, 122, 123, 125, 126, 129, 168, 275, 276, 301, 332, 333, 336, 338, 357, 358, 363, 365, 367, 370, 371, 382, 385], "idx3": 22, "t10k": 22, "cifar10": [22, 354, 391], "extract": [22, 125, 127, 129, 143, 160, 162, 164, 165, 168, 171, 181, 186, 190, 200, 206, 218, 227, 230, 244, 249, 250, 251, 265, 267, 275, 276, 282, 284, 288, 291, 324, 326, 330, 337], "toronto": [22, 195, 214, 267], "edu": [22, 121, 168, 187, 302], "kriz": 22, "cifar": [22, 57], "tar": [22, 63, 117, 118, 130, 131, 132, 168, 265, 276, 277, 301, 338, 357, 358, 363, 365, 367, 370, 371, 382, 385], "cifar100": 22, "imagerecord": [22, 26, 56, 61, 63, 65, 66, 75, 357, 358, 391], "arrang": [22, 45], "000": [22, 143, 160, 165, 172, 187, 218, 222, 255, 265, 271, 284], "001": [22, 26, 56, 147, 162, 189, 288, 291], "099": 22, "class_1": 22, "png": [22, 72, 119, 129, 218, 327], "xxy": 22, "xxz": 22, "class_n": 22, "123": [22, 54, 65, 66, 136, 357, 358, 391], "nsdf3": 22, "asd932_": 22, "categori": [22, 71, 186, 244, 245, 278], "folder": [22, 53, 73, 122, 123, 124, 125, 126, 127, 129, 134, 137, 138, 139, 142, 143, 145, 146, 148, 149, 150, 151, 153, 158, 160, 161, 162, 168, 172, 236, 243, 251, 254, 257, 262, 265, 266, 267, 268, 272, 274, 276, 282, 287, 288, 289, 291, 310, 318, 322, 323, 325, 326, 338, 360, 361, 363, 370, 371, 376, 380, 384], "imagenetraw": 22, "data_path": [22, 71, 77, 78, 81, 82, 83, 86, 87, 88, 93, 95, 102, 104, 105, 106, 107, 109, 110, 111, 114, 115, 116, 265], "image_list": [22, 319], "img1": 22, "jpg": [22, 143, 324, 331], "img2": 22, "imgx": 22, "val_map": 22, "cocorecord": 22, "num_cor": [22, 257], "28": [22, 32, 33, 50, 57, 67, 143, 277, 331, 359, 362, 364, 367, 391], "interleav": [22, 159], "parallel": [22, 45, 129, 158, 159, 168, 170, 189, 236, 239, 295, 304, 362, 364], "tfrecord": [22, 368, 370], "gt": [22, 54, 277], "cocoraw": 22, "img_dir": 22, "anno_dir": [22, 326], "val2017": [22, 86, 318, 322, 326, 327], "annot": [22, 38, 86, 129, 187, 218, 236, 244, 278, 280, 282, 318, 322, 326, 327], "instances_val2017": [22, 86, 326, 327], "json": [22, 40, 54, 73, 74, 86, 104, 120, 122, 123, 125, 126, 129, 155, 156, 162, 167, 168, 189, 243, 267, 272, 275, 276, 279, 280, 288, 291, 296, 300, 310, 324, 326, 327, 338, 359, 360, 361, 391], "coconpi": [22, 326], "npy_dir": [22, 326], "npy": [22, 266, 326], "total": [22, 54, 129, 159, 161, 162, 168, 187, 236, 245, 252, 253, 255, 256, 261, 267, 272, 278, 280, 288, 289, 291, 321, 331, 362, 364], "dimens": [22, 24, 45, 54, 162, 170, 231, 232, 236, 244, 251, 252, 267, 278, 288, 291, 319], "128": [22, 48, 54, 57, 70, 100, 103, 108, 141, 142, 163, 250, 256, 257, 261, 263, 264, 276, 280, 282, 297, 298, 299, 300, 302, 304, 305, 307, 308, 311, 312, 314, 315, 359, 362], "lt": [22, 44, 59, 364], "127": [22, 48, 57, 249], "length": [22, 38, 48, 54, 79, 96, 98, 129, 160, 163, 168, 170, 171, 206, 213, 219, 220, 231, 237, 242, 244, 249, 250, 251, 253, 259, 270, 274, 276, 277, 282, 284, 335, 359, 362], "float16": [22, 119], "int32": [22, 253, 391], "int64": [22, 391], "ignor": [22, 124, 168, 170, 247, 249, 251, 254, 276, 296], "stand_norm": 22, "dummy_v2": [22, 64, 67, 391], "input_shap": [22, 64, 67, 358, 391], "label_shap": [22, 64, 391], "eg": [22, 47, 71, 358], "style_transf": [22, 371], "content_fold": [22, 371], "style_fold": [22, 371], "crop_ratio": 22, "resize_shap": 22, "image_format": 22, "content": [22, 123, 159, 189, 190, 203, 204, 205, 206, 254, 283, 284, 285, 286, 371, 386], "crop": [22, 54, 126, 133, 136, 139, 141, 143, 319], "ratio": [22, 32, 45, 50, 54, 57, 129, 143, 259, 272, 284, 298, 308, 309, 319, 322], "transfer": [22, 24, 25, 59, 143, 160, 162, 171, 194, 207, 209, 214, 224, 226, 235, 236, 241, 244, 267, 272, 288, 291, 358], "task": [22, 24, 35, 38, 70, 82, 96, 101, 105, 107, 120, 121, 122, 123, 125, 126, 127, 129, 136, 143, 159, 160, 162, 165, 168, 170, 171, 187, 189, 191, 192, 193, 194, 195, 196, 197, 201, 202, 203, 204, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 234, 235, 236, 238, 239, 240, 241, 242, 243, 244, 245, 248, 250, 252, 254, 255, 256, 264, 265, 267, 270, 272, 275, 276, 278, 279, 280, 282, 284, 285, 287, 288, 291, 296, 298, 306, 308, 316, 317, 359, 360, 361, 362, 363, 364], "holder": 22, "tfrecorddataset": [22, 55], "filenam": [22, 122, 123, 161, 252], "bert": [22, 24, 28, 38, 45, 54, 57, 59, 70, 100, 101, 102, 103, 107, 108, 142, 160, 162, 163, 164, 165, 168, 170, 171, 172, 185, 191, 192, 193, 194, 196, 197, 200, 201, 202, 204, 205, 207, 209, 211, 213, 214, 216, 224, 225, 232, 233, 234, 236, 239, 241, 242, 247, 249, 250, 251, 252, 253, 255, 256, 257, 258, 260, 263, 264, 267, 270, 271, 272, 273, 280, 282, 284, 288, 289, 291, 293, 294, 295, 297, 298, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 316, 361, 362, 376], "label_fil": [22, 54, 360], "squad": [22, 32, 38, 54, 57, 59, 101, 104, 105, 107, 165, 171, 191, 193, 195, 204, 205, 224, 225, 229, 233, 237, 240, 250, 253, 256, 257, 267, 272, 285, 296, 299, 300, 311, 312, 313, 314, 332, 360, 361], "model_typ": [22, 100, 103, 108, 130, 132, 167, 263, 264, 266, 271, 272, 275, 281, 300, 330, 359], "sparse_dummy_v2": 22, "dense_shap": 22, "sparse_ratio": 22, "spars": [22, 45, 46, 59, 208, 272, 291, 295, 296, 297, 298, 304, 307, 308], "distilbert": [22, 57, 59, 102, 160, 165, 168, 171, 172, 250, 251, 253, 255, 278, 293, 294, 306, 311, 314], "xlnet": [22, 160, 171, 188, 209, 225, 250, 253, 255, 263, 281, 293, 311], "xlm": [22, 57, 59, 102, 160, 162, 171, 197, 228, 250, 253, 255, 267, 288, 291, 293, 311, 313], "tensordataset": 22, "huggingfac": [22, 59, 97, 100, 103, 108, 119, 157, 159, 160, 161, 162, 168, 170, 171, 172, 180, 183, 188, 189, 209, 236, 243, 250, 253, 257, 265, 272, 274, 276, 277, 279, 286, 287, 288, 289, 291, 293, 294, 295, 297, 298, 300, 301, 302, 303, 304, 307, 308, 313, 316, 376, 377], "glue": [22, 38, 70, 99, 100, 102, 103, 108, 155, 156, 164, 171, 191, 193, 195, 202, 207, 209, 217, 224, 225, 233, 234, 241, 244, 253, 256, 257, 264, 266, 267, 270, 280, 285, 299, 303, 306, 315, 332, 377], "data_dir": [22, 99, 100, 102, 103, 108, 119, 159, 254, 260, 263, 264, 271, 272, 275, 276, 277, 306, 359], "model_name_or_path": [22, 100, 101, 102, 103, 108, 159, 189, 257, 259, 260, 261, 263, 264, 270, 271, 272, 273, 275, 276, 279, 280, 281, 282, 293, 294, 295, 297, 298, 299, 300, 302, 303, 304, 305, 307, 308, 311, 312, 313, 314, 315, 376, 377], "max_seq_length": [22, 54, 100, 103, 108, 187, 257, 260, 261, 263, 264, 280, 295, 297, 298, 299, 300, 302, 304, 311, 312, 313, 314, 315, 359, 362], "do_lower_cas": [22, 54, 100, 103, 108, 264, 272, 300], "dynamic_length": 22, "shortcut": [22, 251], "maximum": [22, 48, 54, 168, 227, 247, 249, 251, 284, 298, 308, 362], "longer": [22, 54, 159, 162, 168, 170, 189, 191, 219, 220, 236, 237, 250, 254, 276, 282, 288, 291], "truncat": [22, 54, 123, 168, 170, 171, 227, 236, 251, 256, 276], "shorter": [22, 54, 189, 213, 253, 276, 277], "lowercas": [22, 255, 284, 288], "mrpc": [22, 32, 38, 57, 59, 99, 100, 102, 103, 108, 187, 250, 253, 256, 264, 266, 267, 280, 293, 299, 311, 312, 313, 314, 315, 359, 376], "qqp": [22, 38, 57, 187, 264, 266, 267, 272, 280, 313], "qnli": [22, 32, 38, 57, 187, 264, 266, 267, 280, 313], "rte": [22, 32, 38, 57, 187, 264, 266, 267, 280, 312, 313], "st": [22, 32, 38, 264, 267, 280, 313], "b": [22, 32, 38, 133, 142, 143, 158, 162, 165, 168, 244, 249, 253, 255, 257, 264, 274, 276, 277, 280, 282, 288, 291, 313, 357], "cola": [22, 32, 38, 57, 187, 264, 267, 280, 313], "mnli": [22, 38, 57, 187, 204, 205, 234, 250, 257, 263, 264, 266, 267, 272, 278, 280, 313], "wnli": [22, 38, 57, 187, 267, 280, 293, 311, 313], "mobilebert": [22, 24, 57, 59, 108, 171], "roberta": [22, 57, 59, 102, 160, 165, 171, 193, 196, 197, 200, 201, 204, 205, 209, 217, 219, 220, 225, 234, 250, 253, 255, 260, 263, 266, 267, 270, 278, 289, 291, 293, 302, 304, 311, 313], "uncas": [22, 54, 57, 59, 100, 102, 103, 155, 156, 160, 163, 165, 167, 168, 170, 185, 190, 196, 207, 245, 250, 251, 252, 253, 255, 256, 257, 261, 264, 267, 271, 272, 278, 280, 282, 294, 295, 297, 299, 300, 302, 303, 304, 305, 307, 311, 314, 360, 361, 364], "yaml_fil": [22, 26, 38, 42], "collate_fn": [22, 330, 359, 363, 364], "aid": [23, 159], "deploy": [23, 373], "infrastructur": 23, "smaller": [24, 45, 54, 158, 160, 162, 171, 189, 191, 198, 200, 207, 209, 222, 224, 244, 247, 253, 255, 267, 282, 288, 291, 294, 302, 362], "less": [24, 45, 129, 158, 159, 171, 189, 202, 207, 209, 238, 244, 247, 252, 253, 267, 272, 293, 322], "expens": [24, 55, 233, 234, 276], "power": [24, 44, 186, 195, 203, 206, 214, 215, 217, 227, 230, 235, 238, 244, 252, 253, 381], "mobil": [24, 57, 59, 136, 143, 171, 224, 234], "workflow": [24, 32, 36, 39, 53, 58, 168, 171, 254, 283, 286, 382, 385], "produc": [24, 197, 209, 253, 254, 276, 277], "logit": [24, 120, 174, 185, 189, 190, 236, 253, 256, 276, 309, 357, 358], "softmax": [24, 125, 129, 161, 204, 205, 217, 237, 244, 251, 253, 278, 359, 391], "l": [24, 53, 55, 73, 74, 126, 133, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 155, 156, 223, 231, 244, 254, 255, 279, 282, 338, 360, 361], "kd": 24, "z": [24, 129, 244, 333], "where": [24, 28, 45, 53, 55, 79, 96, 98, 123, 124, 125, 126, 127, 129, 159, 160, 162, 168, 170, 171, 172, 189, 193, 204, 205, 208, 209, 218, 219, 223, 230, 231, 235, 243, 244, 247, 249, 251, 252, 253, 254, 255, 264, 265, 274, 275, 276, 278, 279, 280, 281, 287, 288, 291, 295, 304, 319, 322, 362, 364, 370, 380, 384], "distanc": [24, 207, 231], "g": [24, 33, 45, 51, 55, 136, 159, 162, 163, 170, 172, 181, 188, 189, 190, 196, 217, 225, 235, 239, 244, 251, 253, 254, 255, 263, 274, 275, 284, 288, 291, 323, 373, 376], "euclidean": 24, "kullback": 24, "leibler": 24, "diverg": [24, 289, 309], "term": [24, 37, 38, 42, 43, 55, 157, 165, 168, 171, 198, 199, 206, 208, 231, 237, 244, 256, 272, 274], "patient": [24, 129], "compact": [24, 45, 154, 224, 252, 374], "agnost": [24, 214, 224, 256], "resourc": [24, 32, 45, 159, 171, 187, 193, 224, 241, 254, 264, 266, 267, 272, 280, 338], "summar": [24, 160, 162, 165, 170, 171, 193, 194, 196, 210, 219, 227, 229, 235, 236, 240, 244, 249, 250, 251, 257, 288, 291, 293, 301], "1x1": [24, 298, 308], "convolut": [24, 45, 46, 124, 129, 133, 136, 154, 160, 171, 202, 205, 213, 234, 244], "etc": [24, 35, 52, 124, 126, 129, 133, 158, 160, 161, 162, 163, 188, 203, 218, 225, 249, 251, 254, 263, 278, 283, 288, 291, 298, 308, 310, 319, 388], "ia": 24, "stage": [24, 53, 162, 189, 222, 243, 255, 288, 291, 295, 304, 329, 337], "attach": [24, 158, 159, 255], "shallow": 24, "depth": [24, 49, 133, 162, 254, 288, 291], "deepest": 24, "convent": [24, 123, 136, 231], "deeper": [24, 159, 162, 213, 288, 291], "lead": [24, 39, 45, 157, 162, 189, 191, 241, 252, 254, 255, 261, 275, 276, 279, 288, 291, 322], "much": [24, 28, 33, 45, 54, 123, 124, 125, 129, 133, 159, 162, 189, 190, 191, 213, 231, 233, 236, 243, 244, 247, 254, 255, 256, 276, 278, 282, 288, 291, 322, 381], "architectur": [24, 32, 36, 45, 46, 58, 129, 133, 136, 162, 163, 170, 171, 172, 187, 191, 192, 193, 195, 197, 198, 200, 204, 205, 206, 209, 210, 213, 214, 230, 233, 234, 235, 236, 237, 240, 244, 248, 250, 251, 253, 254, 257, 267, 272, 275, 280, 288, 289, 291, 362, 364], "paper": [24, 45, 129, 133, 136, 139, 143, 158, 160, 161, 162, 171, 187, 189, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 247, 253, 259, 264, 266, 267, 270, 272, 273, 274, 276, 284, 288, 290, 291, 295, 303, 304, 317, 331, 362], "Will": [24, 35, 331], "10006": 24, "student_model": 24, "teacher_model": [24, 130, 131, 132], "distillationconf": 24, "insid": [24, 45, 79, 96, 98, 120, 159, 170, 172, 189, 223, 243, 244, 254, 262, 280, 286, 287, 359, 360], "on_train_begin": [24, 298, 308], "on_after_compute_loss": 24, "student_output": 24, "student_loss": 24, "blendcnn": [24, 57, 59], "train_func": [24, 26, 45], "loss_sum": 24, "iter_bar": 24, "tqdm": [24, 159, 179, 247, 291], "train_dataload": [24, 45, 236, 298, 308], "desc": [24, 45, 71], "teacher_logit": 24, "input_id": [24, 45, 161, 162, 163, 168, 170, 188, 190, 193, 196, 197, 218, 219, 220, 223, 228, 231, 235, 236, 245, 247, 249, 251, 253, 256, 267, 288, 291], "segment_id": 24, "input_mask": 24, "pytorchknowledgedistillationloss": 24, "promis": [25, 32, 45, 203, 248, 272], "footprint": [25, 42, 45, 47, 55, 160, 171, 189, 191, 202, 217, 244, 253, 272], "huge": [25, 159, 189, 211, 224, 244, 254, 276], "bit": [25, 39, 46, 48, 129, 143, 159, 162, 189, 213, 236, 244, 247, 251, 252, 253, 272, 288, 291], "heavi": [25, 224, 254], "booster": 25, "degrad": [25, 191], "retrain": [25, 143, 160, 171], "incorpor": [25, 55, 124, 218, 223, 224, 248], "novel": [25, 162, 193, 194, 202, 204, 205, 217, 221, 225, 229, 234, 237, 240, 244, 250, 278, 288, 291, 373, 381], "pipelin": [25, 43, 59, 73, 74, 123, 124, 127, 129, 133, 160, 164, 165, 171, 172, 206, 244, 248, 252, 253, 254, 278, 285, 295, 304, 322], "builtin": [26, 61, 63, 276], "write": [26, 34, 52, 53, 75, 76, 148, 158, 159, 160, 162, 168, 171, 189, 214, 215, 234, 267, 281, 283, 284, 288, 291, 322, 327, 373], "program": [26, 33, 39, 124, 159, 162, 189, 252, 254, 288, 291, 335, 366, 373], "real": [26, 46, 48, 129, 136, 172, 218, 235], "addition": [26, 55, 162, 187, 190, 216, 230, 236, 243, 284, 288, 291, 319], "eager": [26, 35, 48, 49, 53, 57, 59, 134, 137, 138, 142, 145, 146, 148, 151, 155, 156, 162, 288, 291, 293, 296, 301, 306, 311, 313, 316, 330, 332, 337, 338], "enable_eager_execut": 26, "yaml_file_path": 26, "pre_process": 26, "evaluation_result": 26, "evaluation_time_cost": 26, "partit": [26, 189], "distributedsampl": 26, "train_sampl": 26, "util": [26, 27, 45, 48, 61, 63, 67, 123, 125, 129, 143, 148, 149, 162, 168, 171, 190, 196, 217, 236, 252, 279, 288, 289, 291, 311, 312, 314, 315, 318, 322, 330, 358, 363, 373], "train_dataset": [26, 168, 236, 256, 299, 311, 312, 314], "num_replica": 26, "hvd": 26, "rank": [26, 189, 212, 242, 275, 295, 304], "train_kwarg": 26, "sampler": [26, 276], "adadelta": 26, "distributedoptim": 26, "named_paramet": [26, 256], "broadcast": [26, 54], "broadcast_paramet": 26, "root_rank": 26, "broadcast_optimizer_st": 26, "set_epoch": 26, "batch_idx": 26, "nll_loss": 26, "log_interv": 26, "0f": 26, "tloss": 26, "6f": 26, "item": [26, 52, 69, 70, 71, 76, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 156, 159, 161, 168, 236, 251, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 386], "dry_run": 26, "test_func": [26, 70, 71], "host": [26, 73, 74, 129, 135, 141, 152, 160, 172, 187, 189, 214, 215, 254, 259, 270, 282, 317, 320, 340, 341, 354, 388], "np": [26, 54, 62, 75, 135, 141, 147, 152, 168, 236, 254, 333, 340, 341, 354, 360], "num_of_process": [26, 135, 152, 340, 341, 354], "h": [26, 54, 71, 129, 133, 135, 136, 143, 152, 244, 255, 278, 319, 331, 340, 341, 354, 360, 361, 365, 371], "002": [26, 143, 163], "ssh": 26, "readm": [26, 162, 163, 169, 193, 194, 227, 243, 246, 253, 257, 262, 279, 283, 286, 287, 288, 291, 293, 294, 297, 299, 301, 302, 305, 307, 311, 312, 313, 314, 316, 324, 332, 333, 336, 338, 357, 366, 390], "md": [26, 27, 161, 162, 163, 166, 169, 193, 194, 227, 243, 246, 253, 276, 279, 283, 286, 287, 288, 291, 322, 324], "exactli": [26, 122, 123, 129, 162, 168, 189, 249, 255, 288, 289, 291], "resnet50_v1": [26, 33, 96, 357], "resizecropimagenet": [26, 54, 65, 66, 357, 358, 391], "height": [26, 45, 54, 56, 61, 63, 65, 66, 75, 143, 218, 319, 322, 331, 357, 358, 391], "realiz": [26, 38, 42, 49, 52, 159, 214], "tow": 26, "situat": [26, 129, 159, 189, 253, 254], "node1": 26, "node2": 26, "TO": [26, 69, 71, 123, 144, 156, 356, 357, 358, 370], "your_node1_nam": 26, "your_node2_nam": 26, "resnet50_fp32_pretrained_model": [26, 33, 357], "nc_resnet50_v1": [26, 69, 357], "materi": 27, "ux": [27, 387, 388], "system": [27, 45, 126, 129, 133, 136, 160, 163, 182, 189, 206, 208, 212, 217, 234, 254, 263, 268, 276, 283, 286, 306, 325, 374], "simplifi": [27, 73, 74, 250, 296, 322, 373, 381, 386], "explain": [27, 158, 159, 160, 162, 163, 164, 232, 236, 244, 252, 254, 267, 272, 288, 291, 311], "kit": 27, "instal": [27, 30, 44, 58, 60, 121, 123, 124, 125, 127, 130, 131, 132, 133, 135, 144, 147, 154, 158, 159, 162, 167, 171, 179, 190, 214, 236, 243, 250, 254, 257, 262, 265, 267, 269, 272, 274, 276, 280, 286, 287, 288, 289, 291, 300, 306, 309, 317, 323, 324, 328, 373, 382, 385], "app": [27, 120, 161, 165, 172, 390], "bfp16": 27, "platform": [27, 32, 33, 35, 46, 48, 52, 57, 160, 165, 172, 179, 187, 189, 234, 254, 373], "model_convers": 27, "purpos": [27, 31, 39, 47, 55, 159, 160, 162, 170, 171, 207, 230, 236, 249, 253, 254, 272, 288, 291, 322], "factor": [28, 44, 57, 124, 129, 131, 133, 165, 231, 235, 241, 242, 244, 247, 259, 267], "oppos": [28, 129], "entail": [28, 187, 214, 216, 236, 263, 278, 280, 284], "signal": [28, 238, 272], "preserv": [28, 143, 203, 207, 267, 283], "nlp": [28, 45, 48, 59, 155, 156, 160, 162, 164, 165, 170, 171, 194, 196, 197, 201, 204, 205, 207, 209, 211, 218, 222, 224, 226, 228, 230, 234, 235, 244, 247, 248, 250, 252, 253, 257, 275, 276, 277, 286, 288, 291, 293, 294, 295, 296, 297, 301, 302, 303, 304, 305, 306, 307, 311, 315, 316, 359, 360, 361, 363, 376], "mandatori": [28, 56, 69, 70, 71, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 156, 162, 280, 288, 291, 293, 295, 299, 301, 304, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "onnxrt_integerop": [28, 47, 69, 76], "post_training_dynamic_qu": [28, 47, 76, 301, 311, 312, 313, 316], "post_training_static_qu": [28, 47, 55, 76, 293, 299, 314, 318], "rel": [28, 47, 52, 55, 56, 57, 69, 70, 71, 75, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 168, 170, 201, 204, 205, 235, 236, 237, 241, 244, 252, 254, 276, 291, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 366, 370, 371, 391], "absolut": [28, 38, 44, 45, 48, 55, 67, 69, 72, 73, 74, 134, 137, 138, 142, 156, 158, 159, 162, 170, 191, 195, 200, 203, 206, 208, 214, 215, 221, 224, 234, 236, 239, 261, 288, 291, 326, 357, 358, 365, 370, 391], "exit_polici": [28, 52, 55, 56, 69, 70, 71, 75, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 293, 299, 301, 311, 312, 313, 314, 316, 318, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 391], "earli": [28, 48, 55, 56, 69, 70, 71, 134, 137, 138, 142, 151, 156, 179, 189, 272, 283, 293, 299, 301, 311, 312, 313, 314, 315, 316, 332, 333, 336, 357, 358, 365, 370], "stop": [28, 55, 56, 69, 70, 71, 134, 137, 138, 142, 151, 156, 179, 189, 193, 249, 253, 255, 275, 276, 293, 299, 301, 311, 312, 313, 314, 315, 316, 332, 333, 336, 357, 358, 365, 370], "max_trial": [28, 55, 69, 134, 137, 138, 142, 156, 293, 299, 301, 311, 312, 313, 314, 316, 318, 357, 358, 359, 360, 362, 363, 364, 365, 370, 391], "random_se": [28, 52, 55, 56, 69, 70, 71, 75, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 391], "9527": [28, 52, 55, 56, 69, 70, 71, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 391], "determinist": [28, 55, 69, 134, 137, 138, 142, 156, 162, 254, 272, 288, 291, 357, 358, 365, 370], "wide": [29, 39, 48, 59, 159, 160, 172, 189, 195, 204, 205, 207, 208, 211, 213, 214, 226, 230, 241, 252, 256, 272, 298, 308, 311, 368], "varieti": [29, 47, 55, 124, 159, 213, 218, 219, 220, 225, 226, 235, 241, 252, 254, 256], "demonstr": [29, 32, 33, 41, 45, 53, 61, 62, 63, 64, 65, 66, 67, 68, 75, 121, 127, 139, 148, 149, 157, 158, 159, 160, 165, 168, 196, 200, 207, 209, 211, 214, 215, 219, 221, 223, 226, 234, 238, 239, 247, 275, 358, 373], "numpi": [30, 54, 167, 168, 181, 251, 253, 254, 333], "ndarrai": [30, 54], "incompat": [30, 129, 189, 323], "88": [30, 32, 50, 52, 57, 133, 139, 143, 154, 204, 205, 261, 264, 267, 272, 280, 309], "header": [30, 280], "80": [30, 32, 50, 53, 57, 133, 139, 140, 143, 154, 158, 195, 222, 237, 260, 261, 264, 272, 284, 309, 335], "pyobject": 30, "reinstal": [30, 158], "pycocotool": [30, 36, 320], "cach": [30, 48, 141, 160, 171, 190, 248, 251, 254], "importerror": 30, "libgl": 30, "share": [30, 31, 55, 159, 160, 165, 171, 205, 211, 212, 244, 251, 267, 272, 276, 278, 279, 282, 286, 298, 308], "apt": [30, 32, 36, 243, 374, 381], "yum": [30, 32, 36], "opencv": [30, 320, 367, 381], "conflict": [30, 123, 189], "pend": 30, "long": [30, 54, 129, 159, 160, 161, 162, 165, 170, 171, 189, 196, 206, 214, 219, 220, 231, 232, 236, 237, 244, 251, 253, 255, 276, 288, 291, 357, 370], "sqlalchemi": [30, 36], "27": [30, 32, 36, 57, 70, 73, 74, 140, 143, 218, 391], "alemb": [30, 36, 389], "quick": [31, 56, 62, 129, 159, 167, 171, 190, 247, 249, 276, 278, 280], "friendli": [31, 56, 159, 162, 288, 291], "capabl": [31, 39, 47, 48, 55, 56, 156, 160, 203, 207, 214, 215, 221, 236, 242, 244, 252, 257, 272, 280, 332], "NOT": [31, 129, 142, 248, 293, 299, 301, 311, 312, 313, 314, 316, 332, 333, 336], "unless": [31, 124, 133, 159, 172, 243, 249, 254, 276], "let": [31, 47, 56, 119, 129, 158, 159, 162, 163, 168, 172, 185, 189, 190, 207, 236, 243, 244, 245, 247, 248, 251, 252, 254, 255, 256, 257, 278, 282, 283, 288, 289, 291, 376], "15": [31, 32, 33, 57, 58, 163, 187, 231, 244, 250, 255, 261, 264, 272, 280, 284, 291, 308, 322, 358, 370, 391], "up1": [31, 32, 58], "up2": [31, 32, 58], "valid_mixed_precis": 31, "matmul": [31, 220, 231, 298, 308, 359, 360], "concatv2": 31, "maxpool": 31, "avgpool": 31, "depthwiseconv2dn": 31, "sym": [31, 55, 56], "per_channel": [31, 55, 56, 61, 359, 360, 362, 363, 364], "per_tensor": [31, 55, 56], "minmax": [31, 55, 56, 61, 357, 358, 365], "kl": [31, 55, 56, 274, 309], "asym": [31, 55, 56], "biasadd": [31, 391], "addn": 31, "addv2": 31, "grappler": 31, "grappler_optim": 31, "constfold": 31, "fold": [31, 79, 96, 98, 120, 121, 127, 129, 252, 369], "debug_stripp": 31, "consolid": [32, 36, 275], "latest": [32, 36, 46, 51, 101, 102, 133, 159, 172, 189, 257, 267, 272, 280, 389], "place": [32, 36, 53, 124, 189, 251, 253, 310, 348], "along": [32, 36, 129, 133, 160, 162, 174, 185, 211, 244, 252, 254, 257, 268, 288, 291], "streamlin": [32, 36], "scienc": [32, 36, 129, 274, 278], "anaconda": [32, 36, 133, 143, 190, 257, 323], "suit": [32, 36, 53, 128, 158, 162, 194, 254, 265, 288, 291, 326, 329, 335, 337], "prerequisit": [32, 127, 129], "satisfi": [32, 36, 158, 162, 254, 276, 288, 291], "success": [32, 36, 129, 162, 201, 213, 224, 225, 254, 288, 291, 391], "virtual": [32, 73, 74, 129, 158, 160, 172, 243, 257], "nc": [32, 52, 55, 62, 148, 149, 150, 318, 329, 358], "hello": [32, 62, 160, 174, 185, 243, 249, 254, 267], "world": [32, 62, 147, 158, 160, 200, 218, 230, 254, 255, 278, 279], "processor": [32, 33, 39, 44, 46, 48, 49, 50, 57, 73, 74, 171, 217], "lakecoop": 32, "lakeskylakeic": 32, "3ubuntu": 32, "18": [32, 57, 133, 212, 227, 237, 244, 250, 253, 276, 309, 370, 391], "63": [32, 57, 133, 143, 203, 267, 326, 391], "73": [32, 57, 133, 136, 143, 148, 149, 267], "83": [32, 50, 52, 57, 133, 139, 154, 195, 204, 205, 261, 264, 267, 272, 280, 303], "up3": [32, 58], "ipex": [32, 35, 48, 57, 59, 150, 300, 328, 336, 377, 378], "gain": [32, 43, 46, 162, 193, 209, 214, 219, 233, 239, 241, 245, 288, 291, 381], "variou": [32, 35, 47, 124, 159, 161, 168, 188, 189, 190, 202, 224, 236, 242, 244, 252, 253, 254, 262, 277, 373], "baselin": [32, 52, 53, 69, 70, 71, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 154, 197, 205, 206, 212, 216, 217, 223, 230, 293, 299, 301, 309, 311, 312, 313, 314, 316, 318, 326, 330, 332, 333, 336, 337, 340, 341, 354, 357, 358, 365, 370], "realtim": 32, "resnet50v1": 32, "70": [32, 50, 57, 59, 136, 143, 218, 267, 272, 278, 280, 297, 307], "26": [32, 50, 57, 133, 140, 163, 250, 271, 276, 277, 280, 391], "23x": [32, 57], "resnet101": [32, 57, 59, 64, 143, 144, 147, 148, 149, 150, 151, 153, 154, 346, 358, 365, 367, 391], "77": [32, 50, 57, 133, 143, 224, 267, 272], "40": [32, 44, 56, 57, 131, 136, 139, 159, 182, 207, 215, 253, 255, 267, 280, 321, 391], "05": [32, 33, 38, 57, 73, 74, 123, 139, 141, 162, 163, 288, 291, 293, 326], "42x": [32, 50, 264], "inception_v1": [32, 63, 88, 357], "69": [32, 57, 143, 236, 267, 278, 284], "57": [32, 50, 57, 267, 272, 280, 331, 391], "88x": [32, 57], "inception_v2": [32, 357], "00": [32, 50, 57, 133, 139, 391], "14": [32, 50, 57, 133, 139, 140, 231, 250, 288, 291, 321, 391], "96x": 32, "inception_v3": [32, 53, 148, 149, 343, 357, 391], "65": [32, 50, 57, 133, 139, 140, 272, 277, 280, 308], "36x": [32, 57], "inception_v4": [32, 357, 391], "37": [32, 50, 57, 133, 139, 321, 331, 391], "59x": [32, 50, 57], "inception_resnet_v2": [32, 342, 357], "97x": 32, "mobilenetv1": [32, 113, 339, 391], "ssd_resnet50_v1": [32, 391], "coco": [32, 38, 64, 86, 110, 111, 112, 113, 114, 115, 116, 117, 118, 250, 317, 318, 320, 326, 328, 329, 365, 367], "90": [32, 50, 56, 57, 59, 133, 139, 140, 143, 204, 205, 224, 253, 261, 264, 267, 272, 280, 295, 303, 304, 309, 319], "38": [32, 50, 57, 72, 139, 140, 160, 163, 239, 391], "mask_rcnn_inception_v2": [32, 391], "29": [32, 57, 133, 143, 163, 193, 280, 391], "66x": [32, 57], "vgg16": [32, 57, 59, 143, 351, 357], "72": [32, 57, 133, 136, 139, 140, 143, 148, 149, 218, 267, 272], "75x": [32, 57], "vgg19": [32, 57, 59, 143, 352, 357], "97": [32, 50, 57, 133, 139, 140, 207, 267, 326], "79x": 32, "75": [32, 57, 133, 139, 143, 267, 272, 391], "23": [32, 50, 57, 73, 74, 194, 253, 267, 278, 280, 332, 333, 336, 391], "63x": 32, "resnext101_32x8d": [32, 57, 59], "79": [32, 53, 57, 133, 139, 143, 218, 224, 267, 272, 308], "31": [32, 57, 136, 140, 200, 291, 321, 391], "61x": [32, 57], "0a0": [32, 321], "24aac32": 32, "bert_base_mrpc": [32, 359], "19": [32, 50, 56, 57, 133, 139, 143, 162, 170, 208, 231, 247, 267, 288, 291, 300, 326, 358, 391], "98x": [32, 57], "bert_base_cola": 32, "59": [32, 50, 57, 133, 140, 160, 267, 272, 284, 331], "06": [32, 56, 57, 139, 143, 154, 163, 280, 391], "58": [32, 50, 57, 143, 163, 264, 267, 280, 303], "84": [32, 50, 57, 133, 139, 140, 143, 261, 264, 267, 272, 280, 303], "19x": [32, 57], "bert_base_st": 32, "89": [32, 50, 57, 133, 143, 205, 261, 264, 267, 272, 303], "28x": [32, 57], "bert_base_sst": 32, "sst": [32, 57, 59, 102, 251, 264, 266, 267, 280, 311, 313, 314], "91": [32, 57, 133, 139, 143, 204, 205, 261, 264, 267, 272, 280, 303, 337], "51": [32, 57, 139, 261, 267, 291, 331], "86": [32, 50, 57, 133, 195, 202, 204, 205, 244, 261, 264, 267, 272, 303], "30x": [32, 57, 209], "bert_base_rt": 32, "68": [32, 50, 54, 57, 65, 66, 139, 143, 261, 357, 358, 391], "52": [32, 57, 73, 74, 139, 261, 267, 391], "15x": [32, 57], "bert_large_mrpc": 32, "87": [32, 50, 57, 133, 236, 267, 280, 284, 303, 309], "33": [32, 50, 57, 133, 139, 140, 200, 267, 303, 321, 391], "99": [32, 33, 50, 57, 133, 140, 160, 237, 267, 274, 291], "73x": [32, 57], "bert_large_squad": [32, 360, 361], "92": [32, 50, 57, 133, 143, 261, 264, 267, 280, 303, 337], "85": [32, 52, 57, 133, 154, 261, 264, 267, 272, 280], "93": [32, 50, 57, 133, 143, 195, 218, 247, 261, 264], "21": [32, 57, 133, 139, 143, 237, 267, 276, 277, 280, 284, 370, 377, 391], "01x": [32, 57], "bert_large_qnli": 32, "82": [32, 50, 57, 133, 139, 143, 154, 267, 272], "69x": [32, 57], "primarili": [33, 223, 254], "similar": [33, 47, 55, 56, 159, 162, 170, 191, 194, 202, 205, 212, 214, 217, 222, 224, 227, 231, 234, 236, 243, 244, 249, 250, 251, 254, 255, 257, 267, 276, 278, 281, 288, 291, 319, 322, 331, 386], "subexpress": 33, "elimin": 33, "bfloat16": [33, 39, 49, 369, 373], "word": [33, 38, 57, 59, 158, 159, 160, 162, 168, 170, 188, 189, 203, 204, 205, 211, 215, 216, 218, 228, 237, 244, 249, 250, 251, 253, 255, 257, 261, 267, 284, 288, 291, 299, 300], "explicitli": [33, 34, 189, 229, 240, 244, 279], "graph_optim": 33, "op_to_stor": 33, "optimized_model": [33, 387, 391], "cpx": 33, "clx": [33, 73, 74], "force_bf16": 33, "cmd": [33, 62, 63, 133, 158, 276, 296, 365], "executable_nc_wrapp": 33, "prefix": [33, 53, 71, 129, 133, 158, 161, 170, 222, 223, 227, 235, 244, 253, 376], "consequ": [33, 39, 157, 198, 248, 255], "later": [33, 53, 159, 162, 189, 251, 253, 288, 291, 368], "fallback": [33, 39, 49, 55], "graph_optimization_conf": 33, "throughput": [33, 69, 71, 72, 73, 74, 126, 299, 360], "resnet50_measur": 33, "8280": 33, "2021": [33, 64, 357, 367, 391], "165": 33, "139": [33, 326], "567": [33, 57], "sec": [33, 57, 299, 312, 314, 326, 360], "output_graph": [33, 357, 358, 366, 370], "fp32_optimized_model": 33, "3x": [33, 189, 224, 234, 250], "325": 33, "56": [33, 50, 57, 139, 143, 267, 277, 280, 284, 303], "41": [33, 57, 139, 140, 154, 280, 321, 391], "068": [33, 133], "992": [33, 143], "q_dataload": [34, 55, 148], "na": [35, 133], "gpu": [35, 45, 47, 48, 58, 120, 124, 127, 133, 158, 159, 162, 163, 191, 200, 209, 217, 222, 227, 243, 244, 255, 256, 257, 259, 261, 265, 267, 275, 276, 277, 278, 280, 288, 291, 295, 296, 304, 321, 331, 358], "broad": [35, 377], "snippet": [35, 158, 234, 252, 284, 365], "upload": [35, 129, 160, 162, 171, 254, 278, 288, 291, 368, 382, 385], "dispatch": 35, "fx": [35, 46, 48, 49, 57, 59, 149, 153, 299, 312, 313, 314, 315, 318, 326, 329, 333, 336, 377, 378], "qlinearop": [35, 48, 59, 79, 80, 81, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 110, 111, 112, 113, 117, 118], "qintegerop": [35, 48], "unstructur": [35, 45, 57, 59, 295, 297, 304, 307], "lock": [35, 43, 45, 59, 295, 297, 304, 307], "snip": [35, 45, 57, 59, 298, 308], "gradient": [35, 45, 57, 59, 164, 165, 171, 190, 219, 236, 247, 256, 257, 276, 305, 306], "sensit": [35, 45, 59, 159, 231, 244, 293, 298, 305, 306, 308, 364], "lasso": [35, 45, 59, 309], "intermedi": [35, 45, 48, 162, 170, 236, 244, 250, 284, 288, 291, 298, 308], "plan": [35, 39, 124, 161, 193, 229, 240, 244, 249, 253], "frequent": [36, 253, 255], "ask": [36, 158, 159, 162, 170, 236, 251, 253, 276, 287, 288, 291], "esri": 36, "apach": [37, 58, 120, 284], "softwar": [37, 39, 44, 46, 51, 150, 158, 159, 300], "copyright": 37, "notic": [37, 159, 162, 170, 172, 254, 255, 288, 291, 359], "subject": [37, 159, 248, 387], "mit": [37, 73, 74, 253, 322], "accompani": [37, 167, 190, 216, 255], "wish": [37, 124, 126, 129, 161, 168, 256, 289, 298, 308], "bibtex": [37, 322], "entri": [37, 123, 129, 159, 160, 170, 171, 189, 276, 279, 322], "misc": [37, 253, 264, 276, 284, 322], "author": [37, 136, 139, 160, 161, 162, 165, 170, 193, 194, 198, 199, 200, 205, 220, 223, 227, 229, 231, 236, 240, 248, 258, 262, 264, 266, 267, 268, 270, 272, 273, 274, 275, 276, 278, 283, 284, 288, 289, 290, 291, 322, 331], "feng": [37, 160, 171, 202, 244], "tian": 37, "chuanqi": 37, "wang": [37, 136], "guom": 37, "zhang": [37, 139, 160, 171, 206, 227, 229, 240, 244], "penghui": 37, "cheng": [37, 322], "pengxin": 37, "yuan": 37, "haihao": 37, "shen": 37, "jiong": 37, "gong": [37, 160, 171, 229, 240, 244], "titl": [37, 136, 139, 158, 160, 243, 264, 266, 267, 272, 275, 276, 284, 322, 331], "howpublish": [37, 322], "url": [37, 136, 139, 143, 150, 159, 160, 243, 254, 266, 300, 322, 367, 391], "year": [37, 136, 139, 160, 212, 216, 218, 249, 253, 264, 266, 267, 272, 276, 279, 284, 322, 324, 331], "2020": [37, 129, 139, 160, 163, 194, 197, 198, 199, 228, 229, 240, 264, 266, 267, 272, 276, 284, 291], "logo": [37, 44], "atom": 37, "phi": 37, "pentium": 37, "vtune": 37, "corpor": [37, 44, 168], "subsidiari": [37, 44], "brand": [37, 44, 288], "claim": [37, 44], "popularli": 38, "mae": 38, "compare_label": 38, "error": [38, 55, 73, 74, 159, 162, 182, 189, 243, 252, 254, 288, 291, 322, 358, 391], "rmse": [38, 55], "squar": [38, 55, 244, 362, 364], "problem": [38, 39, 124, 129, 158, 159, 160, 162, 168, 172, 189, 191, 225, 230, 235, 237, 244, 254, 255, 278, 282, 288, 291], "anno_path": 38, "iou_thr": [38, 330], "map_point": 38, "label_map": 38, "union": 38, "decis": [38, 129, 157, 179, 189, 230, 254], "bound": [38, 54, 218, 221, 319, 322, 331], "string": [38, 54, 129, 133, 158, 159, 161, 162, 168, 188, 193, 236, 248, 249, 251, 253, 254, 255, 288, 291, 391], "95": [38, 57, 133, 143, 207, 218, 253, 264, 265, 267, 272, 274, 303], "standard": [38, 54, 55, 129, 167, 168, 170, 188, 189, 193, 198, 213, 216, 219, 220, 231, 235, 244, 248, 251, 256, 272, 273, 278, 289, 386], "threshold": [38, 264, 266, 272, 391], "101": [38, 57, 59, 139, 148, 149, 150, 151, 153, 170, 196, 226, 244, 249, 251, 321, 331, 349, 358], "interpol": [38, 54, 129, 133], "ap": [38, 133, 318, 321, 324, 330], "area": [38, 54, 159, 189, 198, 199], "pr": [38, 158, 160, 161, 162, 254, 277, 279, 287, 288, 291, 382, 385], "curv": [38, 243], "target_boxes_num": 38, "str_label": 38, "int_label": 38, "image_id": [38, 318, 365], "inturn": 38, "id": [38, 52, 55, 123, 125, 127, 129, 161, 162, 168, 188, 223, 231, 236, 241, 245, 249, 250, 251, 253, 255, 279, 280, 282, 288, 291, 321, 387, 391], "cocomap": [38, 365], "vocmap": 38, "cocomapv2": 38, "output_index_map": 38, "num_detect": [38, 56, 117, 118, 365, 391], "bleu": [38, 212, 223, 239, 276, 279, 301, 316, 363, 364], "approxim": [38, 129, 217, 231, 247, 252], "piec": [38, 162, 179, 280, 288, 291], "decod": [38, 54, 160, 162, 165, 171, 188, 193, 194, 196, 204, 205, 212, 213, 219, 222, 223, 227, 229, 235, 238, 240, 242, 244, 248, 249, 250, 252, 253, 255, 276, 285, 288, 291, 337], "By": [38, 40, 75, 119, 143, 158, 162, 163, 179, 189, 196, 235, 244, 247, 249, 251, 252, 254, 267, 272, 275, 278, 288, 291, 335, 380, 381, 384], "ngram": [38, 205, 229, 240], "breviti": [38, 129], "penalti": [38, 272], "beam": [38, 227], "squadf1": [38, 360], "categor": [38, 253], "multiclass": [38, 165], "multilabel": 38, "multi_metr": 38, "equal": [38, 158, 231, 244, 247, 298, 300, 308], "num": [38, 123, 133, 141, 147, 331, 359, 391], "newmetr": 38, "reflect": [38, 44, 54, 75, 159, 167, 189, 236, 311], "recent": [39, 158, 159, 168, 195, 196, 200, 202, 204, 205, 216, 217, 218, 224, 226, 228, 233, 236, 239, 244, 252, 257, 262, 267, 280, 364], "growth": 39, "complex": [39, 129, 159, 162, 170, 186, 220, 231, 255, 256, 278, 288, 291], "googl": [39, 46, 103, 133, 158, 159, 160, 161, 162, 167, 171, 196, 204, 205, 209, 218, 222, 227, 231, 233, 236, 250, 253, 257, 276, 277, 282, 288, 291, 292, 357, 358], "fp16": [39, 48, 159, 163, 189, 227, 257, 275, 276, 277, 278, 280], "ieee": [39, 317], "half": [39, 204, 205, 254, 259, 276], "sixteen": [39, 164], "bandwidth": 39, "3rd": [39, 46, 48, 49, 139], "gen": [39, 46, 49, 133, 134, 253], "codenam": 39, "boost": [39, 46, 59, 73, 74, 139, 194, 261, 278], "avx512": [39, 48, 72, 73, 74], "vcvtne2ps2bf16": 39, "vcvtneps2bf16": 39, "vdpbf16p": 39, "dot": [39, 48, 231, 247, 255], "pair": [39, 75, 162, 165, 168, 171, 187, 203, 212, 214, 215, 221, 222, 232, 236, 250, 279, 280, 284, 288, 291, 306, 344], "forc": [39, 49, 223, 235, 249, 253, 254, 255, 267, 275], "mixedprecis": 39, "drop": [39, 45, 57, 123, 219, 220, 244, 291, 298, 308, 381], "user_defined_funct": 39, "converted_model": 39, "output_path": [39, 97, 391], "avx512_bf16": 39, "encapsul": [40, 69, 70, 71, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 186, 275, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371], "persist": 40, "workspac": [40, 62, 317, 387], "gap": [40, 160, 171, 227, 244], "brought": [40, 48, 123], "graphdef": [40, 117, 118], "tf1": 40, "tf2": [40, 160, 171, 256, 367], "h5": [40, 243, 342, 343, 345, 346, 347, 349, 350, 351, 352, 353], "pt": [40, 46, 49, 148, 149, 155, 156, 160, 174, 185, 193, 196, 198, 216, 220, 222, 223, 227, 231, 235, 236, 247, 249, 251, 252, 253, 256, 276, 284, 291, 295, 296, 297, 304, 307, 318, 326, 332, 333, 336, 337], "onnx_ml_pb2": 40, "modelproto": 40, "hybridblock": 40, "0000": [40, 122, 123, 125], "inc_model": 40, "input_model": [40, 53, 69, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 156, 293, 300, 311, 313, 315, 326, 328, 329, 332, 333, 336, 337, 339, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 364, 365, 367, 368, 370, 371, 387, 391], "saved_result": [40, 315, 326, 329, 337, 338], "tflite": [41, 80, 107, 133], "modelconvers": 41, "destin": [41, 125, 127], "saved_model": [41, 62, 266, 371], "models": [42, 47, 55], "multi_object": [42, 391], "peak": [42, 163, 170, 278], "durat": [42, 52, 254, 391], "start_tim": 42, "_result_list": 42, "customobj": 42, "simultan": [43, 47, 229, 240, 244, 295, 304, 373], "arbitrari": [43, 59, 129, 163, 319], "meaning": [43, 129, 162, 255, 288, 291], "benefit": [43, 45, 129, 158, 159, 172, 189, 272], "Of": [43, 159, 189, 236, 254, 256, 279], "cours": [43, 126, 159, 189, 236, 254, 256], "schedul": [43, 124, 168, 171, 227, 253, 254, 256, 298, 308, 322], "prune_conf": [43, 145, 146], "post_training_quantization_conf": 43, "opt_model": [43, 145, 146], "quantization_aware_training_conf": 43, "configurationintel": 44, "platinum": [44, 50, 57], "8380": [44, 50, 57], "manufactur": [44, 272], "m50cyp2sbstd": 44, "bio": 44, "se5c6200": 44, "86b": 44, "0022": 44, "d64": 44, "2105220049": 44, "microcod": 44, "0xd0002b1": 44, "30ghz": 44, "frequenc": [44, 56, 141, 255, 298, 308], "3ghz": 44, "socket": [44, 50, 57, 362, 364], "turbo": 44, "perf": 44, "balanc": [44, 224, 236, 284], "256gb": 44, "16x16gb": 44, "ddr4": 44, "3200mt": 44, "nic": 44, "ethernet": 44, "10g": 44, "x550t": 44, "drive": [44, 126, 277, 282], "1x": [44, 321, 322], "intel_ssdsc2kw01": 44, "953": 44, "9g": 44, "ct1000mx500ssd1": 44, "931": 44, "5g": 44, "vari": [44, 57, 129, 163, 189, 216, 250, 252], "publicli": [44, 129, 196, 198, 199, 204, 205, 206, 239, 241, 284], "servic": [44, 159, 253, 390], "compil": [44, 129, 150, 162, 168, 189, 252, 256, 280, 288, 291, 322], "degre": [44, 253], "mark": [44, 244, 254, 331], "trademark": 44, "briefli": 45, "least": [45, 55, 79, 96, 98, 126, 129, 160, 162, 170, 182, 189, 190, 227, 231, 247, 248, 252, 254, 255, 288, 291], "maxim": [45, 55, 72, 129, 159, 242, 253, 255, 259], "state": [45, 129, 160, 163, 164, 168, 171, 174, 179, 189, 191, 193, 194, 195, 196, 197, 201, 208, 211, 213, 214, 217, 218, 219, 220, 221, 225, 226, 227, 228, 229, 230, 231, 233, 235, 236, 237, 238, 239, 240, 242, 244, 248, 250, 251, 253, 267, 272, 276, 285, 322, 374], "art": [45, 129, 160, 171, 191, 193, 194, 195, 196, 197, 201, 208, 211, 214, 217, 218, 219, 220, 221, 225, 226, 228, 229, 230, 231, 233, 235, 236, 237, 238, 239, 240, 242, 244, 248, 272, 276, 285, 322], "increasingli": 45, "plai": [45, 46, 124, 129, 160, 172, 236, 264, 265, 284], "crucial": [45, 162, 231, 234, 267, 288, 291], "role": [45, 124, 209], "rule": [45, 159, 162, 251, 255, 288, 291, 322, 373], "salient": 45, "nonzero": 45, "irregular": 45, "anywher": 45, "2in4": [45, 59], "amper": 45, "delet": [45, 126, 172, 243, 244, 254, 289], "due": [45, 48, 53, 124, 129, 162, 168, 191, 219, 220, 234, 236, 242, 288, 291], "restrict": [45, 52, 280], "howev": [45, 123, 129, 158, 159, 161, 162, 168, 170, 189, 191, 193, 198, 202, 209, 216, 217, 224, 225, 230, 234, 236, 242, 244, 247, 249, 252, 254, 255, 272, 278, 288, 291], "abl": [45, 48, 124, 129, 158, 159, 162, 164, 172, 189, 190, 193, 200, 213, 241, 243, 244, 249, 251, 254, 255, 265, 272, 275, 288, 291, 322, 335], "contigu": [45, 244, 333], "gemm": [45, 296, 298, 308], "ic": [45, 46], "oc": [45, 222], "kh": 45, "kw": [45, 222], "examin": [45, 213], "lowest": [45, 255], "head": [45, 59, 133, 161, 162, 164, 168, 170, 174, 183, 202, 209, 236, 244, 248, 250, 251, 252, 253, 256, 267, 275, 278, 284, 288, 291], "fastform": 45, "regular": [45, 126, 129, 160, 223, 243, 244, 248, 255, 257, 272, 298, 308, 386], "dens": [45, 57, 160, 162, 171, 208, 230, 232, 244, 272, 288, 291, 298, 308], "mask": [45, 57, 59, 129, 139, 160, 161, 165, 168, 171, 186, 188, 195, 204, 205, 209, 211, 216, 220, 221, 224, 225, 227, 234, 235, 236, 238, 239, 241, 242, 244, 245, 247, 248, 250, 251, 252, 256, 257, 261, 267, 284, 285, 299, 300, 317, 318, 365], "formula": [45, 252], "w": [45, 54, 133, 139, 160, 165, 171, 217, 220, 234, 254, 257, 272, 277, 319, 328, 331], "caus": [45, 121, 129, 162, 190, 215, 254, 255, 267, 270, 288, 291], "gradual": [45, 213], "on_before_optimizer_step": [45, 298, 308], "pruning_func": 45, "num_train_epoch": [45, 100, 103, 108, 159, 168, 189, 256, 257, 260, 261, 264, 271, 272, 276, 280, 294, 295, 297, 298, 302, 303, 304, 305, 307, 308, 313, 315, 359], "pbar": 45, "progressbar": [45, 254], "n_total": 45, "attention_mask": [45, 168, 170, 188, 236, 249, 251, 256], "token_type_id": [45, 170, 193, 207, 220, 225, 233, 236, 249, 291], "n_gpu": [45, 254], "gradient_accumulation_step": [45, 119, 189, 260, 261, 271, 276], "clip_grad_norm_": [45, 190], "max_grad_norm": [45, 189, 190], "rate": [45, 48, 124, 168, 189, 190, 233, 251, 256, 276, 284, 309, 322, 359], "cv": 45, "chines": [46, 245, 250, 255, 267, 270], "grain": [46, 129, 252], "aug": [46, 367], "purif": 46, "sacrif": [46, 241], "jun": 46, "partner": [46, 198, 199, 252], "democrat": [46, 189], "apr": [46, 198, 199], "ecosystem": [46, 143], "mar": 46, "workload": [46, 285, 387], "feb": 46, "sigopt": 46, "jan": [46, 73, 74, 229, 240, 391], "tutori": [46, 58, 69, 70, 71, 72, 113, 117, 118, 127, 134, 137, 138, 139, 141, 142, 148, 149, 150, 151, 153, 156, 160, 165, 168, 171, 243, 249, 251, 255, 293, 301, 311, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371], "bilibili": 46, "dec": [46, 227, 244, 391], "ml": [46, 171, 179, 189], "doubl": [46, 159, 161, 170, 190, 249], "mlperf": [46, 59, 107, 121, 317, 326, 327, 329, 332, 333, 336, 337, 364, 369], "3d": [46, 57, 59, 121, 123, 124, 125], "digit": [46, 122, 123, 222], "reconstruct": [46, 209, 223, 244], "abound": 46, "cern": 46, "gan": [46, 244], "3dgan": 46, "4th": 46, "iml": 46, "workshop": [46, 267], "highli": [46, 129, 189, 213, 234, 256, 267], "intelcaff": 46, "aris": 47, "tell": [47, 125, 129, 158, 159, 162, 168, 189, 254, 265, 270, 287, 288, 291], "context": [47, 104, 159, 160, 168, 170, 171, 195, 202, 203, 206, 208, 215, 220, 221, 223, 229, 237, 240, 242, 244, 245, 247, 249, 251, 253, 254, 255, 257, 259, 275, 284, 317], "henc": [47, 162, 213, 230, 251, 254, 288, 291, 365], "tensorflow_itex": [47, 365], "pytorch_ipex": [47, 56, 69, 134, 137, 138, 142, 150, 336, 357, 358, 365, 370], "onnxrt_qlinearop": [47, 69, 76], "onnxrt_qdq": 47, "onnxrt_qoper": 47, "quant_aware_train": [47, 151, 153], "op_type_list": 47, "exhaust": [47, 272], "use_bf16": [47, 49, 119], "learning_r": [47, 56, 100, 103, 108, 119, 151, 168, 189, 256, 257, 260, 261, 264, 272, 276, 278, 280, 294, 295, 296, 297, 298, 302, 304, 305, 307, 308, 313, 315, 359], "weight_compress": [47, 56], "initial_spars": [47, 56], "target_spars": [47, 56, 298, 308], "max_sparsity_ratio_per_lay": [47, 298, 308], "98": [47, 50, 57, 133, 267, 298, 308, 391], "prune_typ": [47, 56, 298, 308], "basic_magnitud": [47, 56], "start_epoch": [47, 56], "end_epoch": [47, 56, 151], "start_step": [47, 298, 308], "end_step": [47, 298, 308], "update_frequ": 47, "update_frequency_on_step": [47, 298, 308], "prune_domain": [47, 298, 308], "tile_pattern_1x1": 47, "warmup": [47, 141, 168, 190, 256, 284, 359, 362, 364, 391], "inter_num_of_thread": 47, "intra_num_of_thread": 47, "graph_optimization_level": 47, "disable_al": 47, "veri": [48, 55, 123, 124, 125, 129, 133, 158, 159, 160, 162, 163, 168, 189, 194, 200, 201, 203, 211, 212, 215, 219, 231, 241, 243, 244, 249, 251, 252, 253, 254, 255, 257, 267, 276, 285, 288, 291, 322], "invent": 48, "int4": 48, "mainli": [48, 164, 177, 196], "miss": [48, 162, 252, 254, 277, 288, 291], "cost": [48, 160, 162, 171, 191, 202, 213, 236, 244, 261, 288, 291], "theoret": 48, "affin": 48, "math": [48, 253, 254, 293, 362], "equat": 48, "zeropoint": 48, "255": [48, 62, 75, 143], "overflow": [48, 190], "solv": [48, 51, 156, 158, 159, 162, 238, 248, 253, 254, 255, 275, 288, 291, 332], "belong": [48, 123, 124, 159, 207, 218, 220, 225, 233, 253, 288, 291], "unseen": 48, "dump": [48, 53, 55, 240, 267], "peopl": [48, 157, 158, 159, 162, 164, 243, 253, 288, 291], "emul": [48, 189, 254], "uniqu": [48, 122, 123, 124, 143, 159, 231, 235, 254, 255], "parti": [48, 139, 189], "pain": 48, "lossi": [48, 327], "queri": [48, 104, 159, 202, 220, 231, 236, 244, 261, 275, 284, 298, 308], "philosophi": [48, 162, 171, 288, 291, 365], "fulli": [48, 55, 129, 158, 162, 168, 189, 234, 242, 243, 247, 254, 268, 272, 288, 291], "respons": [48, 123, 126, 159, 160, 171, 206, 227, 251, 387, 391], "val_dataset": [48, 71, 168], "val_dataload": [48, 298, 308], "num_work": [48, 71, 330], "worker": [48, 138, 254, 275], "ping_memori": 48, "enhanc": [49, 120, 121, 160, 171, 204, 205, 373], "datatyp": [49, 55, 387], "bf16_op": 49, "cast": [49, 54], "bf16convert": 49, "matter": [49, 159, 162, 236, 288, 291], "wrapper": [49, 186, 189, 218, 233, 250, 254], "bf16wrapper": 49, "retrac": 49, "bert_large_squad_stat": 50, "78": [50, 54, 57, 65, 66, 133, 139, 143, 264, 267, 272, 280, 298, 303, 308, 357, 358, 391], "49": [50, 57, 139, 267, 277, 280, 303], "08": [50, 54, 57, 133, 143, 163, 237, 280, 391], "48": [50, 57, 133, 139, 236, 250, 276, 280, 303, 331, 391], "64x": 50, "bert_base_mrpc_stat": 50, "35": [50, 57, 59, 131, 133, 140, 160, 163, 267, 280, 321, 331, 391], "09": [50, 57, 133, 143, 163, 391], "497": 50, "151": [50, 57], "29x": [50, 57], "bert_base_nli_mean_tokens_stsb_stat": 50, "55": [50, 57, 139, 236, 280, 331], "546": [50, 133], "60x": 50, "bert_base_sparse_mrpc_stat": 50, "551": 50, "153": [50, 57], "bert_mini_mrpc_stat": 50, "6962": 50, "3252": 50, "14x": [50, 57], "bert_mini_sst2_stat": 50, "6850": 50, "3218": 50, "13x": [50, 57], "distilbert_base_uncased_sst2_stat": 50, "25": [50, 57, 133, 139, 140, 143, 163, 223, 244, 250, 267, 277, 323, 391], "1086": 50, "306": [50, 133], "54x": [50, 57], "distilbert_base_uncased_mrpc_stat": 50, "07": [50, 56, 57, 73, 74, 139, 143, 218, 276, 280, 303, 391], "1091": 50, "303": 50, "distilbert_base_uncased_emotion_stat": 50, "94": [50, 54, 57, 65, 66, 133, 143, 218, 253, 264, 267, 357, 358, 391], "1081": 50, "53x": [50, 57], "minilm_l6_h384_uncased_sst2_stat": 50, "2594": 50, "1083": 50, "39x": 50, "roberta_base_mrpc_stat": 50, "508": [50, 133, 136, 143], "31x": [50, 57], "distilroberta_base_wnli_stat": 50, "34": [50, 57, 133, 140, 159, 239, 253, 261, 280, 308, 321], "1097": [50, 163], "22": [50, 57, 143, 221, 261, 280, 321, 323, 331, 362, 391], "315": [50, 133], "47x": [50, 57], "paraphrase_xlm_r_multilingual_v1_stsb_stat": 50, "66": [50, 57, 133, 143, 267, 280], "552": [50, 133], "44": [50, 57, 133, 139, 277, 331, 391], "finbert_financial_phrasebank_stat": 50, "999": [50, 56, 189], "292": [50, 133, 143], "site": [51, 172], "assist": 51, "comparison": [51, 53, 162, 216, 233, 267, 276, 278, 288, 291, 303, 322], "impact": [51, 55, 72, 157, 233, 247, 254], "old": [51, 133, 162, 171, 236, 249, 253, 259, 261, 279, 288, 291, 331], "renam": [51, 168, 286], "sed": 51, "your_script": 51, "backbon": [52, 317, 321, 331], "interact": [52, 120, 157, 162, 218, 288, 291], "mechan": [52, 170, 190, 204, 205, 219, 220, 229, 230, 231, 237, 240, 244, 245, 253, 254, 259, 275, 291], "sigopt_api_token": [52, 55], "sigopt_project_id": [52, 55], "sigopt_experiment_id": 52, "login": [52, 119, 243, 257, 286, 324, 382, 385], "although": [52, 124, 202, 214, 244, 253], "certain": [52, 159, 162, 170, 189, 203, 244, 288, 291], "suffici": [52, 126, 129, 145, 146, 159, 162, 272, 288, 291, 335], "ordinari": 52, "capac": [52, 143, 159, 189, 213, 241, 253], "obtain": [52, 55, 125, 129, 143, 161, 195, 200, 216, 218, 236, 239, 244, 249, 255, 267, 272, 280, 282, 295, 304, 327], "sigopt_experiment_nam": [52, 55], "receiv": [52, 159, 189], "analysi": [52, 59, 148, 160, 164, 165, 172, 186, 187, 216, 242, 251, 252, 253, 263, 373], "draw": [52, 55, 158], "8266": 52, "8372": 52, "2132": [52, 162, 288, 291], "7495": 52, "8299": 52, "8294": 52, "0837": 52, "8291": 52, "4469": 52, "visual": [53, 55, 162, 218, 221, 288, 291], "discov": [53, 158, 253, 267, 278], "why": [53, 157, 158, 159, 162, 189, 243, 244, 251, 255, 270, 284, 288, 291], "valuabl": [53, 158], "instrument": [53, 253], "writer": 53, "pseudo": [53, 162, 288, 291], "_pre_eval_hook": 53, "_post_eval_hook": 53, "submodul": [53, 120, 150, 256, 291, 296], "whitelist": 53, "_recordingobserv": 53, "output_tensors_dict": 53, "current_it": 53, "export": [53, 79, 80, 96, 98, 99, 100, 101, 102, 103, 106, 108, 117, 118, 119, 120, 121, 126, 129, 143, 163, 167, 171, 189, 209, 260, 261, 263, 264, 267, 270, 276, 280, 282, 285, 300, 313, 322, 328, 357, 362, 364, 369, 370, 374], "get_tensor_valu": 53, "_observer_forward_hook": 53, "_add_observer_": 53, "child": [53, 160, 171, 215], "named_children": 53, "op_nam": 53, "leaf": 53, "add_modul": 53, "register_forward_hook": 53, "dump_tim": 53, "summarywrit": 53, "_acc": 53, "tune_": 53, "add_graph": 53, "get_observer_dict": 53, "observer_dict": 53, "strip": [53, 168, 359], "parent": [53, 124, 162, 171, 254, 288, 291, 327], "is_quant": 53, "add_histogram": 53, "merg": [53, 55, 125, 158, 159, 161, 162, 243, 254, 255, 276, 288, 289, 291, 382, 385], "shell": [53, 155, 158, 163, 172, 189], "bind_al": [53, 148, 149], "logdir_spec": [53, 148, 149], "tune_0_acc0": [53, 148, 149], "tune_1": 53, "tune_1_acc0": [53, 148, 149], "image_recognit": [53, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 357, 358], "run_tuning_dump_tensor": [53, 148, 149], "sh": [53, 69, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 144, 147, 148, 149, 150, 154, 156, 227, 273, 276, 282, 286, 293, 296, 300, 301, 306, 309, 311, 313, 315, 316, 317, 318, 326, 328, 329, 330, 331, 332, 333, 336, 337, 338, 339, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 371], "four": [53, 75, 123, 151, 161, 212, 217, 253, 276, 278, 282], "session": [53, 62, 120, 126, 206, 254, 365], "baseline_acc_0": 53, "776": [53, 133, 272], "tune_1_acc_0": 53, "095": 53, "runs_v3": 53, "inceptionv3": [53, 69, 143], "skip": [53, 55, 129, 158, 243, 252], "v0": 53, "cg": 53, "conv0": 53, "op_wis": [53, 55, 56, 299, 359, 360, 365, 386], "bash": [53, 69, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 144, 150, 154, 189, 214, 254, 276, 282, 295, 296, 300, 304, 306, 315, 318, 326, 328, 329, 330, 331, 332, 333, 336, 337, 338, 339, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 368, 370, 371], "run_tun": [53, 69, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 150, 156, 293, 300, 301, 311, 313, 315, 316, 318, 326, 328, 329, 332, 333, 336, 337, 338, 339, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 362, 364, 365, 367, 368, 370, 371], "topologi": [53, 69, 71, 106, 124, 129, 144, 147, 148, 149, 150, 154, 257, 293, 300, 301, 306, 311, 313, 316, 326, 329, 338, 356, 367], "dataset_loc": [53, 69, 71, 148, 149, 150, 154, 156, 293, 300, 311, 313, 326, 328, 329, 332, 333, 336, 337, 338, 359, 362, 364, 367, 368, 371], "inceptionv3_fp32_pretrained_model": [53, 357], "output_model": [53, 69, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 144, 154, 156, 297, 305, 306, 307, 315, 318, 326, 329, 337, 338, 339, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 370, 371], "nc_inceptionv3": [53, 357], "inceptionv3_dump_tensor": 53, "poor": [53, 247], "tab": [53, 161, 162, 168, 275, 282, 288, 291, 335], "eightbit": 53, "requant": 53, "disappear": 53, "bilinear": [54, 61, 63, 133], "desir": [54, 129, 143, 158, 159, 189, 213, 222, 255, 276, 295, 304, 311], "nearest": 54, "bicub": [54, 133], "aspect": [54, 124, 143, 171, 203, 254, 319, 322], "deviat": [54, 276], "randomcrop": 54, "transform_list": 54, "cropres": 54, "y": [54, 72, 129, 160, 168, 171, 198, 199, 222, 223, 244, 331, 374], "boundari": 54, "horizont": [54, 159, 317], "flip": [54, 317, 319], "randomverticalflip": 54, "vertic": 54, "decodeimag": 54, "jpeg": [54, 327], "encod": [54, 124, 139, 141, 160, 161, 162, 165, 168, 170, 171, 188, 190, 193, 194, 195, 196, 197, 201, 204, 205, 208, 209, 214, 216, 219, 220, 221, 222, 223, 227, 228, 229, 232, 235, 236, 237, 240, 244, 245, 247, 248, 249, 253, 267, 272, 275, 276, 288, 291, 319], "encodejp": 54, "transpos": [54, 162, 288, 291, 319], "perm": 54, "permut": [54, 160, 171, 225, 242, 244], "resizewithratio": 54, "min_dim": 54, "max_dim": 54, "800": [54, 133, 143, 227, 237, 322], "1365": 54, "longest": [54, 227, 249], "exce": [54, 219, 233, 322], "arrai": [54, 62, 75, 123, 162, 168, 238, 251, 253, 288, 291, 333, 360], "croptoboundingbox": 54, "offset_height": 54, "offset_width": 54, "target_height": 54, "target_width": 54, "coordin": [54, 236, 319, 331], "toarrai": 54, "pil": [54, 143, 218, 319, 322], "rescal": [54, 143, 330], "alignimagechannel": [54, 391], "dim": [54, 129, 251, 253, 391], "deprec": [54, 129, 279, 382, 385], "parsedecodeimagenet": [54, 75], "pars": [54, 120, 160, 171, 201, 211, 228, 236, 275, 284, 386], "proto": 54, "random_crop": 54, "resize_sid": 54, "random_flip_left_right": 54, "mean_valu": [54, 65, 66, 357, 358, 391], "116": [54, 65, 66, 357, 358, 391], "103": [54, 65, 66, 237, 250, 267, 357, 358, 391], "017": 54, "quantizedinput": 54, "labelshift": 54, "label_shift": 54, "shift": [54, 235, 253, 276], "bilinearimagenet": [54, 56, 61, 63, 65, 66, 75], "central_fract": 54, "875": [54, 133, 143], "fraction": [54, 129, 170, 254], "squadv1": [54, 101], "n_best_siz": 54, "max_query_length": [54, 187], "max_answer_length": 54, "doc_strid": [54, 187, 261, 297, 298, 300], "vocab_fil": [54, 359, 360, 361, 363, 364], "vocabulari": [54, 161, 165, 167, 168, 170, 183, 188, 190, 192, 205, 212, 243, 248, 250, 251, 253, 255, 267, 284], "nbest_predict": 54, "384": [54, 133, 163, 261, 295, 297, 298, 300], "wordpiec": [54, 168, 170, 250, 284], "chunk": [54, 219, 231, 244, 247, 255], "topilimag": 54, "padding_mod": 54, "border": 54, "pixel": [54, 123, 143, 224, 234, 317], "edg": [54, 160, 172, 207, 217, 272, 391], "colorjitt": 54, "bright": [54, 279], "contrast": [54, 214, 219, 220, 238, 244, 255, 272], "satur": 54, "hue": 54, "jitter": 54, "tondarrai": 54, "logic": [55, 56, 75, 162, 217, 220, 236, 244, 275, 276, 284, 286, 288, 291], "max_trail": [55, 391], "scale_propagation_max_pool": 55, "scale_propagation_concat": 55, "first_conv_or_matmul_quant": 55, "2000": [55, 162, 189, 251, 276, 288, 291], "tf_record": [55, 360, 361], "model_wis": [55, 56, 61, 357, 358, 359, 360, 362, 363, 364, 365], "conv1": [55, 56], "pool1": 55, "conv2": 55, "guarante": [55, 97, 129, 272], "performance_onli": [55, 362], "tri": [55, 133, 159, 200, 209], "sort": [55, 157, 231, 254, 282], "accordingli": [55, 129, 159, 245], "increment": 55, "classic": [55, 160, 164, 244, 247], "black": [55, 158, 162, 288, 291], "come": [55, 119, 121, 125, 127, 133, 158, 159, 168, 171, 189, 243, 244, 251, 252, 254, 311, 315, 326, 329, 337, 357], "discret": [55, 159], "compli": [55, 162, 288, 291], "gaussian": 55, "posterior": 55, "focu": [55, 159, 162, 196, 218, 244, 252, 255, 256, 288, 291], "short": [55, 129, 158, 159, 161, 170, 196, 237, 250, 253, 276, 290], "never": [55, 129, 133, 159, 162, 223, 255, 278, 288, 291], "loglevel": 55, "messag": [55, 158, 159, 234, 254, 323, 365, 371, 387, 389, 391], "endlessli": 55, "idea": [55, 133, 158, 162, 189, 227, 242, 244, 253, 288, 291], "primari": 55, "smbo": 55, "trial": [55, 162, 288, 291, 391], "hyperparamet": [55, 129, 172, 233, 236, 255], "appl": [55, 253], "surrog": 55, "entropi": [55, 247, 256, 266, 317], "quantil": 55, "x1": [55, 218, 319, 322], "x2": [55, 319, 322], "densiti": 55, "parzen": 55, "minimum": [55, 162, 254, 276, 288, 291], "greatest": [55, 158, 255, 275], "hour": [55, 127, 172, 200, 238, 254, 259, 265, 276, 277], "dai": [55, 160, 171, 172, 209, 211, 234, 237, 242, 244, 253, 254, 275, 279, 284, 332, 333, 336], "travers": 55, "perspect": [55, 202, 244], "tunestrategi": 55, "strategy_registri": 55, "abctunestrategi": 55, "next_tune_cfg": 55, "till": 55, "mobilenet_v1": [56, 75, 357], "onnxrt_integ": [56, 134, 137, 138, 142, 357, 358, 365, 370], "onnxrt_qlinear": [56, 134, 137, 138, 142, 357, 358, 365, 370], "image_tensor": [56, 117, 118, 365, 391], "detection_box": [56, 117, 118, 365, 391], "detection_scor": [56, 117, 118, 365, 391], "detection_class": [56, 117, 118, 365, 391], "subsect": 56, "adam": [56, 70, 160, 168, 171, 189, 190, 226, 235, 254, 256, 284], "1e": [56, 162, 189, 190, 256, 272, 276, 288, 291, 294, 295, 297, 298, 302, 304, 308], "beta_1": 56, "beta_2": 56, "epsilon": 56, "sparsecategoricalcrossentropi": [56, 168, 256], "reduct": [56, 151, 191, 213], "sum_over_batch_s": 56, "from_logit": [56, 168, 256], "54": [56, 57, 133, 139, 221, 237, 261, 267, 280, 391], "pruner": [56, 147], "func": [56, 69, 70, 71, 134, 137, 138, 142, 149, 150, 151, 153, 156, 161, 293, 299, 301, 311, 312, 313, 314, 316, 318, 329, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371], "nesterov": 56, "weight_decai": [56, 168, 189, 256, 297, 298, 307, 308], "knowledgedistillationloss": 56, "temperatur": [56, 132, 236, 278, 294, 295, 302, 304], "loss_typ": 56, "ce": [56, 168], "loss_weight": [56, 132, 155, 156, 294, 295, 302, 304], "overal": [56, 157, 159, 252, 254, 255], "percentag": [56, 244, 326, 337, 391], "ye": [57, 139, 158], "dlrm": [57, 59, 332, 333, 336], "rnn": [57, 59, 170, 237, 244, 284], "unet": [57, 59, 120, 121, 124], "performancethroughput": 57, "efficientnet": [57, 59, 134, 339, 367], "03": [57, 139, 143, 274, 291, 296, 391], "43": [57, 133, 139, 163, 280, 326, 331, 391], "32x": 57, "cnn": [57, 59, 69, 73, 74, 130, 136, 139, 156, 165, 193, 213, 229, 240, 250, 253, 257, 265, 275, 277, 279, 317], "incept": [57, 59, 69, 133, 341, 342, 343, 365, 367], "53": [57, 139, 140, 143, 236, 247, 267, 277, 280, 284, 309, 321, 331, 391], "57x": [57, 264], "savedmodel": [57, 59, 339, 342, 343, 345, 346, 347, 349, 350, 351, 352, 353], "46": [57, 139, 143, 267, 277, 391], "61": [57, 140, 264], "58x": 57, "39": [57, 133, 139, 253, 309, 321, 391], "11x": 57, "51x": 57, "06x": 57, "25x": 57, "163": [57, 143], "133": 57, "22x": 57, "111": [57, 326], "20x": 57, "v3": [57, 59, 69, 133, 139, 171, 197, 243, 257, 284, 286, 330, 341, 343, 358, 367], "02": [57, 130, 131, 132, 168, 218, 291, 298, 362, 391], "43x": 57, "v4": [57, 59, 160, 171, 172, 197, 358, 367, 377], "33x": 57, "ckpt": [57, 59, 63, 167, 276, 291, 357, 358, 359, 370, 371, 388], "44x": 57, "374": [57, 129, 143], "226": 57, "47": [57, 139, 267, 277], "41x": 57, "fashion": [57, 59, 73, 235, 244, 284, 348], "359": 57, "244": [57, 133], "172": [57, 133], "76x": 57, "112": [57, 249, 373], "35x": 57, "26x": 57, "56x": 57, "93x": 57, "178": [57, 133], "156": [57, 133], "18x": 57, "albert": [57, 59, 102, 160, 165, 171, 188, 234, 250, 255, 259, 264, 293, 311, 377], "barthez": [57, 160, 171, 250, 313], "81": [57, 133, 139, 140, 143, 261, 267, 272], "82x": 57, "203": 57, "216": 57, "102": [57, 133, 170, 196, 245, 249, 250, 251, 391], "10x": [57, 215, 276], "sst2": [57, 59, 102, 187, 253, 280, 302, 303, 304, 305, 307, 308, 311, 312, 314, 362, 377], "218": 57, "stsb": [57, 187, 280], "49x": 57, "70x": 57, "50x": 57, "40x": 57, "3878": 57, "3717": 57, "04x": 57, "camembert": [57, 59, 102, 160, 171, 188, 194, 233, 250, 313], "188": [57, 133, 143], "91x": 57, "ctrl": [57, 160, 171, 190, 250, 253, 281, 293, 311, 317], "deberta": [57, 160, 171, 250, 289, 313], "124": [57, 133], "81x": 57, "347": [57, 218], "382": 57, "198": [57, 133, 331], "flaubert": [57, 160, 171, 194, 250, 255, 313], "561": 57, "370": [57, 133], "52x": 57, "hubert": [57, 59], "409": 57, "181": 57, "longform": [57, 160, 165, 171, 219, 250, 291, 313], "mbart": [57, 159, 160, 165, 171, 250, 276, 277, 279, 293, 311], "16x": 57, "639": [57, 222, 286], "490": 57, "lvwerra": [57, 59], "pegasu": [57, 59, 160, 171, 250, 277, 291, 293, 301], "samsum": [57, 59, 301], "peleenet": [57, 59, 137, 386], "419": 57, "316": [57, 277], "resnet18": [57, 59, 69, 143, 144, 147, 154], "686": [57, 133], "332": [57, 133], "07x": 57, "611": 57, "333": 57, "83x": 57, "327": 57, "162": [57, 133], "175": 57, "197": [57, 272, 276], "99x": 57, "se_resnext50_32x4d": [57, 59, 143], "308": [57, 133], "144": 57, "squeezebert": [57, 160, 171, 250, 313], "186": 57, "155": [57, 170, 249], "78x": 57, "transfo": [57, 167, 190, 250, 253, 293, 311], "xl": [57, 133, 160, 171, 190, 215, 242, 250, 253, 255, 281, 293, 311], "37x": 57, "wave2vec2": 57, "60": [57, 139, 207, 253, 261, 267, 276, 303, 319, 391], "21x": 57, "114": [57, 133], "yolo": [57, 330, 331, 367, 391], "690": [57, 321], "330": 57, "09x": 57, "614": [57, 133], "334": 57, "84x": 57, "410": 57, "168": 57, "finetun": [57, 59, 101, 102, 143, 155, 156, 160, 165, 171, 219, 220, 223, 234, 236, 237, 242, 244, 250, 251, 253, 261, 267, 272, 279, 298, 299, 300, 301, 308, 311, 313, 314], "resnext101_32x16d_wsl": [57, 59, 150], "1189": 57, "680": 57, "677": 57, "381": 57, "alexnet": [57, 59, 73, 74, 143, 358, 377], "960": [57, 133], "469": 57, "17": [57, 133, 139, 140, 143, 168, 245, 250, 280, 282, 391], "05x": 57, "962": 57, "466": [57, 133], "arcfac": [57, 59], "235": 57, "130": [57, 253], "294": [57, 133, 143], "125": [57, 272, 391], "34x": 57, "604": [57, 133], "80x": 57, "caffenet": [57, 59], "1501": 57, "536": [57, 133], "1493": 57, "533": 57, "1372": 57, "541": 57, "480": [57, 133], "1250": 57, "753": 57, "1130": 57, "748": [57, 133], "emot": [57, 59], "ferplu": [57, 59], "336": 57, "65x": 57, "fcn": [57, 59], "googlenet": [57, 59, 367], "740": [57, 143], "587": 57, "770": [57, 133], "824": 57, "601": 57, "819": 57, "597": 57, "45x": 57, "613": 57, "506": 57, "2454": 57, "1543": 57, "2164": 57, "1564": 57, "38x": 57, "2147": 57, "1046": 57, "1877": 57, "1054": 57, "mobilenetv2": [57, 69, 90, 131, 339], "zoo": [57, 59, 69, 70, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 104, 105, 109, 110, 111, 112, 113, 114, 115, 116, 142, 143, 293, 299, 301, 311, 312, 313, 314, 316, 328, 332, 333, 336, 348, 359, 360, 361, 362, 363, 364, 367, 368, 369, 371], "2751": 57, "1797": 57, "2656": 57, "1835": 57, "7615": 57, "7646": 57, "764": [57, 133], "901": 57, "434": [57, 133, 143], "141": 57, "7614": [57, 151], "575": 57, "952": [57, 133], "433": 57, "7226": 57, "7229": 57, "761": 57, "432": [57, 143], "615": 57, "722": [57, 133], "032": 57, "894": 57, "885": 57, "454": [57, 133, 143], "95x": 57, "603": 57, "455": 57, "644": 57, "636": [57, 133, 143, 326], "254": [57, 133], "791": 57, "shufflenet": [57, 59, 136], "2298": 57, "1480": 57, "55x": 57, "1951": 57, "1490": 57, "squeezenet": [57, 59], "2588": 57, "1605": 57, "2566": [57, 162, 288, 291], "1936": 57, "725": 57, "570": 57, "27x": 57, "666": 57, "539": 57, "641": 57, "519": 57, "633": 57, "492": [57, 133], "542": [57, 133], "401": 57, "68x": 57, "tini": [57, 59, 233, 252, 254, 280], "yolov3": [57, 59, 366], "648": [57, 133], "518": [57, 143], "221": 57, "319": 57, "307": 57, "yolov4": [57, 59, 114], "zfnet": [57, 59], "459": 57, "261": 57, "460": [57, 133], "264": [57, 133, 143], "74x": 57, "441": 57, "337": 57, "272": [57, 133], "211": 57, "152": [57, 59, 133, 143, 331, 358], "423": 57, "180": [57, 133], "311": 57, "taskdataset": 57, "accuracyspars": 57, "ratiospars": 57, "commentsbalanc": 57, "unbalanc": 57, "classificationimagenet": 57, "76top": 57, "13top": 57, "magnitudepost": 57, "magnitudequant": 57, "answeringsquad": 57, "34f1": 57, "2x1": [57, 59], "lassounbalanc": 57, "classificationmnli": 57, "mm": [57, 272], "lockbalanc": 57, "classificationsst": 57, "32accuraci": 57, "sensitivitybalanc": 57, "classificationqqp": 57, "classificationqnli": 57, "54accuraci": 57, "em": [57, 275], "87f1": 57, "4x1": [57, 59, 298, 308], "momentumunbalanc": 57, "momentumbalanc": 57, "classificationmrpc": 57, "52f1": 57, "61accuraci": 57, "7965": 57, "wideresnet40": [57, 59, 131], "9522": 57, "8178": 57, "0213": 57, "5494": 57, "7153": 57, "5540": 57, "0046": 57, "vgg": [57, 59, 94, 132, 358], "7022": 57, "7415": 57, "7025": 57, "0003": [57, 123], "6739": 57, "7399": 57, "6845": 57, "0106": 57, "7034": 57, "8382": 57, "bilstm": [57, 59, 302], "8314": 57, "9403": 57, "9048": 57, "0734": 57, "7323": 57, "8256": 57, "8084": 57, "8814": 57, "7442": 57, "8371": 57, "0119": 57, "0115": [57, 162, 288, 291], "tinybert": [57, 59], "8018": 57, "8044": 57, "8363": 57, "8411": [57, 280], "8025": 57, "8074": 57, "0007": [57, 367], "0030": [57, 162, 288, 291], "8626": 57, "8213": 57, "9091": 57, "8782": 57, "8684": 57, "8259": 57, "0058": 57, "distilroberta": [57, 59, 160, 171, 250, 267, 302], "6057": 57, "6455": 57, "6187": 57, "0130": 57, "c6i": 57, "2xlarg": 57, "c6a": 57, "c6g": 57, "a100cuda": 57, "except": [57, 133, 158, 163, 189, 194, 201, 244, 253, 254, 280, 293, 295, 304], "mkl": [58, 381], "nativ": [58, 171, 189, 236, 253, 276], "upstream": [58, 162, 288, 291], "opt": [58, 133, 330, 376], "tabl": [59, 133, 136, 160, 165, 171, 236, 249, 254, 255, 261, 272, 277, 282, 284, 331, 388], "example1": [59, 60, 61], "example2": [59, 60, 62], "example3": [59, 60, 63], "example4": [59, 60, 64], "example5": [59, 60, 65], "example6": [59, 60, 66], "example7": [59, 60, 67], "flavor": [59, 60, 67, 188], "example8": [59, 60, 68], "pure": [59, 60, 68, 188, 272], "recogn": [59, 73, 74, 123, 125, 236], "handwrit": [59, 74], "densenet121": [59, 143, 357], "densenet161": [59, 143, 357], "densenet169": [59, 143, 357], "b0": [59, 133, 134, 339, 367], "xception": [59, 353], "natur": [59, 129, 157, 160, 170, 171, 187, 191, 193, 194, 195, 196, 200, 201, 202, 203, 204, 205, 207, 209, 211, 214, 215, 216, 217, 224, 225, 228, 234, 235, 236, 239, 242, 244, 251, 253, 263, 272, 276, 278, 306], "vit": 59, "densenet201": [59, 143, 356], "resnest50": [59, 139, 141], "speech": [59, 160, 171, 181, 197, 201, 228, 238, 249, 282, 338], "wav2vec2": [59, 160, 171], "t5": [59, 159, 160, 162, 165, 170, 171, 188, 189, 190, 205, 226, 250, 253, 255, 279, 288, 291, 293, 316], "helsinki": [59, 222, 250, 276, 277, 286], "opu": [59, 160, 171, 222, 250, 276, 277], "mt": [59, 162, 222, 250, 277, 288, 291], "en": [59, 159, 189, 205, 212, 214, 222, 223, 244, 245, 250, 254, 276, 277, 279, 280, 284, 293, 316, 363, 364], "ro": [59, 159, 189, 222, 223, 244, 250, 276, 277, 279, 293, 316, 357, 358], "pruneofa": [59, 295, 304], "densenet": [59, 136], "integerop": 59, "gpt2": [59, 160, 162, 167, 171, 174, 205, 206, 247, 249, 250, 253, 255, 259, 267, 281, 288, 291, 293, 311], "lm": [59, 252, 264, 284, 285], "wikitext": [59, 106, 237, 247, 250, 259, 267, 270, 293], "bidaf": 59, "minilm": [59, 102, 302], "l12": [59, 102], "h384": [59, 102, 302], "l6": [59, 102], "spanbert": [59, 101], "multilingu": [59, 101, 160, 171, 194, 201, 216, 223, 226, 228, 239, 241, 244, 245, 250, 251, 267, 276, 280, 282], "duc": 59, "ultra": 59, "enter": [60, 254, 296, 362, 381], "pretrain": [60, 79, 96, 98, 105, 107, 123, 126, 127, 134, 145, 146, 147, 148, 149, 150, 151, 152, 153, 160, 165, 167, 170, 171, 172, 180, 183, 188, 191, 192, 193, 194, 195, 196, 200, 201, 204, 205, 207, 209, 210, 211, 213, 214, 215, 218, 219, 220, 221, 222, 223, 227, 229, 230, 233, 235, 239, 240, 241, 242, 243, 244, 248, 249, 253, 255, 256, 261, 264, 267, 272, 276, 285, 310, 328, 338, 357, 358, 362, 367, 368, 370, 373, 377], "resampl": [61, 63, 124], "224x224": [61, 63], "And": [61, 119, 159, 162, 190, 222, 243, 249, 254, 265, 270, 272, 279, 288, 291, 357, 359, 374], "tf_imagenet": 61, "work_dir": 62, "train_imag": [62, 75], "train_label": [62, 75, 168], "test_imag": [62, 75], "test_label": [62, 75, 168], "fashion_mnist": [62, 75], "load_data": [62, 75], "astyp": [62, 75, 236], "mymetr": [62, 75], "pred_list": [62, 75], "label_list": [62, 75, 253], "argmax": [62, 75, 253, 256, 391], "axi": [62, 75, 124, 251, 253, 333], "correct_num": [62, 75], "hello_world": [62, 75], "as_default": [62, 365], "sess": 62, "import_graph_def": [62, 365], "graph_def": [62, 365], "styled_imag": 62, "feed_dict": [62, 362], "inception_v1_2016_08_28": [63, 357, 358], "xvf": [63, 117, 118, 265, 357, 358, 365, 370], "last_batch": [63, 65, 66], "discard": [63, 65, 66], "openvinotoolkit": [64, 357, 367], "open_model_zoo": [64, 357, 367], "checkout": [64, 121, 150, 158, 162, 254, 257, 288, 291, 317, 357, 367], "rfcn": [64, 367], "output_dir": [64, 70, 100, 103, 108, 119, 159, 168, 189, 256, 257, 259, 260, 261, 263, 264, 266, 270, 271, 272, 275, 276, 278, 279, 280, 282, 293, 294, 295, 297, 298, 299, 300, 301, 302, 303, 304, 307, 308, 311, 312, 313, 314, 315, 316, 318, 357, 358, 359, 360, 361, 367, 371, 376, 377], "rfcn_resnet101_coco_2018_01_28": 64, "write_graph": [66, 363], "graph_or_graph_def": 66, "logdir": [66, 331], "as_text": 66, "frozen_graph": 67, "resnet152": 69, "prepare_dataset": [69, 71, 326, 337, 357, 358, 359, 360, 361, 365, 366], "q90": 69, "rec": [69, 141], "prepare_model": [69, 99, 100, 103, 108, 342, 343, 345, 346, 347, 349, 350, 351, 352, 353, 359, 360, 365, 371], "model_nam": [69, 76, 119, 143, 222, 227, 236, 251, 276, 277, 289, 357, 365, 367, 387], "model_path": [69, 97, 263, 365, 367, 371, 387, 391], "val_256_q90": 69, "nc_resnet18": 69, "nc_resnet152_v1": 69, "nc_squeezenet": 69, "nc_mobilenet1": 69, "nc_mobilenetv2_1": 69, "nc_inception_v3": [69, 358], "run_benchmark": [69, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 150, 156, 163, 300, 315, 326, 328, 329, 332, 333, 336, 337, 338, 339, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 362, 364, 367, 368, 371], "q": [69, 70, 71, 134, 137, 138, 142, 149, 150, 151, 153, 156, 208, 234, 244, 254, 270, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371], "itself": [69, 70, 71, 129, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 158, 160, 162, 170, 221, 236, 244, 248, 251, 254, 267, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 376], "simplic": [69, 134, 137, 138, 139, 142, 148, 149, 150, 151, 153, 156, 189, 318, 330, 357], "toler": [69, 70, 71, 134, 137, 138, 142, 148, 149, 150, 151, 153, 162, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316, 318, 330, 332, 333, 334, 336, 357, 358, 365, 370], "symbol_fil": 69, "param_fil": 69, "logger": [69, 159, 162, 182, 288, 291, 293, 299, 301, 311, 312, 313, 314, 316], "gluonnlp": 70, "finetune_classifi": 70, "finetune_squad": 70, "2e": [70, 100, 103, 108, 257, 264, 280, 302, 305, 307, 309, 315, 359], "task_nam": [70, 99, 100, 102, 103, 108, 257, 260, 263, 264, 280, 302, 303, 304, 305, 307, 308, 311, 312, 313, 314, 315, 359, 376, 377], "warmup_ratio": 70, "3e": [70, 189, 256, 261, 272, 276, 296, 309], "bert_model": [70, 105, 107, 167, 282, 315, 360, 361], "bert_12_768_12": 70, "only_infer": 70, "model_paramet": 70, "model_bert_mrpc_4": 70, "round_to": 70, "test_batch_s": 70, "only_predict": 70, "At": [70, 71, 73, 74, 159, 160, 162, 164, 172, 254, 255, 276, 288, 291, 331], "dev": [70, 104, 129, 155, 156, 158, 162, 168, 224, 254, 264, 267, 272, 275, 280, 282, 288, 289, 291, 296, 300, 337, 338, 360, 361, 380, 384, 390], "hybrid": [70, 255], "static_alloc": 70, "static_shap": 70, "segment": [70, 121, 122, 123, 124, 125, 127, 129, 168, 170, 207, 220, 225, 228, 233, 236, 237, 244, 247, 284, 317, 322, 370], "dev_data": 70, "dev_data_list": 70, "metric_nm": 70, "metric_v": 70, "loader_dev": 70, "voc2007": 71, "unchang": 71, "coco2017": [71, 110, 111, 114, 115, 116, 318, 326], "home": [71, 126, 141, 143, 172, 326, 374, 391], "dataset_nam": [71, 189, 259, 261, 270, 273, 279, 282, 293, 294, 295, 297, 298, 299, 300, 318], "nc_ssd_resnet50_voc": 71, "nc_ssd_mobilenet1": 71, "0_voc": 71, "nc_ssd_resnet50_coco": 71, "0_coco": 71, "model_prefix": 71, "nc_ssd_model": 71, "vocmapmetr": 71, "cocoev": 71, "val_metr": 71, "get_dataset": 71, "val_data": 71, "get_dataload": 71, "obvious": [72, 73, 74], "screen": [72, 73, 74], "lscpu": 72, "avx512_vnni": 72, "set_env": 72, "env_intel_tf": 72, "bin": [72, 73, 74, 82, 158, 162, 167, 189, 243, 269, 276, 288, 291, 300, 310, 323], "fp": [72, 73, 74, 129, 136, 331], "378": [72, 133], "35371907536023": 72, "x113": 72, "26080122625": 72, "190600580098675": 72, "y7": 72, "58170614437181": 72, "qt": 72, "qpa": 72, "xcb": 72, "xkeyboard": 72, "fp32_int8_absolut": [72, 73, 74], "throughput_times1": 72, "942381018341494": 72, "latency_tim": [72, 73, 74], "46036736467385464": 72, "fp32_int8_tim": [72, 73, 74], "lost": [72, 126], "newer": [73, 74, 189], "big": [73, 74, 159, 162, 189, 244, 251, 255, 279, 288, 291], "blocker": [73, 74], "demo": [73, 74, 130, 131, 132, 135, 152, 162, 218, 256, 268, 278, 281, 288, 291, 320], "train_mnist": 73, "alexnet_mnist_fp32_mod": 73, "pth": [73, 130, 131, 132, 143, 147, 318, 328], "inc_quantize_model": [73, 74], "mnistmodel": [73, 74], "pthyaml": 73, "alexnet_mnist_int8_mod": 73, "profiling_inc": [73, 74], "pthalexnet_mnist_int8_mod": 73, "json8": [73, 74], "compare_perf": [73, 74], "stdout": [73, 74, 266], "stderrlog": [73, 74], "filefp32_int8_absolut": [73, 74], "pngfp32_int8_tim": [73, 74], "But": [73, 74, 129, 159, 162, 189, 254, 270, 278, 279, 288, 291, 322], "2nd": [73, 74, 280], "vector": [73, 74, 162, 204, 205, 208, 213, 221, 223, 230, 231, 244, 288, 291], "freeli": [73, 74, 123], "articl": [73, 74, 139, 162, 196, 223, 237, 244, 253, 265, 272, 276, 278, 284, 288, 291, 331], "familiar": [73, 74, 162, 244, 256, 288, 291], "termin": [73, 74, 126, 129, 158, 243, 380, 381, 384], "env": [73, 74, 119, 133, 158, 162, 172, 254, 258, 288, 291, 296, 300, 320, 328], "devcloud_setup_env": [73, 74], "ipynb": [73, 74, 163, 269, 322], "icx": [73, 74, 150], "spr": [73, 74, 300, 328, 362], "qsub": [73, 74], "run_in_intel_devcloud": [73, 74], "pwd": [73, 74, 276, 370], "ppn": [73, 74], "28029": [73, 74], "qsvr": [73, 74], "nda": [73, 74], "aidevcloud": [73, 74], "bad": [73, 74, 162, 253, 254, 288, 291], "uid": [73, 74], "msg": [73, 74, 254], "ruserok": [73, 74], "uxxxxx": [73, 74], "s001": [73, 74], "n054": [73, 74], "qstat": [73, 74], "fault": [73, 74], "o28029": [73, 74], "e28029": [73, 74], "tail": [73, 74], "latr": [73, 74], "awk": [73, 74], "o1842253": [73, 74], "572": [73, 74], "4982883964987": [73, 74], "3030": [73, 74], "70552731285": [73, 74], "8339174329018104": [73, 74], "128233714979522": [73, 74], "9799": [73, 74], "9796": [73, 74], "throughput_tim": [73, 74], "293824608282245": [73, 74], "7509864932092611": [73, 74], "accuracy_tim": [73, 74], "9996938463108482": [73, 74], "thank": [73, 74, 143, 158, 159, 242, 257], "1842253": [73, 74], "date": [73, 74, 159, 163, 279, 288, 322], "pm": [73, 74], "pst": [73, 74], "copi": [73, 74, 124, 129, 141, 158, 159, 161, 162, 254, 256, 276, 278, 288, 289, 291, 303, 369], "scp": [73, 74], "pip_set_env": [73, 74], "env_inc": [73, 74], "conda_set_env": [73, 74], "run_sampl": [73, 74], "chapter": [73, 74, 338], "keras_tf_train_mnist": 74, "fp32_frozen": 74, "pbyaml": 74, "alexnet_int8_model": 74, "pbalexnet_int8_model": 74, "mayb": [74, 129, 151, 153, 243, 288, 291, 330], "diagram": 75, "mismatch": [75, 162, 168, 187, 280, 288, 291], "correctli": [75, 162, 189, 227, 231, 236, 243, 244, 252, 254, 288, 291], "quantconf": 75, "simple_model": 75, "omit": [76, 122, 124, 129, 161], "onnxrt_qdqop": 76, "fer": 77, "yourself": [77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 125, 158, 159, 162, 248, 249, 256, 288, 291, 357], "body_analysi": [77, 78, 82], "emotion_ferplu": 77, "wider": [78, 213], "ultrafac": 78, "rfb": 78, "ilsvr2012": [79, 80, 81, 83, 84, 85, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98], "torchvis": [79, 98, 133, 148, 150, 151, 153, 296, 320, 373, 377], "mobilenet_v2": [79, 151, 345, 357], "randn": [79, 96, 98, 133], "being": [79, 96, 98, 129, 133, 143, 159, 160, 162, 170, 171, 200, 207, 220, 223, 231, 235, 236, 238, 244, 248, 249, 254, 255, 267, 274, 279, 288, 291], "export_param": [79, 96, 98], "opset_vers": [79, 96, 98], "do_constant_fold": [79, 96, 98], "input_nam": [79, 96, 98], "output_nam": [79, 96, 98], "dynamic_ax": [79, 96, 98], "ax": [79, 96, 98, 124, 252], "mobilenet_v2_qdq": 79, "tf2onnx": [80, 96, 107, 117, 118], "mlcommon": [80, 121, 329, 364], "mobile_model": [80, 107], "v0_7": [80, 107], "mobilenet_edgetpu_224_1": 80, "0_float": 80, "opset": [80, 96, 107, 117, 118, 252], "mobilenet_v3": 80, "mobilenet_v3_qdq": 80, "bvlcalexnet": 81, "label_path": [81, 83, 86, 87, 88, 93, 95, 109], "alexnet_qdq": 81, "celeb": 82, "1m": [82, 133, 278], "arcfaceresnet100": 82, "faces_ms1m_112x112": 82, "nfold": 82, "nfolds_num": 82, "caffenet_qdq": 83, "121": 84, "efficientnet_qdq": 85, "2017": [86, 110, 111, 112, 113, 114, 115, 116, 117, 118, 139, 143, 168, 206, 251, 317, 322, 328], "object_detection_segment": [86, 109, 110, 111, 112, 113, 114, 115, 116], "fcn_rn50": 86, "fcn_rn50_qdq": 86, "inception_and_googlenet": [87, 88], "googlenet_qdq": 87, "inception_v1_qdq": 88, "mobilenetv2_qdq": 90, "resnet50_v1_5": [91, 96, 357, 391], "resnet50_v1_5_qdq": [91, 96], "shufflenetv2": 92, "shufflenetv2_qdq": 92, "squeezenet1": [93, 143], "squeezenet_qdq": 93, "vgg16_qdq": [94, 98], "512": [95, 119, 163, 168, 244, 247, 250, 251, 253, 261, 271, 277, 284, 291], "zfnet512": 95, "zfnet512_qdq": 95, "requires_grad": [96, 98, 143, 256, 330], "torch_out": [96, 98], "zenodo": [96, 120, 121, 326, 337, 357], "2535873": [96, 357], "nchw": [96, 326], "input_tensor": [96, 143, 357, 363, 365, 391], "softmax_tensor": [96, 357, 391], "resnet50_v1_5_mlperf": 96, "resnet50_v1_5_mlperf_qdq": 96, "convert_stable_diffusion_checkpoint_to_onnx": 97, "compvi": [97, 119], "workdir": [97, 391], "translat": [99, 100, 101, 102, 103, 105, 106, 107, 108, 157, 159, 160, 162, 165, 170, 171, 189, 193, 196, 212, 222, 223, 227, 235, 239, 244, 245, 250, 251, 255, 257, 288, 291, 293, 316, 364], "prepare_data": [99, 100, 102, 103, 108], "glue_dir": [99, 100, 102, 103, 108, 264], "glue_data": [99, 100, 102, 103, 108, 264], "input_dir": [99, 100, 103, 108], "bert_dynam": 99, "model_tun": [99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 293, 311, 313], "bert_stat": 99, "bert_qdq": [99, 105], "out_dir": [100, 103, 108, 296], "run_glu": [100, 103, 108, 167, 187, 253, 257, 263, 280, 312, 313, 314, 315, 376, 377], "do_train": [100, 103, 108, 159, 189, 257, 259, 260, 261, 264, 270, 271, 272, 276, 279, 280, 282, 293, 299, 311, 312, 313, 314, 315], "do_ev": [100, 103, 108, 257, 259, 260, 261, 263, 264, 270, 271, 272, 279, 280, 282, 293, 295, 299, 300, 303, 305, 311, 312, 313, 314, 315, 376, 377], "per_gpu_eval_batch_s": [100, 103, 108, 260, 261, 264], "per_gpu_train_batch_s": [100, 103, 108, 261, 264, 272], "save_step": [100, 103, 108, 261, 264, 280, 282, 315], "100000": [100, 103, 108], "language_transl": [100, 103, 108], "distilbert_qdq": 100, "identifi": [101, 102, 122, 123, 124, 127, 159, 163, 168, 170, 209, 222, 245, 253, 255, 289, 293], "co": [101, 102, 123, 129, 157, 160, 171, 203, 222, 243, 250, 276, 277, 279, 286, 293, 298, 300, 301, 308], "mrm8488": 101, "salti": 101, "qa_dynam": 101, "english": [102, 165, 187, 189, 194, 197, 201, 211, 212, 222, 223, 226, 235, 236, 239, 244, 245, 250, 251, 253, 261, 267, 272, 273, 275, 277, 279, 280, 282, 284, 311, 314, 362, 364], "alireza1044": 102, "philschmid": 102, "glue_dynam": 102, "mobilebert_qdq": [103, 107], "paragraph": [104, 158, 168, 254], "machine_comprehens": [104, 105], "bidirectional_attention_flow": 104, "squad_v1": 104, "vocab": [105, 107, 167, 243, 244, 249, 250, 251, 254, 276, 296, 310, 359, 360, 361, 363, 364], "2018_10_18": [105, 107], "uncased_l": [105, 107, 155, 156, 167], "12_h": [105, 107, 155, 156, 167], "768_a": [105, 107, 155, 156, 167], "unzip": [105, 107, 120, 155, 156, 275, 302, 332, 333, 336, 360, 361, 369], "bertsquad": 105, "gpt2_lm_wikitext2": 106, "fatihcakir": 107, "mobilebert_float_384_20200602": 107, "mobilebert_squad": 107, "roberta_qdq": 108, "cityscap": 109, "leftimg8bit": 109, "gtfine": [109, 324], "rcnn": [110, 111, 115, 318, 365, 367], "fasterrcnn": [110, 143], "faster_rcnn": 110, "anno": [110, 111, 112, 113, 114, 115, 116, 365], "faster_rcnn_qdq": 110, "mask_rcnn": 111, "mask_rcnn_qdq": 111, "ssd_qdq": 112, "ssdmobilenet": [113, 117, 118], "ssd_mobilenet_v1_12": 113, "ssd_mobilenet_v1": [113, 117, 391], "ssd_mobilenet_v1_qdq": [113, 117], "tiny_yolov3": 114, "ssd_mobilenet_v1_coco_2018_01_28": [117, 365], "object_detect": [117, 118, 317, 318, 326, 328, 329, 330, 357, 365, 366], "frozen_inference_graph": [117, 118, 365], "fold_const": [117, 118], "ssd_mobilenet_v2_coco_2018_03_29": 118, "ssd_mobilenet_v2": 118, "ssd_mobilenet_v2_qdq": 118, "progress": [119, 129, 158, 162, 179, 189, 204, 205, 220, 231, 235, 255, 288, 291, 326, 331, 381, 387, 391], "taught": 119, "textual_invers": 119, "licens": [119, 129, 159, 253, 284, 338, 367], "ll": [119, 162, 168, 172, 189, 243, 247, 249, 254, 255, 288, 291, 322], "card": [119, 162, 206, 222, 254, 284, 286, 288, 291, 331], "tick": 119, "agre": [119, 162, 288, 291, 335], "hub": [119, 139, 140, 150, 160, 162, 163, 168, 171, 196, 198, 222, 236, 248, 251, 252, 254, 258, 259, 270, 278, 280, 282, 283, 284, 288, 291, 300, 339], "authent": 119, "cli": [119, 158, 167, 243, 286, 289, 390], "pictur": 119, "sd": [119, 276], "dicoo2": 119, "dicoo": 119, "textual_inversion_ipex": 119, "pretrained_model_name_or_path": 119, "train_data_dir": 119, "learnable_properti": 119, "placeholder_token": 119, "initializer_token": 119, "toi": 119, "resolut": [119, 124, 125, 127, 133], "train_batch_s": [119, 189, 276, 359], "max_train_step": 119, "3000": 119, "0e": 119, "scale_lr": 119, "lr_schedul": 119, "lr_warmup_step": 119, "dicoo_model": 119, "ccl": 119, "oneccl_bindings_for_pytorch_path": 119, "oneccl_bindings_for_pytorch": 119, "cwd": 119, "setvar": 119, "intel_extension_for_pytorch": [119, 150, 300], "throughput_mod": 119, "stablediffusionpipelin": 119, "model_id": [119, 222, 247, 391], "soon": [119, 125, 162, 288, 291], "pipe": [119, 254, 390], "from_pretrain": [119, 160, 162, 167, 168, 170, 172, 174, 185, 190, 192, 193, 196, 197, 198, 216, 222, 223, 227, 228, 236, 243, 245, 247, 248, 249, 251, 252, 253, 255, 256, 267, 272, 276, 278, 284, 288, 291, 311, 312, 314, 315], "torch_dtyp": 119, "cuda": [119, 134, 138, 141, 143, 162, 168, 189, 227, 247, 254, 256, 288, 291, 317, 321, 323, 328, 373], "love": [119, 158, 172, 253, 255, 256, 275, 279], "red": [119, 123, 129, 253, 275, 279], "dress": [119, 275], "hat": [119, 222], "snowli": 119, "brightli": 119, "night": [119, 158, 279], "brighli": 119, "num_inference_step": 119, "guidance_scal": 119, "generated_imag": 119, "dicoo_christma": 119, "nnunet": [120, 121, 123, 124, 125, 126, 127, 129], "brat": [120, 121], "2019": [120, 121, 193, 197, 200, 201, 204, 205, 211, 227, 233, 241, 244, 263, 267, 270, 276], "brain": [120, 121, 160, 171], "tumor": [120, 121, 129], "85300": [120, 121], "9141": [120, 121], "8679": [120, 121], "7770": [120, 121], "openvino": [120, 357, 367], "meant": [120, 168], "fastest": [120, 129], "download_data_dir": [120, 121], "miccai_brats_2019_data_train": [120, 121], "build_dock": 120, "launch_dock": 120, "preprocess_data": [120, 121], "ov": 120, "singlestream": 120, "multistream": 120, "har": 120, "consol": [120, 159, 189, 265], "log_fil": 120, "loadgen_log": 120, "output_dtyp": 120, "loadgen": [120, 121], "sut": [120, 337], "qsl": 120, "volum": [120, 129, 172, 275, 276], "voxel": [120, 124, 129], "forti": [120, 369], "cal": [120, 369], "sha": 121, "b7e8f0da170a421161410d18e5d2a05d75d6bccf": 121, "b38c69b345b2f60cd0d053039669e8f988b0c0af": 121, "diff": [121, 159], "layernorm": [121, 162, 252, 256, 288, 291], "whl": [121, 150, 155, 156, 296, 300, 357, 382, 385], "torch_stabl": [121, 155, 156, 296], "med": 121, "upenn": 121, "cbica": 121, "brats2019": 121, "download_pytorch_model": 121, "mkdir_postprocessed_data": 121, "preprocessed_data_dir": 121, "calib_preprocess": 121, "validation_fold_fil": 121, "brats_cal_images_list": 121, "recurs": [121, 150, 162, 254, 288, 291, 296], "absl": 121, "run_pytorch_nc_tun": 121, "model_dir": 121, "3d_fullr": [121, 125, 127, 129], "task043_brats2019": 121, "nnunettrainerv2__nnunetplansv2": [121, 129], "preprocessed_data": [121, 369], "mlperf_conf": 121, "fromnnunet": 121, "imagestr": [122, 123, 125, 126, 127], "modal": [122, 123, 125, 129, 160, 171, 221, 250], "task005": [122, 123], "prostat": [122, 123, 125, 129], "input_fold": [122, 129], "prostate_03_0000": [122, 126], "nii": [122, 123, 125, 126, 129], "prostate_03_0001": [122, 126], "prostate_05_0000": 122, "prostate_05_0001": 122, "prostate_08_0000": 122, "prostate_08_0001": 122, "t2": [122, 123, 125], "adc": [122, 123, 125], "task002": [122, 129], "heart": [122, 129], "imagest": [122, 123, 125, 126, 127], "la_001_0000": [122, 123, 126], "la_002_0000": [122, 123, 126], "la_006_0000": 122, "nnu": [123, 126, 127, 128], "interpret": [123, 124, 165, 249], "medic": [123, 125, 127, 129], "msd": [123, 129], "associ": [123, 129, 133, 136, 160, 167, 170, 248, 249, 251, 255, 266, 268, 276, 284], "nnunet_raw_data_bas": [123, 125, 126, 129, 369], "nnunet_raw_data": [123, 125, 126, 129], "task001_braintumour": 123, "task002_heart": [123, 126], "task003_liv": 123, "task004_hippocampu": 123, "task005_prost": [123, 125, 126], "labelstr": [123, 125, 126, 127], "postproces": 123, "ensembl": [123, 125, 129, 154, 212], "ground": [123, 129, 236, 275, 276, 278], "truth": [123, 129, 236, 275, 276, 278], "metadata": [123, 271, 276, 286], "nifti": [123, 125, 127], "consecut": [123, 129, 168, 244], "background": [123, 129, 143, 254], "especi": [123, 143, 159, 163, 213, 231, 252, 253, 255], "photo": 123, "green": [123, 129, 254, 279], "divers": [123, 129, 157, 187, 211, 214, 215, 216, 221, 230, 235], "ct": [123, 124, 129], "mri": [123, 124, 129], "suffix": [123, 222, 244, 252], "xxxx": [123, 129], "herebi": [123, 129, 163, 235], "braintumour": 123, "flair": 123, "t1w": 123, "t1gd": 123, "0002": 123, "t2w": 123, "brats_001_0000": 123, "brats_001_0001": 123, "brats_001_0002": 123, "brats_001_0003": 123, "brats_002_0000": 123, "brats_002_0001": 123, "brats_002_0002": 123, "brats_002_0003": 123, "brats_003_0000": 123, "brats_003_0001": 123, "brats_003_0002": 123, "brats_003_0003": 123, "brats_004_0000": 123, "brats_004_0001": 123, "brats_004_0002": 123, "brats_004_0003": 123, "brats_485_0000": 123, "brats_485_0001": 123, "brats_485_0002": 123, "brats_485_0003": 123, "brats_486_0000": 123, "brats_486_0001": 123, "brats_486_0002": 123, "brats_486_0003": 123, "brats_487_0000": 123, "brats_487_0001": 123, "brats_487_0002": 123, "brats_487_0003": 123, "brats_488_0000": 123, "brats_488_0001": 123, "brats_488_0002": 123, "brats_488_0003": 123, "brats_489_0000": 123, "brats_489_0001": 123, "brats_489_0002": 123, "brats_489_0003": 123, "brats_001": 123, "brats_002": 123, "brats_003": 123, "brats_004": 123, "la_003_0000": [123, 126], "la_004_0000": [123, 126], "la_003": [123, 126], "la_004": [123, 126], "geometri": 123, "ones": [123, 162, 168, 182, 189, 209, 213, 236, 244, 249, 253, 254, 276, 280, 282, 288, 291], "therebi": [123, 162, 247, 288, 291], "descript": [123, 129, 158, 160, 161, 162, 163, 165, 236, 258, 285, 288, 291, 335, 387, 391], "transit": 123, "peripher": [123, 125], "radboud": 123, "univers": [123, 160, 171, 236], "nijmegen": 123, "centr": [123, 211], "licenc": 123, "cc": [123, 136, 320], "BY": 123, "sa": 123, "relas": 123, "2018": [123, 136, 143, 200, 204, 205, 211, 233, 255, 276, 322, 331, 367], "tensorimages": 123, "4d": [123, 125, 127], "pz": 123, "tz": 123, "numtrain": 123, "numtest": 123, "prostate_16": 123, "prostate_04": 123, "prostate_08": 123, "prostate_22": 123, "prostate_30": 123, "clariti": [123, 157], "blank": [123, 168, 251, 273, 381], "confus": 123, "nnunet_convert_decathlon_task": [123, 125, 127], "folder_to_task_as_downloaded_from_msd": 123, "num_process": 123, "AS": 123, "task05": [123, 129], "overwrit": [123, 124, 129, 189, 254, 267, 380, 384], "output_task_id": 123, "empir": [124, 160, 168, 191, 195, 196, 213, 224, 241, 242], "thing": [124, 129, 158, 159, 162, 168, 172, 189, 251, 252, 254, 255, 266, 288, 291], "deriv": [124, 133, 188, 189, 190, 203, 212], "feel": [124, 159, 162, 172, 251, 253, 276, 277, 288, 289, 291, 322], "guidanc": [124, 159], "augment": [124, 133, 230, 244, 272, 330], "trainer": [124, 129, 160, 165, 171, 179, 190, 243, 248, 251, 257, 259, 270, 276, 278, 282, 287, 293, 299, 301, 311, 312, 313, 314, 316], "2d": [124, 125, 218, 244], "nnunettrainerv2": [124, 127, 129], "nnunettrainerv2cascadefullr": [124, 129], "overrid": [124, 133, 179, 182, 189, 253, 254, 276, 322], "quit": [124, 129, 133, 159, 162, 255, 267, 288, 291, 331], "subfold": [124, 125, 126, 127, 129, 257], "somewher": [124, 162, 189, 288, 291], "twice": [124, 267], "worri": [124, 125, 162, 214, 243, 277, 288, 291, 331], "kind": [124, 157, 159, 170, 221, 244, 249, 276], "network_train": 124, "loss_funct": 124, "data_augment": 124, "optimizer_and_lr": 124, "architectural_vari": 124, "nnunettrainerv2_bn": 124, "pynnunet": 124, "nnunettrainerv2_frn": 124, "nnunettrainerv2_gn": 124, "nnunettrainerv2_nonormalization_lr1en3": 124, "nonlinear": [124, 217], "nnunettrainerv2_relu": 124, "nnunettrainerv2_mish": 124, "nnunettrainerv2_3convperstag": 124, "nnunettrainerv2_resencunet": 124, "fingerprint": [124, 129], "dimension": [124, 162, 288, 291], "captur": [124, 129, 237], "intens": [124, 129, 230, 244, 275], "datset": 124, "datasetanalyz": 124, "nnunet_plan_and_preprocess": [124, 127, 129], "experimentplann": [124, 129], "experimentplanner2d": 124, "v21": [124, 129], "experimentplanner3d": [124, 129], "nnunettrain": [124, 129], "data_identifi": 124, "plans_fnam": 124, "planner": [124, 129], "nnunet_train": [124, 127, 129], "priorit": 124, "patch": [124, 129, 143, 150, 375], "prioritizi": 124, "definit": [124, 133, 162, 168, 189, 288, 291, 331, 387], "inspir": [124, 143, 157], "preprocessor": 124, "preprocessor_nam": 124, "genericpreprocessor": 124, "preprocessorfor2d": 124, "anisotrop": [124, 129], "fname": 124, "overwritten": [124, 143, 236, 289, 340, 354, 376], "explanatori": 124, "wrt": 124, "downsampl": [124, 129], "supervis": [124, 160, 170, 171, 191, 194, 223, 229, 235, 236, 238, 239, 240, 244, 267, 272, 284], "suppos": [124, 134, 137, 138, 142, 145, 146, 148, 156, 267, 270, 332], "dynamiccali": 124, "furthermor": [124, 129, 217, 218, 231, 242, 365, 366], "consumpt": [124, 191, 217], "disregard": [124, 167, 221], "unreason": 124, "vram": [124, 129, 170], "occupi": 124, "mostli": [124, 161, 254, 284], "cudnn": [124, 254, 320, 321], "imposs": [124, 159, 162, 252, 288, 291], "approch": 124, "straightforward": [124, 254, 255], "largest": [124, 227, 247, 250, 252], "dowmsampl": 124, "illustr": [124, 168, 303, 322], "fabiansunet": 124, "modular": [124, 129, 160, 248, 322], "experimentplanner3dfabiansresunet": 124, "approx": [124, 231], "decathlon": [125, 127, 129], "relev": [125, 127, 159, 162, 163, 192, 206, 244, 251, 275, 282, 284, 288, 291], "archiv": [125, 127, 265], "task05_prost": 125, "nnunet_download_pretrained_model": [125, 129], "rgb": [125, 143, 367], "case_0000": 125, "case_0001": 125, "whenev": [125, 159, 162, 257, 288, 291], "nnunet_print_pretrained_model_info": 125, "central": [125, 143, 182], "medicaldecathlon": 125, "ran": [125, 161, 162, 276, 288, 291], "medcial": 125, "exemplarili": 125, "nnunet_predict": [125, 129], "output_directori": 125, "littl": [125, 129, 159, 251, 253, 331], "output_directory_3d": 125, "save_npz": [125, 129], "output_directory_2d": 125, "probabl": [125, 129, 162, 190, 243, 244, 247, 249, 251, 253, 255, 267, 278, 288, 291, 319, 322, 323], "nnunet_ensembl": [125, 129], "output_folder_ensembl": 125, "pp": [125, 129], "postprocessing_fil": [125, 129], "were": [125, 126, 129, 143, 157, 159, 162, 163, 189, 190, 203, 209, 212, 222, 227, 231, 239, 251, 253, 254, 255, 257, 259, 261, 276, 279, 283, 284, 288, 291, 321, 374], "results_fold": [125, 126, 129, 369], "ensemble_2d__nnunettrainerv2__nnunetplansv2": 125, "3d_fullres__nnunettrainerv2__nnunetplansv2": 125, "reli": [126, 158, 162, 170, 188, 189, 190, 202, 208, 212, 224, 234, 236, 239, 242, 244, 254, 255, 272, 288, 291], "care": [126, 127, 129, 162, 170, 190, 233, 235, 248, 251, 252, 253, 254, 256, 288, 289, 291], "rest": [126, 127, 167, 170, 189, 202, 244, 254, 255, 335], "tree": [126, 133, 212, 276, 279, 329, 335, 368], "prostate_00_0000": 126, "prostate_00_0001": 126, "prostate_00": 126, "prostate_01": 126, "sata": 126, "nvme": 126, "linux": [126, 129, 133, 158, 163, 381], "bashrc": 126, "me": [126, 275, 279, 284], "fabian": [126, 128, 129], "editor": [126, 136, 159], "al": [126, 160, 171, 197, 200, 211, 222, 226, 228, 233, 244, 253, 255, 261, 263, 317], "rare": [126, 168, 243, 255, 267, 276, 282], "touch": [126, 254], "nnunet_raw": 126, "nnunet_preprocess": [126, 369], "nnunet_trained_model": 126, "rememb": [126, 129, 159, 162, 189, 249, 254, 288, 291], "reload": [126, 190, 248, 256, 390], "verifi": [126, 129, 133, 138, 150, 159, 162, 218, 243, 288, 291], "properli": [126, 129, 170, 172, 249, 255, 320, 323], "echo": [126, 189, 243, 254, 374], "task04_hippocampu": 127, "modern": [127, 252], "altern": [128, 163, 168, 172, 189, 209, 243, 254, 256, 257, 276, 284], "believ": [128, 253], "superior": [128, 198, 199], "biomed": 129, "drastic": [129, 231, 278], "liver": 129, "challeng": [129, 162, 198, 199, 207, 214, 221, 222, 233, 286, 288, 291], "tomographi": 129, "scan": [129, 165, 218], "512x512x512": 129, "isotrop": 129, "quantit": 129, "hounsfield": 129, "cardiac": 129, "diagnosi": 129, "cine": 129, "10x320x320": 129, "qualit": [129, 254], "acdc": 129, "suffer": [129, 202, 224, 225, 242, 244], "slice": [129, 190, 251], "misalign": [129, 282], "heterogen": [129, 211], "plane": 129, "artifact": [129, 161, 257, 276, 390], "practic": [129, 143, 159, 162, 171, 189, 201, 208, 231, 235, 244, 247, 255, 287, 288, 291], "mind": [129, 158, 159, 162, 248, 288, 291, 319], "indirectli": 129, "displai": [129, 161, 179, 198, 199, 236, 265, 317, 331], "affect": [129, 157, 205, 227, 254, 255, 278], "recept": [129, 244], "influenc": [129, 244], "inher": 129, "deal": [129, 168, 170, 189, 251, 254, 255], "somain": 129, "condens": 129, "against": [129, 159, 162, 170, 254, 275, 288, 291], "evid": [129, 191], "inexperienc": 129, "intervent": 129, "roll": [129, 172], "isense": 129, "paul": [129, 164], "j\u00e4ger": 129, "simon": 129, "kohl": 129, "jen": [129, 160, 171, 223], "petersen": 129, "klau": 129, "maier": 129, "hein": 129, "arxiv": [129, 133, 139, 164, 165, 194, 219, 223, 253, 264, 272, 274, 275, 276, 284, 305, 322, 331], "preprint": [129, 139], "1904": [129, 133], "08128": 129, "cite": [129, 136, 160, 206, 264, 266, 267, 272, 322], "ecotrust": 129, "canada": 129, "markdown": [129, 161], "toc": 129, "gb": [129, 170, 203, 215, 227, 250, 321], "rtx": [129, 163, 170, 280], "2080ti": 129, "volta": [129, 280], "titan": [129, 163, 170, 280, 331], "v100": [129, 227, 261, 265, 276, 278, 280, 321], "tensorcor": 129, "ture": [129, 217, 280], "strongli": [129, 158, 162, 248, 288, 291], "apex": [129, 189, 190, 257, 276, 280], "slower": [129, 189, 243, 259, 276], "experienc": [129, 162], "nvcc": [129, 189, 323], "swap": [129, 244, 284], "cluster": [129, 159, 267, 275], "torch_cuda_arch_list": 129, "mic": 129, "dkfz": 129, "hiddenlay": 129, "plot": [129, 266, 271], "upgrad": [129, 159, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "nanohanno": 129, "bugfix": 129, "get_trace_graph": 129, "egg": 129, "nnunet_": 129, "identif": 129, "coars": 129, "taskxxx_mytask": 129, "verify_dataset_integr": 129, "taskxxx": 129, "mytask": 129, "pkl": [129, 276], "Their": [129, 279], "happen": [129, 158, 159, 162, 251, 253, 255, 279, 288, 291], "fly": [129, 159, 189, 231, 243, 272], "ram": [129, 158, 189, 254, 276], "trainer_class_nam": 129, "task_name_or_id": 129, "OR": 129, "crossvalidaton": 129, "3d_cascade_fullr": 129, "five": [129, 171, 215, 221, 232, 253, 267, 272], "beforehand": [129, 162, 252, 288, 291], "written": [129, 157, 158, 161, 162, 254, 265, 276, 284, 288, 291, 327], "mytasknam": 129, "__": [129, 161, 194, 212, 254, 290, 323], "task02_heart": 129, "fold_0": 129, "fold_1": 129, "fold_2": 129, "fold_3": 129, "fold_4": 129, "model_best": [129, 130, 131, 132], "model_final_checkpoint": 129, "network_architectur": 129, "pdf": [129, 136, 218], "validation_raw": 129, "la_007": 129, "la_016": 129, "la_021": 129, "la_024": 129, "validation_arg": 129, "lowr": 129, "fullr": 129, "blueprint": 129, "Not": [129, 162, 249, 253, 254, 288, 291], "dice": 129, "foreground": 129, "salt": 129, "drawn": 129, "aggreg": [129, 236], "tp": 129, "fn": [129, 133, 168], "pretend": [129, 278], "proper": [129, 161, 193, 249], "watch": [129, 189, 253, 254, 380, 384], "dataparallel": 129, "dp": 129, "ddp": [129, 254], "prefer": [129, 158, 162, 170, 288, 291], "variant": [129, 133, 139, 198, 199, 200, 202, 219, 226, 244, 253, 364], "cuda_visible_devic": [129, 163, 189, 254, 261], "nnunet_train_dp": 129, "nnunettrainerv2_dp": 129, "db": 129, "master_port": [129, 189, 267], "nproc_per_nod": [129, 159, 189, 257, 261, 267, 276, 277, 295, 304, 322], "run_training_ddp": 129, "nnunettrainerv2_ddp": 129, "someth": [129, 158, 159, 162, 172, 193, 198, 212, 220, 222, 223, 227, 229, 231, 235, 236, 240, 243, 251, 254, 255, 270, 276, 279, 291], "4321": 129, "sai": [129, 158, 170, 172, 189, 193, 223, 251, 253, 278, 376], "said": [129, 159, 160, 162, 189, 190, 248, 253, 288, 291], "nnunet_change_trainer_class": 129, "nnunet_find_best_configur": 129, "strict": [129, 162, 288, 291], "crash": 129, "flag": [129, 133, 158, 159, 189, 190, 243, 251, 253, 254, 257, 259, 270, 275, 280, 357, 359, 360, 363, 364, 390], "easiest": [129, 158, 162, 235, 251, 276, 288, 291, 322, 365], "output_fold": [129, 318], "alongsid": [129, 161, 162, 170, 187, 253, 288, 291], "disk": [129, 158, 162, 222, 227, 252, 254, 272, 276, 288, 291, 322], "folder1": 129, "folder2": 129, "nnunet_print_available_pretrained_model": 129, "task029_lit": 129, "task029": 129, "lit": 129, "abdomin": 129, "hippocampu": 129, "usabl": [129, 289], "abort": 129, "preprocessing_output_dir": 129, "taskxx_my_dataset": 129, "splits_fin": 129, "dictionari": [129, 160, 170, 174, 185, 188, 249, 251, 279], "patientid": 129, "pickl": [129, 267], "batchgener": 129, "robust": [129, 158, 264, 276], "happi": [129, 158, 159, 160, 162, 251, 267, 279, 287, 288, 289, 291], "contextu": [129, 209, 211, 275], "promise12": 129, "tbe": 129, "overfit": [129, 229, 240, 244], "whoever": 129, "recipi": 129, "11gb": 129, "slack": [129, 162, 288, 291], "exact": [129, 159, 162, 189, 190, 220, 254, 261, 275, 288, 291, 321], "3dunet": [129, 369], "attempt": [129, 254], "headroom": 129, "ref": [129, 270], "generic_unet": 129, "use_this_for_batch_size_computation_3d": 129, "32gb": 129, "remain": [129, 159, 170, 191, 207, 227, 230, 244, 245, 253, 254, 272, 284, 376], "substanti": [129, 195, 209], "goe": [129, 244, 249, 254, 270, 272], "void": 129, "thcudatensor_scatterfillkernel": 129, "tensorinfo": 129, "indextyp": 129, "unsign": 129, "4770": 129, "indexvalu": 129, "unexpect": [129, 191, 252, 279], "foregound": 129, "wrong": [129, 159, 162, 270, 288, 291], "median": 129, "128x128x128": 129, "enforc": [129, 253, 276], "creation": [129, 284, 286, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "how_much_of_a_patient_must_the_network_see_at_stage0": 129, "train_without_distil": [130, 131, 132], "student_typ": [130, 132, 267], "teacher_typ": [130, 132, 267], "widen": 131, "wideresnet": 131, "mixnet": 133, "genefficientnet": 133, "layout": [133, 160, 171, 218], "newli": [133, 245, 250, 276], "rand": [133, 319, 373], "favour": 133, "lite": [133, 160, 171, 191, 244], "5m": [133, 140, 231], "110d": 133, "140": [133, 203, 391], "8m": 133, "120d": 133, "tpu": [133, 165, 189, 191, 254, 259, 270, 278, 284, 291, 357, 367], "scratch": [133, 156, 162, 168, 223, 231, 250, 251, 256, 259, 261, 275, 285, 288, 291], "impl": [133, 331], "fix_group_fanout": 133, "initialize_weight_goog": 133, "l2": [133, 236], "b7": [133, 367], "noisystud": 133, "b8": 133, "randaug": 133, "advprop": 133, "edgetpu": 133, "andrew": 133, "lavin": 133, "b2": 133, "b3": 133, "rwightman": 133, "torchscript": [133, 163, 171, 190], "mixedconv2d": 133, "moduledict": 133, "1911": 133, "09665": 133, "spec": 133, "aa": 133, "ra": [133, 170], "minimalist": 133, "mine": [133, 276], "biggest": [133, 244], "mem": [133, 321], "swish": 133, "mish": 133, "autograd": [133, 143], "autgrad": 133, "factori": [133, 358], "helper": [133, 254, 257, 322], "condconv": 133, "b5": [133, 367], "algo": 133, "my": [133, 158, 159, 162, 174, 185, 189, 198, 244, 254, 267, 274, 279, 288, 291, 331, 391], "pool": [133, 213, 244], "entrypoint": 133, "chamnet": 133, "04252": 133, "1905": [133, 164], "11946": 133, "googleblog": 133, "04971": 133, "1907": 133, "09595": 133, "mnasnet": 133, "b1": 133, "a1": 133, "excit": [133, 172], "1807": 133, "11626": 133, "02244": 133, "fbnet": 133, "1812": 133, "03443": 133, "02877": 133, "repositori": [133, 158, 159, 160, 161, 167, 171, 172, 180, 183, 188, 205, 236, 243, 250, 252, 254, 265, 284, 289, 317, 362, 372, 382, 385], "caffe2": [133, 321, 322], "ve": [133, 160, 162, 168, 171, 193, 236, 243, 278, 335, 365], "prec": 133, "err": [133, 159, 254], "madd": 133, "efficientnet_b3": 133, "866": 133, "134": 133, "836": 133, "164": [133, 136], "tbd": [133, 144, 154, 356], "672": [133, 143], "328": 133, "904": 133, "mixnet_xl": 133, "074": [133, 163], "926": [133, 143], "282": 133, "718": 133, "efficientnet_b2": 133, "612": 133, "388": 133, "318": 133, "682": 133, "288": [133, 200], "476": [133, 272], "524": [133, 136, 143], "936": 133, "064": [133, 163], "712": 133, "166": 133, "834": 133, "1003": 133, "260": 133, "890": 133, "mixnet_l": 133, "976": 133, "024": 133, "184": 133, "816": 133, "efficientnet_b1": 133, "692": 133, "086": [133, 143], "914": 133, "694": 133, "240": [133, 136], "882": 133, "efficientnet_": 133, "066": [133, 143], "934": 133, "efficientnet_b0": 133, "698": 133, "302": 133, "532": 133, "468": 133, "390": 133, "mobilenetv2_120d": 133, "706": [133, 391], "502": [133, 323], "498": [133, 143], "mixnet_m": 133, "744": 133, "418": 133, "582": 133, "353": 133, "mobilenetv2_140": 133, "990": 133, "010": 133, "mixnet_": 133, "988": 133, "012": 133, "794": 133, "206": 133, "mobilenetv3_large_100": 133, "766": [133, 143], "234": [133, 143, 162, 288, 291, 391], "458": 133, "mobilenetv3_rw": 133, "634": 133, "366": 133, "708": 133, "219": 133, "mnasnet_a1": 133, "448": [133, 143], "396": [133, 143], "312": 133, "fbnetc_100": 133, "876": 133, "386": [133, 143], "385": 133, "mobilenetv2_110d": 133, "052": 133, "948": 133, "820": 133, "mnasnet_b1": 133, "658": [133, 143], "342": 133, "886": [133, 143], "spnasnet_100": 133, "084": 133, "916": 133, "818": [133, 143], "182": [133, 143, 249], "mobilenetv2_100": 133, "978": 133, "022": [133, 163], "016": 133, "984": 133, "pretti": [133, 190, 243, 331], "equival": [133, 162, 170, 189, 247, 254, 255, 256, 276, 278, 288, 291], "tf_efficientnet_b5": 133, "img": [133, 330], "pct": 133, "ie": 133, "tf_efficientnet_b8_ap": 133, "954": 133, "tf_efficientnet_l2_n": 133, "tfp": 133, "352": 133, "652": 133, "348": 133, "961": [133, 321], "tf_efficientnet_l2_ns_475": 133, "475": 133, "828": 133, "566": [133, 143, 321], "tf_efficientnet_b7_n": 133, "844": 133, "600": [133, 318], "840": 133, "094": 133, "906": 133, "tf_efficientnet_b6_n": 133, "452": [133, 143], "548": [133, 143], "118": [133, 263], "528": 133, "444": 133, "556": 133, "880": 133, "120": 133, "tf_efficientnet_b5_n": 133, "746": [133, 143], "088": [133, 163], "912": 133, "752": [133, 143], "248": 133, "436": 133, "564": 133, "728": 133, "tf_efficientnet_b8": 133, "616": 133, "394": 133, "606": 133, "630": 133, "610": 133, "368": 133, "632": 133, "tf_efficientnet_b4_n": 133, "298": [133, 222, 326], "702": 133, "504": 133, "496": 133, "380": 133, "838": 133, "470": 133, "530": 133, "922": 133, "tf_efficientnet_b7_ap": 133, "154": 133, "846": 133, "756": 133, "252": [133, 143], "949": 133, "tf_efficientnet_b7": 133, "940": 133, "060": 133, "214": 133, "786": 133, "932": 133, "208": 133, "792": 133, "tf_efficientnet_b6_ap": 133, "138": [133, 170, 249], "862": 133, "942": 133, "760": 133, "tf_efficientnet_b5_ap": 133, "276": 133, "724": 133, "tf_efficientnet_b6": 133, "860": 133, "852": 133, "148": 133, "110": [133, 136, 143], "tf_efficientnet_b3_n": 133, "054": [133, 163], "946": 133, "918": 133, "082": 133, "048": 133, "910": 133, "090": 133, "822": [133, 143], "812": 133, "tf_efficientnet_b4_ap": 133, "278": 133, "376": 133, "624": [133, 143], "tf_efficientnet_b4": 133, "700": [133, 327], "tf_efficientnet_b2_n": 133, "268": 133, "732": 133, "620": [133, 143, 321], "tf_efficientnet_b3_ap": 133, "662": [133, 143], "338": 133, "tf_efficientnet_b3": 133, "364": 133, "576": 133, "424": 133, "tf_efficientnet_lite4": 133, "472": 133, "668": 133, "tf_efficientnet_b1_n": 133, "514": 133, "486": 133, "676": 133, "324": 133, "738": 133, "262": 133, "tf_efficientnet_el": 133, "534": 133, "190": 133, "810": 133, "tf_efficientnet_b2_ap": 133, "580": 133, "040": 133, "028": [133, 143, 321], "972": [133, 272], "tf_efficientnet_b2": 133, "974": 133, "026": [133, 143], "908": 133, "092": 133, "tf_efficientnet_lite3": 133, "734": 133, "266": [133, 143], "tf_efficientnet_b1_ap": 133, "622": 133, "tf_efficientnet_cc_b1_8": 133, "464": 133, "tf_efficientnet_b1": 133, "450": [133, 237], "550": 133, "tf_efficientnet_em": 133, "958": 133, "042": 133, "tf_efficientnet_b0_n": 133, "806": 133, "194": [133, 143], "tf_mixnet_l": 133, "212": 133, "788": 133, "826": 133, "174": 133, "802": 133, "230": 133, "004": [133, 163], "996": 133, "742": 133, "258": [133, 143], "tf_efficientnet_cc_b0_8": 133, "314": 133, "790": 133, "210": 133, "656": 133, "344": 133, "tf_efficientnet_cc_b0_4": 133, "304": [133, 143, 391], "696": 133, "tf_efficientnet_": 133, "750": [133, 282], "tf_efficientnet_lite2": 133, "544": [133, 321], "540": 133, "tf_efficientnet_b0_ap": 133, "736": [133, 143], "400": [133, 143, 218, 272], "tf_efficientnet_b0": 133, "478": [133, 255], "522": 133, "tf_mixnet_m": 133, "072": [133, 272], "928": 133, "950": 133, "050": 133, "848": 133, "228": 133, "772": 133, "tf_efficientnet_lite1": 133, "236": [133, 143], "326": 133, "674": 133, "638": 133, "362": 133, "232": 133, "768": [133, 250, 252, 267], "tf_mixnet_": 133, "tf_mobilenetv3_large_100": 133, "710": 133, "290": 133, "516": 133, "484": 133, "tf_efficientnet_lite0": 133, "842": 133, "158": 133, "170": [133, 143, 170, 249, 319], "830": 133, "tf_mobilenetv3_large_075": 133, "730": 133, "270": [133, 141], "442": 133, "558": 133, "tf_mobilenetv3_large_minimal_100": 133, "678": 133, "322": 133, "tf_mobilenetv3_small_100": 133, "tf_mobilenetv3_small_075": 133, "142": [133, 143], "858": [133, 143], "136": [133, 136, 143, 249], "864": 133, "tf_mobilenetv3_small_minimal_100": 133, "898": 133, "window": [133, 159, 161, 162, 219, 220, 244, 247, 253, 254, 288, 291], "myself": [133, 279], "cudatoolkit": [133, 189, 323], "geffnet": [133, 134], "create_model": 133, "drop_rat": 133, "drop_connect_r": 133, "as_sequenti": 133, "onnx_export": 133, "mobilenetv3_100": 133, "onnx_optim": 133, "onnx_to_caff": 133, "c2": 133, "caffe2_valid": 133, "_export": 133, "set_export": 133, "rw": 134, "unlimit": [134, 137, 138, 142, 148, 149, 150, 151, 153, 318, 330], "builder": [134, 158], "conf_efficientnet_b0": 134, "horovod": [135, 340, 341, 354], "horovodrun": [135, 141, 147, 152, 340, 341, 354], "great": [136, 158, 159, 162, 164, 168, 186, 218, 224, 231, 244, 253, 254, 288, 291, 373], "pele": 136, "neurip": [136, 267], "incollect": 136, "nips2018_7466": 136, "robert": [136, 160, 171, 216, 226, 235], "j": [136, 137, 142, 160, 171, 194, 200, 227, 231, 235, 244, 328, 333], "li": [136, 139, 160, 171, 218, 223, 235, 244, 275], "xiang": [136, 160, 171, 206], "ling": 136, "charl": 136, "booktitl": [136, 160, 266, 267], "bengio": 136, "wallach": 136, "larochel": 136, "grauman": 136, "cesa": 136, "bianchi": 136, "garnett": 136, "1963": 136, "1972": 136, "curran": 136, "nip": 136, "7466": 136, "flop": [136, 213], "tx2": 136, "569": 136, "condensenet": 136, "274m": 136, "0m": 136, "5x": [136, 189, 224, 276], "621": 136, "245": 136, "what_you_w": 138, "splat": 138, "downstream": [139, 162, 168, 191, 201, 202, 204, 205, 209, 211, 217, 218, 219, 220, 224, 227, 230, 235, 244, 245, 253, 275, 284, 285, 288, 291, 295, 304], "deeplabv3": [139, 367], "zhanghang1989": [139, 140], "269": [139, 141], "416": [139, 331, 366], "caff": [139, 357], "extra": [139, 223, 250, 254, 259, 270, 276, 277, 282, 322], "ablat": [139, 221], "studi": [139, 164, 173, 174, 175, 176, 177, 178, 196, 207, 214, 221, 224, 233, 235, 239, 248, 254], "force_reload": [139, 140], "detectron2": 139, "fork": [139, 159, 162, 254, 276, 286, 288, 291, 335, 382, 385], "trick": [139, 161, 189, 243, 255], "dcn": 139, "mutli": 139, "dev2019": 139, "pq": 139, "gluoncv": [139, 141], "pixacc": 139, "miou": [139, 370], "deeplab": 139, "mapillari": 139, "recordio": 139, "prepare_imagenet": 139, "slightli": [139, 162, 189, 217, 223, 236, 254, 255, 259, 261, 276, 288, 291], "wors": [139, 247, 276], "hang": [139, 160, 171, 211, 244, 279], "chongruo": 139, "wu": [139, 160, 171, 208, 215], "zhongyu": 139, "yi": 139, "zhu": 139, "zhi": 139, "haibin": 139, "lin": [139, 266], "yue": [139, 222], "sun": [139, 160, 171, 206, 224], "tong": 139, "jona": 139, "muller": [139, 160, 171, 201], "manmatha": 139, "mu": 139, "alex": [139, 143], "smola": 139, "zhang2020resnest": 139, "alexand": [139, 160, 272, 276, 322], "journal": [139, 276, 331], "2004": [139, 284], "08955": 139, "gflop": 140, "resnest": 140, "1s1x64d": 140, "3m": [140, 250, 284], "2s1x64d": 140, "4s1x64d": 140, "9m": [140, 284], "1s2x40d": 140, "2s2x40d": 140, "4s2x40d": 140, "4m": 140, "1s4x24d": 140, "7m": 140, "fast_2s1x64d": 140, "resnest50_fast_2s1x64d": 140, "cu100": 141, "horovod_gpu_allreduc": 141, "nccl": [141, 321], "mpi4pi": 141, "unfortun": [141, 198, 278], "ramdisk": 141, "sudo": [141, 189, 243, 331, 374], "mkdir": [141, 155, 156, 168, 275, 276, 300, 317, 318, 322, 324], "mount": 141, "tmpf": 141, "200g": 141, "cp": [141, 276, 324], "hostfil": 141, "gamma": [141, 274], "wd": 141, "smooth": [141, 267, 278, 317], "mixup": 141, "params_": 141, "interv": 141, "auto_aug": 141, "se": [142, 143, 222], "resnext": 142, "pretrainedmodel": [142, 143, 162, 171, 253, 288, 291], "resnext50": [142, 143], "32x4d": [142, 143], "imagenet_ev": [142, 143], "senet": 142, "convnet": 143, "travi": 143, "parinov": 143, "senet154": 143, "cafferesnet101": 143, "veronika": 143, "yurchuk": 143, "anastasiia": 143, "ross": [143, 322], "wightman": 143, "standlei": 143, "transformimag": 143, "pretrained_set": 143, "pull": [143, 162, 172, 258, 283, 285, 288, 291], "durand": 143, "caden": 143, "valset": 143, "dualpathnet68": 143, "dualpathnet92": 143, "dualpathnet98": 143, "dualpathnet107": 143, "dualpathnet113": 143, "fbresnet152": 143, "resnext101": [143, 148, 149, 150, 151, 153], "64x4d": 143, "vgg11": 143, "vgg13": 143, "resnext101_32x4d": 143, "resnext101_64x4d": 143, "squeezenet1_0": 143, "squeezenet1_1": 143, "vgg11_bn": 143, "vgg13_bn": 143, "vgg16_bn": 143, "vgg19_bn": 143, "nasnetalarg": 143, "nasnetamobil": 143, "se_resnet50": 143, "se_resnet101": 143, "se_resnet152": 143, "se_resnext101_32x4d": 143, "pnasnet5larg": 143, "lip6": 143, "fr": [143, 222, 245], "a1897284": 143, "331": 143, "1001": [143, 357], "torch_hom": 143, "load_img": 143, "loadimag": 143, "ex": [143, 158, 190], "tobgr": 143, "torange255": 143, "tf_img": 143, "path_img": 143, "cat": [143, 189, 222, 253, 276, 282, 374], "input_img": 143, "3x400x225": 143, "3x299x299": 143, "unsqueez": [143, 185, 256, 267], "1x3x299x299": 143, "output_logit": 143, "1x1000": 143, "bewar": 143, "output_featur": 143, "1x14x14x2048": 143, "imagenet_logit": 143, "tiger": 143, "imagenet_2012": 143, "693": 143, "062": 143, "dualpathnet107_5k": 143, "684": 143, "torch7": 143, "dualpathnet131": 143, "574": 143, "dualpathnet92_5k": 143, "488": 143, "resnext50_32x4d": 143, "076": 143, "500": [143, 159, 165, 168, 189, 256, 276, 279, 284, 307, 326, 359, 360, 362, 363, 364, 368], "956": 143, "888": 143, "428": 143, "560": 143, "798": 143, "438": 143, "594": 143, "dualpathnet68b_5k": 143, "034": [143, 321], "590": 143, "900": [143, 297], "980": 143, "868": 143, "774": 143, "646": 143, "080": 143, "554": [143, 321], "562": 143, "608": [143, 331], "354": 143, "494": 143, "274": 143, "970": 143, "108": 143, "378x378": 143, "kaimingh": 143, "xiong": [143, 160, 171, 203], "yuanjun": 143, "resnext101_62x4d": 143, "chen": [143, 160, 171, 191, 202, 204, 205, 206, 208, 223, 229, 233, 240, 244], "yunpeng": [143, 160, 171, 202, 244], "hi": [143, 236, 253], "crope": 143, "dpn68": 143, "dpn98": 143, "dpn131": 143, "dpn68b": 143, "5k": [143, 277], "dpn92": 143, "dpn107": 143, "imagenet5k": 143, "imagenet1k": 143, "jie": 143, "hu": [143, 253], "cuhk": 143, "multimedia": 143, "299": [143, 358], "bgr": 143, "substrat": 143, "input_224": 143, "2048": [143, 250], "input_448": 143, "bellow": 143, "dim_feat": 143, "in_featur": [143, 162, 288, 291], "nb_class": 143, "th": [143, 253], "fbresnet": 143, "resnet152_dump": 143, "lua": 143, "resnet152_load": 143, "clcarwin": 143, "contributor": [143, 158, 162, 284, 288, 291], "run_distil": [144, 154, 356], "torchvision_model": [145, 146, 148, 149, 150, 151, 153], "optimization_pipelin": [145, 146], "prune_and_ptq": 145, "ptq_conf": 145, "qat_during_prun": 146, "qat_conf": 146, "model_fin": 147, "32x8d": [148, 149, 151, 153, 321], "main_dump_tensor": 148, "nc_model": [148, 149, 150, 318], "path_to_save_configure_fil": [148, 149, 150, 318], "join": [148, 149, 170, 236, 243, 247, 318], "best_configur": [148, 149, 318], "best_model_weight": [148, 149, 318], "imagenet_ptq": [148, 149, 150], "didn": [148, 151, 174, 185, 253, 254, 276], "tune_2_acc0": [148, 149], "acc0": [148, 149], "tune_2": [148, 149], "your_dataload": [149, 318], "gcc9": 150, "sync": [150, 296], "1279c5824f1bcb61cd8990f4148abcadf3f214a4": 150, "resnet18_ipex": 150, "resnet50_ipex": 150, "32x16d": 150, "resnext101_32x16d_wsl_ipex": 150, "conf_ipex": [150, 336], "himself": [151, 153], "imagenet_qat": [151, 153], "crossentropyloss": 151, "prev_loss": 151, "loss_increase_tim": 151, "patienc": [151, 158, 271], "curr_loss": 151, "val_loader_earlystop": 151, "main_buildin": [151, 152], "conf_buildin": [151, 152], "config_fil": [151, 153, 322, 362, 364], "7613": 151, "functionet": 151, "omp_num_thread": 152, "use_cpu": 154, "weiaicunzai": 154, "Be": [154, 160, 162, 248, 288, 291], "classifier1": 154, "classifier2": 154, "classifier3": 154, "classifier4": 154, "mv": [155, 156, 276], "dev_id": [155, 156], "tsv": [155, 156, 236, 275], "blend": [156, 198, 199], "model_config": 156, "bert_dataload": 156, "loader": [156, 318, 330, 332, 333, 336], "data_it": 156, "nc_yaml": 156, "leader": 157, "invis": 157, "healthi": 157, "opinion": [157, 162, 248, 276, 288, 291], "feedback": [157, 158, 160, 283], "apolog": 157, "mistak": [157, 158, 162, 254, 288, 291], "email": [157, 162, 243, 288, 291], "moder": 157, "promptli": 157, "fairli": [157, 251, 276], "privaci": 157, "violat": 157, "unprofession": 157, "around": [157, 165, 172, 186, 189, 233, 243, 248, 250, 265, 271, 279, 284], "apologi": 157, "unsolicit": 157, "period": [157, 206], "seriou": 157, "sustain": 157, "aggress": 157, "disparag": 157, "mozilla": 157, "ladder": 157, "everybodi": [158, 162, 288, 291], "immens": 158, "spread": [158, 289], "blog": [158, 159, 162, 168, 189, 205, 207, 231, 232, 247, 252, 253, 268, 274, 288, 291], "shout": 158, "star": 158, "whichev": 158, "outstand": 158, "reliabl": 158, "notifi": [158, 162, 288, 291], "realli": [158, 159, 162, 164, 253, 267, 288, 291], "appreci": [158, 227], "traceback": [158, 159, 254], "src": [158, 159, 162, 163, 167, 190, 222, 250, 254, 286, 288, 289, 291], "transformers_cli": 158, "willing": 158, "frustrat": 158, "hear": 158, "think": [158, 159, 253, 254, 275, 279], "screenshot": [158, 287], "advis": [158, 162, 191, 195, 203, 206, 214, 215, 219, 224, 234, 236, 249, 288, 291], "nobodi": [158, 159], "unsur": 158, "profici": 158, "enjoi": [158, 162, 288, 291, 376], "book": [158, 195, 203, 214, 244, 267, 338], "pro": [158, 242], "remot": [158, 162, 243, 254, 288, 291], "uninstal": [158, 254], "pytest": [158, 162, 288, 289, 291], "overload": 158, "dist": [158, 254, 382, 385, 390], "loadfil": [158, 254], "isort": [158, 162, 288, 291], "qualiti": [158, 159, 162, 187, 288, 289, 291], "ci": [158, 161, 171, 172], "verif": [158, 162, 288, 291], "fixup": [158, 289], "modified_fil": 158, "regularli": 158, "rebas": [158, 162, 288, 291], "push": [158, 162, 195, 196, 239, 254, 283, 285, 288, 291], "too": [158, 159, 162, 167, 172, 189, 190, 198, 243, 244, 254, 259, 279, 288, 291, 293], "webpag": [158, 162, 168, 253, 288, 291, 331], "ok": 158, "mention": [158, 161, 168, 244, 245, 251, 253, 254, 255, 257, 280, 288, 291, 323], "consult": [158, 163, 278], "wip": [158, 162, 288, 291], "duplic": [158, 162, 288, 291], "differenti": [158, 230], "readi": [158, 162, 168, 256, 288, 291, 308, 313], "coverag": [158, 254], "modeltest": [158, 288], "all_model_class": 158, "mymodelwithlmhead": 158, "slow": [158, 171, 190, 276, 278, 291], "run_slow": [158, 162, 254, 288, 291], "test_my_new_model": 158, "test_tokenization_": 158, "your_model_nam": 158, "circleci": [158, 161, 254], "docstr": [158, 162, 190, 193, 288, 291], "nice": [158, 162, 168, 253, 288, 291], "sphinx": [158, 161], "modeling_ctrl": 158, "xdist": [158, 254], "san": 158, "gigabyt": 158, "likewis": 158, "run_custom_token": 158, "runner": [158, 254], "unittest": [158, 254], "crlf": 158, "lf": [158, 243, 286], "autocrlf": 158, "msys2": 158, "msys64": 158, "menu": [158, 159], "pacman": 158, "syu": 158, "usr": [158, 189, 323], "powershel": 158, "ping": [158, 162, 288, 291], "unnessari": 158, "notif": [158, 159], "squash": 158, "encourag": [159, 229, 240, 244, 251, 267, 284], "misunderstand": 159, "importantli": [159, 162, 213, 221, 247, 288, 291], "formul": [159, 230, 242], "chanc": [159, 162, 288, 291], "understood": [159, 162], "venu": 159, "difficulti": [159, 236, 242], "discuss": [159, 162, 189, 193, 198, 199, 247, 254, 256, 288, 291], "crystal": 159, "proce": [159, 189, 247], "particular": [159, 162, 167, 168, 188, 203, 234, 248, 253, 254, 272, 288, 291], "bertmodel": [159, 163, 170, 171, 190, 192, 210, 233, 248, 252, 291], "rl": 159, "bertformaskedlm": [159, 170, 171, 190], "chatbotmodel": 159, "embed": [159, 162, 170, 183, 190, 191, 195, 200, 203, 206, 208, 209, 212, 214, 215, 221, 222, 223, 224, 227, 231, 233, 234, 235, 236, 237, 244, 248, 250, 252, 255, 272, 275, 288, 291, 298, 308], "matrix": [159, 162, 191, 205, 231, 244, 252, 255, 288, 291], "t5model": [159, 171], "de": [159, 160, 171, 200, 201, 208, 212, 222, 223, 252, 254, 279, 280, 363, 364], "everyth": [159, 161, 162, 171, 189, 254, 256, 272, 288, 289, 291, 376], "hint": 159, "repli": 159, "someon": [159, 162, 200, 288, 291], "quot": 159, "remaind": [159, 253], "commonli": [159, 279], "shortli": [159, 253], "stackexchang": 159, "went": 159, "dependency_versions_check": 159, "file_util": [159, 162, 173, 288, 291], "is_tokenizers_avail": 159, "modulenotfounderror": 159, "stack": [159, 244, 247, 254], "favorit": [159, 165, 189, 243, 258, 261, 279, 282], "noth": [159, 172, 279], "outsid": [159, 253], "filesystem": [159, 254], "tmp": [159, 254, 257, 259, 260, 261, 270, 279, 280, 282, 357, 365], "wrong_path": 159, "filenotfounderror": 159, "errno": 159, "unrel": 159, "hit": [159, 189, 270, 275], "satisfactori": 159, "shoe": 159, "anyth": [159, 161, 168, 179, 232, 254, 276], "mental": 159, "intuit": [159, 213, 231, 247, 255], "distributeddataparallel": 159, "disentangl": [159, 160, 171, 204, 205], "local_rank": [159, 189], "enclos": 159, "tripl": [159, 207], "backtick": [159, 161], "backslash": 159, "seq2seq": [159, 162, 165, 170, 189, 193, 194, 198, 227, 230, 244, 253, 254, 265, 275, 276, 279, 288, 291], "finetune_train": [159, 279], "sshleifer": [159, 276, 277], "wmt_en_ro": [159, 254, 276, 293], "overwrite_output_dir": [159, 189, 279, 280, 299, 311, 312, 314, 315], "n_train": 159, "per_device_train_batch_s": [159, 168, 189, 256, 257, 260, 261, 278, 279, 280, 297, 298, 302, 305, 307, 308, 313, 315], "freeze_emb": [159, 276], "src_lang": [159, 223], "en_xx": [159, 223, 279], "tgt_lang": [159, 223], "ro_ro": [159, 223, 279], "sharded_ddp": [159, 189], "scroll": 159, "immedi": [159, 160, 380, 384], "pertin": 159, "pastebin": 159, "benefici": [159, 218], "tend": 159, "expir": 159, "reader": [159, 244], "anymor": [159, 162, 190, 251, 288, 291], "luxuri": 159, "couldn": 159, "dispair": 159, "perhap": 159, "colab": [159, 162, 171, 256, 257, 278, 288, 291], "notebook": [159, 162, 163, 171, 218, 219, 236, 246, 254, 256, 257, 268, 272, 278, 288, 291, 309, 320], "upper": [159, 218], "lengthi": 159, "albeit": 159, "older": [159, 189], "revis": [159, 165, 236, 243, 311, 312, 314, 315, 389], "highest": [159, 200], "retest": [159, 254], "hf": 159, "suppli": [159, 170, 189, 190, 192, 249], "gave": 159, "direct": [159, 165, 182, 201, 212, 215, 223, 237, 242, 243, 247, 253, 254, 390], "triag": 159, "doubt": 159, "surpris": 159, "prevent": [159, 189, 203, 215, 229, 240, 244, 252, 254], "expertis": 159, "coher": [159, 191, 203, 214, 215, 237, 253, 267], "typo": 159, "aren": [159, 189, 212, 254], "seem": 159, "sift": 159, "dozen": [159, 160, 189, 235, 256], "discontinu": 159, "bullet": 159, "outcom": 159, "readabl": [159, 162, 251, 254, 288, 291], "bartmodel": [159, 171, 198, 212], "stand": [159, 162, 189, 195, 255, 267, 288, 291], "comprehens": [159, 160, 171, 187, 191, 193, 213, 216, 244], "ital": 159, "bold": 159, "referenc": 159, "latter": [159, 189, 254, 362, 363, 364, 365, 371], "9257": 159, "issuecom": 159, "749945162": 159, "poster": 159, "somewhat": [159, 236], "advic": [159, 162, 288, 291], "satisfact": 159, "elucid": 159, "hesit": [159, 161, 162, 270, 288, 291], "thousand": [160, 162, 219, 220, 227, 237, 288, 291], "Its": [160, 212, 240, 253], "cut": [160, 253, 276, 282, 382, 385], "standalon": [160, 289, 291], "seamless": [160, 198, 199, 283], "entiti": [160, 171, 186, 197, 201, 216, 228, 249, 251, 282, 284], "electra": [160, 162, 165, 171, 250, 255, 288, 291], "gpt": [160, 162, 164, 165, 171, 172, 190, 193, 196, 206, 209, 215, 233, 250, 253, 255, 274, 281, 284, 288, 291], "bart": [160, 162, 165, 170, 171, 190, 194, 222, 223, 250, 253, 254, 275, 276, 277, 288, 291, 293, 311], "versu": [160, 205, 251], "neg": [160, 168, 251, 253, 254, 274], "alloc": 160, "sentiment": [160, 165, 168, 172, 186, 216, 242, 251, 253, 256, 362], "9978193640708923": 160, "confid": [160, 162, 253, 278, 288, 291], "question_answer": 160, "5135612454720828": 160, "sentenc": [160, 165, 168, 170, 171, 187, 188, 191, 193, 195, 196, 203, 211, 213, 220, 221, 222, 225, 227, 231, 233, 235, 244, 245, 250, 251, 253, 255, 267, 270, 282, 284, 306, 362], "autotoken": [160, 171, 196, 197, 216, 228, 243, 249, 251, 253, 278], "automodel": [160, 171, 197, 216, 228, 243, 251, 253], "return_tensor": [160, 174, 185, 193, 196, 198, 216, 220, 222, 223, 227, 231, 235, 236, 247, 249, 251, 253, 256, 284], "tfautomodel": [160, 171, 197, 228, 251], "fourth": [160, 244], "fifth": 160, "nlu": [160, 170, 171, 187, 195, 200, 216, 224, 234, 236, 251, 253], "nlg": [160, 170, 171, 251, 253], "barrier": [160, 171, 367], "practition": [160, 171, 196, 248], "carbon": [160, 171, 253, 287], "lifetim": [160, 171], "seamlessli": [160, 171, 172, 256], "independ": [160, 162, 170, 188, 236, 244, 247, 255, 278, 288, 291], "toolbox": [160, 248], "refactor": [160, 162, 288, 291], "strive": [160, 172], "unfamiliar": [160, 172], "flax": [160, 171, 172, 273], "bleed": [160, 172], "wait": [160, 254, 279, 380, 384], "toyota": [160, 171], "technolog": [160, 171], "institut": [160, 171], "chicago": [160, 171], "zhenzhong": [160, 171, 191, 244], "lan": [160, 171, 191, 198, 199, 244, 274], "mingda": [160, 171, 191], "sebastian": [160, 171, 191, 230, 244], "goodman": [160, 171, 191], "kevin": [160, 164, 171, 191, 244], "gimpel": [160, 171, 191], "piyush": [160, 171, 191], "sharma": [160, 171, 191], "radu": [160, 171, 191], "soricut": [160, 171, 191], "facebook": [160, 171, 193, 198, 199, 201, 204, 205, 212, 223, 241, 250, 275, 276, 277, 279, 334, 335], "denois": [160, 171, 193, 223, 235, 242, 244], "mike": [160, 171, 193, 223, 230, 233, 244], "lewi": [160, 171, 193, 208, 223, 230, 233, 244, 253], "yinhan": [160, 171, 193, 198, 199, 223, 233, 244], "liu": [160, 171, 193, 197, 198, 199, 200, 204, 205, 206, 210, 223, 224, 225, 227, 229, 233, 235, 240, 244, 265, 274], "naman": [160, 171, 193, 198, 199, 223, 230, 233, 241, 244], "goyal": [160, 171, 193, 198, 199, 223, 230, 233, 241, 244, 253], "marjan": [160, 171, 193, 223, 244], "ghazvininejad": [160, 171, 193, 223, 244], "abdelrahman": [160, 171, 193, 238], "moham": [160, 171, 193, 238], "omer": [160, 164, 171, 193, 233], "levi": [160, 164, 171, 193, 233], "stoyanov": [160, 171, 193, 233, 241], "luke": [160, 171, 193, 223, 233, 241, 244], "zettlemoy": [160, 171, 193, 223, 233, 241, 244], "\u00e9cole": [160, 171], "polytechniqu": [160, 171], "skill": [160, 162, 171, 194, 198, 199, 288, 291], "french": [160, 171, 194, 201, 211, 222, 223, 244, 245, 250, 251], "moussa": [160, 171, 194], "kamal": [160, 171, 194], "eddin": [160, 171, 194], "antoin": [160, 171, 194], "tixier": [160, 171, 194], "michali": [160, 171, 194], "vazirgianni": [160, 171, 194], "bidirect": [160, 171, 193, 195, 213, 221, 224, 234, 242, 244, 259, 284], "jacob": [160, 171, 195, 244], "devlin": [160, 171, 195, 197, 200, 211, 233, 244], "ming": [160, 171, 195, 218, 229, 240, 244], "wei": [160, 171, 195, 218, 235, 264], "kenton": [160, 171, 195], "lee": [160, 171, 195, 235, 266], "kristina": [160, 171, 195], "toutanova": [160, 171, 195], "sascha": [160, 171, 196, 210], "roth": [160, 171, 196, 210], "shashi": [160, 171, 196, 210], "narayan": [160, 171, 196, 210], "aliaksei": [160, 171, 196, 210], "severyn": [160, 171, 196, 210], "blenderbot": [160, 171], "chatbot": [160, 165, 171, 198, 199], "stephen": [160, 171, 198, 199], "roller": [160, 171, 198, 199], "emili": [160, 171, 198, 199], "dinan": [160, 171, 198, 199], "da": [160, 164, 171, 198, 199, 222, 235], "ju": [160, 171, 198, 199], "mari": [160, 171, 198, 199, 253], "williamson": [160, 171, 198, 199], "jing": [160, 171, 198, 199], "xu": [160, 171, 198, 199, 218, 225, 264, 276], "myle": [160, 171, 198, 199, 212, 233, 241], "ott": [160, 171, 198, 199, 212, 233, 241], "kurt": [160, 171, 198, 199, 217, 234], "shuster": [160, 171, 198, 199], "eric": [160, 171, 198, 199, 274], "smith": [160, 171, 198, 199], "boureau": [160, 171, 198, 199], "jason": [160, 171, 198, 199, 274], "weston": [160, 171, 198, 199], "blenderbotsmal": [160, 165, 171, 198], "bort": [160, 171], "alexa": [160, 171], "subarchitectur": [160, 171, 200], "adrian": [160, 171, 200, 273], "wynter": [160, 171, 200], "daniel": [160, 171, 200], "perri": [160, 171, 200], "inria": [160, 171], "sorbonn": [160, 171], "tasti": [160, 171, 201], "loui": [160, 171, 201], "martin": [160, 171, 201, 236, 284], "benjamin": [160, 171, 201], "pedro": [160, 171, 201], "javier": [160, 171, 201], "ortiz": [160, 171, 201], "su\u00e1rez": [160, 171, 201], "yoann": [160, 171, 201], "dupont": [160, 171, 201], "laurent": [160, 171, 201], "romari": [160, 171, 201], "\u00e9ric": [160, 171, 201], "villemont": [160, 171, 201], "la": [160, 171, 201, 222], "clergeri": [160, 171, 201], "djam\u00e9": [160, 171, 201], "seddah": [160, 171, 201], "beno\u00eet": [160, 171, 201], "sagot": [160, 171, 201], "convbert": [160, 171], "yitutech": [160, 171], "span": [160, 165, 171, 188, 193, 202, 206, 235, 242, 244, 259, 282], "zihang": [160, 171, 202, 237, 242, 244], "jiang": [160, 171, 202, 244], "weihao": [160, 171, 202, 244], "yu": [160, 171, 202, 224, 229, 240, 244, 266], "daquan": [160, 171, 202, 244], "zhou": [160, 171, 202, 218, 224, 229, 235, 238, 240, 244, 264], "jiashi": [160, 171, 202, 244], "shuicheng": [160, 171, 202, 244], "yan": [160, 171, 202, 225, 229, 240, 244], "salesforc": [160, 171, 236, 250], "nitish": [160, 171, 203, 244], "shirish": [160, 171, 203, 244], "keskar": [160, 171, 203, 244], "bryan": [160, 171, 203], "mccann": [160, 171, 203], "lav": [160, 171, 203], "varshnei": [160, 171, 203], "caim": [160, 171, 203], "richard": [160, 171, 203], "socher": [160, 171, 203], "pengcheng": [160, 171, 204, 205], "xiaodong": [160, 171, 204, 205], "jianfeng": [160, 171, 204, 205, 206, 225], "gao": [160, 171, 204, 205, 206], "weizhu": [160, 171, 204, 205], "dialogpt": [160, 165, 171, 250, 293], "yizh": [160, 171, 206], "siqi": [160, 171, 206], "michel": [160, 164, 171, 206], "gallei": [160, 171, 206], "yen": [160, 171, 206], "chun": [160, 171, 206], "chri": [160, 171, 206], "brockett": [160, 171, 206], "jingj": [160, 171, 206], "bill": [160, 171, 206], "dolan": [160, 171, 206], "cheaper": [160, 171, 172, 207, 244, 267, 362], "lighter": [160, 171, 207, 244, 267, 362], "victor": [160, 171, 244, 267, 272, 276], "sanh": [160, 171, 244, 267, 272, 276], "lysandr": [160, 162, 171, 267, 276, 288, 291], "debut": [160, 171, 267, 276], "thoma": [160, 162, 171, 236, 267, 272, 276, 284, 288, 291], "wolf": [160, 171, 267, 272, 276], "distilgpt2": [160, 165, 171, 250, 267], "distilmbert": [160, 171, 267], "german": [160, 171, 212, 235, 239, 244, 245, 250, 251, 253, 267, 279, 364], "dpr": [160, 171, 230, 275], "passag": [160, 168, 171, 208, 230, 244], "retriev": [160, 162, 164, 171, 190, 192, 208, 230, 236, 253, 288, 291, 367], "vladimir": [160, 171, 208, 230, 244], "karpukhin": [160, 171, 208, 230, 244], "barla": [160, 171, 208], "o\u011fuz": [160, 171, 208], "sewon": [160, 171, 208], "patrick": [160, 165, 171, 208, 230, 244, 276, 291], "ledel": [160, 171, 208], "sergei": [160, 171, 208, 212, 223, 244], "edunov": [160, 171, 208, 212, 223, 244], "danqi": [160, 171, 208, 233], "wen": [160, 171, 208, 230, 244], "tau": [160, 171, 208, 230, 244], "yih": [160, 171, 208, 230, 244], "stanford": [160, 168, 171, 187, 236, 302, 362], "discrimin": [160, 171, 194, 209, 214, 244], "clark": [160, 164, 171, 244], "minh": [160, 171], "thang": [160, 171], "luong": [160, 171], "quoc": [160, 171, 197, 228, 237, 242], "le": [160, 171, 211, 223, 237, 242, 244, 276], "christoph": [160, 164, 171, 253], "man": [160, 164, 171, 253], "cnr": [160, 171, 211], "unsupervis": [160, 171, 196, 203, 211, 215, 235, 239, 241, 244], "lo\u00efc": [160, 171], "vial": [160, 171], "jibril": [160, 171], "frej": [160, 171], "vincent": [160, 171], "segonn": [160, 171], "maximin": [160, 171], "coavoux": [160, 171], "lecouteux": [160, 171], "alexandr": [160, 171], "allauzen": [160, 171], "crabb\u00e9": [160, 171], "besaci": [160, 171], "didier": [160, 171], "schwab": [160, 171], "funnel": [160, 171, 250, 293, 311], "cmu": [160, 171], "redund": [160, 171, 202, 213, 244], "guokun": [160, 171], "lai": [160, 163, 171], "yime": [160, 171, 224, 237, 242], "yang": [160, 171, 210, 211, 224, 237, 242, 244, 265, 322], "openai": [160, 171, 206, 250, 253, 267], "alec": [160, 171, 214, 215, 244], "radford": [160, 171, 211, 214, 215, 244], "karthik": [160, 171, 214], "narasimhan": [160, 171, 214], "tim": [160, 171, 214, 230, 244, 276], "saliman": [160, 171, 214], "ilya": [160, 171, 214, 215], "sutskev": [160, 171, 214, 215], "multitask": [160, 171, 215, 244], "learner": [160, 171, 215, 244], "jeffrei": [160, 171, 215], "rewon": [160, 171, 215], "david": [160, 171, 215, 273], "luan": [160, 171, 215], "dario": [160, 171, 215], "amodei": [160, 171, 215], "layoutlm": [160, 165, 171, 250, 313], "asia": [160, 171], "yiheng": [160, 171, 218], "minghao": [160, 171, 218], "lei": [160, 171, 218], "cui": [160, 171, 218], "shaohan": [160, 171, 218], "huang": [160, 171, 218, 261], "furu": [160, 171, 218, 264], "led": [160, 165, 171, 233], "allenai": [160, 165, 171, 250], "iz": [160, 165, 171, 219, 220, 244], "beltagi": [160, 165, 171, 219, 220, 244], "matthew": [160, 171, 219, 220, 280], "peter": [160, 165, 171, 211, 219, 220, 227, 235, 244, 273, 288], "arman": [160, 171, 219, 220], "cohan": [160, 171, 219, 220], "lxmert": [160, 171, 250], "unc": [160, 171], "chapel": [160, 171], "hill": [160, 171], "hao": [160, 171, 221], "tan": [160, 171, 221, 225], "mohit": [160, 171, 221], "bansal": [160, 171, 221], "marianmt": [160, 171, 250, 293, 316], "j\u00f6rg": [160, 171, 222], "tiedemann": [160, 171, 222], "marian": [160, 171, 222, 244, 255, 277, 286], "jiatao": [160, 171, 223, 244], "gu": [160, 171, 223, 244], "xian": [160, 171, 223, 244], "yuqe": [160, 171, 223], "tang": [160, 171, 223, 266], "chau": [160, 171, 223], "tran": [160, 171, 223], "peng": [160, 171, 223], "vishrav": [160, 171, 223, 241], "chaudhari": [160, 171, 223, 241], "angela": [160, 171, 223], "fan": [160, 171, 223, 253, 279], "mpnet": [160, 171], "kaitao": [160, 171, 225], "song": [160, 171, 224, 225, 273], "tao": [160, 171, 225, 264], "qin": [160, 171, 225], "lu": [160, 171, 225], "tie": [160, 171, 225], "mt5": [160, 171], "massiv": [160, 171, 226, 244, 255], "lint": [160, 171, 226, 244, 335], "xue": [160, 171, 226, 244], "noah": [160, 171, 226, 302], "mihir": [160, 171, 226], "kale": [160, 171, 226], "rami": [160, 171, 226], "rfou": [160, 171, 226], "aditya": [160, 171, 226], "siddhant": [160, 171, 226], "barua": [160, 171, 226], "colin": [160, 171, 226, 235, 244], "raffel": [160, 171, 226, 235, 244], "jingq": [160, 171, 227, 244], "yao": [160, 171, 217, 227, 244], "zhao": [160, 171, 227, 244], "mohammad": [160, 171, 227, 244], "saleh": [160, 171, 227, 244], "prophetnet": [160, 171], "gram": [160, 171, 229, 240, 244], "weizhen": [160, 171, 229, 240, 244], "qi": [160, 171, 229, 240, 244], "yeyun": [160, 171, 229, 240, 244], "dayiheng": [160, 171, 229, 240, 244], "nan": [160, 171, 229, 236, 240, 244], "duan": [160, 171, 229, 240, 244], "jiusheng": [160, 171, 229, 240, 244], "ruofei": [160, 171, 229, 240, 244], "reform": [160, 165, 170, 171, 250, 253, 285, 293], "nikita": [160, 171, 231, 244], "kitaev": [160, 171, 231, 244], "\u0142ukasz": [160, 171, 231], "kaiser": [160, 171, 231, 273], "anselm": [160, 171, 231], "levskaya": [160, 171, 231], "robustli": [160, 171, 233, 244], "jingfei": [160, 171, 233], "du": [160, 171, 233], "mandar": [160, 171, 233], "joshi": [160, 171, 233], "veselin": [160, 171, 233, 241], "teach": [160, 162, 171, 234], "forrest": [160, 171, 234], "iandola": [160, 171, 234], "shaw": [160, 171, 234, 261], "ravi": [160, 171, 234], "krishna": [160, 171, 234], "keutzer": [160, 171, 217, 234], "noam": [160, 171, 235], "shazeer": [160, 171, 235], "katherin": [160, 171, 235], "sharan": [160, 171, 235], "narang": [160, 171, 235], "michael": [160, 165, 171, 212, 217, 235, 238], "matena": [160, 171, 235], "yanqi": [160, 171, 235], "tapa": [160, 165, 171], "weakli": [160, 171, 236, 284], "jonathan": [160, 171, 236, 284], "herzig": [160, 171, 236, 284], "pawe\u0142": [160, 171, 236, 284], "krzysztof": [160, 171, 236, 273, 284], "nowak": [160, 171, 236, 284], "m\u00fcller": [160, 171, 236, 284], "francesco": [160, 171, 236, 284], "piccinno": [160, 171, 236, 284], "julian": [160, 171, 236, 264, 284], "eisenschlo": [160, 171, 236, 284], "beyond": [160, 171, 237, 244], "zhilin": [160, 171, 237, 242, 244], "jaim": [160, 171, 237, 242], "carbonel": [160, 171, 237, 242], "ruslan": [160, 171, 237, 242], "salakhutdinov": [160, 171, 237, 242], "wav2vec": [160, 171, 238], "alexei": [160, 171, 212, 238, 253], "baevski": [160, 171, 212, 238], "henri": [160, 171, 238], "auli": [160, 171, 212, 238], "lingual": [160, 171, 187, 239, 240, 241, 244, 280], "guillaum": [160, 171, 239, 241, 244], "lampl": [160, 171, 239, 244], "alexi": [160, 171, 239, 241, 244], "conneau": [160, 171, 197, 228, 239, 241, 244], "kartikai": [160, 171, 241], "khandelw": [160, 164, 171, 241], "wenzek": [160, 171, 241], "francisco": [160, 171, 241, 322], "guzm\u00e1n": [160, 171, 241], "edouard": [160, 171, 241], "grave": [160, 171, 241], "autoregress": [160, 170, 171, 210, 242, 247, 259, 284], "migrat": [160, 171, 243, 283], "inproceed": [160, 266, 267], "etal": [160, 266], "julien": [160, 243, 267, 276], "chaumond": [160, 267, 276], "clement": [160, 276], "delangu": [160, 276], "anthoni": [160, 276], "moi": [160, 276], "pierric": [160, 276], "cistac": [160, 276], "rault": [160, 276], "r\u00e9mi": [160, 276], "louf": [160, 276], "morgan": [160, 276], "funtowicz": [160, 276], "joe": [160, 276], "davison": [160, 276], "sam": [160, 276], "shleifer": [160, 276], "von": [160, 165, 258, 276], "platen": [160, 165, 258, 276], "clara": [160, 276], "ma": [160, 216, 276], "yacin": [160, 276], "jernit": [160, 276], "canwen": [160, 264, 276], "teven": [160, 276], "scao": [160, 276], "sylvain": [160, 276], "gugger": [160, 276], "mariama": [160, 276], "drame": [160, 276], "quentin": [160, 276], "lhoest": [160, 276], "rush": [160, 272, 276], "proceed": [160, 266], "confer": [160, 206, 317], "month": [160, 171, 190, 266], "linguist": [160, 266], "aclweb": [160, 266], "anthologi": [160, 266], "emnlp": 160, "theme": 161, "sphinx_rtd_them": 161, "recommonmark": 161, "restructur": 161, "_build": 161, "rebuild": [161, 380, 384], "restructuredtext": 161, "rst": [161, 162, 288, 289, 291], "expand": [161, 165, 252, 254, 371], "build_doc": 161, "sourceforg": 161, "unlik": [161, 189, 194, 195, 241], "beginn": 161, "model_doc": [161, 162, 288, 289, 291], "tip": [161, 162, 191, 195, 196, 200, 201, 202, 203, 206, 207, 209, 213, 214, 215, 218, 219, 220, 221, 224, 225, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 267, 278, 288, 290, 291], "xxxconfig": 161, "autoclass": [161, 192], "xxxtoken": 161, "build_inputs_with_special_token": 161, "get_special_tokens_mask": 161, "create_token_type_ids_from_sequ": 161, "save_vocabulari": 161, "surround": [161, 244, 259], "obj": [161, 254], "xxxclass": 161, "meth": 161, "underscor": 161, "loc": [161, 253], "indent": [161, 335], "showcas": [161, 162, 165, 214, 215, 253, 267, 272, 288, 291], "far": [161, 196, 230, 253, 254, 255, 272], "longtensor": 161, "sequence_length": [161, 163, 170, 245], "alberttoken": [161, 171, 190], "pretrainedtoken": [161, 171, 177, 249], "glossari": [161, 165, 171], "imagin": 161, "signatur": 161, "my_funct": 161, "semicolon": 161, "doctest": 161, "stai": 161, "compris": [161, 188, 195, 214, 218, 236], "floattensor": [161, 330], "bertconfig": [161, 163, 171, 248, 252], "masked_lm_label": [161, 190, 220], "prediction_scor": 161, "vocab_s": [161, 267, 291], "ideal": [162, 288, 291], "empow": [162, 288, 291], "sound": 162, "insight": [162, 235, 288, 291], "principl": [162, 255, 288, 291], "resembl": [162, 278, 288], "fundament": 162, "composit": [162, 231, 244, 255, 288, 291], "favor": [162, 190, 247, 288, 291], "modeling_": [162, 288, 289, 291], "possibli": [162, 288, 291, 319], "tweak": [162, 233, 244, 251, 265, 280, 288, 291], "pretrainedconfig": [162, 171, 288, 291], "exemplari": [162, 255, 288, 291], "brandnewbertmodel": [162, 288, 291], "brandnewbertpretrainedmodel": [162, 288, 291], "save_pretrain": [162, 190, 243, 248, 251, 256, 276, 288, 291], "deseri": [162, 288, 291], "modeling_brand_new_bert": [162, 288, 291], "brandnewbertformaskedlm": [162, 288, 291], "brandnewbertconfig": [162, 288, 291], "brandi": [162, 288, 291], "brand_new_bert": [162, 288, 291], "pytorch_model": [162, 167, 243, 256, 276, 288, 291, 300], "wmt19": [162, 212, 254, 288, 291], "sta": [162, 254, 288, 291], "reinvent": [162, 288, 291], "wheel": [162, 288, 291], "rg": [162, 288, 291], "friend": [162, 198, 288, 291], "fsmt": [162, 171, 190, 254, 288, 291], "scientif": [162, 211, 253, 288, 291], "spend": [162, 288, 291], "stuck": [162, 288, 291], "skeleton": [162, 288, 291], "job": [162, 192, 251, 254, 288, 291], "troubl": [162, 288, 291], "sentencepiec": [162, 188, 205, 288, 291], "gotten": [162, 288, 291], "venv": [162, 269, 288, 291], "org_that_created_brand_new_bert_org": 162, "researchi": [162, 288, 291], "reimplement": [162, 288, 291], "shoulder": [162, 288, 291], "giant": [162, 288, 291], "rewrit": [162, 254, 288, 291], "beauti": [162, 288, 291], "encodermodel": [162, 288, 291], "decodermodel": [162, 288, 291], "statement": [162, 172, 253, 284, 288, 291, 323], "debugg": [162, 254, 288, 291], "ipdb": [162, 288, 291], "pycharm": [162, 288, 291], "costli": [162, 231, 288, 291], "cell": [162, 189, 236, 243, 284, 288, 291, 381], "jupit": [162, 278, 288, 291], "obviou": [162, 288, 291], "disadvantag": [162, 255, 288, 291], "jupyth": [162, 288, 291], "Such": [162, 216, 253, 254, 255, 275, 288, 291, 326], "pseudocod": [162, 288], "load_pretrained_checkpoint": [162, 288, 291], "original_output": [162, 288, 291], "decompos": [162, 247, 255, 288, 291], "testabl": [162, 288, 291], "breakpoint": [162, 276, 288, 291], "worth": [162, 255, 288, 291], "road": [162, 288, 291], "rope": [162, 288, 291], "occur": [162, 203, 215, 218, 253, 255, 284, 288, 291], "meshtensorflow": [162, 288, 291], "1465": [162, 288, 291], "6501": [162, 288, 291], "1993": [162, 288, 291], "1451": [162, 288, 291], "3430": [162, 288, 291], "6024": [162, 288, 291], "4417": [162, 288, 291], "5920": [162, 288, 291], "3450": [162, 288, 291], "3062": [162, 288, 291], "6182": [162, 288, 291], "7132": [162, 288, 291], "5009": [162, 288, 291], "7122": [162, 288, 291], "4548": [162, 288, 291], "3662": [162, 288, 291], "6091": [162, 288, 291], "7648": [162, 288, 291], "5613": [162, 288, 291], "6332": [162, 288, 291], "4324": [162, 288, 291], "3792": [162, 288, 291], "7372": [162, 288, 291], "9288": [162, 288, 291], "5416": [162, 288, 291], "6345": [162, 288, 291], "4180": [162, 288, 291], "3564": [162, 288, 291], "6992": [162, 288, 291], "9191": [162, 288, 291], "5334": [162, 288, 291], "6403": [162, 288, 291], "4271": [162, 288, 291], "3339": [162, 288, 291], "6533": [162, 288, 291], "8694": [162, 288, 291], "coupl": [162, 163, 190, 254, 288, 291], "nearli": [162, 209, 227, 288, 291], "certainli": [162, 288, 291], "jax": [162, 273, 288, 291], "smallest": [162, 267, 288, 291], "sens": [162, 211, 244, 276, 288, 291], "autoregressive_sampl": [162, 288, 291], "set_se": [162, 254, 288, 291], "amaz": [162, 288, 291], "cookiecutt": [162, 287, 288, 291], "carefulli": [162, 224, 233, 288, 291], "add_brand_new_bert": 162, "draft": [162, 288, 291, 382, 385], "forget": [162, 190, 243, 251, 287, 288, 289, 291], "configuration_brand_new_bert": 162, "unclean": [162, 288, 291], "simplemodel": [162, 288, 291], "layer_norm": [162, 288, 291], "out_featur": [162, 288, 291], "ep": [162, 189, 288, 291], "elementwise_affin": [162, 288, 291], "0818": [162, 251, 288, 291], "2207": [162, 288, 291], "0749": [162, 288, 291], "0045": [162, 288, 291], "1569": [162, 288, 291], "1598": [162, 288, 291], "0212": [162, 288, 291], "2077": [162, 288, 291], "2157": [162, 288, 291], "1044": [162, 288, 291], "0201": [162, 288, 291], "0990": [162, 288, 291], "2482": [162, 288, 291], "3116": [162, 288, 291], "2509": [162, 288, 291], "2866": [162, 288, 291], "2190": [162, 288, 291], "2166": [162, 288, 291], "1107": [162, 288, 291], "1999": [162, 253, 288, 291], "3119": [162, 288, 291], "1559": [162, 288, 291], "0993": [162, 288, 291], "1776": [162, 288, 291], "1950": [162, 288, 291], "1023": [162, 288, 291], "0447": [162, 288, 291], "0888": [162, 288, 291], "1092": [162, 288, 291], "2281": [162, 288, 291], "0336": [162, 288, 291], "1817": [162, 288, 291], "2096": [162, 288, 291], "1415": [162, 288, 291], "1876": [162, 288, 291], "2467": [162, 288, 291], "2208": [162, 288, 291], "2352": [162, 288, 291], "1426": [162, 288, 291], "2636": [162, 288, 291], "2889": [162, 288, 291], "2061": [162, 288, 291], "2849": [162, 288, 291], "0465": [162, 288, 291], "2577": [162, 288, 291], "0402": [162, 288, 291], "1502": [162, 288, 291], "2465": [162, 288, 291], "0693": [162, 288, 291], "0530": [162, 288, 291], "1859": [162, 288, 291], "0604": [162, 288, 291], "1680": [162, 288, 291], "1733": [162, 288, 291, 326], "2407": [162, 288, 291], "1721": [162, 288, 291], "1484": [162, 288, 291], "0358": [162, 288, 291], "0633": [162, 288, 291], "0721": [162, 288, 291], "0090": [162, 288, 291], "2707": [162, 288, 291], "1173": [162, 288, 291], "1561": [162, 288, 291], "2945": [162, 288, 291], "0595": [162, 288, 291], "1996": [162, 251, 288, 291], "2988": [162, 288, 291], "0802": [162, 288, 291], "0407": [162, 288, 291], "1829": [162, 288, 291], "1568": [162, 288, 291], "1164": [162, 288, 291], "2228": [162, 288, 291], "0403": [162, 288, 291], "0428": [162, 288, 291], "1339": [162, 288, 291], "0047": [162, 288, 291], "1967": [162, 288, 291], "2923": [162, 288, 291], "0333": [162, 288, 291], "0536": [162, 288, 291], "1492": [162, 288, 291], "1616": [162, 288, 291], "1057": [162, 288, 291], "2807": [162, 288, 291], "2710": [162, 288, 291], "1586": [162, 288, 291], "0739": [162, 288, 291], "2220": [162, 288, 291], "2358": [162, 288, 291], "layer_nam": [162, 288, 291], "pretrained_weight": [162, 288, 291, 331], "array_of_dense_lay": [162, 288, 291], "model_point": [162, 288, 291], "getattr": [162, 288, 291], "from_numpi": [162, 288, 291], "pointer": [162, 288, 291], "incorrect": [162, 288, 291], "analog": [162, 288, 291], "last_hidden_st": [162, 267, 288, 291], "throw": [162, 249, 288, 291, 358], "disappoint": [162, 288, 291], "forgotten": [162, 288, 291], "ti": [162, 231, 237, 280, 288, 291], "offset": [162, 168, 253, 288, 291], "allclos": [162, 288, 291], "atol": [162, 288, 291], "congratul": [162, 288, 291], "cakewalk": [162, 288, 291], "test_modeling_brand_new_bert": 162, "essenti": [162, 231, 254, 288, 291], "earlier": [162, 189, 254, 255, 288, 291], "brandnewbertmodelintegrationtest": 162, "sv": [162, 222, 254, 288, 291], "brandnewbertmodeltest": 162, "extrem": [162, 234, 288, 291], "acquir": [162, 288, 291, 373], "input_str": [162, 288, 291], "charact": [162, 168, 188, 219, 220, 222, 244, 247, 250, 254, 255, 270, 282, 288, 291, 335], "2872": [162, 288, 291], "brandnewberttoken": 162, "forgot": [162, 288, 291], "concis": [162, 288, 291], "oneself": [162, 288, 291], "lastli": [162, 168, 221, 251, 278, 288, 291], "awesom": [162, 243, 288, 291], "stream": [162, 225, 229, 240, 244, 255, 288, 291, 303], "eventu": [162, 168, 288, 291], "credit": [162, 288, 291], "hundr": [162, 224, 227, 234, 241, 288, 291], "proud": [162, 288, 291], "prefix_link": [163, 164, 167, 187, 193, 194, 227, 245, 253, 254], "pytorchbenchmark": 163, "tensorflowbenchmark": 163, "flexibli": 163, "pytorchbenchmarkargu": 163, "tensorflowbenchmarkargu": 163, "benchmark_args_util": 163, "benchmark_arg": 163, "benchmark_args_tf": 163, "run_benchmark_tf": 163, "seq": [163, 359, 362], "006": 163, "018": 163, "1227": 163, "1281": 163, "1307": 163, "1539": 163, "transformers_vers": 163, "use_torchscript": 163, "framework_vers": 163, "python_vers": 163, "x86_64": 163, "64bit": 163, "371351": 163, "use_multiprocess": 163, "only_pretrain_model": 163, "cpu_ram_mb": 163, "32088": 163, "use_gpu": 163, "num_gpu": [163, 189], "gpu_ram_mb": 163, "24217": 163, "gpu_power_watt": 163, "280": 163, "gpu_performance_st": 163, "use_tpu": 163, "005": 163, "008": [163, 321], "105": 163, "1330": [163, 249], "1770": 163, "use_xla": [163, 280], "617317": 163, "save_to_csv": 163, "hid": 163, "config_bas": 163, "config_384_hid": 163, "hidden_s": [163, 170, 231, 252, 291], "config_6_lai": 163, "num_hidden_lay": [163, 252, 291], "011": 163, "003": 163, "009": 163, "044": 163, "1277": 163, "1005": [163, 251], "1027": 163, "1035": 163, "1255": 163, "1101": 163, "1127": 163, "1359": 163, "143267": 163, "106": [163, 280], "007": 163, "0011": 163, "1540": 163, "487125": 163, "no_multi_process": 163, "heavili": [163, 202, 244], "xla": [163, 257, 280], "blogpost": [163, 267], "ever": [163, 254, 279], "grow": [164, 171, 190, 254, 278], "concern": [164, 245, 253], "rediscov": 164, "ian": 164, "tennei": 164, "dipanjan": 164, "elli": 164, "pavlick": 164, "05950": 164, "graham": 164, "neubig": 164, "10650": 164, "urvashi": 164, "1906": 164, "04341": 164, "research_project": [164, 259, 275], "run_bertologi": 164, "regroup": 165, "flashcard": 165, "learnt": 165, "anki": 165, "retent": 165, "introductori": [165, 272], "video": 165, "darigov": 165, "amp": [165, 189, 190, 276, 280, 321, 373, 378], "muhammad": 165, "harri": 165, "suraj": [165, 279], "patil": [165, 279], "lightn": [165, 222, 254, 378], "nathan": [165, 212], "fastai": 165, "blurr": 165, "wayd": 165, "gilliam": 165, "anyon": [165, 243, 306], "tweet": [165, 197, 287], "bori": 165, "dayma": 165, "bias": [165, 207, 273], "qa": [165, 168, 208, 230, 275], "triviaqa": [165, 219, 220], "lorenzo": 165, "ampil": 165, "abhishek": 165, "kumar": 165, "mishra": 165, "track": [165, 252, 331, 335], "wandb": [165, 179, 257, 273, 276], "bucket": [165, 172, 205, 231, 254], "benesti": 165, "bi": [165, 201, 242, 253], "sci": 165, "scibert": 165, "cord": 165, "tanmai": 165, "thakur": 165, "captum": 165, "eliza": 165, "szczechla": 165, "philipp": 165, "schmid": 165, "dhaval": 165, "taunk": 165, "nadir": 165, "el": 165, "manouzi": 165, "pascal": [165, 257, 280, 322, 370], "zoleko": 165, "bayerl": 165, "dailymail": [165, 229, 240, 279], "warm": [165, 196, 256], "encoderdecodermodel": [165, 171, 196], "bbc": 165, "xsum": [165, 227, 277, 279], "sqa": [165, 236], "tapasforquestionansw": [165, 171], "niel": 165, "rogg": 165, "tabfact": [165, 236], "tapasforsequenceclassif": [165, 171], "seq2seqtrain": [165, 171], "hindi": [165, 223], "vasudev": [165, 291], "gupta": 165, "funsd": [165, 218], "layoutlmfortokenclassif": [165, 171], "aakash": 165, "tripathi": 165, "8k": 165, "pubm": 165, "rvl": [165, 218], "cdip": [165, 218], "layoutlmforsequenceclassif": [165, 171], "convert_bert_original_tf_checkpoint_to_pytorch": 167, "bert_config": [167, 291, 359], "tour": [167, 171, 249, 276], "bert_base_dir": 167, "tf_checkpoint": 167, "pytorch_dump_output": 167, "convert_albert_original_tf_checkpoint_to_pytorch": 167, "albert_config": 167, "albert_base_dir": 167, "albert_bas": 167, "openai_gpt_checkpoint_folder_path": 167, "openai_gpt_config": 167, "finetuning_task_nam": 167, "openai_gpt_finetuned_task": 167, "openai_gpt2_checkpoint_path": 167, "openai_gpt2_config": 167, "openai_gpt2_finetuned_task": 167, "transfo_xl_checkpoint_folder_path": 167, "transfo_xl": 167, "transfo_xl_config": 167, "transfo_xl_finetuned_task": 167, "transfo_xl_checkpoint_path": 167, "transfo_xl_config_path": 167, "xlnet_finetuned_task": 167, "xlm_checkpoint_path": 167, "xml_config": 167, "xml_finetuned_task": 167, "t5_model": 167, "t5_config": 167, "brief": 168, "tftrainer": [168, 171, 190, 243, 248, 251, 256, 257], "load_dataset": [168, 247, 362], "movi": [168, 236, 244, 271, 284], "amaa": 168, "aclimdb_v1": 168, "xf": 168, "po": [168, 189, 249, 282, 285], "pathlib": [168, 254], "read_imdb_split": 168, "split_dir": 168, "label_dir": 168, "text_fil": 168, "iterdir": 168, "read_text": 168, "train_text": 168, "aclimdb": 168, "test_text": 168, "taint": 168, "sklearn": [168, 256, 333], "model_select": 168, "train_test_split": 168, "val_text": 168, "val_label": 168, "test_siz": 168, "alright": [168, 288, 291], "tackl": [168, 275], "distilberttokenizerfast": [168, 171], "train_encod": 168, "val_encod": 168, "test_encod": 168, "from_tensor_slic": 168, "constructor": 168, "imdbdataset": 168, "test_dataset": [168, 256], "trainingargu": [168, 171, 179, 256, 257, 278], "tftrainingargu": [168, 171, 256], "distilbertforsequenceclassif": [168, 171, 243, 251], "training_arg": [168, 189, 256, 293, 299, 301, 311, 312, 313, 314, 316], "per_device_eval_batch_s": [168, 256, 261, 279, 280, 298, 299, 311, 312, 314, 315], "warmup_step": [168, 189, 256, 272, 276, 278, 362, 364], "strength": [168, 256], "decai": [168, 184, 190, 256, 317], "logging_dir": [168, 256, 261], "logging_step": [168, 261, 264, 280], "eval_dataset": [168, 256, 293, 299, 311, 312, 313, 314], "tfdistilbertforsequenceclassif": [168, 171, 243, 251], "scope": [168, 189, 358], "adamw": [168, 171, 189, 236, 256], "is_avail": [168, 227, 254], "5e": [168, 236, 260, 280, 284, 295, 296, 298, 307, 308, 313], "compute_loss": [168, 189], "wnut": [168, 282], "wnut_17": 168, "corpu": [168, 187, 194, 195, 203, 211, 214, 215, 229, 235, 240, 244, 247, 249, 250, 253, 255, 267, 278, 284, 362], "noisi": [168, 212], "wnut17train": 168, "conll": [168, 253, 257, 267, 282], "token_doc": 168, "token_tag": 168, "read_wnut": 168, "file_path": [168, 267], "raw_text": 168, "raw_doc": 168, "tag_doc": 168, "week": [168, 243, 253], "train_tag": 168, "val_tag": 168, "moment": [168, 227, 254, 261, 276], "unique_tag": 168, "tag2id": 168, "id2tag": 168, "is_split_into_word": [168, 190, 249], "return_offsets_map": 168, "arriv": 168, "obstacl": 168, "subtoken": [168, 282], "offset_map": 168, "cl": [168, 170, 189, 196, 249, 250, 252, 253, 254, 264, 272, 276, 278, 284, 331], "encode_tag": 168, "encoded_label": 168, "doc_label": 168, "doc_offset": 168, "doc_enc_label": 168, "arr_offset": 168, "tolist": [168, 251, 253, 330], "wnutdataset": 168, "distilbertfortokenclassif": [168, 171], "num_label": [168, 251, 256], "tfdistilbertfortokenclassif": [168, 171], "squad_v2": [168, 261], "rajpurkar": [168, 296, 360, 361], "apart": [168, 179], "read_squad": 168, "rb": 168, "squad_dict": 168, "train_context": 168, "train_quest": 168, "train_answ": 168, "val_context": 168, "val_quest": 168, "val_answ": 168, "subsequ": [168, 196, 247, 263, 373], "add_end_idx": 168, "gold_text": 168, "start_idx": 168, "answer_start": [168, 253], "end_idx": 168, "answer_end": [168, 253], "gold": [168, 187, 236, 275], "char_to_token": 168, "add_token_posit": 168, "start_posit": 168, "end_posit": 168, "model_max_length": [168, 190, 227], "inputs_dict": 168, "labels_dict": 168, "squaddataset": 168, "distilbertforquestionansw": [168, 171], "tfdistilbertforquestionansw": [168, 171], "minor": [168, 222], "lambda": 168, "return_dict": 168, "esperanto": [168, 256], "150": [168, 253, 319], "column_nam": 168, "rename_column_": 168, "set_format": 168, "tensorshap": 168, "thorough": [168, 209], "autoencod": [170, 171, 210, 242], "mlm": [170, 195, 209, 211, 216, 224, 225, 234, 236, 239, 244, 245, 250, 259, 267, 270, 284], "clm": [170, 203, 206, 214, 215, 224, 234, 236, 239, 244, 245, 250, 259, 293], "causal": [170, 203, 206, 214, 215, 224, 234, 236, 237, 239, 244, 245, 247, 250, 285], "hide": [170, 244], "timestep": [170, 244], "corrupt": [170, 209, 242, 244, 284], "multimod": [170, 171, 271], "talk": [170, 198, 199, 288, 291], "wikipedia": [170, 195, 203, 230, 236, 240, 244, 245, 250, 261, 267, 273, 275, 284], "recurr": [170, 237, 244, 284], "attend": [170, 220, 221, 231, 237, 253], "subword": [170, 249], "punctuat": [170, 249, 251, 255], "bear": [170, 267], "underli": [170, 188, 190, 209, 252], "berttoken": [170, 171, 185, 190, 196, 248, 252, 255, 256, 282], "24gb": 170, "tokenized_sequ": 170, "wasn": 170, "hash": [170, 231, 243, 244, 276], "rust": [170, 188], "encoded_sequ": 170, "18696": [170, 249], "1942": [170, 249], "3190": [170, 249], "1144": [170, 249], "1572": [170, 249], "13745": [170, 249], "1104": [170, 249], "159": [170, 249], "9664": [170, 249], "2107": [170, 249], "decoded_sequ": 170, "sequence_a": 170, "sequence_b": 170, "encoded_sequence_a": 170, "encoded_sequence_b": 170, "padded_sequ": 170, "1188": 170, "1110": 170, "1603": 170, "4954": 170, "119": 170, "1897": 170, "1263": 170, "1135": 170, "1120": 170, "1655": 170, "2039": 170, "1190": 170, "1103": [170, 249], "nyc": 170, "encoded_dict": 170, "wherea": [170, 244], "xlnetmodel": [170, 171], "contrari": 170, "unawar": 170, "position_id": [170, 207], "max_position_embed": 170, "sinusoid": [170, 222, 227, 237], "bertforsequenceclassif": [170, 171, 185, 190, 256, 272], "bertfortokenclassif": [170, 171], "seq_length": 170, "bartforconditionalgener": [170, 171, 190, 198, 219, 222, 227, 276, 279], "mbartforconditionalgener": [170, 171, 276, 279], "tgt_seq_length": 170, "decoder_input_id": [170, 193, 196, 235], "bigger": [170, 189, 244, 331], "intermediate_s": [170, 252, 291], "mathemat": 170, "_0": 170, "_n": 170, "concat": [170, 253], "afterward": [170, 252, 289, 291], "trade": [170, 189, 241], "emploi": [170, 220, 247], "apply_chunking_to_forward": 170, "chunk_siz": 170, "interoper": [171, 253, 256], "fairseq": [171, 193, 212, 276], "rag": [171, 275], "retribert": 171, "xlmprophetnet": 171, "hood": 171, "technic": [171, 252], "byte": [171, 214, 233, 244, 252], "bpe": [171, 188, 212, 222, 233, 244, 249], "imdb": [171, 256], "nut": 171, "emerg": [171, 235, 253, 282], "bertologi": 171, "perplex": [171, 237, 259, 267, 293], "ppl": 171, "callback": [171, 189, 190], "trainercallback": 171, "trainerst": 171, "trainercontrol": 171, "moduleutilsmixin": 171, "tfpretrainedmodel": 171, "tfmodelutilsmixin": 171, "flaxpretrainedmodel": 171, "adafactor": [171, 227], "adamweightdecai": 171, "modeloutput": [171, 174], "basemodeloutput": 171, "basemodeloutputwithpool": 171, "basemodeloutputwithcrossattent": 171, "basemodeloutputwithpoolingandcrossattent": 171, "basemodeloutputwithpast": 171, "basemodeloutputwithpastandcrossattent": 171, "seq2seqmodeloutput": 171, "causallmoutput": 171, "causallmoutputwithcrossattent": 171, "causallmoutputwithpast": 171, "maskedlmoutput": 171, "seq2seqlmoutput": 171, "nextsentencepredictoroutput": 171, "sequenceclassifieroutput": 171, "seq2seqsequenceclassifieroutput": 171, "multiplechoicemodeloutput": 171, "tokenclassifieroutput": 171, "questionansweringmodeloutput": 171, "seq2seqquestionansweringmodeloutput": 171, "tfbasemodeloutput": 171, "tfbasemodeloutputwithpool": 171, "tfbasemodeloutputwithpast": 171, "tfseq2seqmodeloutput": 171, "tfcausallmoutput": 171, "tfcausallmoutputwithpast": 171, "tfmaskedlmoutput": 171, "tfseq2seqlmoutput": 171, "tfnextsentencepredictoroutput": 171, "tfsequenceclassifieroutput": 171, "tfseq2seqsequenceclassifieroutput": 171, "tfmultiplechoicemodeloutput": 171, "tftokenclassifieroutput": 171, "tfquestionansweringmodeloutput": 171, "tfseq2seqquestionansweringmodeloutput": 171, "xnli": [171, 239, 241, 245, 250, 257, 267], "pretrainedtokenizerfast": [171, 177], "batchencod": [171, 256], "seq2seqtrainingargu": 171, "extractor": 171, "pretrainedfeatureextractor": 171, "batchfeatur": 171, "albertconfig": 171, "alberttokenizerfast": 171, "albertmodel": 171, "albertforpretrain": [171, 190], "albertformaskedlm": [171, 190], "albertforsequenceclassif": 171, "albertformultiplechoic": 171, "albertfortokenclassif": 171, "albertforquestionansw": 171, "tfalbertmodel": 171, "tfalbertforpretrain": 171, "tfalbertformaskedlm": 171, "tfalbertforsequenceclassif": 171, "tfalbertformultiplechoic": 171, "tfalbertfortokenclassif": 171, "tfalbertforquestionansw": 171, "autoconfig": 171, "automodelforpretrain": 171, "automodelforcausallm": 171, "automodelformaskedlm": 171, "automodelforseq2seqlm": [171, 276], "automodelforsequenceclassif": [171, 251, 253, 278], "automodelformultiplechoic": 171, "automodelfornextsentencepredict": 171, "automodelfortokenclassif": [171, 253], "automodelforquestionansw": [171, 253], "automodelfortablequestionansw": 171, "tfautomodelforpretrain": 171, "tfautomodelforcausallm": 171, "tfautomodelformaskedlm": 171, "tfautomodelforseq2seqlm": 171, "tfautomodelforsequenceclassif": [171, 251, 253], "tfautomodelformultiplechoic": 171, "tfautomodelfortokenclassif": [171, 253], "tfautomodelforquestionansw": [171, 253], "flaxautomodel": 171, "bartconfig": 171, "barttoken": [171, 219], "barttokenizerfast": 171, "bartforsequenceclassif": 171, "bartforquestionansw": 171, "bartforcausallm": 171, "tfbartmodel": 171, "tfbartforconditionalgener": 171, "bartheztoken": 171, "bartheztokenizerfast": 171, "berttokenizerfast": 171, "bertforpretrain": [171, 190], "bertmodellmheadmodel": 171, "bertfornextsentencepredict": 171, "bertformultiplechoic": 171, "bertforquestionansw": [171, 272], "tfbertmodel": 171, "tfbertforpretrain": 171, "tfbertmodellmheadmodel": 171, "tfbertformaskedlm": 171, "tfbertfornextsentencepredict": 171, "tfbertforsequenceclassif": [171, 256], "tfbertformultiplechoic": 171, "tfbertfortokenclassif": 171, "tfbertforquestionansw": 171, "flaxbertmodel": 171, "flaxbertformaskedlm": 171, "bertweet": 171, "bertweettoken": 171, "bertgener": 171, "bertgenerationconfig": 171, "bertgenerationtoken": [171, 291], "bertgenerationencod": 171, "bertgenerationdecod": 171, "blenderbotconfig": 171, "blenderbottoken": 171, "blenderbotmodel": [171, 199], "blenderbotforconditionalgener": [171, 199], "blenderbotforcausallm": 171, "tfblenderbotmodel": 171, "tfblenderbotforconditionalgener": 171, "blenderbotsmallconfig": 171, "blenderbotsmalltoken": 171, "blenderbotsmallmodel": 171, "blenderbotsmallforconditionalgener": 171, "blenderbotsmallforcausallm": 171, "tfblenderbotsmallmodel": 171, "tfblenderbotsmallforconditionalgener": 171, "camembertconfig": 171, "camemberttoken": [171, 190], "camemberttokenizerfast": 171, "camembertmodel": 171, "camembertforcausallm": 171, "camembertformaskedlm": 171, "camembertforsequenceclassif": 171, "camembertformultiplechoic": 171, "camembertfortokenclassif": 171, "camembertforquestionansw": 171, "tfcamembertmodel": 171, "tfcamembertformaskedlm": 171, "tfcamembertforsequenceclassif": 171, "tfcamembertformultiplechoic": 171, "tfcamembertfortokenclassif": 171, "tfcamembertforquestionansw": 171, "convbertconfig": 171, "convberttoken": 171, "convberttokenizerfast": 171, "convbertmodel": 171, "convbertformaskedlm": 171, "convbertforsequenceclassif": 171, "convbertformultiplechoic": 171, "convbertfortokenclassif": 171, "convbertforquestionansw": 171, "tfconvbertmodel": 171, "tfconvbertformaskedlm": 171, "tfconvbertforsequenceclassif": 171, "tfconvbertformultiplechoic": 171, "tfconvbertfortokenclassif": 171, "tfconvbertforquestionansw": 171, "ctrlconfig": 171, "ctrltoken": 171, "ctrlmodel": 171, "ctrllmheadmodel": 171, "ctrlforsequenceclassif": 171, "tfctrlmodel": 171, "tfctrllmheadmodel": 171, "tfctrlforsequenceclassif": 171, "debertaconfig": 171, "debertatoken": 171, "debertamodel": 171, "debertapretrainedmodel": 171, "debertaformaskedlm": 171, "debertaforsequenceclassif": 171, "debertafortokenclassif": 171, "debertaforquestionansw": 171, "debertav2config": 171, "debertav2token": 171, "debertav2model": 171, "debertav2pretrainedmodel": 171, "debertav2formaskedlm": 171, "debertav2forsequenceclassif": 171, "debertav2fortokenclassif": 171, "debertav2forquestionansw": 171, "distilbertconfig": [171, 251], "distilberttoken": [171, 251, 267], "distilbertmodel": [171, 267], "distilbertformaskedlm": [171, 190], "distilbertformultiplechoic": 171, "tfdistilbertmodel": 171, "tfdistilbertformaskedlm": 171, "tfdistilbertformultiplechoic": 171, "dprconfig": 171, "dprcontextencodertoken": 171, "dprcontextencodertokenizerfast": 171, "dprquestionencodertoken": 171, "dprquestionencodertokenizerfast": 171, "dprreadertoken": 171, "dprreadertokenizerfast": 171, "dprcontextencod": 171, "dprquestionencod": 171, "dprreader": 171, "tfdprcontextencod": 171, "tfdprquestionencod": 171, "tfdprreader": 171, "electraconfig": 171, "electratoken": 171, "electratokenizerfast": 171, "electramodel": 171, "electraforpretrain": 171, "electraformaskedlm": [171, 190], "electraforsequenceclassif": 171, "electraformultiplechoic": 171, "electrafortokenclassif": 171, "electraforquestionansw": 171, "tfelectramodel": 171, "tfelectraforpretrain": 171, "tfelectraformaskedlm": 171, "tfelectraforsequenceclassif": 171, "tfelectraformultiplechoic": 171, "tfelectrafortokenclassif": 171, "tfelectraforquestionansw": 171, "encoderdecoderconfig": 171, "flaubertconfig": 171, "flauberttoken": 171, "flaubertmodel": 171, "flaubertwithlmheadmodel": 171, "flaubertforsequenceclassif": 171, "flaubertformultiplechoic": 171, "flaubertfortokenclassif": 171, "flaubertforquestionansweringsimpl": 171, "flaubertforquestionansw": 171, "tfflaubertmodel": 171, "tfflaubertwithlmheadmodel": 171, "tfflaubertforsequenceclassif": 171, "tfflaubertformultiplechoic": 171, "tfflaubertfortokenclassif": 171, "tfflaubertforquestionansweringsimpl": 171, "fsmtconfig": 171, "fsmttoken": 171, "fsmtmodel": 171, "fsmtforconditionalgener": [171, 276, 279], "funnelconfig": 171, "funneltoken": 171, "funneltokenizerfast": 171, "funnelbasemodel": 171, "funnelmodel": 171, "funnelmodelforpretrain": 171, "funnelformaskedlm": 171, "funnelforsequenceclassif": 171, "funnelformultiplechoic": 171, "funnelfortokenclassif": 171, "funnelforquestionansw": 171, "tffunnelbasemodel": 171, "tffunnelmodel": 171, "tffunnelmodelforpretrain": 171, "tffunnelformaskedlm": 171, "tffunnelforsequenceclassif": 171, "tffunnelformultiplechoic": 171, "tffunnelfortokenclassif": 171, "tffunnelforquestionansw": 171, "herbert": 171, "herberttoken": 171, "herberttokenizerfast": 171, "ibertconfig": 171, "ibertmodel": 171, "ibertformaskedlm": 171, "ibertforsequenceclassif": 171, "ibertformultiplechoic": 171, "ibertfortokenclassif": 171, "ibertforquestionansw": 171, "layoutlmconfig": 171, "layoutlmtoken": 171, "layoutlmtokenizerfast": 171, "layoutlmmodel": 171, "layoutlmformaskedlm": 171, "ledconfig": 171, "ledtoken": 171, "ledtokenizerfast": 171, "ledmodel": 171, "ledforconditionalgener": 171, "ledforsequenceclassif": 171, "ledforquestionansw": 171, "tfledmodel": 171, "tfledforconditionalgener": 171, "longformerconfig": 171, "longformertoken": 171, "longformertokenizerfast": 171, "longformermodel": [171, 219], "longformerformaskedlm": [171, 190], "longformerforsequenceclassif": 171, "longformerformultiplechoic": 171, "longformerfortokenclassif": 171, "longformerforquestionansw": 171, "tflongformermodel": 171, "tflongformerformaskedlm": 171, "tflongformerforquestionansw": 171, "tflongformerforsequenceclassif": 171, "tflongformerfortokenclassif": 171, "tflongformerformultiplechoic": 171, "lxmertconfig": 171, "lxmerttoken": 171, "lxmerttokenizerfast": 171, "lxmertmodel": 171, "lxmertforpretrain": 171, "lxmertforquestionansw": 171, "tflxmertmodel": 171, "tflxmertforpretrain": 171, "marianconfig": 171, "mariantoken": 171, "marianmodel": 171, "marianmtmodel": [171, 276, 279], "marianforcausallm": 171, "tfmarianmodel": 171, "tfmarianmtmodel": 171, "mbartconfig": 171, "mbarttoken": [171, 190], "mbarttokenizerfast": 171, "mbart50token": 171, "mbart50tokenizerfast": 171, "mbartmodel": 171, "mbartforquestionansw": 171, "mbartforsequenceclassif": 171, "mbartforcausallm": 171, "tfmbartmodel": 171, "tfmbartforconditionalgener": 171, "mobilebertconfig": 171, "mobileberttoken": 171, "mobileberttokenizerfast": 171, "mobilebertmodel": 171, "mobilebertforpretrain": 171, "mobilebertformaskedlm": [171, 190], "mobilebertfornextsentencepredict": 171, "mobilebertforsequenceclassif": 171, "mobilebertformultiplechoic": 171, "mobilebertfortokenclassif": 171, "mobilebertforquestionansw": 171, "tfmobilebertmodel": 171, "tfmobilebertforpretrain": 171, "tfmobilebertformaskedlm": 171, "tfmobilebertfornextsentencepredict": 171, "tfmobilebertforsequenceclassif": 171, "tfmobilebertformultiplechoic": 171, "tfmobilebertfortokenclassif": 171, "tfmobilebertforquestionansw": 171, "mpnetconfig": 171, "mpnettoken": 171, "mpnettokenizerfast": 171, "mpnetmodel": 171, "mpnetformaskedlm": 171, "mpnetforsequenceclassif": 171, "mpnetformultiplechoic": 171, "mpnetfortokenclassif": 171, "mpnetforquestionansw": 171, "tfmpnetmodel": 171, "tfmpnetformaskedlm": 171, "tfmpnetforsequenceclassif": 171, "tfmpnetformultiplechoic": 171, "tfmpnetfortokenclassif": 171, "tfmpnetforquestionansw": 171, "mt5config": 171, "mt5token": 171, "mt5tokenizerfast": 171, "mt5model": 171, "mt5forconditionalgener": 171, "mt5encodermodel": 171, "tfmt5model": 171, "tfmt5forconditionalgener": 171, "tfmt5encodermodel": 171, "openaigptconfig": 171, "openaigpttoken": 171, "openaigpttokenizerfast": 171, "openaigptmodel": 171, "openaigptlmheadmodel": 171, "openaigptdoubleheadsmodel": [171, 190], "openaigptforsequenceclassif": 171, "tfopenaigptmodel": 171, "tfopenaigptlmheadmodel": 171, "tfopenaigptdoubleheadsmodel": 171, "tfopenaigptforsequenceclassif": 171, "gpt2config": 171, "gpt2token": [171, 174], "gpt2tokenizerfast": [171, 247], "gpt2model": [171, 267], "gpt2lmheadmodel": [171, 174, 247], "gpt2doubleheadsmodel": [171, 190], "gpt2forsequenceclassif": 171, "tfgpt2model": 171, "tfgpt2lmheadmodel": 171, "tfgpt2doubleheadsmodel": 171, "tfgpt2forsequenceclassif": 171, "tfsequenceclassifieroutputwithpast": 171, "pegasusconfig": 171, "pegasustoken": [171, 190], "pegasustokenizerfast": 171, "pegasusmodel": 171, "pegasusforconditionalgener": [171, 276, 279], "pegasusforcausallm": 171, "tfpegasusmodel": 171, "tfpegasusforconditionalgener": 171, "phobert": 171, "phoberttoken": 171, "prophetnetconfig": 171, "prophetnettoken": 171, "prophetnetmodel": 171, "prophetnetencod": 171, "prophetnetdecod": 171, "prophetnetforconditionalgener": 171, "prophetnetforcausallm": 171, "ragconfig": 171, "ragtoken": 171, "ragretriev": 171, "ragmodel": 171, "ragsequenceforgener": [171, 275], "ragtokenforgener": [171, 275], "axial": [171, 244], "lsh": [171, 244], "reformerconfig": 171, "reformertoken": [171, 190], "reformertokenizerfast": 171, "reformermodel": 171, "reformermodelwithlmhead": 171, "reformerformaskedlm": 171, "reformerforsequenceclassif": 171, "reformerforquestionansw": 171, "retribertconfig": 171, "retriberttoken": 171, "retriberttokenizerfast": 171, "retribertmodel": 171, "robertaconfig": 171, "robertatoken": 171, "robertatokenizerfast": 171, "robertamodel": [171, 216, 267], "robertaforcausallm": 171, "robertaformaskedlm": [171, 190, 220], "robertaforsequenceclassif": 171, "robertaformultiplechoic": 171, "robertafortokenclassif": 171, "robertaforquestionansw": 171, "tfrobertamodel": 171, "tfrobertaformaskedlm": 171, "tfrobertaforsequenceclassif": 171, "tfrobertaformultiplechoic": 171, "tfrobertafortokenclassif": 171, "tfrobertaforquestionansw": 171, "flaxrobertamodel": 171, "squeezebertconfig": 171, "squeezeberttoken": 171, "squeezeberttokenizerfast": 171, "squeezebertmodel": 171, "squeezebertformaskedlm": 171, "squeezebertforsequenceclassif": 171, "squeezebertformultiplechoic": 171, "squeezebertfortokenclassif": 171, "squeezebertforquestionansw": 171, "t5config": 171, "t5token": [171, 190, 226], "t5tokenizerfast": [171, 226], "t5forconditionalgener": [171, 190, 276, 279], "t5encodermodel": 171, "tft5model": 171, "tft5forconditionalgener": 171, "tft5encodermodel": 171, "tapasconfig": 171, "tapastoken": [171, 284], "tapasmodel": [171, 284], "tapasformaskedlm": 171, "transfoxlconfig": 171, "transfoxltoken": 171, "transfoxl": 171, "transfoxlmodel": 171, "transfoxllmheadmodel": 171, "transfoxlforsequenceclassif": 171, "tftransfoxlmodel": 171, "tftransfoxllmheadmodel": 171, "tftransfoxlforsequenceclassif": 171, "wav2vec2config": 171, "wav2vec2ctctoken": 171, "wav2vec2featureextractor": 171, "wav2vec2processor": 171, "wav2vec2model": 171, "wav2vec2forctc": 171, "xlmconfig": 171, "xlmtoken": [171, 212, 245], "xlmmodel": 171, "xlmwithlmheadmodel": [171, 245], "xlmforsequenceclassif": 171, "xlmformultiplechoic": 171, "xlmfortokenclassif": 171, "xlmforquestionansweringsimpl": 171, "xlmforquestionansw": 171, "tfxlmmodel": 171, "tfxlmwithlmheadmodel": 171, "tfxlmforsequenceclassif": 171, "tfxlmformultiplechoic": 171, "tfxlmfortokenclassif": 171, "tfxlmforquestionansweringsimpl": 171, "xlmprophetnetconfig": 171, "xlmprophetnettoken": 171, "xlmprophetnetmodel": 171, "xlmprophetnetencod": 171, "xlmprophetnetdecod": 171, "xlmprophetnetforconditionalgener": 171, "xlmprophetnetforcausallm": 171, "xlmrobertaconfig": 171, "xlmrobertatoken": [171, 190], "xlmrobertatokenizerfast": 171, "xlmrobertamodel": 171, "xlmrobertaforcausallm": 171, "xlmrobertaformaskedlm": 171, "xlmrobertaforsequenceclassif": 171, "xlmrobertaformultiplechoic": 171, "xlmrobertafortokenclassif": 171, "xlmrobertaforquestionansw": 171, "tfxlmrobertamodel": 171, "tfxlmrobertaformaskedlm": 171, "tfxlmrobertaforsequenceclassif": 171, "tfxlmrobertaformultiplechoic": 171, "tfxlmrobertafortokenclassif": 171, "tfxlmrobertaforquestionansw": 171, "xlnetconfig": 171, "xlnettoken": [171, 190, 255], "xlnettokenizerfast": 171, "xlnetlmheadmodel": 171, "xlnetforsequenceclassif": 171, "xlnetformultiplechoic": 171, "xlnetfortokenclassif": 171, "xlnetforquestionansweringsimpl": 171, "xlnetforquestionansw": 171, "tfxlnetmodel": 171, "tfxlnetlmheadmodel": 171, "tfxlnetforsequenceclassif": 171, "tflnetformultiplechoic": 171, "tfxlnetfortokenclassif": 171, "tfxlnetforquestionansweringsimpl": 171, "pretrainedtokenizerbas": [171, 188], "specialtokensmixin": [171, 188], "enum": [171, 390], "namedtupl": 171, "logitsprocessor": 171, "beamsearch": 171, "9998704791069031": 172, "stuff": [172, 190], "hasn": [172, 236], "sooner": 172, "hate": [172, 251, 253], "constantli": 172, "magic": [172, 189, 251, 253], "anaconda3": [172, 323], "lib": [172, 320, 328, 374], "resid": [172, 189, 253, 254], "saw": [172, 249, 251, 255, 323], "cache_dir": [172, 311, 312, 314, 315], "transformers_cach": 172, "prioriti": [172, 189, 298, 308], "hf_home": 172, "xdg_cache_hom": 172, "predecessor": 172, "pytorch_transformers_cach": 172, "pytorch_pretrained_bert_cach": 172, "swift": 172, "coreml": 172, "distilgpt": [172, 215], "prototyp": [172, 253], "greedy_search": 174, "beam_search": 174, "beam_sampl": 174, "group_beam_search": 174, "dog": [174, 185, 235, 244, 267, 274], "cute": [174, 185, 235, 244, 267], "generation_output": 174, "return_dict_in_gener": 174, "output_scor": 174, "greedysearchdecoderonlyoutput": 174, "hidden_st": [174, 185], "output_hidden_st": [174, 185, 251], "output_attent": [174, 185, 190, 251], "mixin": 177, "defaultflowcallback": 179, "printercallback": 179, "progresscallback": 179, "deactiv": [179, 249], "tensorboardcallback": [179, 190], "tensorboardx": 179, "wandbcallback": 179, "cometcallback": 179, "comet_ml": [179, 257], "mlflowcallback": 179, "mlflow": 179, "azuremlcallback": 179, "azureml": 179, "sdk": 179, "s3": [180, 183, 188, 300], "charg": [181, 188, 253], "audio": [181, 238, 338], "mel": 181, "spectrogram": 181, "verbos": [182, 249, 254, 354], "set_verbosity_info": [182, 254], "transformers_verbos": [182, 254], "myprogram": 182, "get_verbos": 182, "set_verbos": 182, "parenthesi": 182, "fatal": 182, "among": [183, 191, 204, 205, 225, 236, 244, 247, 255, 381], "tfmoduleutilsmixin": 183, "generationmixin": 183, "tfgenerationmixin": 183, "_lrschedul": 184, "accumul": [184, 256, 276], "dedic": [186, 189, 252, 254, 365, 366], "tradit": [187, 208, 213, 217, 219, 229, 240, 244, 250, 284, 374], "dataprocessor": 187, "inputexampl": [187, 282], "inputfeatur": 187, "mrpcprocessor": 187, "mnliprocessor": 187, "mnlimismatchedprocessor": 187, "sst2processor": 187, "stsbprocessor": 187, "qqpprocessor": 187, "qnliprocessor": 187, "rteprocessor": 187, "wnliprocessor": 187, "nli": [187, 263, 278], "crowd": [187, 280], "multinli": [187, 195, 280], "nyu": 187, "bowman": 187, "textual": [187, 214, 216, 280], "swahili": [187, 241, 280], "xnliprocessor": 187, "run_xnli": [187, 253, 280], "unanswer": 187, "squadv1processor": 187, "squadv2processor": 187, "squadprocessor": 187, "squadfeatur": 187, "aforement": [187, 189, 322], "tensorflow_dataset": [187, 256], "get_dev_exampl": 187, "squad_v2_data_dir": 187, "squad_v1_data_dir": 187, "squad_convert_examples_to_featur": 187, "is_train": [187, 318], "tfds_exampl": 187, "tfd": [187, 256], "get_examples_from_dataset": 187, "run_squad": [187, 253, 261], "xlmroberta": 188, "encode_plu": 188, "batch_encode_plu": 188, "behav": [188, 190, 251, 289], "mixed_precis": 189, "inject": 189, "get_train_dataload": [189, 301, 311, 316], "get_train_tfdataset": 189, "get_eval_dataload": [189, 293, 299, 312, 313, 314], "get_eval_tfdataset": 189, "get_test_dataload": 189, "get_test_tfdataset": 189, "create_optimizer_and_schedul": 189, "training_step": [189, 190], "prediction_step": 189, "run_model": [189, 190], "mytrain": 189, "my_custom_loss": 189, "dramat": 189, "trillion": 189, "samyam": 189, "rajbhandari": 189, "jeff": 189, "raslei": 189, "olatunji": 189, "ruwas": 189, "yuxiong": 189, "dealt": [189, 255], "unix": 189, "ld_library_path": 189, "whatev": [189, 254, 256], "despit": [189, 201, 218, 254, 278], "lib64": 189, "prepend": [189, 222, 235, 256, 275], "libcudart": 189, "realiti": [189, 278], "refus": 189, "gcc": [189, 320, 323, 326, 337], "complain": 189, "ln": [189, 318, 322, 324], "symlink": [189, 322, 380, 384], "succe": [189, 254], "unsuccess": 189, "shard": 189, "offload": 189, "number_of_gpus_you_hav": 189, "haven": [189, 335], "run_seq2seq": [189, 253, 279], "max_train_sampl": [189, 279], "wmt16": [189, 279], "dataset_config": [189, 273, 279], "translation_en_to_ro": [189, 279], "source_prefix": [189, 279], "romanian": [189, 223, 239, 244, 245, 250, 277, 279], "larger": [189, 199, 207, 209, 233, 244, 247, 254, 261, 276, 322], "zero_dp_2": 189, "zero_dp_3": 189, "cpu_offload": 189, "caveat": 189, "predict_with_gener": [189, 279], "fullyshardeddataparallel": 189, "billion": [189, 203, 215, 234, 237], "ds_config": 189, "your_program": 189, "everywher": [189, 279], "deepspeed_config": 189, "sake": [189, 278], "deleg": 189, "smart": 189, "zero_optim": 189, "allgather_partit": 189, "allgather_bucket_s": 189, "2e8": 189, "reduce_scatt": 189, "reduce_bucket_s": 189, "overlap_comm": 189, "contiguous_gradi": 189, "buffer": [189, 254], "localhost": [189, 331, 390, 391], "master_addr": [189, 267, 295, 304], "9994": 189, "runtimeerror": 189, "world_siz": [189, 267], "eot": 189, "loss_scal": 189, "loss_scale_window": 189, "hysteresi": 189, "min_loss_scal": 189, "zero_allow_untested_optim": 189, "beta": 189, "warmuplr": 189, "warmup_min_lr": 189, "warmup_max_lr": 189, "warmup_num_step": 189, "steps_per_print": 189, "wall_clock_breakdown": 189, "deepspeedexampl": 189, "lamb": 189, "5e8": 189, "adam_beta1": 189, "adam_beta2": 189, "adam_epsilon": 189, "lr_scheduler_typ": [189, 308], "constant_with_warmup": 189, "fp16_backend": 189, "chose": [189, 255], "shouldn": 189, "train_micro_batch_size_per_gpu": 189, "9gb": 189, "2byte": 189, "8gb": 189, "oom": [189, 275], "6gb": 189, "exclus": [189, 218], "onebitadam": 189, "thoroughli": 189, "isn": [189, 236], "lrrangetest": 189, "onecycl": 189, "warmupdecaylr": 189, "total_num_step": 189, "max_step": 189, "fp16_opt_level": [189, 276], "opt_level": 189, "o1": [189, 276], "subtl": 189, "gradient_clip": 189, "roughli": [190, 276, 322], "grouped_ent": 190, "use_fast": [190, 197], "lift": 190, "forese": 190, "harder": [190, 191, 255, 276], "intermediari": 190, "modeling_bert": 190, "bertlay": 190, "unpack": [190, 251, 306], "value0": 190, "value1": 190, "8604": 190, "lm_label": 190, "decoder_cached_st": 190, "past_key_valu": 190, "decoder_past_key_valu": 190, "max_len": [190, 276], "return_length": 190, "is_pretoken": 190, "tb_writer": 190, "prediction_loss_onli": 190, "data_col": [190, 256, 299, 311, 312, 314], "_log": 190, "_training_step": 190, "_prediction_loop": 190, "prediction_loop": 190, "is_local_mast": 190, "is_local_process_zero": 190, "is_world_mast": 190, "is_world_process_zero": 190, "_setup_wandb": 190, "setup_wandb": 190, "_run_model": 190, "trainerargu": 190, "evaluate_during_train": [190, 264], "evaluation_strategi": [190, 280, 315], "tie_weight": 190, "tie_words_embed": 190, "reset_length": 190, "reset_memory_length": 190, "fillmaskpipelin": 190, "top_k": [190, 253], "1010": 190, "1204": 190, "1195": 190, "inputs_id": 190, "ii": [190, 253], "save_directori": [190, 251], "add_token": [190, 227], "special_token_1": 190, "special_token_2": 190, "resize_token_embed": 190, "my_saved_model_directori": 190, "clip": 190, "num_training_step": 190, "num_warmup_step": [190, 256, 297, 298, 307], "warmup_proport": 190, "warmup_linear": 190, "train_data": 190, "correct_bia": 190, "get_linear_schedule_with_warmup": [190, 256], "matric": [191, 204, 205, 220, 231, 244], "inter": [191, 254, 362, 364], "establish": [191, 208], "fewer": [191, 202, 213, 244, 252, 322], "guess": [192, 244], "disclaim": [193, 198, 212, 220, 223, 227, 229, 231, 235, 240, 284], "strang": [193, 198, 212, 220, 222, 223, 227, 229, 231, 235, 240, 282], "patrickvonplaten": [193, 222, 223, 227, 229, 240, 273, 275], "particularli": [193, 194, 209, 241, 249, 253, 278], "dialogu": [193, 198, 199, 206], "roug": [193, 227, 276, 277, 301, 316], "forum": [193, 276], "force_bos_token_to_be_gener": 193, "mask_token_id": [193, 253], "tok": [193, 276], "example_english_phras": [193, 223], "un": [193, 222, 223, 255], "chief": [193, 223], "syria": [193, 223], "generated_id": 193, "batch_decod": [193, 198, 223, 227], "skip_special_token": [193, 222, 223, 227, 253], "chemic": 193, "weapon": 193, "2010": [194, 253, 276, 284, 305], "12321": 194, "induct": [194, 207], "storm": 194, "countless": 194, "monolingu": [194, 223, 228, 239, 241, 250], "perturb": 194, "flue": [194, 211], "orangesum": 194, "mbarthez": [194, 250], "unlabel": [195, 211, 213, 214, 235, 238, 278], "jointli": [195, 218, 230, 238, 244, 284], "conceptu": [195, 238], "eleven": 195, "nsp": [195, 244], "revolution": 196, "efficaci": 196, "bert2bert": 196, "bo": [196, 223, 253], "eo": [196, 223, 235, 253], "bos_token_id": 196, "eos_token_id": [196, 223], "add_cross_attent": 196, "is_decod": 196, "add_special_token": [196, 249, 253], "sentence_fus": 196, "roberta2roberta_l": 196, "24_discofus": 196, "encoderdecod": 196, "dat": [197, 228], "nguyen": [197, 228], "thanh": 197, "vu": 197, "anh": [197, 228], "tuan": [197, 228], "et": [197, 200, 211, 228, 233, 244, 253, 255, 261, 263, 317], "strong": [197, 206, 208, 209, 221, 229, 236, 240, 241, 244, 245, 248, 253], "vinai": [197, 228], "sc": [197, 222], "presumpt": 197, "coronaviru": 197, "dhec": 197, "httpurl": 197, "cry": 197, "blender": [198, 199], "ingredi": [198, 199, 365], "expert": [198, 199], "conversationalist": [198, 199], "engag": [198, 199], "persona": [198, 199], "90m": [198, 199, 250], "7b": [198, 199], "4b": [198, 199], "human": [198, 199, 205, 206, 212, 227, 234, 275, 284], "engaging": [198, 199], "blenderbot_small_90m": 198, "mname": 198, "400m": [198, 227, 250], "utter": 198, "cool": [198, 251], "eat": 198, "carb": 198, "reply_id": 198, "lose": [198, 253, 255, 264], "healthier": 198, "breakthrough": 200, "parametr": [200, 230], "9x": 200, "agora": 200, "sadli": 200, "138gb": 201, "ubiquit": 201, "concaten": [201, 206, 235, 244, 250, 255, 259, 267, 333], "hope": [201, 251], "impress": [202, 244, 253], "equip": [202, 224, 244], "remark": [202, 244, 321], "convbertbas": [202, 244], "electrabas": [202, 244], "yitu": 202, "opensourc": 202, "unidirect": [203, 214, 215], "govern": [203, 251], "syntact": [203, 214, 215, 284], "run_gener": [203, 214, 215, 242, 245, 281], "reus": [203, 215, 231, 237, 248, 252, 291, 298, 308, 311, 312, 314, 315], "5b": [205, 250], "superglu": [205, 244], "submiss": [205, 212, 254], "surpass": 205, "128k": 205, "ngie": 205, "induc": [205, 272], "asid": 205, "postion": 205, "900m": [205, 250], "147m": [206, 250], "exchang": [206, 219, 250, 252], "reddit": [206, 244, 250], "tunabl": 206, "chain": 206, "2005": [206, 272, 275], "attain": [206, 226, 255], "facilit": [206, 235, 266, 373], "intellig": 206, "chat": 206, "bot": [206, 382, 385], "multiturn": 206, "frame": 206, "x_1": [206, 247], "x_n": 206, "cheap": [207, 267], "preval": 207, "budget": 207, "counterpart": [207, 252], "retain": [207, 272, 278], "cosin": [207, 231, 244], "sep_token": [207, 220, 225, 233], "though": [207, 244, 252, 253, 267, 272, 331], "candid": [208, 255, 278], "idf": 208, "bm25": 208, "facto": 208, "alon": [208, 231, 238, 255], "dual": 208, "lucen": 208, "plausibl": [209, 284], "mirella": [210, 265], "lapata": [210, 265], "nowadai": 211, "2015": [211, 255], "howard": 211, "ruder": 211, "2019b": 211, "jean": 211, "zai": 211, "supercomput": 211, "paraphras": [211, 253], "disambigu": 211, "protocol": 211, "stas00": [212, 276], "machinetransl": 212, "ng": [212, 390], "kyra": 212, "yee": 212, "russian": [212, 253], "bitext": 212, "rerank": 212, "campaign": 212, "upon": [212, 214, 248, 254], "wmt": [212, 239, 250, 253, 257, 277, 293, 316, 364], "exploit": 213, "abund": [213, 214], "overlook": [213, 233], "invest": 213, "quarter": 213, "upsampl": [213, 244], "funnelforpretrain": 213, "assess": 214, "corpora": [214, 216, 223, 225, 255], "scarc": 214, "adequ": 214, "craft": 214, "webapp": [214, 215], "ftfy": [214, 255], "spaci": [214, 255], "basictoken": 214, "million": [215, 224, 236, 250, 253, 284, 368], "medium": [215, 249, 250], "klej": 216, "polish": 216, "piotr": 216, "rybak": 216, "mroczkowski": 216, "janusz": 216, "tracz": 216, "ireneusz": 216, "gawlik": 216, "unlock": 216, "pace": 216, "allevi": [216, 236, 244], "leaderboard": 216, "adopt": [216, 225, 234, 334, 373], "commerc": 216, "allegro": 216, "promot": 216, "nine": [216, 253, 306], "encoded_input": [216, 249, 284], "kto": 216, "lepsz\u0105": 216, "sztuk\u0119": 216, "lepszi": 216, "rz\u0105d": 216, "jasn": 216, "sehoon": 217, "kim": 217, "amir": 217, "gholami": 217, "zhewei": 217, "mahonei": 217, "prohibit": [217, 231], "viabl": 217, "lightweight": [217, 256, 279], "gelu": 217, "preliminari": 217, "0x": 217, "t4": 217, "receipt": 218, "199": [218, 263], "sroie": 218, "626": 218, "widespread": 218, "manipul": [218, 230, 254], "neglect": [218, 225, 242], "vital": 218, "ocr": 218, "tesseract": 218, "x0": 218, "y0": 218, "y1": [218, 319, 322], "normalize_bbox": 218, "name_of_your_docu": 218, "unabl": [219, 220], "quadrat": [219, 220], "linearli": [219, 220, 256, 278], "text8": [219, 220, 237], "enwik8": [219, 220, 250], "wikihop": [219, 220], "alia": [219, 276, 378], "1024": [219, 245, 247, 250, 291, 360, 361, 374], "attention_window": [219, 220], "pad_to_multiple_of": 219, "global_attention_mask": [219, 220], "16384": [219, 250], "gradient_checkpoint": 219, "frac": [220, 231, 247], "succed": 220, "convention": 220, "bertselfattent": 220, "bottleneck": [220, 224, 231, 244], "mathcal": [220, 231, 255], "n_": [220, 231], "insignific": 220, "mlm_label": 220, "roi": 221, "mscoco": 221, "genom": 221, "vqa": [221, 250], "gqa": [221, 250], "relationship": [221, 247, 250], "endow": 221, "intra": [221, 362, 364], "generaliz": 221, "nlvr": 221, "prove": 221, "spacial": 221, "static_position_embed": 222, "layernorm_embed": 222, "normalize_embed": 222, "pad_token_id": [222, 227], "token_embed": [222, 227], "bulk": 222, "convert_marian_to_pytorch": 222, "tgt": [222, 250], "inconsist": [222, 323], "es_ar": 222, "code_": 222, "region": 222, "spanish": [222, 251, 267], "argentina": 222, "iso": [222, 286], "src_text": [222, 223, 227], "constitu": [222, 263], "roa": 222, "tatoeba": [222, 286], "fra": 222, "por": 222, "portugues": 222, "esp": 222, "supported_language_cod": 222, "zlm_latn": 222, "mfe": 222, "pap": 222, "ast": 222, "ind": 222, "glg": 222, "wln": 222, "spa": 222, "ron": 222, "ita": 222, "oci": 222, "est": 222, "phrase": 222, "anglai": 222, "que": 222, "nou": 222, "voulon": 222, "traduir": 222, "fran\u00e7ai": 222, "isto": 222, "deve": 222, "ir": [222, 252, 284], "para": 222, "portugu\u00ea": 222, "esto": 222, "espa\u00f1ol": 222, "hf_api": 222, "hfapi": 222, "model_list": 222, "modelid": 222, "startswith": 222, "old_style_multi_model": 222, "north_eu": 222, "romanc": 222, "scandinavia": 222, "zh": 222, "celtic": 222, "norwai": 222, "fi": 222, "fi_nb_no_nn_ru_sv_en": 222, "sami": 222, "group_memb": 222, "cmn": 222, "cn": 222, "ze_zh": 222, "zh_cn": 222, "zh_hk": 222, "zh_tw": 222, "zh_yue": 222, "zht": 222, "fr_be": 222, "fr_ca": 222, "fr_fr": 222, "frp": 222, "ca": 222, "rm": [222, 254, 317, 323], "lld": 222, "fur": 222, "lij": 222, "lmo": 222, "es_cl": 222, "es_co": 222, "es_cr": 222, "es_do": 222, "es_ec": 222, "es_": 222, "es_gt": 222, "es_hn": 222, "es_mx": 222, "es_ni": 222, "es_pa": 222, "es_p": 222, "es_pr": 222, "es_sv": 222, "es_ui": 222, "es_v": 222, "pt_br": 222, "pt_pt": 222, "gl": 222, "lad": 222, "mwl": 222, "it_it": 222, "nap": 222, "scn": 222, "vec": 222, "nl": 222, "fy": 222, "af": 222, "fo": 222, "nb": 222, "sma": 222, "smj": 222, "smn": 222, "sm": 222, "nb_no": 222, "nn_no": 222, "nog": 222, "no_nb": 222, "ga": 222, "cy": 222, "br": 222, "gd": 222, "gv": 222, "src_lang_cod": 223, "tgt_lang_cod": 223, "as_target_token": 223, "militari": [223, 274], "expected_translation_romanian": 223, "\u015feful": 223, "onu": 223, "declar\u0103": 223, "c\u0103": 223, "nu": 223, "exist\u0103": 223, "solu\u0163i": 223, "militar\u0103": 223, "\u00een": 223, "siria": 223, "decoder_start_token_id": 223, "translated_token": 223, "lang_code_to_id": 223, "2008": 223, "00401": 223, "cc25": [223, 244, 250, 276], "extended": 223, "strongest": 223, "bilingu": 223, "lang_cod": 223, "tgt_text": [223, 227], "model_input": 223, "forced_bos_token_id": 223, "arab": [223, 267], "article_hi": 223, "\u0938": 223, "\u092f": 223, "\u0915": 223, "\u0924": 223, "\u0930": 223, "\u0937": 223, "\u091f": 223, "\u092a": 223, "\u0930\u092e": 223, "\u0916": 223, "\u0915\u0939\u0928": 223, "\u0939": 223, "\u092e": 223, "\u0908": 223, "\u0928": 223, "\u0938\u092e": 223, "\u0927": 223, "\u0928\u0939": 223, "article_ar": 223, "\u0627\u0644\u0623\u0645\u064a\u0646": 223, "\u0627\u0644\u0639\u0627\u0645": 223, "\u0644\u0644\u0623\u0645\u0645": 223, "\u0627\u0644\u0645\u062a\u062d\u062f\u0629": 223, "\u064a\u0642\u0648\u0644": 223, "\u0625\u0646\u0647": 223, "\u0644\u0627": 223, "\u064a\u0648\u062c\u062f": 223, "\u062d\u0644": 223, "\u0639\u0633\u0643\u0631\u064a": 223, "\u0641\u064a": 223, "\u0633\u0648\u0631\u064a\u0627": 223, "mmt": [223, 250], "hi_in": 223, "encoded_hi": 223, "generated_token": 223, "fr_xx": 223, "chef": 223, "affirm": 223, "qu": 223, "il": 223, "pa": 223, "militair": 223, "ar_ar": 223, "encoded_ar": 223, "secretari": 223, "zhiqe": 224, "hongkun": 224, "xiaodan": 224, "renji": 224, "denni": 224, "thin": 224, "bert_larg": 224, "bert_bas": 224, "competit": [224, 234, 241], "gluescor": 224, "phone": 224, "plm": [225, 259], "discrep": [225, 242], "auxiliari": 225, "160gb": [225, 229, 240], "margin": [225, 230, 242, 244], "crawl": [226, 235, 236, 250], "intention": [227, 243, 244], "whenc": 227, "568m": [227, 250], "replic": [227, 233, 276], "finetune_pegasus_xsum": [227, 276], "num_beam": [227, 253, 276, 301, 316], "max_length": [227, 236, 247, 249, 251, 253, 256, 265, 282, 301, 305, 307, 308, 316], "length_penalti": [227, 253, 276], "convert_pegasus_tf_to_pytorch": 227, "pg": 227, "blackout": 227, "forecast": 227, "wind": 227, "amid": 227, "dry": 227, "risk": 227, "wildfir": 227, "shutoff": 227, "middai": 227, "tomorrow": 227, "torch_devic": [227, 254], "california": 227, "electr": 227, "vietnames": 228, "BE": 228, "t\u00f4i": 228, "l\u00e0": 228, "sinh_vi\u00ean": 228, "tr\u01b0\u1eddng": 228, "\u0111\u1ea1i_h\u1ecdc": 228, "c\u00f4ng_ngh\u1ec7": 228, "ahead": [229, 240], "correl": [229, 240, 244], "16gb": [229, 240, 261, 276, 280], "gigaword": [229, 240], "ethan": [230, 244], "perez": [230, 244], "aleksandara": [230, 244], "piktu": [230, 244], "fabio": [230, 244], "petroni": [230, 244], "heinrich": [230, 244], "k\u00fcttler": [230, 244], "rockt\u00e4schel": [230, 244], "riedel": [230, 244], "douw": [230, 244], "kiela": [230, 244], "factual": 230, "lag": 230, "behind": [230, 251], "proven": 230, "nonparametr": 230, "overcom": [230, 242, 299, 312, 314], "routin": 231, "llog": 231, "trax": 231, "ldot": 231, "max_embedding_s": 231, "x_": [231, 247, 252, 255], "500m": 231, "mod": [231, 387], "ge": [231, 264], "lfloor": 231, "rfloor": 231, "x_j": 231, "mathbb": 231, "1_": 231, "2_": 231, "49000": 231, "axial_pos_embds_dim": 231, "axial_pos_shap": 231, "angular": [231, 390], "num_bucket": 231, "premis": 231, "num_hash": 231, "lsh_chunk_length": 231, "themselv": [231, 236], "lsh_num_chunks_befor": 231, "neighbor": 231, "lsh_num_chunks_aft": 231, "local_chunk_length": 231, "local_num_chunks_befor": 231, "local_num_chunks_aft": 231, "64000": 231, "computation": [233, 234], "undertrain": 233, "ffn": 234, "proofread": 234, "opportun": 234, "myriad": 234, "busi": [234, 278], "smartphon": [234, 250], "todai": [234, 253, 255], "headless": [234, 250, 381], "rich": 235, "rise": 235, "methodologi": [235, 253], "landscap": 235, "systemat": 235, "coloss": [235, 250], "mixtur": [235, 253, 291], "appendix": 235, "sentinel": [235, 244], "extra_id_0": 235, "extra_id_1": 235, "extra_id_99": 235, "walk": [235, 257], "park": 235, "extra_id_2": 235, "hous": 235, "wonder": [235, 279], "hau": 235, "ist": [235, 253], "wunderbar": 235, "slight": [236, 244, 311], "tabular": 236, "wtq": 236, "wikisql": 236, "simpler": [236, 238], "weak": 236, "denot": 236, "parser": 236, "pose": 236, "joint": [236, 252, 253], "rival": 236, "wikitq": 236, "trivial": [236, 254, 278], "16k": [236, 278], "syrin": [236, 284], "krichen": [236, 284], "restart": 236, "reset_position_index_per_cel": 236, "no_reset": 236, "prev_label": 236, "actor": [236, 284], "cristiano": 236, "ronaldo": 236, "career": 236, "scatter": [236, 275], "necessarili": 236, "num_aggregation_label": 236, "average_logits_per_cel": 236, "select_one_column": 236, "brittl": 236, "bookkeep": 236, "table_fil": 236, "answer_coordin": 236, "answer_text": 236, "aggregation_label": 236, "float_answ": 236, "interestingli": 236, "perfect": 236, "numeric_valu": 236, "numeric_values_scal": 236, "panda": [236, 284, 286], "pd": [236, 284], "brad": [236, 284], "pitt": [236, 284], "leonardo": [236, 284], "di": [236, 274, 284], "caprio": [236, 284], "georg": [236, 284], "cloonei": [236, 284], "209": 236, "datafram": [236, 284], "from_dict": [236, 284], "tsv_path": 236, "your_path_to_the_tsv_fil": 236, "table_csv_path": 236, "your_path_to_a_directory_containing_all_csv_fil": 236, "tabledataset": 236, "iloc": 236, "read_csv": 236, "use_answer_as_supervis": 236, "answer_loss_cutoff": 236, "664694": 236, "cell_selection_prefer": 236, "207951": 236, "huber_loss_delta": 236, "121194": 236, "init_cell_selection_weights_to_zero": 236, "allow_empty_column_select": 236, "0352513": 236, "handi": [236, 254], "convert_logits_to_predict": 236, "predicted_answer_coordin": 236, "predicted_aggregation_indic": 236, "detach": [236, 333], "logits_aggreg": 236, "id2aggreg": 236, "aggregation_predictions_str": 236, "iat": 236, "cell_valu": 236, "predicted_agg": 236, "uni": 237, "sinuso\u00efd": 237, "disrupt": 237, "tempor": [237, 238], "bpc": [237, 247], "enwiki8": 237, "penn": 237, "treebank": [237, 362], "transcrib": 238, "semi": 238, "latent": 238, "librispeech": [238, 337, 338], "wer": 238, "ten": 238, "53k": 238, "feasibl": 238, "waveform": 238, "connectionist": 238, "ctc": 238, "tlm": [239, 244, 245, 250], "suitabl": [239, 293, 299, 301, 311, 312, 313, 314, 316], "lang": [239, 241, 245], "prohpetnet": 240, "wiki100": 240, "5tb": [241, 245], "commoncrawl": [241, 245, 250], "terabyt": [241, 332, 333, 336], "dub": 241, "mbert": [241, 245, 267, 280], "mlqa": 241, "ner": [241, 249, 251, 253, 257, 267, 285], "urdu": [241, 267], "dilut": 241, "ri": 241, "likelihood": [242, 247, 255, 259, 278], "con": 242, "perm_mask": 242, "target_map": 242, "paradigm": 243, "pin": [243, 270, 380, 384], "esperberto": 243, "live": 243, "credenti": 243, "usernam": [243, 283], "decent": [243, 252, 267], "change_config": 243, "pariti": 243, "tf_model": [243, 251], "from_pt": [243, 251], "pt_model": [243, 251], "from_tf": [243, 251, 256], "garbag": 243, "special_tokens_map": [243, 276], "tokenizer_config": [243, 276], "added_token": 243, "save_model": 243, "ethic": 243, "consider": [243, 247, 272, 278, 280], "meta": 243, "model_card": 243, "namespac": [243, 283], "password": [243, 320], "profil": 243, "gentl": 244, "fall": 244, "webtext": [244, 267], "outgo": 244, "karma": [244, 390], "pai": [244, 249, 309], "subtract": 244, "recomput": 244, "feedforward": 244, "justifi": 244, "subunit": 244, "unicod": [244, 255], "fool": 244, "preselect": 244, "rotat": 244, "forabstract": 244, "gsg": 244, "marcin": 244, "junczi": 244, "dowmunt": 244, "forth": 244, "delimit": 244, "xglue": 244, "headlin": 244, "bitransform": 244, "qk": 244, "n_round": 244, "e1": 244, "e2": [244, 275, 390], "l_": 244, "d_": 244, "l1": [244, 272, 317], "mono": 245, "enfr": [245, 250], "enro": [245, 250], "xnli15": [245, 250], "lang2id": 245, "id2lang": 245, "language_id": 245, "reshap": [245, 329], "104": [245, 250, 267], "exponenti": 247, "x_0": 247, "x_t": 247, "exp": [247, 293, 298, 308], "sum_i": 247, "p_": 247, "theta": 247, "x_i": 247, "ith": 247, "preced": [247, 289], "thought": 247, "uniformli": 247, "fantast": 247, "weren": 247, "greater": [247, 255], "broken": 247, "tempt": 247, "suboptim": [247, 255], "disjoint": 247, "serv": [247, 248, 275, 278, 390], "slide": [247, 272], "repeatedli": 247, "closer": [247, 255, 288, 291], "decomposit": 247, "downsid": 247, "compromis": 247, "overlap": [247, 253], "n_posit": 247, "begin_loc": 247, "end_loc": 247, "trg_len": 247, "target_id": 247, "log_likelihood": 247, "jump": [247, 254], "seek": 248, "vice": [248, 256], "versa": [248, 256], "batch_sent": 249, "8667": 249, "146": 249, "1423": 249, "5650": 249, "1262": 249, "1304": 249, "1314": 249, "1141": 249, "1731": 249, "1385": 249, "1132": 249, "1128": 249, "1201": [249, 337], "return_input_id": 249, "return_token_type_id": 249, "batch_of_second_sent": 249, "1115": 249, "2947": 249, "1114": 249, "1148": 249, "1431": 249, "1129": 249, "12544": 249, "1248": 249, "1301": 249, "boolean": 249, "do_not_pad": 249, "only_first": 249, "only_second": 249, "longest_first": 249, "do_not_trunc": 249, "wouldn": [249, 275], "110m": 250, "336m": 250, "109m": 250, "335m": 250, "168m": 250, "179m": 250, "103m": 250, "deepset": 250, "dbmdz": [250, 253, 267], "tohoku": 250, "japanes": [250, 255], "111m": 250, "mecab": 250, "fugashi": 250, "ja": 250, "char": 250, "turkunlp": 250, "finnish": 250, "125m": [250, 267], "wietsedv": 250, "dutch": [250, 251], "117m": 250, "345m": 250, "774m": 250, "1600": 250, "1558m": 250, "wt103": 250, "257m": 250, "340m": 250, "355m": 250, "82m": [250, 267], "detector": [250, 329], "66m": [250, 267], "65m": [250, 267], "134m": [250, 267], "6b": [250, 302], "11m": 250, "17m": 250, "xlarg": 250, "58m": 250, "xxlarg": 250, "4096": 250, "223m": 250, "60m": 250, "c4": [250, 321], "220m": 250, "3072": [250, 252], "770m": 250, "3b": 250, "8b": 250, "11b": 250, "65536": 250, "270m": 250, "tb": 250, "550m": 250, "flaubert_small_cas": 250, "54m": 250, "flaubert_base_uncas": 250, "137m": 250, "flaubert_base_cas": 250, "138m": 250, "flaubert_large_cas": 250, "373m": 250, "406m": 250, "139m": 250, "moussakam": 250, "216m": 250, "561m": 250, "124m": [250, 267], "149m": 250, "crime": [250, 293], "punish": [250, 293], "fyodor": 250, "dostoyevski": 250, "74m": 250, "096": 250, "435m": 250, "610m": 250, "228m": 250, "couplet": 250, "visualgenom": 250, "130m": 250, "115m": 250, "3x2": 250, "177m": [250, 267], "161m": 250, "386m": 250, "358m": 250, "468m": 250, "440m": 250, "113m": 250, "343m": 250, "140m": 250, "750m": 250, "1536": 250, "51m": 250, "sop": 250, "reiniti": [250, 273], "dig": 251, "9997795224189758": 251, "9998": 251, "5309": 251, "neutral": 251, "gather": [251, 275], "nlptown": 251, "italian": 251, "beneath": 251, "2057": 251, "2024": 251, "2200": 251, "3407": 251, "2265": 251, "19081": 251, "3075": 251, "1012": 251, "pt_batch": 251, "tf_batch": 251, "3246": 251, "2123": 251, "1056": 251, "5223": 251, "2009": 251, "pt_output": 251, "tf_output": 251, "0833": 251, "3364": 251, "0418": 251, "grad_fn": 251, "addmmbackward": 251, "0832963": 251, "336414": 251, "08181786": 251, "04179301": 251, "pt_predict": 251, "tf_predict": 251, "2042994e": 251, "9977952e": 251, "3086340e": 251, "6913657e": 251, "2043e": 251, "9978e": 251, "3086e": 251, "6914e": 251, "softmaxbackward": 251, "dataclass": 251, "autocomplet": 251, "all_hidden_st": 251, "all_attent": 251, "scene": 251, "brows": 251, "n_head": 251, "ort": 252, "convert_graph_to_onnx": 252, "2gb": 252, "fastgelu": 252, "greatli": [252, 255], "y_": 252, "_point": 252, "deepen": 252, "upcom": 252, "serializ": 252, "optimiz": 252, "necess": 252, "impli": [252, 254], "unti": 252, "synchron": [252, 318], "propag": 252, "singleton": 252, "traced_bert": 252, "enc": 252, "jim": 252, "henson": 252, "puppet": 252, "tokenized_text": 252, "masked_index": 252, "indexed_token": 252, "convert_tokens_to_id": 252, "segments_id": 252, "tokens_tensor": 252, "segments_tensor": 252, "dummy_input": 252, "vocab_size_or_config_json_fil": 252, "32000": [252, 291], "num_attention_head": [252, 291], "traced_model": 252, "initialis": 252, "loaded_model": 252, "all_encoder_lay": 252, "pooled_output": [252, 291], "dunder": 252, "versatil": 253, "run_": [253, 267], "run_tf_glu": [253, 280], "run_tf_text_classif": [253, 280], "9991": 253, "9999": 253, "sequence_0": 253, "compani": 253, "york": 253, "citi": 253, "sequence_1": 253, "health": 253, "sequence_2": 253, "headquart": 253, "manhattan": 253, "not_paraphras": 253, "paraphrase_classification_logit": 253, "not_paraphrase_classification_logit": 253, "paraphrase_result": 253, "not_paraphrase_result": 253, "run_qa": [253, 261, 299, 300], "run_tf_squad": [253, 261], "6226": 253, "5053": 253, "147": 253, "161": 253, "answer_start_scor": 253, "start_logit": 253, "answer_end_scor": 253, "end_logit": 253, "convert_tokens_to_str": 253, "convert_ids_to_token": 253, "lysandrejik": 253, "lui": 253, "run_mlm": [253, 259], "pprint": 253, "mask_token": 253, "1792745739221573": 253, "3944": 253, "token_str": 253, "\u0121tool": 253, "11349421739578247": 253, "7208": 253, "\u0121framework": 253, "05243554711341858": 253, "5560": 253, "\u0121librari": 253, "03493533283472061": 253, "databas": [253, 254], "8503": 253, "\u0121databas": 253, "02860250137746334": 253, "17715": 253, "\u0121prototyp": 253, "automodelwithlmhead": 253, "mask_token_index": 253, "token_logit": 253, "mask_token_logit": 253, "top_5_token": 253, "tfautomodelwithlmhead": 253, "run_clm": [253, 259], "top_k_top_p_filt": 253, "dumbo": 253, "next_token_logit": 253, "filtered_next_token_logit": 253, "top_p": 253, "next_token": 253, "multinomi": 253, "num_sampl": [253, 274], "resulting_str": 253, "tf_top_k_top_p_filt": 253, "hopefulli": 253, "portion": [253, 267], "text_gener": 253, "am": 253, "do_sampl": 253, "generated_text": 253, "admit": 253, "market": 253, "stretch": 253, "overridden": 253, "aman": 253, "rusia": 253, "rusiaaman": 253, "padding_text": 253, "1991": 253, "tsar": 253, "nichola": 253, "famili": 253, "maria": 253, "voic": [253, 255], "young": 253, "son": 253, "tsarevich": 253, "nikolaevich": 253, "narrat": 253, "stori": [253, 265], "1883": 253, "western": 253, "siberia": 253, "grigori": 253, "rasputin": 253, "father": 253, "men": 253, "denounc": 253, "hors": 253, "thief": 253, "slap": 253, "him": [253, 279], "accus": 253, "chase": 253, "beaten": 253, "twenti": 253, "virgin": 253, "priest": 253, "famou": 253, "bishop": 253, "beg": 253, "bless": [253, 279], "eod": 253, "weather": 253, "prompt_length": 253, "clean_up_tokenization_spac": 253, "eop": 253, "organis": [253, 289], "2003": [253, 267, 282], "run_ner": [253, 282], "mi": 253, "miscellan": 253, "stefan": [253, 282], "9995632767677307": 253, "gging": 253, "9915938973426819": 253, "9982671737670898": 253, "9994403719902039": 253, "9994346499443054": 253, "9993270635604858": 253, "9993864893913269": 253, "9825621843338013": 253, "um": 253, "936983048915863": 253, "8987102508544922": 253, "9758241176605225": 253, "990249514579773": 253, "hack": 253, "conll03": 253, "daili": [253, 257, 265], "liana": 253, "barriento": 253, "she": 253, "marri": 253, "westchest": 253, "counti": 253, "divorc": 253, "her": 253, "husband": 253, "marriag": 253, "hitch": 253, "declar": 253, "bronx": 253, "crimin": 253, "court": 253, "prosecutor": 253, "immigr": 253, "scam": 253, "fridai": 253, "plead": 253, "guilti": 253, "suprem": 253, "attornei": 253, "wright": 253, "declin": 253, "arrest": 253, "theft": 253, "trespass": 253, "allegedli": 253, "sneak": 253, "subwai": 253, "annett": 253, "markowski": 253, "polic": 253, "spokeswoman": 253, "2002": [253, 282], "island": 253, "jersei": 253, "eight": 253, "approv": 253, "unclear": 253, "prosecut": 253, "district": 253, "offic": 253, "depart": 253, "homeland": 253, "seven": 253, "countri": 253, "egypt": 253, "turkei": 253, "georgia": 253, "pakistan": 253, "mali": 253, "eighth": 253, "rashid": 253, "rajput": 253, "deport": 253, "2006": [253, 264], "terror": 253, "convict": 253, "prison": 253, "min_length": [253, 265], "summary_text": 253, "early_stop": 253, "translation_en_to_d": [253, 279], "pari": 253, "translation_text": 253, "ein": 253, "technologieunternehmen": 253, "sitz": 253, "und": 253, "yml": 254, "ton": 254, "test_optim": 254, "test_log": 254, "subtest": 254, "optimizationtest": 254, "test_adam_w": 254, "keyword": [254, 288, 298, 308], "ada": 254, "unstag": 254, "looponfail": 254, "looponfailroot": 254, "cfg": [254, 318, 322, 331], "ini": 254, "tox": 254, "test_modeling_": [254, 288, 289], "test_model": 254, "isol": 254, "plugin": [254, 373], "onto": 254, "unpredict": 254, "undetect": 254, "replai": 254, "somehow": 254, "tear": 254, "uncov": 254, "flakefind": 254, "flake": 254, "finder": 254, "test_failing_test": 254, "presenc": 254, "573663": 254, "narrow": 254, "test_a": 254, "test_c": 254, "test_b": 254, "impos": 254, "pspec": 254, "instafail": 254, "require_torch": 254, "require_torch_gpu": 254, "require_torch_multi_gpu": 254, "require_torch_non_multi_gpu": 254, "require_torch_tpu": 254, "depict": 254, "test_example_with_multi_gpu": 254, "require_tf": 254, "test_tf_thing_with_tensorflow": 254, "test_example_slow_on_gpu": 254, "require_": 254, "parameter": 254, "test_integration_foo": 254, "testing_util": 254, "get_gpu_count": 254, "spawn": [254, 257, 322], "test_seq2seq_examples_multi_gpu": 254, "pl": [254, 276, 344], "test_finetune_train": 254, "execute_subprocess_async": 254, "sent": [254, 272], "junit": 254, "junitxml": 254, "xml": [254, 324], "white": [254, 279], "fixtur": 254, "neither": 254, "test_this1": 254, "testmathunittest": 254, "testcas": 254, "test_floor": 254, "assert_equ": 254, "floor": 254, "test_mytest": 254, "test_floor_0_neg": 254, "test_floor_1_integ": 254, "test_floor_2_large_fract": 254, "marker": 254, "test_this2": 254, "test_util": 254, "testcaseplu": 254, "accessor": 254, "test_file_path": 254, "__file__": 254, "test_file_dir": 254, "tests_dir": 254, "examples_dir": 254, "repo_root_dir": 254, "src_dir": 254, "stringifi": 254, "test_file_path_str": 254, "test_file_dir_str": 254, "tests_dir_str": 254, "examples_dir_str": 254, "repo_root_dir_str": 254, "src_dir_str": 254, "pathexampletest": 254, "test_something_involving_local_loc": 254, "test_data": [254, 293], "oboject": 254, "_str": 254, "test_something_involving_stringified_loc": 254, "tempfil": 254, "examplestest": 254, "test_whatev": 254, "tmp_dir": 254, "get_auto_remove_tmp_dir": 254, "monitor": [254, 257], "intact": 254, "subdir": 254, "nuke": 254, "altogeth": 254, "xfail": 254, "xpass": 254, "buggi": 254, "uncondition": 254, "test_feature_x": 254, "has_someth": 254, "unsupport": [254, 299], "getopt": 254, "allow_module_level": 254, "xyz": 254, "docutil": 254, "importorskip": 254, "minvers": 254, "skipif": 254, "sy": [254, 374], "version_info": 254, "win32": 254, "testclass": 254, "afford": [254, 303], "var": 254, "caught": 254, "rough": 254, "50mb": 254, "excruciatingli": 254, "incorrectli": 254, "overheard": 254, "outlier": 254, "slowest": 254, "capsi": 254, "accomplish": 254, "print_to_stdout": 254, "print_to_stderr": 254, "test_result_and_stdout": 254, "readouterr": 254, "raise_except": 254, "test_something_except": 254, "contextlib": 254, "redirect_stdout": 254, "stringio": 254, "getvalu": 254, "cleanup": 254, "buf": 254, "capturestdout": 254, "function_that_writes_to_stdout": 254, "secret": [254, 382, 385], "capturestderr": 254, "function_that_writes_to_stderr": 254, "capturestd": 254, "function_that_writes_to_stdout_and_stderr": 254, "capturelogg": 254, "get_logg": 254, "tokenization_bart": 254, "mockenv": 254, "hfargumentparsertest": 254, "test_env_overrid": 254, "env_level_str": 254, "getenv": 254, "pythonpath": [254, 370], "envexampletest": 254, "test_external_prog": 254, "get_env": 254, "rng": 254, "manual_se": 254, "manual_seed_al": 254, "userwarn": 254, "pdb": 254, "problemat": 254, "interfer": 254, "purposefulli": 254, "solid": 254, "travisci": 254, "workaround": 254, "euo": 254, "pipefail": 254, "suppress": 254, "this_command_will_fail": 254, "cmd_that_may_fail": 254, "vote": 254, "sensibl": 255, "explod": 255, "complic": [255, 276], "mose": 255, "loos": 255, "267": 255, "735": 255, "enorm": 255, "unsatisfactori": 255, "letter": 255, "annoyingli": 255, "annoi": 255, "ly": 255, "kept": [255, 322], "agglutin": 255, "turkish": 255, "arbitrarili": 255, "gp": 255, "er": 255, "sennrich": 255, "pretoken": 255, "pug": 255, "pun": 255, "bun": 255, "occurr": [255, 267, 391], "ug": 255, "mug": 255, "unk": 255, "emoji": 255, "clever": 255, "257": 255, "outlin": [255, 335], "korean": 255, "schuster": 255, "2012": [255, 370], "kudo": 255, "trim": 255, "substr": 255, "conjunct": [255, 259], "percent": 255, "exhibit": 255, "sum_": 255, "thai": 255, "detoken": 255, "quickstart": 256, "nuanc": 256, "hyperpamet": 256, "no_decai": 256, "optimizer_grouped_paramet": 256, "nd": 256, "text_batch": 256, "pixar": 256, "cross_entropi": 256, "num_train_step": 256, "base_model": 256, "glue_convert_examples_to_featur": 256, "steps_per_epoch": 256, "115": 256, "tight": 256, "my_mrpc_model": 256, "tfds_train_dataset": 256, "tfds_test_dataset": 256, "compute_metr": [256, 299, 311, 312, 314], "accuracy_scor": 256, "precision_recall_fscore_support": 256, "label_id": 256, "recal": [256, 330], "snapshot": 257, "swag": 257, "arc": 257, "number_of_gpu_you_hav": 257, "path_to_script": 257, "all_arguments_of_the_script": 257, "mnli_output": 257, "boilerpl": 257, "xla_spawn": 257, "num_tpu_you_hav": 257, "report_to": 257, "wandb_log_model": 257, "wandb_watch": 257, "wandb_project": [257, 276], "run_nam": 257, "partick": 258, "run_language_model": 259, "dataset_config_nam": [259, 270, 279, 293], "k80": 259, "train_fil": [259, 270, 272, 279, 280, 282], "path_to_train_fil": [259, 270, 282], "validation_fil": [259, 270, 279, 282], "path_to_validation_fil": [259, 270, 282], "converg": 259, "line_by_lin": 259, "pad_to_max_length": [259, 270, 294, 295, 303, 304], "mlm_wwm": 259, "plm_probabl": 259, "max_span_length": 259, "run_plm": 259, "run_swag": 260, "swag_bas": 260, "overwrite_output": 260, "eval_acc": 260, "8338998300509847": 260, "eval_loss": [260, 293], "44457291918821606": 260, "swag_dir": 260, "swag_data_dir": 260, "run_tf_multiple_choic": 260, "models_bert": 260, "tesla": [261, 265, 280], "debug_squad": 261, "exact_match": 261, "wwm_uncased_finetuned_squad": 261, "run_qa_beam_search": 261, "wwm_cased_finetuned_squad": 261, "squad_dir": 261, "version_2_with_neg": 261, "45884578997162": 261, "5974600601065": 261, "10570": 261, "hasans_exact": 261, "hasans_f1": 261, "59746006010651": 261, "hasans_tot": 261, "4177545691906": 261, "07154997729623": 261, "11873": 261, "73751686909581": 261, "05558584352873": 261, "5928": 261, "noans_exact": 261, "0874684608915": 261, "noans_f1": 261, "noans_tot": 261, "5945": 261, "bookscorpu": 261, "zhiheng": 261, "relative_squad": 261, "6802270577105": 261, "54772098174814": 261, "heurist": [263, 373], "han": 263, "mccoi": 263, "nafis": 263, "sadat": 263, "moosavi": 263, "hans_dir": 263, "run_han": 263, "heur": 263, "lexical_overlap": 263, "9702": 263, "9942": 263, "9962": 263, "0396": 263, "pabe": 264, "sacrific": 264, "run_glue_with_pabe": 264, "eval_all_checkpoint": 264, "comma": [264, 391], "regression_threshold": 264, "12m": 264, "108m": 264, "62x": 264, "18m": 264, "zhou2020bert": 264, "wangchunshu": 264, "mcaulei": 264, "ke": 264, "eprint": [264, 272, 276, 284], "04152": 264, "archiveprefix": [264, 272, 276, 284], "primaryclass": [264, 272, 276, 284], "nltk": [265, 274], "bertab": [265, 279], "kyunghyun": 265, "cho": 265, "uncompress": 265, "cnn_stori": 265, "tgz": [265, 276, 277], "dailymail_stori": 265, "run_summar": 265, "documents_dir": 265, "summaries_output_dir": 265, "summaries_path": 265, "no_cuda": [265, 278, 295, 299, 300, 304, 311, 312, 314], "beam_siz": 265, "alpha": [265, 309], "block_trigram": 265, "compute_roug": 265, "rouge_scor": 265, "utils_summar": 265, "path_to_data": 266, "plot_data_dir": 266, "analys": 266, "model_s": 266, "xin": 266, "ee": 266, "ji": 266, "raphael": 266, "jaejun": 266, "yaoliang": 266, "jimmi": 266, "58th": 266, "annual": 266, "jul": 266, "acl": 266, "204": 266, "2246": 266, "2251": 266, "victorsanh": [267, 272], "januari": 267, "decemb": 267, "novemb": 267, "octob": 267, "supersed": 267, "septemb": 267, "formal": 267, "macro": 267, "distilroberta1": 267, "ourselv": 267, "germev": 267, "2014": 267, "openwebtextcorpu": 267, "reproduct": 267, "sole": 267, "similarli": 267, "binar": 267, "binarized_data": 267, "tokenizer_typ": [267, 289], "tokenizer_nam": [267, 276, 300], "dump_fil": 267, "binarized_text": 267, "emphasi": 267, "token_count": 267, "data_fil": [267, 278], "token_counts_dump": 267, "30522": 267, "student_config": 267, "training_config": 267, "teacher_nam": 267, "alpha_c": 267, "alpha_mlm": 267, "alpha_co": 267, "alpha_clm": 267, "freeze_pos_emb": 267, "dump_path": 267, "serialization_dir": [267, 272], "my_first_train": 267, "node_rank": [267, 295, 304], "n_node": 267, "n_gpu_nod": 267, "an_open_port": 267, "pkill": 267, "nnode": [267, 295, 304], "extract_distilbert": 267, "student_pretrained_weight": 267, "sanh2019distilbert": 267, "emc": 267, "yjernit": 268, "virtualenv": 269, "req": 269, "run_mlm_wwm": 270, "wwm": [270, 360, 361], "ltp": 270, "\u6211\u559c\u6b22\u4f60": 270, "\u6211": 270, "\u559c": 270, "\u6b22": 270, "\u4f60": 270, "\u559c\u6b22": 270, "chine": 270, "clue": 270, "ltp_resourc": 270, "bert_resourc": 270, "run_chinese_ref": 270, "file_nam": 270, "path_to_train_or_eval_fil": 270, "path_to_ltp_token": 270, "path_to_bert_token": 270, "path_to_reference_fil": 270, "train_ref_fil": 270, "path_to_train_chinese_ref_fil": 270, "validation_ref_fil": 270, "path_to_validation_chinese_ref_fil": 270, "note1": 270, "note2": 270, "rune": 270, "wlhgtc": 270, "run_mmimdb": 271, "mmimdb": 271, "max_seq_len": 271, "num_image_emb": 271, "regim": 272, "basefin": 272, "remainingweight": 272, "l0": 272, "soft": [272, 278], "devem": 272, "145": 272, "964": 272, "367": 272, "devacc": 272, "369": 272, "879": 272, "887": 272, "286": 272, "889": [272, 321], "awai": 272, "invit": 272, "fun": [272, 279], "deck": 272, "340mb": 272, "11mb": 272, "floppi": 272, "null": [272, 391], "hypothet": 272, "q8bert": 272, "nois": 272, "prunebert": 272, "fineprun": 272, "pruned_bert": 272, "stabil": 272, "352d5472b0c1dec0f420d606d16747d851b4bda8": 272, "squad_data": 272, "masked_run_squad": 272, "predict_fil": [272, 300, 360, 361], "masked_bert": 272, "5400": 272, "mask_scores_learning_r": 272, "initial_threshold": 272, "final_threshold": 272, "initial_warmup": 272, "final_warmup": 272, "pruning_method": 272, "mask_init": 272, "mask_scal": 272, "sigmoied_threshold": 272, "final_lambda": 272, "dbg": 272, "coeffici": [272, 274], "counts_paramet": 272, "maskedbertforquestionansw": 272, "bertar": 272, "announc": [272, 298, 308], "sanh2020mov": 272, "07683": 272, "tevenlescao": 273, "choromanski": 273, "valerii": 273, "likhosherstov": 273, "dohan": 273, "xingyou": 273, "andreea": 273, "gane": 273, "tama": 273, "sarlo": 273, "hawkin": 273, "jare": 273, "davi": 273, "afroz": 273, "mohiuddin": 273, "lukasz": 273, "belang": 273, "luci": 273, "colwel": 273, "weller": 273, "sanity_script": 273, "full_script": 273, "wandb_user_nam": 273, "viewer": 273, "sumanth": 274, "dathathri": 274, "andrea": 274, "madotto": 274, "janic": 274, "jane": 274, "hung": 274, "frank": 274, "piero": 274, "molino": 274, "yosinski": 274, "rosann": 274, "1912": 274, "02164": 274, "eng": [274, 286], "uber": 274, "torchtext": 274, "run_pplm": 274, "cond_text": 274, "potato": 274, "num_iter": [274, 298, 308], "stepsiz": 274, "window_length": 274, "kl_scale": 274, "gm_scale": 274, "colorama": 274, "intensifi": 274, "soften": 274, "uncontrol": 274, "repetit": 274, "gm": 274, "grad": 274, "xx": 274, "class_label": 274, "lhoestq": 275, "11401": 275, "finetune_rag": 275, "rag_sequ": 275, "question_encod": 275, "nq": 275, "consolidate_rag_checkpoint": 275, "generator_name_or_path": 275, "question_encoder_name_or_path": 275, "dest": 275, "rai": 275, "distributed_retriev": 275, "num_retrieval_work": 275, "eval_mod": 275, "end2end": 275, "evaluation_set": 275, "gold_data_path": 275, "contan": 275, "datapoint": 275, "constitut": 275, "sing": 275, "reba": 275, "sandi": 275, "spika": 275, "mcentir": 275, "album": 275, "shoot": 275, "moon": [275, 278], "biencod": 275, "fbaipublicfil": 275, "gzip": 275, "parse_dpr_relevance_data": 275, "wherev": 275, "src_path": 275, "eval_rag": 275, "predictions_path": 275, "retrieval_pr": 275, "rag_token": 275, "poutput": 275, "gold_data_mod": 275, "output_list": 275, "owner": 275, "footbal": 275, "club": 275, "xiu": 275, "yongg": 275, "xiuli": 275, "recalcul": 275, "gold_data": 275, "e2e_pr": 275, "n_doc": 275, "print_predict": 275, "use_custom_knowledge_dataset": 275, "use_own_knowledge_dataset": 275, "csv_path": 275, "my_csv": 275, "my_knowledge_dataset": 275, "index_nam": 275, "passages_path": 275, "index_path": 275, "my_knowledge_dataset_hnsw_index": 275, "faiss": 275, "contrib": 276, "cdn": [276, 277, 286, 300, 301], "xzvf": [276, 301], "xsum_dir": 276, "cnn_dm_v2": 276, "cnn_cln": 276, "cnn_dm": 276, "cnn_dir": 276, "enro_dir": 276, "wmt_en_d": 276, "eval_": 276, "leak": 276, "8403": 276, "freeze_encod": 276, "3hr": 276, "best_tfmr": 276, "do_predict": [276, 280], "evaluate_checkpoint": 276, "run_ev": [276, 277], "summ": 276, "13gb": 276, "cnndm": 276, "val_max_target_length": 276, "test_max_target_length": 276, "rerun": 276, "test_gener": 276, "max_target_length": 276, "logger_nam": 276, "hf_xsum": 276, "legacyseq2seqdataset": 276, "prepare_seq2seq_batch": 276, "seq2seqdataset": 276, "encoder_layerdrop": 276, "decoder_layerdrop": 276, "attention_dropout": 276, "xsum_result": 276, "starter": 276, "train_mbart_cc25_enro": 276, "enro_finetune_baselin": 276, "label_smooth": 276, "sortish_sampl": 276, "6h": 276, "romanian_postprocess": 276, "multigpu": 276, "git_log": 276, "val_avg_rouge2": 276, "1984": 276, "step_count": 276, "summarizationdistil": 276, "test_result": 276, "hparam": 276, "save_dir": [276, 277, 286], "convert_pl_checkpoint_to_hf": 276, "path_to_ckpt": 276, "randomly_initialized_hf_model_path": 276, "run_distributed_ev": [276, 277], "max_tokens_per_batch": 276, "sortish": 276, "save_len_fil": 276, "dynamic_bs_exampl": 276, "benchmark_dynamic_b": 276, "uneven": 276, "723": 276, "shrink": 276, "dm": [276, 277], "dbart": 276, "tradeoff": 276, "deval": 276, "proc": 276, "dd": 276, "dbart_12_3_xsum_ev": 276, "dbart_12_6_cnn_ev": 276, "dpx_cnn_eval": 276, "dpx_xsum_ev": 276, "make_stud": 276, "dbart_xsum_12_3": 276, "dpx_xsum_16_4": 276, "create_student_by_copying_alternating_lay": 276, "val_check_interv": 276, "n_val": 276, "eval_beam": 276, "distilbart_xsum_sft_12_3": 276, "train_distilbart_cnn": 276, "no_teach": 276, "dbart_xsum_12_3_pl": 276, "curl": [276, 277, 282, 286, 296], "bart_xsum_pl": [276, 277], "xvz": [276, 277], "pegasus_xsum": [276, 277], "all_pl": 276, "train_distilbart_xsum": 276, "13h": 276, "supervise_forward": 276, "normalize_hidden": 276, "shleifer2020pretrain": 276, "13002": 276, "wolf2019huggingfacest": 276, "1910": 276, "03771": 276, "took": 277, "rouge2": 277, "ft": 277, "282173": 277, "2016": 277, "sync_timeout": 277, "60000": 277, "max_source_length": 277, "type_path": 277, "pegasus_cnn_cnn_pl": 277, "sortishsampl": 277, "joeddav": 278, "distill_classifi": 278, "unlabeled_data": 278, "class_names_fil": 278, "class_nam": [278, 366], "teacher_name_or_path": 278, "student_name_or_path": 278, "distillbert": 278, "hypothesis_templ": 278, "hypothesi": 278, "sport": 278, "multi_class": 278, "contradict": 278, "smoother": 278, "teacher_batch_s": 278, "tech": [278, 322], "orbit": 278, "zero_shot_classifi": 278, "7035840153694153": 278, "18744826316833496": 278, "06027870625257492": 278, "04868902638554573": 278, "agnew": 278, "train_unlabel": 278, "newlin": 278, "textclassificationpipelin": 278, "distilled_classifi": 278, "return_all_scor": 278, "14899294078350067": 278, "03205857425928116": 278, "05943061783909798": 278, "7595179080963135": 278, "dirti": 278, "seet": 278, "secretli": 278, "held": 278, "legaci": 279, "jsonlin": 279, "tst": 279, "max_val_sampl": 279, "cnn_dailymail": 279, "text_column": 279, "summary_column": 279, "path_to_csv_or_jsonlines_fil": 279, "sit": 279, "bore": 279, "room": 279, "raini": 279, "sundai": 279, "afternoon": 279, "wast": 279, "rose": 279, "bloom": 279, "ski": 279, "dark": 279, "sacr": 279, "garden": 279, "flower": 279, "christma": 279, "cheer": 279, "children": 279, "snowflak": 279, "air": 279, "carol": 279, "olden": 279, "ancient": 279, "rhyme": 279, "dream": 279, "text_column_nam": 279, "summary_column_nam": 279, "source_lang": 279, "target_lang": 279, "nether": 279, "path_to_jsonlines_fil": 279, "dismiss": 279, "joke": 279, "al\u021bii": 279, "au": 279, "numit": 279, "glum\u0103": 279, "implos": 279, "iar": 279, "a\u0219teapt\u0103": 279, "implozia": 279, "wmt14": 279, "isntead": 280, "corr": 280, "spearman": 280, "toggl": 280, "use_amp": 280, "tlkh": 280, "8438": 280, "8281": 280, "8333": 280, "8568": 280, "8646": 280, "8359": 280, "8464": 280, "8385": 280, "1080": 280, "dev_fil": 280, "test_fil": 280, "label_column_id": 280, "train_languag": 280, "debug_xnli": 280, "7093812375249501": 280, "scrip": 282, "conll2003": 282, "outer": 282, "uc": 282, "1jjhbal535vvz2ap4v4r_rn1uehtdlk5p": 282, "tr": 282, "1zfrcqthdtar5pprjidtrvp7btxscubbm": 282, "1u9mb7knjhwqcwywemdrmutfoohofebth": 282, "x96": 282, "u200": 282, "x95": 282, "xad": 282, "x80": 282, "uniq": 282, "num_epoch": 282, "preciou": 283, "tapas_inter_masklm_base_reset": 284, "flatten": 284, "refut": 284, "counterfactu": 284, "tapas": 284, "infobox": 284, "wikit": 284, "authro": 284, "caption": 284, "gerald": 284, "ford": 284, "taller": 284, "presid": 284, "herzig2020tapa": 284, "02349": 284, "eisenschlos2020understand": 284, "00571": 284, "wrote": 285, "gitpython": 286, "language_cod": 286, "3b2": 286, "convert_marian_tatoeba_to_pytorch": 286, "heb": 286, "convert_model": 286, "tatoebaconvert": 286, "upload_model": 286, "tatoebacoderesolv": 286, "write_model_card": 286, "adding_a_new_example_script": 287, "brandnewbert": [288, 291], "mentor": [288, 291], "model_summari": [288, 291], "todo": 288, "add_": 288, "configuration_": [288, 289], "forconditionalgener": [288, 290], "test_attention_output": 288, "modelintegrationtest": 288, "closest": 288, "modelnam": 289, "plain": 289, "uppercase_modelnam": 289, "lowercase_modelnam": 289, "camelcase_modelnam": 289, "modelhub": 289, "checkpoint_identifi": 289, "modeling_tf_": 289, "tokenization_": 289, "test_modeling_tf_": 289, "test_": 289, "checklist": 289, "generate_tensorflow_and_pytorch": 290, "is_encoder_decoder_model": [290, 291], "endif": 290, "yannic": 291, "kilcher": 291, "superfici": 291, "big_bird": 291, "bigbirdconfig": 291, "ckpt_path": 291, "bigbr_bas": 291, "ckpt_reader": 291, "newcheckpointread": 291, "set_weight": 291, "get_tensor": 291, "trainable_weight": 291, "bigbp_larg": 291, "00000": 291, "00001": 291, "add_big_bird": 291, "modeling_big_bird": 291, "configuration_big_bird": 291, "bigbirdmodel": 291, "discourag": 291, "bigbirdattent": 291, "bigbirdforconditionalgener": 291, "test_modeling_big_bird": 291, "bigbirdmodelintegrationtest": 291, "bigbirdmodeltest": 291, "mistaken": 291, "tokenizer_class": 291, "bird": 291, "bigbirdtokenizationtest": 291, "bigbird": 292, "huggingface_model": [293, 296, 299, 301, 306, 311, 312, 313, 314, 315, 316], "ptq_static": [293, 299, 313, 314], "run_clm_tun": 293, "ptq_dynam": [293, 301, 311, 312, 316, 337, 338], "topology_nam": [293, 301, 311, 313, 316], "billsum": [293, 301], "matrics": [293, 301, 311, 316], "mcc": [293, 299, 301, 311, 312, 313, 314, 316], "spearmanr": [293, 299, 301, 311, 312, 313, 314, 316], "eval_func_for_nc": [293, 301, 311, 313, 316], "eval_output": 293, "eval_samples_per_second": [293, 299, 312, 314], "clm_task_metrics_kei": 293, "csarron": [294, 295], "portal": [294, 295, 297, 302, 303, 304, 307], "run_qa_no_trainer_distil": 294, "teacher_model_name_or_path": [294, 295, 298, 302, 303, 304], "do_distil": [294, 295, 302, 303, 304], "run_teacher_logit": [294, 295], "5143": [294, 295, 297, 302, 304, 305, 307], "run_qa_no_trainer_pruneofa": 295, "do_prun": [295, 298, 304, 305, 308], "stage1_output_dir": [295, 304], "do_quant": [295, 303, 304], "stage2_output_dir": [295, 304], "best_model": [295, 304], "master_address": [295, 304], "num_processes_per_nod": [295, 304], "num_nod": [295, 304], "lanuch": [295, 304], "pip3": [296, 331, 381], "cu113": 296, "torchaudio": [296, 338], "group_lasso": 296, "pyyaml": 296, "squad1": 296, "settl": [296, 298, 308], "ngc": 296, "bert_pyt_ckpt_large_pretraining_amp_lamb": 296, "bert_large_pretrained_amp": 296, "lo": 296, "run_squad_spars": 296, "tf32": 296, "outdir": [296, 324], "prune_bert": 296, "init_checkpoint": [296, 359], "ckpt_8601": 296, "bert_prep_working_dir": 296, "bert_data": 296, "prune_config": 296, "run_qa_no_trainer_prun": 297, "nxm": [298, 308], "oneshot": [298, 308], "weight_compression_pytorch": [298, 308], "excluded_nam": [298, 308], "prune_layer_typ": [298, 308], "extra_excluded_nam": [298, 308], "snip_momentum": [298, 308], "pytorch_prun": [298, 308], "sparsity_decay_typ": [298, 308], "cube": [298, 308], "update_items_for_all_prun": [298, 308], "sparsity_warm_epoch": [298, 308], "total_iter": [298, 308], "on_after_optimizer_step": [298, 308], "run_qa_no_train": 298, "dense_finetuned_model": 298, "pruning_config": [298, 308], "bert_mini_2in4": 298, "distill_loss_weight": [298, 308], "bert_mini_4x1": 298, "cooldown_epoch": [298, 308], "pruned_squad_bert": 298, "prajjwal1": 298, "output_bert": 298, "7993": 298, "7662": 298, "7687": 298, "7617": 298, "7627": 298, "4795": [298, 308], "7645": 298, "7685": 298, "dataloader_drop_last": [299, 312, 314], "furtur": 299, "metric_nam": [299, 312, 314], "eval_f1": [299, 311, 312, 313, 314], "take_eval_step": [299, 312, 314], "save_metr": [299, 312, 314], "torchvison": 300, "jemalloc": [300, 328, 381], "tcmalloc": 300, "openmp": 300, "amx": [300, 328], "dnnl_max_cpu_isa": [300, 328], "avx512_core_amx": [300, 328], "savedresult": 300, "bert_large_ipex": 300, "verison": 300, "run_qa_1_10": 300, "bert_squad_model": 300, "amazonaw": 300, "int8_fp32": 300, "bert_large_1_10_ipex": 300, "distilbert_base_ipex": 300, "pegasus_data": 301, "model_arg": [301, 311, 312, 314, 315, 316], "metric_key_prefix": [301, 316], "task_metrics_kei": [301, 316], "eval_bleu": [301, 316], "eval_rouge1": [301, 316], "eval_rouge2": [301, 316], "eval_rougel": [301, 316], "eval_rougelsum": [301, 316], "textattack": [302, 304], "glove": 302, "50d": 302, "run_glue_no_trainer_distil": 302, "augmented_sst2_data": 302, "huawei": 302, "tinybert_general_4l_312d": 302, "blackbird": [302, 304], "nreimer": 302, "l3": 302, "howei": 302, "zeroqu": 303, "yoshitomo": 303, "matsubara": 303, "run_glue_no_train": [303, 308], "baseli": 303, "run_glue_no_trainer_pruneofa": 304, "head_conf": 305, "13382": 305, "run_glue_no_trainer_gradient_prun": 305, "run_prun": 306, "distilbert_sst": 306, "run_glue_no_trainer_prun": 307, "1700": 307, "baseline_mrpc": 308, "bert_mini_mrpc_2in4": 308, "baseline_sst2": 308, "bert_mini_sst2_2in4": 308, "mrpcbaselin": 308, "bert_mini_mrpc_4x1": 308, "sst2_baselin": 308, "bert_mini_sst2_4x1": 308, "tee": [308, 374], "sst2_orig": 308, "sst2_snip": 308, "8804": 308, "8619": 308, "8752": 308, "8610": 308, "8722": 308, "8562": 308, "8695": 308, "8815": 308, "8660": 308, "8761": 308, "8651": 308, "8692": 308, "8609": 308, "8693": 308, "nerual": 309, "comporessor": 309, "run_glue_prune_distil": 309, "run_glue_tun": [311, 315], "int8_model_dir": [311, 312, 314], "output_log": [311, 312, 314, 315], "save_for_huggingface_upstream": [311, 312, 314, 315], "load_huggingfac": [311, 312, 314, 315], "optimizedmodel": [311, 312, 314, 315], "model_revis": [311, 312, 314, 315], "use_auth_token": [311, 312, 314, 315], "ramp": [311, 312, 314, 315], "bert_task_acc_kei": [311, 313], "eval_accuraci": [311, 313], "game": 311, "theori": 311, "fulfil": 311, "shap": 311, "shapleyms": 311, "recommand": 313, "optimum": 313, "intergr": 313, "enbal": 315, "eval_step": 315, "greater_is_bett": 315, "load_best_model_at_end": 315, "save_strategi": 315, "metric_for_best_model": 315, "save_total_limit": 315, "install_cuda_dock": 317, "ipc": 317, "download_dataset": [317, 318, 328, 329, 362], "run_and_tim": 317, "kaim": 317, "iccv": 317, "sigmoid": [317, 371], "377": 317, "339": 317, "118k": 317, "train2017": [318, 322], "download_weight": [318, 330, 331], "e2e_mask_rcnn_r_50_fpn_1x": [318, 322], "maskrcnn_dataload": 318, "data_loaders_v": 318, "make_data_load": 318, "is_distribut": 318, "data_loader_v": 318, "iou_typ": 318, "box_onli": 318, "retinanet_on": 318, "rpn_onli": 318, "expected_result": 318, "expected_results_sigma_tol": 318, "solver": [318, 322], "ims_per_batch": [318, 322], "is_calib": 318, "cal_dataload": 318, "maskrcnn_benchmark": [319, 320, 321, 322], "image_s": 319, "to_image_list": 319, "batched_imag": 319, "batched_images_32": 319, "size_divis": 319, "nx4": 319, "geometr": 319, "xyxi": [319, 322], "y2": [319, 322], "xywh": 319, "bounding_box": [319, 322], "flip_left_right": 319, "bbox_scal": 319, "bbox_flip": 319, "add_field": [319, 322], "bbox_subset": 319, "cocoapi": [320, 322], "yac": 320, "matplotlib": 320, "webcam": 320, "fresh": 320, "ipython": 320, "ninja": 320, "cython": 320, "cocodataset": [320, 322, 324, 326], "pythonapi": 320, "build_ext": 320, "facebookresearch": [320, 322, 323], "maco": 320, "macosx_deployment_target": 320, "clang": 320, "cxx": 320, "td": 320, "8888": 320, "dd2c487": 321, "sched": 321, "im": [321, 324], "hr": 321, "4036": 321, "17130": 321, "6358800": 321, "3530": 321, "12580": 321, "6358793": 321, "4591": 321, "143149": 321, "6358804": 321, "7007": 321, "209965": 321, "6358717": 321, "4520": 321, "17796": 321, "6358801": 321, "4536": 321, "12966": 321, "6358792": 321, "5665": 321, "15384": 321, "6358805": 321, "7562": 321, "21739": 321, "6358718": 321, "keypoint": [321, 322], "3771": 321, "10941": 321, "9981060": 321, "p100": 321, "647": 321, "799": 321, "rpn": 322, "mmdetect": 322, "model_zoo": 322, "500mb": 322, "e2e_mask_rcnn_r_101_fpn_1x_caffe2": 322, "heatmap": 322, "e2e_keypoint_rcnn_r_50_fpn_1x_caffe2": 322, "cocodemo": 322, "e2e_mask_rcnn_r_50_fpn_1x_caffe2": 322, "merge_from_fil": 322, "merge_from_list": 322, "coco_demo": 322, "min_image_s": 322, "confidence_threshold": 322, "run_on_opencv_imag": 322, "miniv": 322, "valminusminiv": 322, "path_to_coco_dataset": 322, "train2014": 322, "test2014": 322, "val2014": 322, "test2017": 322, "voc": [322, 370], "path_to_vocdevkit_dir": 322, "coco_2017_train": 322, "coco_2014_train": 322, "coco_2017_v": 322, "paths_catalog": 322, "path_to_maskrcnn_benchmark": 322, "train_net": 322, "drawback": 322, "8x": 322, "base_lr": 322, "0025": 322, "max_it": 322, "720000": 322, "480000": 322, "640000": 322, "ngpu": 322, "boxlist": 322, "mydataset": 322, "get_img_info": 322, "img_height": 322, "img_width": 322, "segmentation_mask": 322, "segmentationmask": 322, "trim_detectron_model": 322, "latex": 322, "massa2018mrcnn": 322, "massa": 322, "girshick": 322, "maskrnn": 322, "retinamask": 322, "fu": 322, "mykhailo": 322, "shvet": 322, "berg": 322, "1901": 322, "03353": 322, "type_trait": 323, "1558": 323, "_from": 323, "_to": 323, "struct": 323, "is_convert": 323, "constexpr": 323, "_tc": 323, "anonym": 323, "_element": 323, "_nonnestedtupl": 323, "_srctupl": 323, "cudapopcallconfigur": 323, "firstli": 323, "abi": 323, "inde": 323, "gnu": 323, "onlinedoc": 323, "libstdc": 323, "gist": 323, "goldsborough": 323, "d466f43e8ffc948ff92de7486c5216d6": 323, "recompil": 323, "rf": 323, "ap50": [324, 331], "ap75": 324, "apm": 324, "apl": 324, "segm": 324, "jpegimag": 324, "pascal_train": 324, "pascal_v": 324, "pascal_test": 324, "vocdevkit": 324, "instanceonly_gtfile_train": 324, "trainvaltest": 324, "gtfine_trainvaltest": 324, "mcordt": 324, "cityscapesscript": 324, "instances2dict_with_polygon": 324, "convert_cityscapes_to_coco": 324, "datadir": 324, "gcc5": [326, 337], "prepare_loadgen": [326, 337], "step1": 326, "step2": 326, "upscal": 326, "1200x1200": 326, "annotations_trainval2017": 326, "origin_dir": 326, "origin_dataset": [326, 337], "convert_dir": [326, 337], "convert_dataset": [326, 337], "3236545": 326, "ssd1200": [326, 328], "1200": 326, "6298": 326, "3103": 326, "3418": 326, "elaps": 326, "76469": 326, "763": 326, "7865": 326, "22288": 326, "4817": 326, "861": 326, "9649": 326, "878": 326, "480769": 326, "0617": 326, "649": 326, "5251": 326, "215259": 326, "5257": 326, "5329": 326, "upscale_coco": 327, "coco700": 327, "ssd_resnet34": 328, "download_model": 328, "preload": 328, "ld_preload": [328, 374], "libjemalloc": [328, 374], "malloc_conf": [328, 374], "oversize_threshold": [328, 374], "background_thread": [328, 374], "metadata_thp": [328, 374], "dirty_decay_m": [328, 374], "9000000000": [328, 374], "muzzy_decay_m": [328, 374], "iomp": 328, "libiomp5": [328, 374], "dataset_dir": [328, 362, 364], "pretained_model": 328, "ssd300": 329, "yolo_v3": 330, "get_coco_dataset": [330, 331], "weights_path": [330, 331], "yolo_dataload": 330, "xywh2xyxi": 330, "img_siz": [330, 331], "ap_class": 330, "valid_path": 330, "conf_thr": 330, "nms_thre": 330, "listdataset": 330, "multiscal": 330, "nc_dataload": 330, "eriklindernoren": 331, "iou": 331, "256x256": 331, "darknet": [331, 366], "1080ti": 331, "image_fold": 331, "gradient_accumul": 331, "model_def": 331, "data_config": 331, "n_cpu": 331, "checkpoint_interv": 331, "evaluation_interv": 331, "compute_map": 331, "multiscale_train": 331, "darknet53": 331, "7300": 331, "14658": 331, "grid_siz": 331, "554926": 331, "446884": 331, "427585": 331, "028157": 331, "044483": 331, "051159": 331, "040524": 331, "035687": 331, "046307": 331, "078980": 331, "066310": 331, "027984": 331, "133414": 331, "094540": 331, "037121": 331, "234448": 331, "165665": 331, "223495": 331, "039402": 331, "040198": 331, "041520": 331, "cls_acc": 331, "recall50": 331, "361111": 331, "384615": 331, "300000": 331, "recall75": 331, "222222": 331, "282051": 331, "520000": 331, "070175": 331, "conf_obj": 331, "599058": 331, "622685": 331, "651472": 331, "conf_noobj": 331, "003778": 331, "004039": 331, "004044": 331, "429395": 331, "eta": 331, "821929": 331, "6006": 331, "create_custom_model": 331, "label_idx": 331, "x_center": 331, "y_center": 331, "joseph": 331, "redmon": 331, "ali": 331, "farhadi": 331, "bunch": 331, "swell": 331, "retinanet": 331, "pjreddi": [331, 366], "pc": [332, 333, 336], "370g": [332, 333, 336], "criteo": [332, 333, 336, 368], "tb00_40m": [332, 333, 336], "90gb": [332, 333, 336], "dlrm_dataload": [332, 333, 336], "x_test": [332, 333, 336, 340, 354], "ls_o_test": [332, 333, 336], "ls_i_test": [332, 333, 336], "test_ld": [332, 336], "fuse_list": 332, "bot_l": 332, "top_l": 332, "test_dataload": 333, "is_contigu": 333, "roc_auc": 333, "roc_auc_scor": 333, "transpar": 335, "bounti": 335, "disclosur": 335, "102400": 336, "ipex_config_path": 336, "int8_configur": 336, "best_acc_test": 336, "best_auc_test": 336, "inference_onli": 336, "train_ld": 336, "speech_recognit": [337, 338], "download_dir": 337, "stage1": 337, "stage2": 337, "flac": 337, "wav": 337, "3662521": 337, "distributeddataparallel_1576581068": 337, "9962234": 337, "scriptmodul": 337, "5477": 337, "796": 337, "7552": 337, "5872": 337, "1202": 337, "2529": 337, "5894": 337, "3231": 337, "5195": 337, "1211": 337, "5965": 337, "6030": 337, "1218": 337, "2211": 337, "4812": 337, "1169": 337, "5080": 337, "torchaudio_model": 338, "speech_dataset": 338, "openslr": 338, "zxvf": [338, 363], "folder_in_arch": 338, "dataset_info": 338, "speaker": 338, "driver": [339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "itex": [339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "nc_savedmodel": 339, "run_experi": 340, "load_weight": 340, "checkpoint_filepath": 340, "top_5_accuraci": 340, "y_test": [340, 354], "vit_model": 340, "uncom": [340, 341, 354], "eval_data": [342, 343, 345, 346, 349, 350, 353], "tensorflow_model_optim": 344, "resnet50_fashion_mnist_train": 348, "lowprecisioninferencetool": [348, 371], "resnet50_fashion": 348, "resnetv2": [349, 350, 354], "resnetv2_101": 349, "resnetv2_50": 350, "resnetv2_model": 354, "resnet_v2": 355, "trained_qat_model": 355, "tensorflow_model": [357, 358, 365], "imagenet_prepar": [357, 358], "synset": [357, 358], "raw_dir": [357, 358], "img_raw": [357, 358], "berkeleyvis": 357, "caffe_ilsvrc12": 357, "intelai": [357, 364, 368], "export_inference_graph": 357, "alsologtostderr": 357, "output_fil": [357, 360, 361], "inception_v1_inf_graph": 357, "0up2": 357, "cp36": 357, "cp36m": 357, "manylinux2010": 357, "cp37": 357, "cp37m": 357, "cp35": 357, "cp35m": 357, "labels_offset": 357, "netron": 357, "inceptionv1": [357, 358], "reshape_1": [357, 358], "freeze_graph": 357, "input_checkpoint": 357, "input_binari": 357, "frozen_inception_v1": 357, "output_node_nam": 357, "nc_resnet50_v15": 357, "resnet101_fp32_pretrained_model": 357, "nc_resnet101": 357, "nc_mobilenetv1": 357, "frozen_mobilenet_v2": 357, "nc_mobilenetv2": 357, "nc_inceptionv1": 357, "frozen_inception_v2": 357, "nc_inceptionv2": 357, "inceptionv4_fp32_pretrained_model": 357, "nc_inceptionv4": 357, "frozen_inception_resnet_v2": 357, "nc_irv2": 357, "frozen_vgg16": 357, "nc_vgg16": 357, "frozen_vgg19": 357, "nc_vgg19": 357, "resnet_v2_50": 357, "frozen_resnet50v2_50": 357, "nc_resnetv2_50": 357, "resnet_v2_101": 357, "frozen_resnetv2_101": 357, "nc_resnetv2_101": 357, "resnet_v2_152": 357, "frozen_resnetv2_152": 357, "nc_resnetv2_152": 357, "nc_densenet121": 357, "nc_densenet161": 357, "nc_densenet169": 357, "nasnet_mobil": 357, "frozen_nasnet_mobil": 357, "nc_nasnet_mobil": 357, "nc_efficientnet": 357, "intelai_model": 357, "resnet50v1_5": 357, "eval_classifier_optimized_graph": [357, 370], "auto_tun": 357, "__main__": 357, "eval_image_": 357, "classifier_infer": 357, "q_graph": 357, "evaluate_opt_graph": 357, "tfslimnetsfactori": 358, "inception_v4_arg_scop": 358, "overfeat": 358, "nc_resnet_v1_50": 358, "nc_resnet_v1_101": 358, "nc_resnet_v1_152": 358, "nc_resnet_v2_50": 358, "nc_resnet_v2_101": 358, "nc_resnet_v2_152": 358, "nc_inception_v1": 358, "nc_inception_v2": 358, "nc_inception_v4": 358, "vgg_16": 358, "nc_vgg_16": 358, "vgg_19": 358, "nc_vgg_19": 358, "tf_util": [358, 363], "get_slim_graph": 358, "slim_graph": 358, "model_func": 358, "arg_scop": 358, "run_classifi": 359, "bert_config_fil": 359, "343": 359, "strip_iter": [359, 360], "input_fil": [359, 360, 364], "iteratorgetnext": [359, 360], "kmp_blocktim": [359, 374], "eval_fil": 359, "input_fn": 359, "estimator_input_fn": 359, "get_model_typ": 359, "frozen_pb": 359, "2019_05_30": [360, 361], "wwm_uncased_l": [360, 361], "24_h": [360, 361], "1024_a": [360, 361], "create_tf_record": [360, 361], "v1_8": [360, 365], "bert_large_checkpoint": 360, "freeze_estimator_to_pb": 360, "bert_fp32": [360, 361], "tune_squad": [360, 361], "unstack": 360, "squadv1posttransform": 360, "result_list": 360, "3f": 360, "v2_7_0": 361, "fp32_bert_squad": 361, "872": 362, "ww42": 362, "path_to_save_dataset": 362, "max_seq": 362, "num_int": [362, 364], "inter_thread": [362, 364], "num_intra": [362, 364], "intra_thread": [362, 364], "bracket": [362, 364, 391], "data_loc": 362, "num_batch": 362, "ceil": 362, "generate_dataload": 362, "create_feed_dict_and_label": 362, "distilbert_bas": 362, "v2_2_0": 363, "transformer_lt_official_fp32_pretrained_model": 363, "prepare_dataset_model": 363, "transformer_lt": 363, "fp32_graphdef": 363, "inputs_fil": 363, "newstest2014": [363, 364], "reference_fil": 363, "getitem": [363, 364], "ref_lin": 363, "tensor2tensor": 363, "strided_slice_19": 363, "32768": 364, "file_out": 364, "output_translation_fil": 364, "bleu_vari": 364, "uniform": 364, "input_token": 364, "strided_slice_15": 364, "fastrcnn": 365, "protobuf": 365, "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03": 365, "xvzf": [365, 371], "faster_rcnn_inception_v2_coco_2018_01_28": 365, "faster_rcnn_resnet101_coco_2018_01_28": 365, "faster_rcnn_resnet50_fp32_coco_pretrained_model": 365, "mask_rcnn_inception_v2_coco_2018_01_28": 365, "ssd_resnet34_fp32_1200x1200_pretrained_model": 365, "data_graph": 365, "input_imag": 365, "get_input": 365, "data_sess": 365, "coco_num_val_imag": 365, "get_graph_def": 365, "output_lay": 365, "infer_graph": 365, "output_tensor": 365, "get_tensor_by_nam": 365, "input_lay": 365, "featureextractor": 365, "resnet_v1_50": 365, "bottom_up_block5": 365, "weightsharedconvolutionalboxpredictor_2": 365, "classpredictiontow": 365, "conv2d_0": 365, "meanwhil": 365, "accuracy_check": 365, "mystic123": 366, "githubusercont": 366, "convert_weights_pb": 366, "weights_fil": 366, "data_format": 366, "nhwc": 366, "infer_detect": 366, "yolov3_fp32": 366, "yolov3_tuned3": 366, "oob": 367, "i3d": 367, "plate": 367, "vehicl": 367, "0123": 367, "ava": 367, "kitti": 367, "lowpropos": 367, "640x640": 367, "retinanet50": 367, "20200711": 367, "coco17": 367, "300x300": 367, "bs1": 367, "model_topologi": 367, "output_model_path": 367, "wide_deep_large_d": 368, "kaggl": 368, "large_vers": 368, "calib": [368, 369], "preprocess_csv_tfrecord": 368, "inputcsv": 368, "datafil": 368, "calibrationcsv": 368, "outputfil": 368, "processed_data": 368, "wide_deep_fp32_pretrained_model": 368, "wnd_int8_opt": 368, "3dunetcnn": 369, "raw_data": 369, "run_accuraci": 369, "calibrationset": 369, "semantic_image_segment": 370, "download_and_convert_voc2012": 370, "deeplabv3_pascal_train_aug_2018_01_04": 370, "export_model": 370, "checkpoint_path": 370, "deeplabv3_pascal_train_aug": 370, "export_path": 370, "deeplab_export": 370, "model_vari": 370, "xception_65": 370, "logtostderr": 370, "eval_split": 370, "atrous_r": 370, "output_strid": 370, "decoder_output_strid": 370, "eval_crop_s": 370, "513": 370, "pascal_voc_seg": 370, "nc_deeplab": 370, "vocrecord": 370, "parsedecodevoc": 370, "arbitrary_style_transf": 371, "styliz": 371, "magenta": 371, "style_tun": 371, "style_images_path": 371, "style_imag": 371, "content_images_path": 371, "content_imag": 371, "style_input": 371, "content_input": 371, "conv3": 371, "autocast": 373, "my_model": 373, "memory_format": 373, "channels_last": 373, "jupyterlab": [373, 377, 380, 384], "bench": [373, 389], "superbench": 373, "bc": [374, 381], "numactl": [374, 381], "conda_prefix": 374, "kmp_affin": 374, "dnnl_primitive_cache_capac": 374, "cpufreq": 374, "scaling_governor": 374, "powersav": 374, "neural_cod": [375, 376, 377], "pytorch_jit_script": [375, 378], "pytorch_channels_last": [375, 378], "run_bench": 375, "patch_path": 375, "your_patch_path": 375, "sweep": 375, "sweep_object": 375, "bench_config": 375, "bench_featur": 375, "inlin": 376, "run_glue_optim": 376, "static_ipex": 376, "stock": 377, "auto_qu": 377, "pytorch_amp": 378, "optimize_for_infer": 378, "pytorch_jit_trac": 378, "pytorch_jit_script_ofi": 378, "pytorch_jit_trace_ofi": 378, "torchdynamo": 378, "pytorch_torchdynamo_jit_script": 378, "pytorch_torchdynamo_jit_trac": 378, "pytorch_torchdynamo_jit_script_ofi": 378, "pytorch_torchdynamo_jit_trace_ofi": 378, "pytorch_inc_bf16": 378, "pytorch_inc_static_quant_fx": 378, "pytorch_inc_static_quant_ipex": 378, "pytorch_inc_dynamic_qu": 378, "pytorch_ipex_fp32": 378, "pytorch_ipex_bf16": 378, "pytorch_ipex_int8_static_qu": 378, "pytorch_ipex_int8_dynamic_qu": 378, "blade": 378, "disc": 378, "pytorch_aliblad": 378, "pytorch_lightning_bf16_cpu": 378, "tensorflow_amp": 378, "keras_amp": 378, "onnx_inc_static_quant_qlinear": 378, "ext": [380, 382, 384, 385], "nodej": [380, 384], "jlpm": [380, 384], "yarn": [380, 384], "npm": [380, 381, 384], "lieu": [380, 384], "labextens": [380, 381, 384], "typescript": [380, 384], "refresh": [380, 384], "rebuilt": [380, 384], "pyproject": [382, 385], "toml": [382, 385], "twine": [382, 385], "sdist": [382, 385], "bdist_wheel": [382, 385], "frontend": [382, 385, 388], "admin_github_token": [382, 385], "pypi_token": [382, 385], "npm_token": [382, 385], "changelog": [382, 385], "pkg": [382, 385], "feedstock": [382, 385], "hatch": 385, "stemblock": 386, "f_cat": 386, "denseblock1": 386, "denselayer1": 386, "denselayer2": 386, "denselayer3": 386, "denseblock2": 386, "denselayer4": 386, "denseblock3": 386, "denselayer5": 386, "denselayer6": 386, "denselayer7": 386, "denselayer8": 386, "denseblock4": 386, "denselay": 386, "workspace_path": 387, "configuration_id": 387, "localdisk": 387, "benchmark_start": [387, 391], "benchmark_progress": 387, "execution_detail": 387, "input_model_benchmark": 387, "config_path": [387, 391], "benchmark_script": 387, "benchmark_model": [387, 391], "perf_throughput_input_model": 387, "optimized_model_benchmark": 387, "perf_throughput_optimized_model": 387, "benchmark_finish": [387, 391], "autogener": [388, 389], "prebuild": 388, "outdat": 389, "4200": 390, "guard": 390, "prod": 390, "protractor": 390, "x2611": 391, "input_nod": 391, "output_nod": 391, "x2610": 391, "input1": 391, "input2": 391, "project_id": 391, "project1": 391, "created_at": 391, "tue": 391, "gmt": 391, "modified_at": 391, "domain_flavour": 391, "supports_graph": 391, "supports_profil": 391, "fri": 391, "metric_param": 391, "dataset_id": 391, "dataset_typ": 391, "calibration_batch_s": 391, "calibration_sampling_s": 391, "precision_id": 391, "optimization_type_id": 391, "optimization_id": 391, "optimization_typ": 391, "log_path": 391, "execution_command": 391, "tune_model": 391, "my_optimization_1": 391, "my_optim": 391, "last_run_at": 391, "accuracy_benchmark_id": 391, "performance_benchmark_id": 391, "tuning_detail": 391, "accuracy_criterion_typ": 391, "accuracy_criterion_threshold": 391, "tuning_histori": 391, "minimal_accuraci": 391, "6999299999999999": 391, "baseline_accuraci": 391, "baseline_perform": 391, "57273483276367": 391, "last_tune_accuraci": 391, "last_tune_perform": 391, "251153230667114": 391, "best_tune_accuraci": 391, "best_tune_perform": 391, "699": 391, "758240222930908": 391, "679": 391, "93209171295166": 391, "257209062576294": 391, "67054533958435": 391, "697": 391, "60370635986328": 391, "95270": 391, "cocorecord_50": 391, "optimize_model": 391, "my_graph_optimization_1": 391, "my_graph_optim": 391, "my_optimization_2": 391, "my_first_optim": 391, "my_first_optimization_2": 391, "request_id": 391, "asd": 391, "exit_cod": 391, "websocket": 391, "optimization_start": 391, "size_input_model": 391, "accuracy_criterion_valu": 391, "optimization_finish": 391, "optimization3": 391, "dataset2": 391, "1231": 391, "pin_accuracy_benchmark": 391, "benchmark_id": 391, "pin_performance_benchmark": 391, "warmup_iter": 391, "number_of_inst": 391, "template_path": 391, "mon": 391, "412": 391, "num_thread": 391, "profiling_id": 391, "tbodi": 391, "node_nam": 391, "total_execution_tim": 391, "accelerator_execution_tim": 391, "cpu_execution_tim": 391, "op_run": 391, "op_defin": 391, "node_a": 391, "117": 391, "node_b": 391, "node_c": 391, "node_d": 391, "185": 391, "profile_model": 391, "profiling_start": 391, "profiling_finish": 391, "micro": 391, "faster_rcnn_inception_resnet_v2": 391, "faster_rcnn_resnet101": 391, "progress_step": 391, "create_example_project_start": 391, "create_example_project_progress": 391, "download_start": 391, "download_progress": 391, "download_finish": 391, "create_example_project_finish": 391, "example_finish": 391, "boundary_nod": 391, "boundary_nodes_start": 391, "boundary_nodes_finish": 391, "placehold": 391, "attribute_typ": 391, "node_typ": 391, "node_group_resnet_model": 391, "resnet_model": 391, "group_nod": 391, "tidx": 391, "output_typ": 391, "is_support": 391, "show_dataset_loc": 391}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"type": [0, 170, 391], "chang": [0, 34, 51, 124, 129, 190], "descript": [0, 284, 327], "expect": 0, "behavior": [0, 190], "potenti": [0, 276], "risk": 0, "how": [0, 21, 33, 41, 76, 123, 126, 129, 139, 158, 159, 162, 163, 190, 254, 267, 272, 283, 287, 288, 291, 299, 312, 313, 314, 327], "ha": [0, 190], "thi": [0, 158, 299, 312, 313, 314], "pr": 0, "been": [0, 190], "test": [0, 158, 254, 317, 331, 369, 390], "depend": [0, 119, 142, 190, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 316, 357, 365, 366, 368, 371], "intel": [1, 18, 35, 57, 58, 69, 70, 71, 72, 73, 74, 134, 137, 138, 142, 150, 156, 293, 299, 301, 311, 312, 313, 314, 316, 332, 333, 336, 339, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 374, 381, 391], "neural": [1, 9, 12, 18, 35, 45, 52, 58, 69, 70, 71, 73, 74, 134, 137, 138, 142, 149, 150, 151, 153, 156, 293, 299, 301, 311, 312, 313, 314, 315, 316, 318, 326, 329, 330, 332, 333, 336, 337, 341, 357, 358, 359, 360, 362, 363, 364, 365, 366, 370, 371, 372, 373, 375, 377, 381, 391], "compressor": [1, 9, 18, 35, 52, 58, 69, 70, 71, 73, 74, 134, 137, 138, 142, 149, 150, 151, 153, 156, 293, 299, 301, 311, 312, 313, 314, 315, 316, 318, 326, 329, 330, 332, 333, 336, 337, 341, 357, 358, 359, 360, 362, 363, 364, 365, 366, 370, 371, 372, 381, 391], "instal": [1, 18, 26, 32, 36, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 119, 129, 134, 137, 138, 139, 141, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 160, 161, 172, 189, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 315, 316, 318, 320, 322, 326, 329, 330, 331, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 380, 381, 384], "prerequisit": [1, 36, 62, 69, 70, 71, 120, 121, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 155, 156, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 315, 316, 318, 326, 329, 330, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "linux": [1, 32, 36, 320], "get": [1, 15, 24, 27, 31, 32, 38, 39, 42, 43, 45, 47, 48, 56, 62, 73, 74, 129, 171, 251, 254, 311, 312, 314, 315, 326, 329, 337, 366, 373, 381, 391], "start": [1, 15, 18, 24, 27, 31, 32, 38, 39, 42, 43, 45, 47, 48, 56, 73, 74, 158, 171, 251, 293, 294, 295, 297, 299, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 316, 373, 376, 381], "quantiz": [1, 8, 11, 14, 16, 17, 25, 28, 47, 48, 49, 57, 59, 62, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 252, 293, 299, 301, 303, 311, 312, 313, 314, 315, 316, 326, 337, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 377], "python": [1, 12, 38, 47, 142, 252, 293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 316, 373, 375, 376, 382, 385], "api": [1, 3, 4, 12, 15, 16, 24, 34, 38, 39, 42, 43, 45, 47, 143, 373, 375], "jupyterlab": [1, 381], "extens": [1, 57, 150, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 373, 380, 381, 384], "gui": [1, 390], "system": [1, 18, 32, 44], "requir": [1, 32, 154, 190, 273, 309, 320, 331, 340, 341, 362, 380, 384], "valid": [1, 32, 50, 57, 139, 143, 331, 366], "hardwar": [1, 32, 57, 73, 74, 321], "environ": [1, 32, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 126, 133, 147, 162, 254, 288, 291, 306, 317, 374], "support": [1, 15, 17, 20, 22, 24, 26, 31, 35, 38, 39, 40, 42, 43, 45, 47, 48, 54, 56, 72, 120, 159, 276, 279, 299, 312, 313, 314, 377, 378, 391], "cpu": [1, 57, 72, 119, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 374], "base": [1, 9, 73, 74, 155, 156, 182, 244, 249, 261, 264, 274, 284, 300, 315, 362], "64": 1, "architectur": [1, 12, 13, 23, 35, 124, 160, 190, 276, 279], "compat": 1, "processor": [1, 187], "gpu": [1, 119, 129, 189, 254, 322, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "built": [1, 9, 22, 34, 38], "": [1, 133, 285, 391], "xe": 1, "onnx": [1, 17, 57, 59, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 252], "model": [1, 13, 18, 32, 40, 41, 50, 55, 57, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 125, 129, 133, 137, 139, 140, 141, 142, 143, 148, 149, 150, 155, 156, 158, 160, 161, 162, 163, 170, 171, 172, 183, 185, 190, 210, 222, 243, 244, 245, 247, 250, 251, 252, 253, 259, 261, 263, 270, 272, 274, 283, 284, 286, 288, 289, 290, 291, 293, 294, 296, 297, 299, 301, 302, 305, 307, 311, 312, 313, 314, 315, 316, 317, 318, 321, 322, 326, 328, 329, 331, 332, 333, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 377, 388, 391], "multipl": [1, 42, 57, 189, 260, 276], "vendor": 1, "through": [1, 57], "runtim": [1, 17, 57, 59, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118], "softwar": [1, 32, 321], "document": [1, 16, 27, 32, 143, 161, 275, 372], "select": [1, 381], "public": [1, 46, 317], "event": [1, 46], "addit": [1, 168, 256, 288, 291, 368, 371], "content": [1, 18, 129, 139, 171, 391], "hire": 1, "secur": [2, 18, 26], "polici": 2, "report": [2, 254], "vulner": 2, "refer": [3, 17, 50, 62, 139, 298, 308, 309], "benchmark": [5, 16, 18, 19, 47, 69, 71, 79, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 110, 111, 112, 113, 117, 118, 120, 154, 163, 258, 311, 312, 314, 315, 317, 322, 326, 329, 332, 333, 336, 337, 358, 359, 360, 361, 362, 364, 367, 370, 371, 387, 391], "object": [6, 42, 71, 139, 311], "prune": [7, 16, 45, 47, 57, 59, 145, 146, 272, 295, 297, 304, 305, 306, 307, 309, 340, 341, 354], "build": [9, 30, 38, 161, 390], "inc": [9, 332, 333, 336], "contain": 9, "To": [9, 159, 254, 311, 312, 314, 315, 326, 329, 337], "pip": [9, 133, 143, 160, 172], "deploy": [9, 172, 189], "develop": [9, 18, 27, 32, 158, 380, 384, 390], "check": [9, 72, 73, 74, 243, 371], "contributor": [10, 20, 139, 157, 335], "coven": [10, 20, 157], "code": [10, 12, 20, 69, 70, 71, 73, 74, 134, 137, 138, 142, 148, 149, 150, 151, 153, 156, 157, 161, 251, 293, 298, 299, 301, 308, 309, 311, 312, 313, 314, 316, 318, 330, 332, 333, 334, 335, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 390], "conduct": [10, 20, 157, 334], "our": [10, 20, 154, 157], "pledg": [10, 20, 157], "standard": [10, 20, 157, 190, 252], "respons": [10, 20, 157], "scope": [10, 20, 157], "enforc": [10, 20, 157], "attribut": [10, 20, 157, 190, 317], "fx": 11, "overview": [11, 162, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 288, 290, 291], "usag": [11, 12, 13, 14, 53, 55, 75, 129, 133, 187, 198, 227, 236, 266, 278, 289, 298, 299, 308, 312, 313, 314, 377], "note": [11, 72, 147, 172, 189, 193, 198, 212, 222, 227, 257, 322, 327, 391], "detail": [11, 18, 120, 288, 291, 359, 360, 362, 363, 364, 365, 371, 391], "common": [11, 30], "problem": [11, 317], "dynam": [11, 12, 28, 48, 76, 99, 276, 326, 337], "static": [11, 48, 76, 99], "awar": [11, 14, 48, 315, 329], "train": [11, 14, 26, 48, 62, 69, 127, 129, 139, 141, 151, 220, 223, 231, 235, 254, 256, 257, 259, 261, 264, 267, 271, 276, 279, 280, 284, 315, 317, 321, 322, 326, 329, 331, 337, 340, 354, 357, 358, 367, 369, 370], "search": [12, 261], "introduct": [12, 15, 16, 18, 24, 25, 26, 31, 33, 35, 38, 39, 40, 41, 42, 43, 45, 47, 48, 52, 53, 55, 56, 58, 61, 62, 63, 64, 65, 66, 67, 68, 72, 73, 74, 121, 255, 386], "na": [12, 47], "basic": [12, 55, 243], "1": [12, 18, 26, 30, 34, 36, 57, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 155, 156, 157, 162, 190, 288, 291, 293, 296, 299, 301, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 322, 326, 329, 330, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "yaml": [12, 19, 21, 25, 26, 31, 56, 61, 62, 63, 65, 66, 69, 70, 71, 134, 137, 138, 142, 149, 150, 151, 153, 156, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "2": [12, 18, 30, 34, 36, 57, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 155, 156, 157, 162, 167, 168, 190, 244, 247, 256, 259, 280, 288, 291, 293, 296, 301, 302, 303, 304, 305, 307, 308, 309, 311, 312, 313, 314, 315, 317, 318, 320, 326, 329, 330, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "onli": [12, 145, 254, 320], "advanc": [12, 27, 171], "custom": [12, 18, 38, 42, 55, 62, 73, 74, 168, 175, 251, 279, 322, 331], "exampl": [12, 13, 14, 15, 19, 24, 25, 26, 29, 32, 33, 39, 40, 42, 43, 45, 48, 50, 53, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 119, 125, 127, 129, 130, 131, 132, 134, 135, 137, 138, 142, 143, 149, 150, 151, 152, 153, 156, 187, 193, 194, 222, 227, 247, 257, 273, 274, 278, 280, 287, 293, 298, 301, 308, 309, 311, 315, 316, 318, 326, 329, 330, 331, 332, 333, 336, 337, 357, 358, 370, 377, 387, 391], "ptq": [13, 57, 145], "design": [13, 14, 23, 53, 55], "pytorch": [13, 17, 22, 38, 49, 53, 54, 57, 59, 73, 133, 134, 137, 138, 139, 140, 143, 149, 150, 151, 153, 156, 168, 175, 184, 190, 256, 276, 280, 293, 296, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 322, 330, 331], "mobilenetv2": [13, 151], "helper": [13, 171, 175], "function": [13, 26, 151, 175, 182, 317, 325], "adaptor": 15, "matrix": [15, 17, 24, 31, 35, 38, 39, 40, 42, 43, 45, 47, 48, 56], "work": [15, 48, 143, 162, 243, 288, 291], "flow": [15, 48], "queri": 15, "background": [15, 73, 74], "ad": [15, 161, 322], "new": [15, 18, 55, 129, 133, 158, 161, 277, 287, 382, 385], "backend": 15, "capabl": 15, "implement": [15, 158, 193, 198, 212, 222, 227, 254, 295, 303, 304], "onnxrtadaptor": 15, "class": [15, 171, 186, 192, 331, 366], "user": [16, 19, 21, 22, 25, 26, 34, 47, 56, 69, 70, 71, 134, 137, 138, 142, 149, 150, 151, 153, 156, 293, 301, 311, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371], "face": [16, 34, 78, 285], "experiment": [16, 254, 276, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "relat": [16, 55], "poc": 16, "default": [16, 33, 190], "tensorflow": [17, 22, 38, 49, 53, 54, 57, 59, 74, 167, 168, 175, 184, 256, 260, 261, 280, 282, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "ipex": [17, 119], "mxnet": [17, 22, 38, 54, 57, 69, 70, 71, 141], "bench": [18, 375, 391], "tabl": [18, 129, 139, 257, 391], "option": [18, 26, 36, 162, 288, 291, 320, 376], "from": [18, 32, 36, 96, 129, 143, 172, 190, 322, 360, 391], "binari": [18, 32, 36], "sourc": [18, 32, 36, 161, 172, 254, 275], "home": 18, "screen": 18, "creat": [18, 21, 129, 288, 291, 324, 391], "project": [18, 262, 322, 391], "predefin": [18, 388], "displai": 18, "graph": [18, 33, 391], "list": [18, 22, 54, 254, 317, 391], "remov": [18, 190], "optim": [18, 33, 43, 184, 189, 190, 252, 317, 344, 378, 391], "tab": 18, "wizard": 18, "edit": [18, 172, 391], "entri": [18, 284], "profil": [18, 391], "diagnosi": 18, "dataset": [18, 22, 34, 61, 63, 65, 66, 69, 70, 71, 99, 100, 101, 102, 103, 105, 106, 107, 108, 123, 127, 129, 134, 137, 138, 139, 142, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 168, 276, 282, 296, 301, 306, 309, 317, 318, 322, 324, 326, 327, 328, 329, 330, 331, 332, 333, 336, 337, 338, 348, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 391], "inform": [18, 37, 62, 326, 337], "config": [19, 21, 42, 63, 69, 70, 71, 134, 137, 138, 142, 149, 150, 151, 153, 156, 290, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 323, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "evalu": [19, 26, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 143, 178, 263, 275, 276, 279, 317, 363, 364, 365, 371], "file": [19, 21, 31, 56, 69, 70, 71, 73, 74, 134, 137, 138, 142, 149, 150, 151, 153, 156, 243, 254, 279, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "us": [19, 21, 33, 41, 62, 76, 119, 123, 124, 143, 160, 162, 168, 171, 190, 243, 249, 251, 252, 267, 275, 284, 288, 289, 291, 311, 322, 366], "specif": [19, 21, 22, 55, 161, 186, 191, 195, 208, 209, 213, 214, 215, 219, 220, 221, 224, 229, 230, 236, 237, 239, 242, 254, 328, 391], "dataload": [19, 21, 62, 63, 391], "run": [19, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 121, 129, 134, 137, 138, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 162, 172, 254, 257, 260, 280, 282, 288, 291, 295, 296, 300, 303, 304, 309, 315, 317, 318, 323, 326, 327, 328, 329, 330, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 371, 390], "contribut": [20, 158, 277, 335, 380, 384], "guidelin": [20, 157], "pull": [20, 158, 161, 335], "request": [20, 158, 159, 161, 335, 387], "checklist": [20, 158], "templat": [20, 288, 298, 308], "onnxrt": [22, 38, 54], "workflow": [23, 243, 276], "distil": [24, 25, 47, 57, 59, 130, 131, 132, 154, 155, 156, 267, 276, 278, 294, 302, 303, 309], "knowledg": [24, 57, 275, 276], "intermedi": 24, "layer": [24, 175, 237, 317], "self": [24, 154, 220, 231], "defin": [25, 26, 62, 161, 261, 331], "distribut": [26, 119, 135, 147, 152, 178, 254, 257, 261, 377], "infer": [26, 119, 120, 122, 124, 125, 129, 236, 252, 264, 272, 300, 322, 328, 331], "horovod": [26, 141], "pure": 26, "configur": [26, 31, 44, 47, 52, 55, 56, 129, 147, 180, 189, 309, 317, 388], "option2": 26, "horovodrun": 26, "follow": [26, 326, 337], "ar": [26, 190, 254], "deep": [27, 72], "dive": 27, "topic": [27, 278], "frequent": 30, "ask": 30, "question": [30, 101, 168, 253, 268], "issu": [30, 51, 158, 159, 276, 335], "3": [30, 36, 61, 62, 63, 64, 65, 66, 67, 68, 70, 137, 145, 146, 148, 149, 150, 151, 153, 155, 156, 157, 162, 190, 296, 309, 315, 317, 326, 329, 330, 332, 333, 336, 337, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "framework": [31, 40, 47, 243, 391], "featur": [31, 35, 47, 48, 56, 143, 158, 171, 181, 254, 276, 377, 378, 381], "ai": [32, 36, 73, 74], "kit": [32, 36], "window": [32, 36, 158], "fp32": [33, 61, 62, 63, 64, 65, 66, 68, 72], "auto": [33, 49, 69, 70, 71, 134, 137, 138, 149, 150, 151, 153, 156, 192, 315, 318, 326, 330, 337, 357, 358, 370, 381], "mix": [33, 39, 49, 189, 257, 280], "precis": [33, 39, 49, 189, 257, 280, 391], "tune": [33, 48, 55, 69, 70, 71, 134, 137, 138, 149, 150, 151, 153, 155, 156, 168, 236, 256, 260, 261, 272, 273, 274, 280, 293, 294, 297, 299, 301, 302, 305, 307, 311, 312, 313, 314, 315, 316, 318, 326, 329, 330, 332, 333, 336, 337, 357, 358, 359, 360, 361, 362, 364, 367, 370, 371], "incompat": [34, 51], "between": 34, "v1": [34, 113, 117, 357, 358], "transform": [34, 54, 158, 160, 162, 163, 167, 171, 172, 190, 213, 237, 244, 247, 252, 254, 285, 287, 288, 291, 293, 301, 311, 316, 363, 391], "metric": [34, 38, 62, 143, 168, 317], "infrastructur": 35, "legal": 37, "licens": [37, 73, 74, 120, 322, 335], "citat": [37, 136, 160, 264, 266, 267, 272, 276, 284, 322], "trademark": 37, "singl": [38, 42, 143, 322], "multi": [38, 43, 129, 161, 222, 245, 322], "convers": [41, 123, 129], "orchestr": [43, 59], "One": 43, "shot": [43, 278], "network": [45, 124], "pattern": 45, "criteria": 45, "schedul": [45, 145, 146, 184, 189, 190], "full": [46, 129, 244, 366], "44": 46, "2022": 46, "26": 46, "2021": 46, "14": [46, 162, 357], "2018": 46, "2020": [46, 133], "4": [46, 61, 62, 63, 64, 65, 66, 67, 68, 145, 146, 148, 149, 151, 157, 162, 190, 317, 326, 337, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371], "style": [47, 158, 222, 335, 371], "access": [47, 251], "fundament": [48, 288, 291], "approach": [48, 274, 360, 365, 371], "post": 48, "accuraci": [48, 143, 311, 312, 314, 315, 321, 326, 329, 337, 391], "turn": 49, "ON": 49, "dure": [49, 146], "releas": [51, 382, 385], "known": 51, "sigopt": [52, 55], "strategi": [52, 55, 184, 315, 326, 329, 337], "prepar": [52, 61, 62, 63, 65, 66, 67, 69, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 134, 137, 138, 139, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 162, 243, 267, 282, 288, 291, 293, 296, 299, 300, 301, 306, 311, 312, 313, 314, 315, 316, 318, 326, 330, 332, 333, 336, 337, 338, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 369, 370, 371], "perform": [52, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 263, 273, 322, 374, 391], "benefit": 52, "comparison": [52, 321], "differ": [52, 124], "tensorboard": [53, 331], "part": [55, 362, 363, 364, 365, 371], "bayesian": 55, "mse": [55, 311], "tpe": 55, "exhaust": 55, "random": [55, 254], "mlperf": [57, 96, 120], "10": [57, 354, 357, 358], "0": [57, 69, 71, 168, 261, 280, 322, 338, 354, 355, 357], "torch": [57, 139], "12": [57, 133, 357, 358], "mode": 57, "qat": [57, 146, 152, 344], "11": [57, 357, 358, 362], "7": [57, 357, 358, 365, 366, 368, 369], "qdq": [57, 76], "int8": [57, 72], "helloworld": [59, 62], "notebook": [59, 73, 74, 165, 189, 243, 285, 322], "hello": 60, "world": 60, "tf_example1": 61, "download": [61, 64, 65, 66, 68, 172, 282, 311, 312, 314, 315, 317, 329, 331, 359, 360, 361, 362, 363, 365, 366, 368, 369], "updat": [61, 65, 66, 69, 70, 71, 134, 137, 138, 142, 148, 149, 151, 153, 156, 190, 283, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 371], "root": [61, 65, 66], "conf": [61, 62, 63, 65, 66], "5": [61, 62, 63, 65, 66, 133, 148, 149, 162, 190, 317, 344, 348, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 369, 370, 371], "command": [61, 62, 63, 64, 65, 66, 67, 68, 120, 141, 261, 274, 293, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 371], "6": [61, 63, 65, 66, 148, 357, 358, 365, 366, 368, 369, 371], "tf_example2": 62, "step": [62, 69, 70, 71, 72, 75, 134, 137, 138, 142, 145, 146, 148, 149, 150, 151, 153, 155, 156, 162, 243, 282, 288, 291, 293, 294, 295, 296, 297, 299, 300, 301, 302, 303, 304, 305, 307, 309, 311, 312, 313, 314, 315, 316, 317, 318, 320, 324, 326, 329, 330, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 370, 371], "add": [62, 162, 243, 287, 288, 291, 391], "input": [62, 170, 190, 249, 252], "output": [62, 174, 185, 190, 191, 195, 208, 209, 213, 214, 215, 219, 220, 221, 224, 229, 230, 236, 237, 239, 242, 254, 276, 326, 337], "tensor": [62, 76, 148, 149], "name": [62, 222, 253, 254, 288, 323, 366], "pleas": 62, "py": [62, 323], "mnist": [62, 89, 135], "data": [62, 122, 129, 141, 176, 249, 267, 276, 282, 284, 317, 366], "loader": 62, "tf_example3": 63, "tf_example4": 64, "tf_example5": 65, "tf_example6": 66, "tf_example7": 67, "tf_example8": 68, "pre": [69, 249, 282, 326, 337, 357, 358, 367, 369, 370, 381], "resnet18_v1": 69, "resnet50_v1": [69, 71], "resnet152_v1": 69, "squeezenet1": 69, "mobilenet1": [69, 71], "mobilenetv2_1": 69, "inception_v3": [69, 358], "enabl": [69, 70, 71, 134, 137, 138, 142, 149, 150, 151, 153, 156, 293, 299, 301, 311, 312, 313, 314, 315, 316, 318, 326, 329, 330, 332, 333, 336, 337, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371, 375, 381], "resnet50": [69, 72, 148, 149, 150, 151, 153, 357], "analysi": [69, 70, 71, 134, 137, 138, 142, 149, 150, 151, 153, 156, 293, 301, 311, 316, 318, 330, 332, 333, 336, 357, 358, 359, 360, 362, 363, 364, 365, 370, 371], "write": [69, 70, 71, 134, 137, 138, 142, 149, 150, 151, 153, 156, 161, 254, 293, 298, 299, 301, 308, 311, 312, 313, 314, 316, 318, 330, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 357, 358, 359, 360, 361, 362, 363, 364, 365, 370, 371], "finetun": [70, 119, 275, 276, 293, 322], "bert_bas": 70, "mrpc": [70, 155, 156, 308], "squad": [70, 168, 187, 261, 294, 295, 297, 298], "ssd": [71, 112, 113, 117, 118, 328], "voc": [71, 324], "coco": [71, 139, 322, 324, 327, 331, 366], "detect": [71, 78, 139], "v": [72, 244], "learn": [72, 139, 158, 160, 184], "boost": 72, "setup": [72, 73, 74, 265, 267, 272, 274, 328], "script": [72, 276, 280, 282, 287], "activ": 72, "sampl": [72, 73, 74], "result": [72, 73, 74, 136, 139, 143, 154, 254, 258, 261, 264, 298, 303, 308, 309, 391], "devcloud": [73, 74], "oneapi": [73, 74], "analyt": [73, 74], "toolkit": [73, 74], "jupyt": [73, 74, 322, 373, 382, 385], "ssh": [73, 74], "login": [73, 74], "job": [73, 74], "submit": [73, 74, 158], "statu": [73, 74], "log": [73, 74, 182, 257, 331], "png": [73, 74], "server": [73, 74, 390], "pypi": [73, 74, 139, 377], "conda": [73, 74, 160, 172, 382, 385], "oper": 76, "orient": 76, "qlinearop": 76, "format": [76, 122, 141, 176, 324], "emot": 77, "ferplu": 77, "ultra": 78, "lightweight": 78, "mobilenet": [79, 80, 90, 113, 117, 118, 357], "v2": [79, 118, 205, 354, 357], "v3": [80, 190, 357, 366], "alexnet": 81, "arcfac": 82, "caffenet": 83, "densenet": [84, 357], "efficientnet": [85, 133, 357], "lite4": 85, "fcn": 86, "googlenet": 87, "incept": [88, 143, 357, 358], "resnet": [91, 96, 134, 137, 143, 149, 150, 151, 153, 318, 354, 357], "50": [91, 96, 223, 357], "shufflenet": 92, "squeezenet": 93, "vgg16": [94, 98, 358], "zfnet": 95, "torchvis": [96, 143], "unet": 97, "bert": [99, 105, 155, 156, 167, 190, 195, 217, 244, 245, 259, 261, 266, 296, 299, 300, 312, 313, 314, 315, 359, 360], "distilbert": [100, 207, 244, 259, 267, 300, 362], "huggingfac": [101, 102, 158, 283, 311, 312, 314, 315], "answer": [101, 168, 253, 268], "text": [102, 253, 265, 274, 280], "classif": [102, 168, 253, 278, 280, 282], "mobilebert": [103, 107, 224], "bidaf": 104, "gpt2": [106, 215], "roberta": [108, 233, 241, 244, 245, 259], "resnet101": [109, 357], "duc": 109, "faster": [110, 321, 322], "r": [110, 111, 321, 322], "cnn": [110, 111, 276, 321, 322], "mask": [111, 170, 193, 253, 259, 270, 321, 322], "tini": 114, "yolov3": [114, 115, 330, 331], "yolov4": 116, "A": [119, 267], "textual": 119, "invers": 119, "method": [119, 161, 272], "person": 119, "text2imag": 119, "nezha": 119, "cartoon": 119, "acceler": 119, "medic": 120, "imag": [120, 320, 331], "3d": [120, 127, 129], "segment": [120, 139, 323], "disclaim": 120, "calibr": [120, 369], "set": [120, 126, 139, 143, 324, 331, 369, 374], "cmd": [121, 368], "baselin": [121, 321, 322], "instruct": 123, "decathlon": 123, "extend": [124, 129], "nnu": [124, 125, 129], "net": [124, 125, 127, 129], "blueprint": 124, "paramet": [124, 261, 272, 327], "pretrain": [125, 129, 133, 137, 139, 140, 141, 143, 144, 155, 156, 162, 190, 250, 251, 265, 284, 288, 291, 293, 296, 301, 311, 312, 313, 314, 331, 332, 333, 336, 339, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 356, 359, 360, 361, 363, 371], "up": [126, 324], "path": [126, 366], "variabl": [126, 254, 374], "an": [126, 147, 331], "altern": 126, "wai": [126, 158], "u": [127, 129, 381], "hippocampu": 127, "experi": [129, 257], "plan": 129, "preprocess": [129, 249, 284, 317], "2d": 129, "resolut": 129, "cascad": 129, "low": 129, "identifi": 129, "best": [129, 163, 374, 381], "faq": 129, "manual": [129, 360, 365, 366, 371, 382, 385], "split": 129, "do": [129, 158, 172, 373], "i": [129, 158, 160, 190, 217, 267, 299, 312, 313, 314, 326, 337], "need": 129, "alwai": [129, 190, 249], "all": [129, 243, 254, 295, 304, 391], "share": [129, 162, 163, 189, 243, 288, 291], "can": [129, 158], "smaller": 129, "error": [129, 323], "seg": 129, "prev": 129, "stage": 129, "miss": 129, "when": [129, 323], "why": [129, 160], "am": 129, "runtimeerror": 129, "cuda": [129, 320], "devic": [129, 172], "side": 129, "assert": 129, "trigger": 129, "3d_lowr": 129, "cifar100": [130, 132, 154], "cifar10": 131, "gener": [133, 161, 162, 170, 173, 174, 183, 253, 274, 277, 280, 281, 288, 289, 291, 366], "what": [133, 267, 283, 373], "april": 133, "march": 133, "23": 133, "feb": 133, "jan": 133, "22": 133, "nov": 133, "2019": [133, 369], "15": [133, 357], "oct": 133, "30": 133, "27": 133, "port": [133, 143, 162, 288, 291], "weight": [133, 252, 257, 317, 318, 322, 330, 331, 366], "hub": [133, 243, 311, 312, 314, 315], "export": [133, 252], "efficientnet_b0": 134, "mobilenetv3_rw": 134, "peleenet": 136, "imagenet": [136, 139, 141, 143], "ilsvrc": 136, "2012": 136, "resnest50": 138, "resnest": [138, 139, 141, 156], "github": [139, 159], "gluon": [139, 140, 141], "transfer": [139, 371], "detectron": [139, 321, 322], "m": 139, "instanc": 139, "panopt": 139, "semant": 139, "ade20k": 139, "cityscap": [139, 324], "verifi": [139, 141], "backbon": 139, "major": 139, "recordio": 141, "first": [142, 296], "se_resnext": 142, "se_resnext50_32x4d": 142, "origin": [142, 162, 244, 288, 291, 296], "readm": [142, 296], "progress": [143, 254], "summari": [143, 244, 253, 255], "repo": [143, 190, 283], "quick": [143, 160, 251, 376], "few": [143, 322], "case": [143, 315], "comput": 143, "logit": 143, "reproduc": [143, 254, 265], "avail": [143, 179, 277], "nasnet": [143, 357], "facebook": 143, "caff": 143, "bnincept": 143, "resnext": 143, "dualpathnetwork": 143, "xception": 143, "senet": 143, "pnasnet": 143, "polynet": 143, "input_s": 143, "input_spac": 143, "input_rang": 143, "mean": 143, "std": 143, "forward": [143, 170], "last_linear": 143, "hand": 143, "resnet152": 143, "automat": [143, 189, 254, 359, 360, 361, 363, 365, 366], "inceptionv4": 143, "inceptionresnetv2": 143, "acknowledg": 143, "non": 147, "other": [147, 173, 182, 244, 272, 341, 368], "resnet18": [148, 149, 150, 151, 153], "resnext101_32x8d": [148, 149, 151, 153], "inceptionv3": [148, 149], "mobilenet_v2": [148, 149], "dump": [148, 149, 323], "debug": [148, 149, 254, 288, 291], "save": [148, 149, 150, 252, 277, 318, 340, 354], "load": [148, 149, 252, 318], "With": [150, 151, 160, 172], "resnext101_32x16d": 150, "Of": [151, 153, 330], "On": [151, 153, 330], "buildin": 151, "without": [151, 245], "paper": 154, "blendcnn": [155, 156], "teacher": [155, 156, 276], "fine": [155, 156, 168, 236, 256, 260, 261, 272, 273, 280, 315], "correct": 157, "warn": 157, "temporari": [157, 254], "ban": 157, "perman": 157, "you": [158, 172, 249, 288, 291, 381], "so": [158, 190], "mani": 158, "did": 158, "find": 158, "bug": 158, "want": [158, 172, 249], "guid": [158, 171], "wa": 158, "heavili": 158, "inspir": 158, "awesom": 158, "scikit": 158, "sync": 158, "fork": 158, "master": 158, "upstream": [158, 311, 312, 314, 315], "The": [159, 186, 190, 257, 326, 337, 368], "forum": 159, "onlin": [160, 254], "demo": [160, 269, 322], "tour": [160, 251], "should": 160, "shouldn": 160, "t": 160, "more": [160, 244, 288, 291], "packag": [161, 190, 357, 365, 366, 368, 371, 380, 382, 384, 385], "element": 161, "tree": 161, "toc": 161, "preview": 161, "tutori": [161, 299, 312, 313, 314], "argument": [161, 176, 190, 376], "line": [161, 322], "block": 161, "return": 161, "token": [162, 168, 170, 177, 188, 190, 249, 251, 255, 282, 288, 290, 291], "recip": [162, 288, 291], "theoret": [162, 288, 291], "aspect": [162, 244, 288, 291], "brandnewbert": 162, "next": [162, 288, 291], "your": [162, 163, 243, 275, 276, 288, 291, 322], "checkpoint": [162, 167, 227, 276, 288, 291, 360], "repositori": [162, 288, 291], "practic": 163, "bertologi": 164, "commun": [165, 285], "resourc": [165, 168, 189, 256, 288, 291], "convert": [167, 276, 286, 324], "albert": [167, 191, 244], "openai": [167, 214, 215], "gpt": [167, 214, 244, 247, 259], "xl": [167, 237, 244], "xlnet": [167, 242, 244, 259, 261, 313], "xlm": [167, 239, 240, 241, 244, 245], "t5": [167, 235, 244], "sequenc": [168, 244, 253, 276, 279], "imdb": [168, 271], "review": 168, "trainer": [168, 178, 189, 256, 261], "nativ": [168, 256], "w": 168, "nut": 168, "emerg": 168, "entiti": [168, 253], "nlp": [168, 299, 312, 313, 314], "librari": [168, 323], "glossari": 170, "term": 170, "id": 170, "attent": [170, 220, 231, 244], "posit": [170, 190, 231, 261], "label": [170, 276, 277], "decod": [170, 210], "feed": 170, "chunk": 170, "research": [171, 262], "main": [171, 189, 248], "intern": [171, 178, 237], "cach": 172, "continu": 172, "integr": [172, 189], "larg": [172, 261, 300], "scale": 172, "mobil": [172, 357], "util": [173, 174, 175, 176, 177, 178, 325], "enum": [173, 177], "namedtupl": [173, 177], "special": 173, "decor": 173, "properti": 173, "greedysearchoutput": 174, "sampleoutput": 174, "beamsearchoutput": 174, "beamsampleoutput": 174, "logitsprocessor": 174, "beamsearch": 174, "modul": [175, 254, 323], "loss": [175, 317], "pipelin": [176, 186, 190, 251], "handl": 176, "pretrainedtokenizerbas": 177, "specialtokensmixin": 177, "callback": [178, 179], "trainercallback": 179, "trainerst": 179, "trainercontrol": 179, "pretrainedconfig": 180, "extractor": 181, "pretrainedfeatureextractor": 181, "batchfeatur": 181, "setter": 182, "pretrainedmodel": 183, "moduleutilsmixin": 183, "tfpretrainedmodel": 183, "tfmodelutilsmixin": 183, "flaxpretrainedmodel": 183, "adamw": [184, 190], "adafactor": 184, "adamweightdecai": 184, "rate": 184, "warmup": 184, "gradient": [184, 189], "gradientaccumul": 184, "modeloutput": 185, "basemodeloutput": 185, "basemodeloutputwithpool": 185, "basemodeloutputwithcrossattent": 185, "basemodeloutputwithpoolingandcrossattent": 185, "basemodeloutputwithpast": 185, "basemodeloutputwithpastandcrossattent": 185, "seq2seqmodeloutput": 185, "causallmoutput": 185, "causallmoutputwithcrossattent": 185, "causallmoutputwithpast": 185, "maskedlmoutput": 185, "seq2seqlmoutput": 185, "nextsentencepredictoroutput": 185, "sequenceclassifieroutput": 185, "seq2seqsequenceclassifieroutput": 185, "multiplechoicemodeloutput": 185, "tokenclassifieroutput": 185, "questionansweringmodeloutput": 185, "seq2seqquestionansweringmodeloutput": 185, "tfbasemodeloutput": 185, "tfbasemodeloutputwithpool": 185, "tfbasemodeloutputwithpast": 185, "tfseq2seqmodeloutput": 185, "tfcausallmoutput": 185, "tfcausallmoutputwithpast": 185, "tfmaskedlmoutput": 185, "tfseq2seqlmoutput": 185, "tfnextsentencepredictoroutput": 185, "tfsequenceclassifieroutput": 185, "tfseq2seqsequenceclassifieroutput": 185, "tfmultiplechoicemodeloutput": 185, "tftokenclassifieroutput": 185, "tfquestionansweringmodeloutput": 185, "tfseq2seqquestionansweringmodeloutput": 185, "abstract": [186, 319, 322], "task": [186, 251, 253, 257, 293, 294, 295, 297, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314], "conversationalpipelin": 186, "featureextractionpipelin": 186, "fillmaskpipelin": 186, "nerpipelin": 186, "questionansweringpipelin": 186, "summarizationpipelin": 186, "tablequestionansweringpipelin": 186, "textclassificationpipelin": 186, "textgenerationpipelin": 186, "text2textgenerationpipelin": 186, "tokenclassificationpipelin": 186, "translationpipelin": 186, "zeroshotclassificationpipelin": 186, "parent": 186, "glue": [187, 293, 308, 311, 312, 313, 314], "xnli": [187, 280], "pretrainedtoken": 188, "pretrainedtokenizerfast": 188, "batchencod": 188, "seq2seqtrain": 189, "tftrainer": 189, "trainingargu": 189, "seq2seqtrainingargu": 189, "tftrainingargu": 189, "fairscal": 189, "deepspe": 189, "one": [189, 366], "zero": [189, 278], "accumul": 189, "clip": 189, "migrat": [190, 389], "previou": 190, "x": 190, "v4": [190, 357], "autotoken": [190, 192], "now": [190, 283], "fast": 190, "rust": 190, "obtain": 190, "same": 190, "sentencepiec": [190, 255], "each": [190, 254, 283], "resid": 190, "its": [190, 254, 311, 312, 314, 315, 326, 329, 337], "folder": [190, 331], "switch": 190, "return_dict": 190, "true": 190, "some": 190, "deprec": 190, "order": [190, 254, 317], "keyword": 190, "attention_mask": 190, "token_type_id": 190, "tupl": 190, "serial": 190, "bertadam": 190, "openaiadam": 190, "albertconfig": 191, "alberttoken": 191, "alberttokenizerfast": 191, "albertmodel": 191, "albertforpretrain": 191, "albertformaskedlm": 191, "albertforsequenceclassif": 191, "albertformultiplechoic": 191, "albertfortokenclassif": 191, "albertforquestionansw": 191, "tfalbertmodel": 191, "tfalbertforpretrain": 191, "tfalbertformaskedlm": 191, "tfalbertforsequenceclassif": 191, "tfalbertformultiplechoic": 191, "tfalbertfortokenclassif": 191, "tfalbertforquestionansw": 191, "autoconfig": 192, "automodel": 192, "automodelforpretrain": 192, "automodelforcausallm": 192, "automodelformaskedlm": 192, "automodelforseq2seqlm": 192, "automodelforsequenceclassif": 192, "automodelformultiplechoic": 192, "automodelfornextsentencepredict": 192, "automodelfortokenclassif": 192, "automodelforquestionansw": 192, "automodelfortablequestionansw": 192, "tfautomodel": 192, "tfautomodelforpretrain": 192, "tfautomodelforcausallm": 192, "tfautomodelformaskedlm": 192, "tfautomodelforseq2seqlm": 192, "tfautomodelforsequenceclassif": 192, "tfautomodelformultiplechoic": 192, "tfautomodelfortokenclassif": 192, "tfautomodelforquestionansw": 192, "flaxautomodel": 192, "bart": [193, 244], "fill": 193, "bartconfig": 193, "barttoken": 193, "barttokenizerfast": 193, "bartmodel": 193, "bartforconditionalgener": 193, "bartforsequenceclassif": 193, "bartforquestionansw": 193, "bartforcausallm": 193, "tfbartmodel": 193, "tfbartforconditionalgener": 193, "barthez": 194, "bartheztoken": 194, "bartheztokenizerfast": 194, "bertconfig": 195, "berttoken": 195, "berttokenizerfast": 195, "bertmodel": 195, "bertforpretrain": 195, "bertmodellmheadmodel": 195, "bertformaskedlm": 195, "bertfornextsentencepredict": 195, "bertforsequenceclassif": 195, "bertformultiplechoic": 195, "bertfortokenclassif": 195, "bertforquestionansw": 195, "tfbertmodel": 195, "tfbertforpretrain": 195, "tfbertmodellmheadmodel": 195, "tfbertformaskedlm": 195, "tfbertfornextsentencepredict": 195, "tfbertforsequenceclassif": 195, "tfbertformultiplechoic": 195, "tfbertfortokenclassif": 195, "tfbertforquestionansw": 195, "flaxbertmodel": 195, "flaxbertformaskedlm": 195, "bertgener": 196, "bertgenerationconfig": 196, "bertgenerationtoken": 196, "bertgenerationencod": 196, "bertgenerationdecod": 196, "bertweet": 197, "bertweettoken": 197, "blenderbot": [198, 199], "blenderbotconfig": 198, "blenderbottoken": 198, "blenderbotmodel": 198, "blenderbotforconditionalgener": 198, "blenderbotforcausallm": 198, "tfblenderbotmodel": 198, "tfblenderbotforconditionalgener": 198, "small": 199, "blenderbotsmallconfig": 199, "blenderbotsmalltoken": 199, "blenderbotsmallmodel": 199, "blenderbotsmallforconditionalgener": 199, "blenderbotsmallforcausallm": 199, "tfblenderbotsmallmodel": 199, "tfblenderbotsmallforconditionalgener": 199, "bort": 200, "camembert": 201, "camembertconfig": 201, "camemberttoken": 201, "camemberttokenizerfast": 201, "camembertmodel": 201, "camembertforcausallm": 201, "camembertformaskedlm": 201, "camembertforsequenceclassif": 201, "camembertformultiplechoic": 201, "camembertfortokenclassif": 201, "camembertforquestionansw": 201, "tfcamembertmodel": 201, "tfcamembertformaskedlm": 201, "tfcamembertforsequenceclassif": 201, "tfcamembertformultiplechoic": 201, "tfcamembertfortokenclassif": 201, "tfcamembertforquestionansw": 201, "convbert": [202, 244], "convbertconfig": 202, "convberttoken": 202, "convberttokenizerfast": 202, "convbertmodel": 202, "convbertformaskedlm": 202, "convbertforsequenceclassif": 202, "convbertformultiplechoic": 202, "convbertfortokenclassif": 202, "convbertforquestionansw": 202, "tfconvbertmodel": 202, "tfconvbertformaskedlm": 202, "tfconvbertforsequenceclassif": 202, "tfconvbertformultiplechoic": 202, "tfconvbertfortokenclassif": 202, "tfconvbertforquestionansw": 202, "ctrl": [203, 244], "ctrlconfig": 203, "ctrltoken": 203, "ctrlmodel": 203, "ctrllmheadmodel": 203, "ctrlforsequenceclassif": 203, "tfctrlmodel": 203, "tfctrllmheadmodel": 203, "tfctrlforsequenceclassif": 203, "deberta": [204, 205], "debertaconfig": 204, "debertatoken": 204, "debertamodel": 204, "debertapretrainedmodel": 204, "debertaformaskedlm": 204, "debertaforsequenceclassif": 204, "debertafortokenclassif": 204, "debertaforquestionansw": 204, "debertav2config": 205, "debertav2token": 205, "debertav2model": 205, "debertav2pretrainedmodel": 205, "debertav2formaskedlm": 205, "debertav2forsequenceclassif": 205, "debertav2fortokenclassif": 205, "debertav2forquestionansw": 205, "dialogpt": 206, "distilbertconfig": 207, "distilberttoken": 207, "distilberttokenizerfast": 207, "distilbertmodel": 207, "distilbertformaskedlm": 207, "distilbertforsequenceclassif": 207, "distilbertformultiplechoic": 207, "distilbertfortokenclassif": 207, "distilbertforquestionansw": 207, "tfdistilbertmodel": 207, "tfdistilbertformaskedlm": 207, "tfdistilbertforsequenceclassif": 207, "tfdistilbertformultiplechoic": 207, "tfdistilbertfortokenclassif": 207, "tfdistilbertforquestionansw": 207, "dpr": [208, 244], "dprconfig": 208, "dprcontextencodertoken": 208, "dprcontextencodertokenizerfast": 208, "dprquestionencodertoken": 208, "dprquestionencodertokenizerfast": 208, "dprreadertoken": 208, "dprreadertokenizerfast": 208, "dprcontextencod": 208, "dprquestionencod": 208, "dprreader": 208, "tfdprcontextencod": 208, "tfdprquestionencod": 208, "tfdprreader": 208, "electra": [209, 244], "electraconfig": 209, "electratoken": 209, "electratokenizerfast": 209, "electramodel": 209, "electraforpretrain": 209, "electraformaskedlm": 209, "electraforsequenceclassif": 209, "electraformultiplechoic": 209, "electrafortokenclassif": 209, "electraforquestionansw": 209, "tfelectramodel": 209, "tfelectraforpretrain": 209, "tfelectraformaskedlm": 209, "tfelectraforsequenceclassif": 209, "tfelectraformultiplechoic": 209, "tfelectrafortokenclassif": 209, "tfelectraforquestionansw": 209, "encod": [210, 231, 255, 256, 265], "encoderdecoderconfig": 210, "encoderdecodermodel": 210, "flaubert": [211, 244], "flaubertconfig": 211, "flauberttoken": 211, "flaubertmodel": 211, "flaubertwithlmheadmodel": 211, "flaubertforsequenceclassif": 211, "flaubertformultiplechoic": 211, "flaubertfortokenclassif": 211, "flaubertforquestionansweringsimpl": 211, "flaubertforquestionansw": 211, "tfflaubertmodel": 211, "tfflaubertwithlmheadmodel": 211, "tfflaubertforsequenceclassif": 211, "tfflaubertformultiplechoic": 211, "tfflaubertfortokenclassif": 211, "tfflaubertforquestionansweringsimpl": 211, "fsmt": [212, 276], "fsmtconfig": 212, "fsmttoken": 212, "fsmtmodel": 212, "fsmtforconditionalgener": 212, "funnel": [213, 244], "funnelconfig": 213, "funneltoken": 213, "funneltokenizerfast": 213, "funnelbasemodel": 213, "funnelmodel": 213, "funnelmodelforpretrain": 213, "funnelformaskedlm": 213, "funnelforsequenceclassif": 213, "funnelformultiplechoic": 213, "funnelfortokenclassif": 213, "funnelforquestionansw": 213, "tffunnelbasemodel": 213, "tffunnelmodel": 213, "tffunnelmodelforpretrain": 213, "tffunnelformaskedlm": 213, "tffunnelforsequenceclassif": 213, "tffunnelformultiplechoic": 213, "tffunnelfortokenclassif": 213, "tffunnelforquestionansw": 213, "openaigptconfig": 214, "openaigpttoken": 214, "openaigpttokenizerfast": 214, "openaigptmodel": 214, "openaigptlmheadmodel": 214, "openaigptdoubleheadsmodel": 214, "openaigptforsequenceclassif": 214, "tfopenaigptmodel": 214, "tfopenaigptlmheadmodel": 214, "tfopenaigptdoubleheadsmodel": 214, "tfopenaigptforsequenceclassif": 214, "gpt2config": 215, "gpt2token": 215, "gpt2tokenizerfast": 215, "gpt2model": 215, "gpt2lmheadmodel": 215, "gpt2doubleheadsmodel": 215, "gpt2forsequenceclassif": 215, "tfgpt2model": 215, "tfgpt2lmheadmodel": 215, "tfgpt2doubleheadsmodel": 215, "tfgpt2forsequenceclassif": 215, "tfsequenceclassifieroutputwithpast": 215, "herbert": 216, "herberttoken": 216, "herberttokenizerfast": 216, "ibertconfig": 217, "ibertmodel": 217, "ibertformaskedlm": 217, "ibertforsequenceclassif": 217, "ibertformultiplechoic": 217, "ibertfortokenclassif": 217, "ibertforquestionansw": 217, "layoutlm": 218, "layoutlmconfig": 218, "layoutlmtoken": 218, "layoutlmtokenizerfast": 218, "layoutlmmodel": 218, "layoutlmformaskedlm": 218, "layoutlmforsequenceclassif": 218, "layoutlmfortokenclassif": 218, "led": 219, "ledconfig": 219, "ledtoken": 219, "ledtokenizerfast": 219, "ledmodel": 219, "ledforconditionalgener": 219, "ledforsequenceclassif": 219, "ledforquestionansw": 219, "tfledmodel": 219, "tfledforconditionalgener": 219, "longform": [220, 244], "longformerconfig": 220, "longformertoken": 220, "longformertokenizerfast": 220, "longformermodel": 220, "longformerformaskedlm": 220, "longformerforsequenceclassif": 220, "longformerformultiplechoic": 220, "longformerfortokenclassif": 220, "longformerforquestionansw": 220, "tflongformermodel": 220, "tflongformerformaskedlm": 220, "tflongformerforquestionansw": 220, "tflongformerforsequenceclassif": 220, "tflongformerfortokenclassif": 220, "tflongformerformultiplechoic": 220, "lxmert": [221, 269], "lxmertconfig": 221, "lxmerttoken": 221, "lxmerttokenizerfast": 221, "lxmertmodel": 221, "lxmertforpretrain": 221, "lxmertforquestionansw": 221, "tflxmertmodel": 221, "tflxmertforpretrain": 221, "marianmt": [222, 244], "multilingu": 222, "old": [222, 282], "lingual": [222, 245], "marianconfig": 222, "mariantoken": 222, "marianmodel": 222, "marianmtmodel": 222, "marianforcausallm": 222, "tfmarianmodel": 222, "tfmarianmtmodel": 222, "mbart": [223, 244], "mbartconfig": 223, "mbarttoken": 223, "mbarttokenizerfast": 223, "mbart50token": 223, "mbart50tokenizerfast": 223, "mbartmodel": 223, "mbartforconditionalgener": 223, "mbartforquestionansw": 223, "mbartforsequenceclassif": 223, "mbartforcausallm": 223, "tfmbartmodel": 223, "tfmbartforconditionalgener": 223, "mobilebertconfig": 224, "mobileberttoken": 224, "mobileberttokenizerfast": 224, "mobilebertmodel": 224, "mobilebertforpretrain": 224, "mobilebertformaskedlm": 224, "mobilebertfornextsentencepredict": 224, "mobilebertforsequenceclassif": 224, "mobilebertformultiplechoic": 224, "mobilebertfortokenclassif": 224, "mobilebertforquestionansw": 224, "tfmobilebertmodel": 224, "tfmobilebertforpretrain": 224, "tfmobilebertformaskedlm": 224, "tfmobilebertfornextsentencepredict": 224, "tfmobilebertforsequenceclassif": 224, "tfmobilebertformultiplechoic": 224, "tfmobilebertfortokenclassif": 224, "tfmobilebertforquestionansw": 224, "mpnet": 225, "mpnetconfig": 225, "mpnettoken": 225, "mpnettokenizerfast": 225, "mpnetmodel": 225, "mpnetformaskedlm": 225, "mpnetforsequenceclassif": 225, "mpnetformultiplechoic": 225, "mpnetfortokenclassif": 225, "mpnetforquestionansw": 225, "tfmpnetmodel": 225, "tfmpnetformaskedlm": 225, "tfmpnetforsequenceclassif": 225, "tfmpnetformultiplechoic": 225, "tfmpnetfortokenclassif": 225, "tfmpnetforquestionansw": 225, "mt5": [226, 244], "mt5config": 226, "mt5token": 226, "mt5tokenizerfast": 226, "mt5model": 226, "mt5forconditionalgener": 226, "mt5encodermodel": 226, "tfmt5model": 226, "tfmt5forconditionalgener": 226, "tfmt5encodermodel": 226, "pegasu": [227, 244, 276], "pegasusconfig": 227, "pegasustoken": 227, "pegasustokenizerfast": 227, "pegasusmodel": 227, "pegasusforconditionalgener": 227, "pegasusforcausallm": 227, "tfpegasusmodel": 227, "tfpegasusforconditionalgener": 227, "phobert": 228, "phoberttoken": 228, "prophetnet": [229, 240, 244], "prophetnetconfig": 229, "prophetnettoken": 229, "prophetnetmodel": 229, "prophetnetencod": 229, "prophetnetdecod": 229, "prophetnetforconditionalgener": 229, "prophetnetforcausallm": 229, "rag": [230, 244], "ragconfig": 230, "ragtoken": 230, "ragretriev": 230, "ragmodel": 230, "ragsequenceforgener": 230, "ragtokenforgener": 230, "reform": [231, 244], "axial": 231, "lsh": 231, "local": 231, "reformerconfig": 231, "reformertoken": 231, "reformertokenizerfast": 231, "reformermodel": 231, "reformermodelwithlmhead": 231, "reformerformaskedlm": 231, "reformerforsequenceclassif": 231, "reformerforquestionansw": 231, "retribert": 232, "retribertconfig": 232, "retriberttoken": 232, "retriberttokenizerfast": 232, "retribertmodel": 232, "robertaconfig": 233, "robertatoken": 233, "robertatokenizerfast": 233, "robertamodel": 233, "robertaforcausallm": 233, "robertaformaskedlm": 233, "robertaforsequenceclassif": 233, "robertaformultiplechoic": 233, "robertafortokenclassif": 233, "robertaforquestionansw": 233, "tfrobertamodel": 233, "tfrobertaformaskedlm": 233, "tfrobertaforsequenceclassif": 233, "tfrobertaformultiplechoic": 233, "tfrobertafortokenclassif": 233, "tfrobertaforquestionansw": 233, "flaxrobertamodel": 233, "squeezebert": 234, "squeezebertconfig": 234, "squeezeberttoken": 234, "squeezeberttokenizerfast": 234, "squeezebertmodel": 234, "squeezebertformaskedlm": 234, "squeezebertforsequenceclassif": 234, "squeezebertformultiplechoic": 234, "squeezebertfortokenclassif": 234, "squeezebertforquestionansw": 234, "t5config": 235, "t5token": 235, "t5tokenizerfast": 235, "t5model": 235, "t5forconditionalgener": 235, "t5encodermodel": 235, "tft5model": 235, "tft5forconditionalgener": 235, "tft5encodermodel": 235, "tapa": [236, 284], "tapasconfig": 236, "tapastoken": 236, "tapasmodel": 236, "tapasformaskedlm": 236, "tapasforsequenceclassif": 236, "tapasforquestionansw": 236, "transfoxlconfig": 237, "transfoxltoken": 237, "transfoxl": 237, "transfoxlmodel": 237, "transfoxllmheadmodel": 237, "transfoxlforsequenceclassif": 237, "tftransfoxlmodel": 237, "tftransfoxllmheadmodel": 237, "tftransfoxlforsequenceclassif": 237, "wav2vec2": [238, 338], "wav2vec2config": 238, "wav2vec2ctctoken": 238, "wav2vec2featureextractor": 238, "wav2vec2processor": 238, "wav2vec2model": 238, "wav2vec2forctc": 238, "xlmconfig": 239, "xlmtoken": 239, "xlmmodel": 239, "xlmwithlmheadmodel": 239, "xlmforsequenceclassif": 239, "xlmformultiplechoic": 239, "xlmfortokenclassif": 239, "xlmforquestionansweringsimpl": 239, "xlmforquestionansw": 239, "tfxlmmodel": 239, "tfxlmwithlmheadmodel": 239, "tfxlmforsequenceclassif": 239, "tfxlmformultiplechoic": 239, "tfxlmfortokenclassif": 239, "tfxlmforquestionansweringsimpl": 239, "xlmprophetnetconfig": 240, "xlmprophetnettoken": 240, "xlmprophetnetmodel": 240, "xlmprophetnetencod": 240, "xlmprophetnetdecod": 240, "xlmprophetnetforconditionalgener": 240, "xlmprophetnetforcausallm": 240, "xlmrobertaconfig": 241, "xlmrobertatoken": 241, "xlmrobertatokenizerfast": 241, "xlmrobertamodel": 241, "xlmrobertaforcausallm": 241, "xlmrobertaformaskedlm": 241, "xlmrobertaforsequenceclassif": 241, "xlmrobertaformultiplechoic": 241, "xlmrobertafortokenclassif": 241, "xlmrobertaforquestionansw": 241, "tfxlmrobertamodel": 241, "tfxlmrobertaformaskedlm": 241, "tfxlmrobertaforsequenceclassif": 241, "tfxlmrobertaformultiplechoic": 241, "tfxlmrobertafortokenclassif": 241, "tfxlmrobertaforquestionansw": 241, "xlnetconfig": 242, "xlnettoken": 242, "xlnettokenizerfast": 242, "xlnetmodel": 242, "xlnetlmheadmodel": 242, "xlnetforsequenceclassif": 242, "xlnetformultiplechoic": 242, "xlnetfortokenclassif": 242, "xlnetforquestionansweringsimpl": 242, "xlnetforquestionansw": 242, "tfxlnetmodel": 242, "tfxlnetlmheadmodel": 242, "tfxlnetforsequenceclassif": 242, "tflnetformultiplechoic": 242, "tfxlnetfortokenclassif": 242, "tfxlnetforquestionansweringsimpl": 242, "upload": [243, 286], "version": [243, 280, 282, 293, 294, 295, 297, 299, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 316], "make": [243, 288, 291, 382, 385], "directori": [243, 254], "befor": 243, "push": 243, "card": [243, 283], "colab": [243, 260], "autoregress": 244, "autoencod": 244, "multimod": 244, "mmbt": 244, "retriev": [244, 275], "technic": 244, "spars": 244, "trick": [244, 276], "languag": [245, 253, 259, 270, 274, 281, 293], "embed": [245, 261], "perplex": 247, "fix": 247, "length": [247, 252], "calcul": 247, "ppl": 247, "philosophi": 248, "concept": 248, "pair": [249, 255], "sentenc": 249, "everyth": 249, "know": 249, "about": 249, "pad": 249, "truncat": 249, "under": 251, "hood": 251, "onnxruntim": 252, "torchscript": 252, "implic": 252, "flag": 252, "ti": 252, "dummi": 252, "trace": 252, "extract": 253, "causal": [253, 259], "recognit": 253, "summar": [253, 265, 276, 279], "translat": [253, 276, 279], "choos": 254, "which": 254, "modifi": [254, 309], "rerun": 254, "fail": 254, "modif": [254, 286], "skip": 254, "clear": 254, "state": 254, "parallel": 254, "repetit": 254, "repeat": 254, "look": 254, "feel": 254, "variat": 254, "pytest": 254, "sugar": 254, "sub": 254, "instantli": 254, "show": 254, "captur": 254, "color": 254, "control": [254, 274, 374], "send": 254, "pastebin": 254, "servic": 254, "parametr": 254, "slow": 254, "stdout": 254, "stderr": 254, "logger": 254, "stream": 254, "ci": 254, "subword": 255, "byte": 255, "bpe": 255, "level": 255, "wordpiec": 255, "unigram": 255, "freez": 256, "import": [257, 291, 323, 388], "big": 257, "tpu": 257, "track": 257, "bias": 257, "comet": 257, "ml": 257, "whole": [259, 270], "word": [259, 270, 274], "permut": 259, "choic": 260, "swag": 260, "squad1": 261, "beam": 261, "squad2": 261, "previous": 261, "hyper": [261, 272], "rel": 261, "adversari": 263, "patienc": 264, "earli": [264, 266], "exit": [264, 266], "author": 265, "roug": 265, "score": 265, "ani": 265, "deebert": 266, "train_deebert": 266, "sh": 266, "eval_deebert": 266, "entropy_ev": 266, "b": 267, "long": 268, "form": 268, "mm": 271, "movement": 272, "adapt": [272, 362, 363, 364, 365, 371], "sparsiti": 272, "extrem": 272, "effici": 272, "storag": 272, "after": 272, "speed": [272, 321], "plug": 274, "plai": 274, "simpl": 274, "pplm": 274, "bow": 274, "bag": 274, "hyperparamet": 274, "discrim": 274, "discrimin": 274, "sentiment": 274, "intro": [275, 298, 308], "end": [275, 321, 390], "own": [275, 322], "xsum": 276, "dailymail": 276, "wmt16": 276, "english": 276, "romanian": 276, "wmt": 276, "german": [276, 282], "tip": 276, "param": 276, "lightn": 276, "batch": 276, "size": 276, "mt": 276, "distilbart": 276, "recommend": 276, "initi": [276, 317], "sft": 276, "No": [276, 323], "pseudo": [276, 277], "direct": [276, 317], "kd": 276, "pseudolabel": 277, "classifi": 278, "csv": [279, 391], "jsonfil": 279, "germev": 282, "2014": 282, "ner": 282, "process": [282, 368], "live": 283, "insid": 283, "co": 283, "happen": 283, "here": 283, "intend": 284, "limit": 284, "procedur": 284, "bibtex": 284, "info": 284, "hug": 285, "camelcas": 288, "sure": [288, 291], "ve": [288, 291], "understood": [288, 291], "cookiecutt": [289, 290], "modelnam": 290, "camelcase_modelnam": 290, "tokenizerfast": 290, "formaskedlm": 290, "forsequenceclassif": 290, "formultiplechoic": 290, "fortokenclassif": 290, "forquestionansw": 290, "forcausallm": 290, "tf": 290, "bigbird": 291, "neural_compressor": [293, 294, 295, 296, 297, 299, 301, 302, 303, 304, 305, 307, 311, 312, 313, 314, 316, 371], "seq2seq": [293, 301], "onc": [295, 304], "For": [295, 304, 365], "pruner": [298, 308], "two": [299, 312, 313, 314], "summarization_billsum": 301, "sst": [302, 303, 304, 305, 307, 308], "mnli": [302, 303, 304, 307], "qqp": [302, 303, 304, 307], "cola": 302, "qnli": [303, 304, 307], "while": 309, "sst2": 309, "extern": 309, "notic": 310, "includ": [311, 312, 314, 315, 326, 329, 337], "batch_siz": [311, 312, 314, 315, 326, 329, 337], "throughput": [311, 312, 314, 315, 326, 329, 337], "shaplei": 311, "uncas": 315, "machin": 317, "separ": 317, "bia": 317, "qualiti": 317, "target": 317, "frequenc": [317, 374], "thorough": 317, "imagelist": 319, "boxlist": 319, "docker": 320, "zoo": [321, 322], "mmdetect": 321, "memori": 321, "highlight": 322, "webcam": [322, 323], "troubleshoot": [322, 323], "maskrcnn": 322, "compil": [323, 365], "importerror": 323, "maskrcnn_benchmark": 323, "undefin": 323, "symbol": 323, "__cudapopcallconfigur": 323, "_c": 323, "fault": 323, "core": 323, "symlink": 324, "pascal": 324, "annot": [324, 331], "ssd_resnet34": [326, 329, 365], "brief": [326, 337], "upscal": 327, "resnet34": 328, "quant": 329, "clone": 331, "credit": 331, "increment": 331, "improv": 331, "dlrm": 335, "agreement": 335, "cla": 335, "rnnt": 337, "hubert": 338, "vit": 340, "abov": [354, 355], "tensorflow_model_optim": 355, "up2": 357, "8": [357, 358, 366, 368, 369], "9": [357, 358, 366, 368], "vgg": 357, "16": 357, "19": 357, "13": 357, "101": 357, "152": 357, "121": 357, "17": 357, "161": 357, "18": 357, "169": 357, "20": 357, "b0": 357, "resnet_v1_50": 358, "resnet_v1_101": 358, "resnet_v1_152": 358, "resnet_v2_50": 358, "resnet_v2_101": 358, "resnet_v2_152": 358, "inception_v1": 358, "inception_v2": 358, "inception_v4": 358, "vgg19": 358, "frozen": [360, 364, 368], "pb": [360, 365, 366, 368], "dev202242": 362, "q_dataload": [362, 363, 364, 365], "lt": 363, "transformer_lt_mlperf": 364, "protocol": 365, "buffer": 365, "autom": [365, 371, 382, 385], "ssd_resnet50_v1": 365, "ssd_mobilenet_v1": 365, "faster_rcnn_inception_resnet_v2": 365, "faster_rcnn_resnet101": 365, "faster_rcnn_resnet50": 365, "mask_rcnn_inception_v2": 365, "ckpt": 365, "yolo": 366, "yolo_v3": 366, "cocoraw": 366, "yolo_v3_itex": 366, "below": 366, "wnd": 368, "brat": 369, "deeplab": 370, "section": 372, "coder": [373, 375, 377], "we": 373, "offer": 373, "lab": 373, "contact": 373, "platform": 374, "mkl": 374, "openmp": 374, "jemalloc": 374, "numa": 374, "govern": 374, "superbench": 375, "launcher": 376, "changelog": [379, 383], "neural_compressor_ext_lab": [380, 382], "uninstal": [380, 384], "Or": 381, "let": 381, "help": [381, 390], "requisit": 381, "npm": [382, 385], "publish": [382, 385], "forg": [382, 385], "neural_compressor_ext_lab_alibaba": [384, 385], "execut": [387, 391], "endpoint": [387, 391], "databas": 389, "scaffold": 390, "unit": 390, "further": 390, "delet": 391, "pin": 391, "boundari": 391, "node": 391, "dictionari": 391, "domain": 391, "flavour": 391, "specifi": 391}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Type of Change": [[0, "type-of-change"]], "Description": [[0, "description"], [327, "description"]], "Expected Behavior & Potential Risk": [[0, "expected-behavior-potential-risk"]], "How has this PR been tested?": [[0, "how-has-this-pr-been-tested"]], "Dependency Change?": [[0, "dependency-change"]], "Intel\u00ae Neural Compressor": [[1, "intel-neural-compressor"]], "Installation": [[1, "installation"], [32, "installation"], [36, "installation"], [129, "installation"], [143, "installation"], [152, "installation"], [160, "installation"], [172, "installation"], [189, "installation"], [320, "installation"], [322, "installation"], [331, "installation"], [381, "installation"]], "Prerequisites": [[1, "prerequisites"], [36, "prerequisites"], [36, "id1"], [120, "prerequisites"], [121, "prerequisites"]], "Install on Linux": [[1, "install-on-linux"]], "Getting Started": [[1, "getting-started"], [32, "getting-started"]], "Quantization with Python API": [[1, "quantization-with-python-api"]], "Quantization with JupyterLab Extension": [[1, "quantization-with-jupyterlab-extension"]], "Quantization with GUI": [[1, "quantization-with-gui"]], "System Requirements": [[1, "system-requirements"], [32, "system-requirements"]], "Validated Hardware Environment": [[1, "validated-hardware-environment"]], "Intel\u00ae Neural Compressor supports CPUs based on Intel 64 architecture or compatible processors:": [[1, "intel-neural-compressor-supports-cpus-based-on-intel-64-architecture-or-compatible-processors"]], "Intel\u00ae Neural Compressor supports GPUs built on Intel\u2019s Xe architecture:": [[1, "intel-neural-compressor-supports-gpus-built-on-intel-s-xe-architecture"]], "Intel\u00ae Neural Compressor quantized ONNX models support multiple hardware vendors through ONNX Runtime:": [[1, "intel-neural-compressor-quantized-onnx-models-support-multiple-hardware-vendors-through-onnx-runtime"]], "Validated Software Environment": [[1, "validated-software-environment"]], "Validated Models": [[1, "validated-models"], [32, "validated-models"], [50, "validated-models"], [57, "validated-models"]], "Documentation": [[1, "documentation"], [143, "documentation"]], "Selected Publications/Events": [[1, "selected-publications-events"]], "Additional Content": [[1, "additional-content"]], "Hiring": [[1, "hiring"]], "Security Policy": [[2, "security-policy"]], "Report a Vulnerability": [[2, "report-a-vulnerability"]], "API Reference": [[3, "api-reference"]], "APIs": [[4, "apis"]], "Benchmark": [[5, "benchmark"], [47, "benchmark"], [69, "benchmark"], [79, "benchmark"], [80, "benchmark"], [81, "benchmark"], [82, "benchmark"], [83, "benchmark"], [85, "benchmark"], [86, "benchmark"], [87, "benchmark"], [88, "benchmark"], [90, "benchmark"], [91, "benchmark"], [92, "benchmark"], [93, "benchmark"], [94, "benchmark"], [95, "benchmark"], [96, "benchmark"], [97, "benchmark"], [98, "benchmark"], [99, "benchmark"], [100, "benchmark"], [101, "benchmark"], [102, "benchmark"], [103, "benchmark"], [103, "id1"], [104, "benchmark"], [105, "benchmark"], [107, "benchmark"], [108, "benchmark"], [110, "benchmark"], [111, "benchmark"], [112, "benchmark"], [113, "benchmark"], [117, "benchmark"], [118, "benchmark"], [359, "benchmark"], [360, "benchmark"], [370, "benchmark"], [391, "benchmark"]], "Objective": [[6, "objective"], [42, "objective"]], "Pruning": [[7, "pruning"], [45, "pruning"], [47, "pruning"], [59, "pruning"], [59, "id2"], [306, "pruning"]], "Quantization": [[8, "quantization"], [47, "quantization"], [48, "quantization"], [59, "quantization"], [59, "id1"], [59, "id4"], [77, "quantization"], [78, "quantization"], [79, "quantization"], [80, "quantization"], [81, "quantization"], [82, "quantization"], [83, "quantization"], [84, "quantization"], [85, "quantization"], [86, "quantization"], [87, "quantization"], [88, "quantization"], [89, "quantization"], [90, "quantization"], [91, "quantization"], [92, "quantization"], [93, "quantization"], [94, "quantization"], [95, "quantization"], [96, "quantization"], [97, "quantization"], [98, "quantization"], [99, "quantization"], [100, "quantization"], [101, "quantization"], [102, "quantization"], [104, "quantization"], [105, "quantization"], [107, "quantization"], [108, "quantization"], [109, "quantization"], [110, "quantization"], [111, "quantization"], [112, "quantization"], [113, "quantization"], [114, "quantization"], [115, "quantization"], [116, "quantization"], [117, "quantization"], [118, "quantization"], [252, "quantization"]], "build Neural Compressor(INC) Containers:": [[9, "build-neural-compressor-inc-containers"]], "To build the the Pip based deployment container:": [[9, "to-build-the-the-pip-based-deployment-container"]], "To build the the Pip based development container:": [[9, "to-build-the-the-pip-based-development-container"]], "Check the Containers built:": [[9, "check-the-containers-built"]], "Contributor Covenant Code of Conduct": [[10, "contributor-covenant-code-of-conduct"], [20, "contributor-covenant-code-of-conduct"], [157, "contributor-covenant-code-of-conduct"]], "Our Pledge": [[10, "our-pledge"], [20, "our-pledge"], [157, "our-pledge"]], "Our Standards": [[10, "our-standards"], [20, "our-standards"], [157, "our-standards"]], "Our Responsibilities": [[10, "our-responsibilities"], [20, "our-responsibilities"]], "Scope": [[10, "scope"], [20, "scope"], [157, "scope"]], "Enforcement": [[10, "enforcement"], [20, "enforcement"], [157, "enforcement"]], "Attribution": [[10, "attribution"], [20, "attribution"], [157, "attribution"]], "FX": [[11, "fx"]], "Overview": [[11, "overview"], [191, "overview"], [193, "overview"], [194, "overview"], [195, "overview"], [196, "overview"], [197, "overview"], [198, "overview"], [199, "overview"], [200, "overview"], [201, "overview"], [202, "overview"], [203, "overview"], [204, "overview"], [205, "overview"], [206, "overview"], [207, "overview"], [208, "overview"], [209, "overview"], [211, "overview"], [212, "overview"], [213, "overview"], [214, "overview"], [215, "overview"], [216, "overview"], [217, "overview"], [218, "overview"], [219, "overview"], [220, "overview"], [221, "overview"], [224, "overview"], [225, "overview"], [226, "overview"], [227, "overview"], [228, "overview"], [229, "overview"], [230, "overview"], [231, "overview"], [232, "overview"], [233, "overview"], [234, "overview"], [235, "overview"], [236, "overview"], [237, "overview"], [238, "overview"], [239, "overview"], [240, "overview"], [241, "overview"], [242, "overview"], [290, "overview"]], "Usage": [[11, "usage"], [14, "usage"], [53, "usage"], [53, "id2"], [55, "usage"], [55, "id2"], [55, "id4"], [55, "id6"], [55, "id8"], [55, "id10"], [55, "id12"], [129, "usage"], [133, "usage"], [198, "usage"], [266, "usage"], [278, "usage"], [289, "usage"], [298, "usage"], [308, "usage"], [377, "usage"]], "Note": [[11, "note"], [72, "note"]], "Details": [[11, "details"], [120, "details"]], "Common Problem": [[11, "common-problem"]], "Dynamic Quantization": [[11, "dynamic-quantization"], [28, "dynamic-quantization"]], "Static Quantization & Quantization Aware Training": [[11, "static-quantization-quantization-aware-training"]], "Neural Architecture Search": [[12, "neural-architecture-search"]], "Introduction": [[12, "introduction"], [15, "introduction"], [16, "introduction"], [18, "introduction"], [24, "introduction"], [25, "introduction"], [26, "introduction"], [31, "introduction"], [33, "introduction"], [35, "introduction"], [38, "introduction"], [39, "introduction"], [40, "introduction"], [41, "introduction"], [42, "introduction"], [43, "introduction"], [45, "introduction"], [47, "introduction"], [53, "introduction"], [55, "introduction"], [56, "introduction"], [62, "introduction"], [72, "introduction"], [73, "introduction"], [74, "introduction"], [121, "introduction"], [255, "introduction"], [386, "introduction"]], "NAS API": [[12, "nas-api"]], "Basic Usage": [[12, "basic-usage"]], "1. Python code + YAML": [[12, "python-code-yaml"]], "2. Python code only": [[12, "python-code-only"]], "Advanced Usage (Custom NAS)": [[12, "advanced-usage-custom-nas"]], "Basic NAS": [[12, "basic-nas"]], "Dynamic NAS": [[12, "dynamic-nas"]], "Examples": [[12, "examples"], [14, "examples"], [19, "examples"], [24, "examples"], [25, "examples"], [29, "examples"], [32, "examples"], [33, "examples"], [39, "examples"], [40, "examples"], [43, "examples"], [45, "examples"], [48, "examples"], [53, "examples"], [53, "id3"], [59, "examples"], [129, "examples"], [193, "examples"], [194, "examples"], [222, "examples"], [227, "examples"], [257, "examples"], [273, "examples"], [298, "examples"], [308, "examples"], [391, "examples"], [391, "id1"]], "PTQ": [[13, "ptq"], [13, "id1"]], "Design": [[13, "design"], [14, "design"], [23, "design"], [53, "design"], [53, "id1"], [55, "design"], [55, "id1"], [55, "id3"], [55, "id5"], [55, "id7"], [55, "id9"], [55, "id11"]], "PyTorch Usage": [[13, "pytorch-usage"]], "MobileNetV2 Model Architecture": [[13, "mobilenetv2-model-architecture"]], "Helper Functions": [[13, "helper-functions"]], "Example": [[13, "example"], [42, "example"], [75, "example"], [377, "example"], [387, "example"]], "Quantization-aware Training": [[14, "quantization-aware-training"]], "Adaptor": [[15, "adaptor"]], "Adaptor Support Matrix": [[15, "adaptor-support-matrix"]], "Working Flow": [[15, "working-flow"], [48, "working-flow"]], "Get Start with Adaptor API": [[15, "get-start-with-adaptor-api"]], "Query API": [[15, "query-api"]], "Background": [[15, "background"], [73, "background"], [74, "background"]], "Query API Introduction": [[15, "query-api-introduction"]], "Example of Adding a New Backend Support": [[15, "example-of-adding-a-new-backend-support"]], "Capability": [[15, "capability"]], "Implement ONNXRTAdaptor Class": [[15, "implement-onnxrtadaptor-class"]], "API Documentation": [[16, "api-documentation"]], "User-facing APIs": [[16, "user-facing-apis"], [34, "user-facing-apis"]], "Experimental user-facing APIs": [[16, "experimental-user-facing-apis"]], "Quantization-related APIs": [[16, "quantization-related-apis"]], "Pruning-related APIs (POC)": [[16, "pruning-related-apis-poc"]], "Benchmarking-related APIs": [[16, "benchmarking-related-apis"]], "Default user-facing APIs": [[16, "default-user-facing-apis"]], "Quantization Support Matrix": [[17, "quantization-support-matrix"]], "TensorFlow": [[17, "tensorflow"], [22, "tensorflow"], [38, "tensorflow"], [54, "tensorflow"]], "PyTorch": [[17, "pytorch"], [22, "pytorch"], [38, "pytorch"], [49, "pytorch"]], "PyTorch IPEX": [[17, "pytorch-ipex"]], "MXNet": [[17, "mxnet"], [22, "mxnet"], [38, "mxnet"], [54, "mxnet"]], "ONNX Runtime": [[17, "onnx-runtime"]], "Reference": [[17, "reference"], [139, "reference"]], "Intel\u00ae Neural Compressor Bench": [[18, "intel-neural-compressor-bench"], [391, "intel-neural-compressor-bench"]], "Table of Contents": [[18, "table-of-contents"], [129, "table-of-contents"], [139, "table-of-contents"], [391, "table-of-contents"]], "Install Intel\u00ae Neural Compressor with Bench": [[18, "install-intel-neural-compressor-with-bench"]], "Option 1 Install from binary": [[18, "option-1-install-from-binary"], [36, "option-1-install-from-binary"], [36, "id2"]], "Option 2 Install from source": [[18, "option-2-install-from-source"], [36, "option-2-install-from-source"], [36, "id3"]], "Start the Intel\u00ae Neural Compressor Bench": [[18, "start-the-intel-neural-compressor-bench"]], "Home screen": [[18, "home-screen"]], "Create new project": [[18, "create-new-project"]], "Predefined model": [[18, "predefined-model"]], "Custom model": [[18, "custom-model"], [331, "custom-model"]], "Display model graph": [[18, "display-model-graph"]], "Project list": [[18, "project-list"]], "Remove project": [[18, "remove-project"]], "Develop the project": [[18, "develop-the-project"]], "Optimization tab": [[18, "optimization-tab"]], "Optimization table": [[18, "optimization-table"]], "Optimization wizard": [[18, "optimization-wizard"]], "Editing optimization entries": [[18, "editing-optimization-entries"]], "Optimization details": [[18, "optimization-details"]], "Benchmark tab": [[18, "benchmark-tab"]], "Benchmark table": [[18, "benchmark-table"]], "Benchmark wizard": [[18, "benchmark-wizard"]], "Editing benchmark entries": [[18, "editing-benchmark-entries"]], "Benchmark details": [[18, "benchmark-details"]], "Profiling tab": [[18, "profiling-tab"]], "Profiling table": [[18, "profiling-table"]], "Profiling wizard": [[18, "profiling-wizard"]], "Editing profiling entries": [[18, "editing-profiling-entries"]], "Profiling details": [[18, "profiling-details"]], "Diagnosis tab": [[18, "diagnosis-tab"]], "Dataset tab": [[18, "dataset-tab"]], "Dataset list": [[18, "dataset-list"]], "Dataset wizard": [[18, "dataset-wizard"]], "Dataset details": [[18, "dataset-details"]], "Custom dataset": [[18, "custom-dataset"]], "Project information": [[18, "project-information"]], "System information": [[18, "system-information"]], "Security": [[18, "security"]], "Benchmarking": [[19, "benchmarking"]], "Config evaluation filed in a yaml file": [[19, "config-evaluation-filed-in-a-yaml-file"]], "Use a user-specific dataloader to run benchmark": [[19, "use-a-user-specific-dataloader-to-run-benchmark"]], "Contribution Guidelines": [[20, "contribution-guidelines"]], "Pull Request Checklist": [[20, "pull-request-checklist"]], "Pull Request Template": [[20, "pull-request-template"]], "Support": [[20, "support"]], "DataLoader": [[21, "dataloader"]], "How to use it": [[21, "how-to-use-it"], [33, "how-to-use-it"], [41, "how-to-use-it"]], "Config dataloader in a yaml file": [[21, "config-dataloader-in-a-yaml-file"]], "Create a user-specific dataloader": [[21, "create-a-user-specific-dataloader"]], "Dataset": [[22, "dataset"], [328, "dataset"], [391, "dataset"]], "Built-in dataset support list": [[22, "built-in-dataset-support-list"]], "ONNXRT": [[22, "onnxrt"], [38, "onnxrt"], [54, "onnxrt"]], "User-specific dataset": [[22, "user-specific-dataset"]], "Architecture": [[23, "architecture"], [35, "architecture"]], "Workflow": [[23, "workflow"]], "Distillation": [[24, "distillation"], [47, "distillation"], [59, "distillation"], [59, "id3"], [276, "distillation"]], "Knowledge Distillation": [[24, "knowledge-distillation"]], "Intermediate Layer Knowledge Distillation": [[24, "intermediate-layer-knowledge-distillation"]], "Self Distillation": [[24, "self-distillation"]], "Distillation Support Matrix": [[24, "distillation-support-matrix"]], "Get Started with Distillation API": [[24, "get-started-with-distillation-api"]], "Distillation for Quantization": [[25, "distillation-for-quantization"]], "User-defined yaml": [[25, "user-defined-yaml"]], "Distributed Training and Inference (Evaluation)": [[26, "distributed-training-and-inference-evaluation"]], "horovod installation": [[26, "horovod-installation"]], "Distributed training and inference (evaluation)": [[26, "id1"]], "Option 1: pure yaml configuration": [[26, "option-1-pure-yaml-configuration"]], "Option2: user defined training function": [[26, "option2-user-defined-training-function"]], "horovodrun": [[26, "horovodrun"]], "security": [[26, "security"]], "Following examples are supported": [[26, "following-examples-are-supported"]], "Developer Documentation": [[27, "developer-documentation"], [32, "developer-documentation"]], "Get Started": [[27, "get-started"], [48, "get-started"]], "Deep Dive": [[27, "deep-dive"]], "Advanced Topics": [[27, "advanced-topics"]], "Frequently Asked Questions": [[30, "frequently-asked-questions"]], "Common Build Issues": [[30, "common-build-issues"]], "Issue 1:": [[30, "issue-1"]], "Issue 2:": [[30, "issue-2"]], "Issue 3:": [[30, "issue-3"]], "Framework YAML Configuration Files": [[31, "framework-yaml-configuration-files"]], "Supported Feature Matrix": [[31, "supported-feature-matrix"], [35, "supported-feature-matrix"], [47, "supported-feature-matrix"], [48, "supported-feature-matrix"], [56, "supported-feature-matrix"]], "Get started with Framework YAML Files": [[31, "get-started-with-framework-yaml-files"]], "Linux Installation": [[32, "linux-installation"], [36, "linux-installation"]], "Install from binary": [[32, "install-from-binary"], [32, "id1"]], "Install from source": [[32, "install-from-source"], [32, "id2"]], "Install from AI Kit": [[32, "install-from-ai-kit"]], "Windows Installation": [[32, "windows-installation"], [36, "windows-installation"]], "Validated Hardware/Software Environment": [[32, "validated-hardware-software-environment"]], "Graph Optimization": [[33, "graph-optimization"]], "FP32 Optimization": [[33, "fp32-optimization"]], "Auto-mixed Precision Optimization": [[33, "auto-mixed-precision-optimization"]], "Default auto-mixed precision": [[33, "default-auto-mixed-precision"]], "Auto-mixed precision with auto-tuning": [[33, "auto-mixed-precision-with-auto-tuning"]], "FP32 optimization": [[33, "id1"]], "Incompatible changes between v1.2 and v1.1": [[34, "incompatible-changes-between-v1-2-and-v1-1"]], "Built-in transform/dataset/metric APIs": [[34, "built-in-transform-dataset-metric-apis"]], "Infrastructure of Intel\u00ae Neural Compressor": [[35, "infrastructure-of-intel-neural-compressor"]], "Option 3 Install from AI Kit": [[36, "option-3-install-from-ai-kit"]], "Legal Information": [[37, "legal-information"]], "License": [[37, "license"], [73, "license"], [74, "license"], [120, "license"], [322, "license"], [335, "license"]], "Citation": [[37, "citation"], [136, "citation"], [160, "citation"], [264, "citation"], [266, "citation"], [267, "citation"], [272, "citation"], [276, "citation"]], "Trademarks": [[37, "trademarks"]], "Metrics": [[38, "metrics"]], "Supported Built-in Metric Matrix": [[38, "supported-built-in-metric-matrix"]], "Get Start with Metrics": [[38, "get-start-with-metrics"]], "Support Single-metric and Multi-metrics": [[38, "support-single-metric-and-multi-metrics"]], "Build Custom Metric with Python API": [[38, "build-custom-metric-with-python-api"]], "Mixed Precision": [[39, "mixed-precision"]], "Mixed Precision Support Matrix": [[39, "mixed-precision-support-matrix"]], "Get start with Mixed Precision API": [[39, "get-start-with-mixed-precision-api"]], "Model": [[40, "model"], [391, "model"]], "Supported Framework Model Matrix": [[40, "supported-framework-model-matrix"]], "Model Conversion": [[41, "model-conversion"]], "Single Objective": [[42, "single-objective"]], "Multiple Objectives": [[42, "multiple-objectives"]], "Objective Support Matrix": [[42, "objective-support-matrix"]], "Get Start with Objective API": [[42, "get-start-with-objective-api"]], "Config Single Objective": [[42, "config-single-objective"]], "Config Multiple Objectives": [[42, "config-multiple-objectives"]], "Config Custom Objective": [[42, "config-custom-objective"]], "Optimization Orchestration": [[43, "optimization-orchestration"]], "One-shot": [[43, "one-shot"]], "Multi-shot": [[43, "multi-shot"]], "Orchestration Support Matrix": [[43, "orchestration-support-matrix"]], "Get Started with Orchestration API": [[43, "get-started-with-orchestration-api"]], "SYSTEM CONFIGURATION": [[44, "system-configuration"]], "Neural Network Pruning": [[45, "neural-network-pruning"]], "Pruning Patterns": [[45, "pruning-patterns"]], "Pruning Criteria": [[45, "pruning-criteria"]], "Pruning Schedule": [[45, "pruning-schedule"]], "Pruning Support Matrix": [[45, "pruning-support-matrix"]], "Get Started with Pruning API": [[45, "get-started-with-pruning-api"]], "Full Publications/Events (44)": [[46, "full-publications-events-44"]], "2022 (26)": [[46, "id1"]], "2021 (14)": [[46, "id2"]], "2018 - 2020 (4)": [[46, "id3"]], "Pythonic Style Access for Configurations": [[47, "pythonic-style-access-for-configurations"]], "Pythonic API for User Configurations": [[47, "pythonic-api-for-user-configurations"], [47, "id1"]], "Pythonic API for Framework Configurations": [[47, "pythonic-api-for-framework-configurations"], [47, "id2"]], "Get Started with Pythonic API for Configurations": [[47, "get-started-with-pythonic-api-for-configurations"]], "NAS": [[47, "nas"]], "Quantization Introduction": [[48, "quantization-introduction"]], "Quantization Fundamentals": [[48, "quantization-fundamentals"]], "Quantization Approaches": [[48, "quantization-approaches"]], "Post Training Dynamic Quantization": [[48, "post-training-dynamic-quantization"]], "Post Training Static Quantization": [[48, "post-training-static-quantization"]], "Quantization Aware Training": [[48, "quantization-aware-training"]], "Accuracy Aware Tuning": [[48, "accuracy-aware-tuning"]], "Turn ON Auto Mixed Precision during Quantization": [[49, "turn-on-auto-mixed-precision-during-quantization"]], "Tensorflow": [[49, "tensorflow"], [260, "tensorflow"]], "Reference Examples": [[50, "reference-examples"]], "Release": [[51, "release"]], "Known Issues": [[51, "known-issues"]], "Incompatible Changes": [[51, "incompatible-changes"]], "SigOpt Strategy": [[52, "sigopt-strategy"]], "Preparation": [[52, "preparation"]], "SigOpt introduction": [[52, "sigopt-introduction"]], "Neural Compressor configuration": [[52, "neural-compressor-configuration"]], "Performance": [[52, "performance"], [77, "performance"], [78, "performance"], [84, "performance"], [89, "performance"], [109, "performance"], [114, "performance"], [115, "performance"], [116, "performance"]], "Benefit for Sigopt strategy": [[52, "benefit-for-sigopt-strategy"]], "Performance comparison of different strategies": [[52, "performance-comparison-of-different-strategies"]], "TensorBoard": [[53, "tensorboard"]], "PyTorch TensorBoard": [[53, "pytorch-tensorboard"]], "TensorFlow Tensorboard": [[53, "tensorflow-tensorboard"]], "Transform": [[54, "transform"]], "Transform support list": [[54, "transform-support-list"]], "Pytorch": [[54, "pytorch"]], "Tuning Strategies": [[55, "tuning-strategies"]], "Strategy Design": [[55, "strategy-design"]], "Configurations": [[55, "configurations"]], "Model-specific configurations": [[55, "model-specific-configurations"]], "Strategy tuning part-related configurations": [[55, "strategy-tuning-part-related-configurations"]], "Basic": [[55, "basic"]], "Bayesian": [[55, "bayesian"]], "MSE": [[55, "mse"]], "TPE": [[55, "tpe"]], "Exhaustive": [[55, "exhaustive"]], "Random": [[55, "random"]], "SigOpt": [[55, "sigopt"]], "Customize a New Tuning Strategy": [[55, "customize-a-new-tuning-strategy"]], "User YAML Configuration Files": [[56, "user-yaml-configuration-files"]], "Get started with User YAML Files": [[56, "get-started-with-user-yaml-files"]], "Validated MLPerf Models": [[57, "validated-mlperf-models"]], "Validated Quantization Examples": [[57, "validated-quantization-examples"]], "TensorFlow models with TensorFlow 2.10.0": [[57, "tensorflow-models-with-tensorflow-2-10-0"]], "PyTorch models with Torch 1.12.1+cpu in PTQ mode": [[57, "pytorch-models-with-torch-1-12-1-cpu-in-ptq-mode"]], "PyTorch models with Torch 1.12.1+cpu in QAT mode": [[57, "pytorch-models-with-torch-1-12-1-cpu-in-qat-mode"]], "PyTorch models with Torch and Intel\u00ae Extension for PyTorch* 1.11.0+cpu": [[57, "pytorch-models-with-torch-and-intel-extension-for-pytorch-1-11-0-cpu"]], "ONNX Models with ONNX Runtime 1.12.1": [[57, "onnx-models-with-onnx-runtime-1-12-1"]], "MXNet models with MXNet 1.7.0": [[57, "mxnet-models-with-mxnet-1-7-0"]], "Validated Pruning Examples": [[57, "validated-pruning-examples"]], "Validated Knowledge Distillation Examples": [[57, "validated-knowledge-distillation-examples"]], "Validated ONNX QDQ INT8 models on multiple hardware through ONNX Runtime": [[57, "validated-onnx-qdq-int8-models-on-multiple-hardware-through-onnx-runtime"]], "Introduction to Intel\u00ae Neural Compressor": [[58, "introduction-to-intel-neural-compressor"]], "Helloworld Examples": [[59, "helloworld-examples"]], "Notebook Examples": [[59, "notebook-examples"]], "TensorFlow Examples": [[59, "tensorflow-examples"]], "PyTorch  Examples": [[59, "pytorch-examples"]], "Orchestration": [[59, "orchestration"]], "ONNX Runtime Examples": [[59, "onnx-runtime-examples"]], "Hello World Examples": [[60, "hello-world-examples"]], "tf_example1 example": [[61, "tf-example1-example"]], "1. Installation": [[61, "installation"], [62, "installation"], [63, "installation"], [64, "installation"], [65, "installation"], [66, "installation"], [67, "installation"], [68, "installation"], [69, "installation"], [70, "installation"], [71, "installation"], [134, "installation"], [137, "installation"], [138, "installation"], [142, "installation"], [145, "installation"], [146, "installation"], [148, "installation"], [149, "installation"], [150, "installation"], [151, "installation"], [153, "installation"], [155, "installation"], [156, "installation"], [293, "installation"], [296, "installation"], [299, "installation"], [301, "installation"], [311, "installation"], [312, "installation"], [313, "installation"], [314, "installation"], [315, "installation"], [316, "installation"], [318, "installation"], [326, "installation"], [329, "installation"], [330, "installation"], [332, "installation"], [333, "installation"], [336, "installation"], [337, "installation"], [338, "installation"], [339, "installation"], [340, "installation"], [342, "installation"], [343, "installation"], [344, "installation"], [345, "installation"], [346, "installation"], [347, "installation"], [348, "installation"], [349, "installation"], [350, "installation"], [351, "installation"], [352, "installation"], [353, "installation"], [354, "installation"], [355, "installation"], [357, "installation"], [358, "installation"], [359, "installation"], [360, "installation"], [361, "installation"], [363, "installation"], [364, "installation"], [365, "installation"], [366, "installation"], [367, "installation"], [368, "installation"], [369, "installation"], [370, "installation"], [371, "installation"]], "2. Prepare Dataset": [[61, "prepare-dataset"], [63, "prepare-dataset"], [65, "prepare-dataset"], [66, "prepare-dataset"], [69, "prepare-dataset"], [71, "prepare-dataset"], [134, "prepare-dataset"], [137, "prepare-dataset"], [138, "prepare-dataset"], [142, "prepare-dataset"], [145, "prepare-dataset"], [146, "prepare-dataset"], [148, "prepare-dataset"], [149, "prepare-dataset"], [151, "prepare-dataset"], [153, "prepare-dataset"], [318, "prepare-dataset"], [326, "prepare-dataset"], [330, "prepare-dataset"], [332, "prepare-dataset"], [333, "prepare-dataset"], [336, "prepare-dataset"], [337, "prepare-dataset"], [338, "prepare-dataset"], [358, "prepare-dataset"]], "3. Download the FP32 model": [[61, "download-the-fp32-model"], [65, "download-the-fp32-model"], [66, "download-the-fp32-model"]], "4. Update the root of dataset in conf.yaml": [[61, "update-the-root-of-dataset-in-conf-yaml"], [65, "update-the-root-of-dataset-in-conf-yaml"], [66, "update-the-root-of-dataset-in-conf-yaml"]], "5. Run Command": [[61, "run-command"], [63, "run-command"], [65, "run-command"], [66, "run-command"]], "6. Introduction": [[61, "introduction"], [63, "introduction"], [65, "introduction"], [66, "introduction"]], "tf_example2 example": [[62, "tf-example2-example"]], "Step-by-Step": [[62, "step-by-step"], [69, "step-by-step"], [70, "step-by-step"], [71, "step-by-step"], [134, "step-by-step"], [137, "step-by-step"], [138, "step-by-step"], [142, "step-by-step"], [145, "step-by-step"], [146, "step-by-step"], [148, "step-by-step"], [149, "step-by-step"], [150, "step-by-step"], [151, "step-by-step"], [153, "step-by-step"], [155, "step-by-step"], [156, "step-by-step"], [293, "step-by-step"], [294, "step-by-step"], [295, "step-by-step"], [296, "step-by-step"], [297, "step-by-step"], [299, "step-by-step"], [301, "step-by-step"], [302, "step-by-step"], [303, "step-by-step"], [304, "step-by-step"], [305, "step-by-step"], [307, "step-by-step"], [311, "step-by-step"], [312, "step-by-step"], [313, "step-by-step"], [314, "step-by-step"], [315, "step-by-step"], [316, "step-by-step"], [318, "step-by-step"], [326, "step-by-step"], [329, "step-by-step"], [330, "step-by-step"], [332, "step-by-step"], [333, "step-by-step"], [336, "step-by-step"], [337, "step-by-step"], [338, "step-by-step"], [339, "step-by-step"], [340, "step-by-step"], [341, "step-by-step"], [342, "step-by-step"], [343, "step-by-step"], [344, "step-by-step"], [345, "step-by-step"], [346, "step-by-step"], [347, "step-by-step"], [348, "step-by-step"], [349, "step-by-step"], [350, "step-by-step"], [351, "step-by-step"], [352, "step-by-step"], [353, "step-by-step"], [354, "step-by-step"], [355, "step-by-step"], [357, "step-by-step"], [358, "step-by-step"], [359, "step-by-step"], [360, "step-by-step"], [361, "step-by-step"], [362, "step-by-step"], [363, "step-by-step"], [364, "step-by-step"], [365, "step-by-step"], [367, "step-by-step"], [368, "step-by-step"], [369, "step-by-step"], [370, "step-by-step"], [371, "step-by-step"]], "Prerequisite": [[62, "prerequisite"], [69, "prerequisite"], [70, "prerequisite"], [71, "prerequisite"], [134, "prerequisite"], [137, "prerequisite"], [138, "prerequisite"], [142, "prerequisite"], [145, "prerequisite"], [146, "prerequisite"], [148, "prerequisite"], [149, "prerequisite"], [150, "prerequisite"], [151, "prerequisite"], [153, "prerequisite"], [155, "prerequisite"], [156, "prerequisite"], [293, "prerequisite"], [294, "prerequisite"], [295, "prerequisite"], [296, "prerequisite"], [297, "prerequisite"], [299, "prerequisite"], [301, "prerequisite"], [302, "prerequisite"], [303, "prerequisite"], [304, "prerequisite"], [305, "prerequisite"], [307, "prerequisite"], [311, "prerequisite"], [312, "prerequisite"], [313, "prerequisite"], [314, "prerequisite"], [315, "prerequisite"], [316, "prerequisite"], [318, "prerequisite"], [326, "prerequisite"], [329, "prerequisite"], [330, "prerequisite"], [332, "prerequisite"], [333, "prerequisite"], [336, "prerequisite"], [337, "prerequisite"], [338, "prerequisite"], [339, "prerequisite"], [340, "prerequisite"], [341, "prerequisite"], [342, "prerequisite"], [343, "prerequisite"], [344, "prerequisite"], [345, "prerequisite"], [346, "prerequisite"], [347, "prerequisite"], [348, "prerequisite"], [349, "prerequisite"], [350, "prerequisite"], [351, "prerequisite"], [352, "prerequisite"], [353, "prerequisite"], [354, "prerequisite"], [355, "prerequisite"], [357, "prerequisite"], [358, "prerequisite"], [359, "prerequisite"], [360, "prerequisite"], [361, "prerequisite"], [362, "prerequisite"], [363, "prerequisite"], [364, "prerequisite"], [365, "prerequisite"], [366, "prerequisite"], [367, "prerequisite"], [368, "prerequisite"], [369, "prerequisite"], [370, "prerequisite"], [371, "prerequisite"]], "2. Prepare FP32 model": [[62, "prepare-fp32-model"]], "Run Command": [[62, "run-command"], [339, "run-command"], [342, "run-command"], [343, "run-command"], [344, "run-command"], [345, "run-command"], [346, "run-command"], [347, "run-command"], [348, "run-command"], [349, "run-command"], [350, "run-command"], [351, "run-command"], [352, "run-command"], [353, "run-command"], [355, "run-command"], [359, "run-command"], [360, "run-command"], [361, "run-command"], [362, "run-command"], [363, "run-command"], [364, "run-command"], [365, "run-command"], [371, "run-command"]], "1. Add inputs and outputs information into conf.yaml, to get the input and output tensor name please refer to helloworld/train.py.": [[62, "add-inputs-and-outputs-information-into-conf-yaml-to-get-the-input-and-output-tensor-name-please-refer-to-helloworld-train-py"]], "2. Define a customer dataloader for mnist": [[62, "define-a-customer-dataloader-for-mnist"]], "3. Define a customized metric": [[62, "define-a-customized-metric"]], "4. Use the customized data loader and metric for quantization": [[62, "use-the-customized-data-loader-and-metric-for-quantization"]], "5. Run quantized model": [[62, "run-quantized-model"]], "tf_example3 example": [[63, "tf-example3-example"]], "3. Prepare the FP32 model": [[63, "prepare-the-fp32-model"]], "4. Config dataloader in conf.yaml": [[63, "config-dataloader-in-conf-yaml"]], "tf_example4 example": [[64, "tf-example4-example"]], "2. Download the FP32 model": [[64, "download-the-fp32-model"], [68, "download-the-fp32-model"]], "3. Run Command": [[64, "run-command"], [67, "run-command"], [68, "run-command"]], "4. Introduction": [[64, "introduction"], [67, "introduction"], [68, "introduction"]], "tf_example5 example": [[65, "tf-example5-example"]], "tf_example6 example": [[66, "tf-example6-example"]], "tf_example7 example": [[67, "tf-example7-example"]], "2. Prepare Model": [[67, "prepare-model"]], "tf_example8 example": [[68, "tf-example8-example"]], "2. Prepare Pre-trained model": [[69, "prepare-pre-trained-model"]], "Run": [[69, "run"], [70, "run"], [71, "run"], [134, "run"], [137, "run"], [138, "run"], [142, "run"], [147, "run"], [148, "run"], [149, "run"], [150, "run"], [151, "run"], [152, "run"], [153, "run"], [156, "run"], [300, "run"], [315, "run"], [318, "run"], [326, "run"], [328, "run"], [329, "run"], [330, "run"], [332, "run"], [333, "run"], [336, "run"], [337, "run"], [338, "run"], [357, "run"], [358, "run"], [367, "run"], [370, "run"]], "ResNet18_v1": [[69, "resnet18-v1"]], "ResNet50_v1": [[69, "resnet50-v1"]], "ResNet152_v1": [[69, "resnet152-v1"]], "SqueezeNet1": [[69, "squeezenet1"]], "MobileNet1.0": [[69, "mobilenet1-0"]], "MobileNetv2_1.0": [[69, "mobilenetv2-1-0"]], "Inception_v3": [[69, "inception-v3"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on MXNet ResNet50": [[69, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-mxnet-resnet50"]], "User Code Analysis": [[69, "user-code-analysis"], [70, "user-code-analysis"], [71, "user-code-analysis"], [134, "user-code-analysis"], [137, "user-code-analysis"], [138, "user-code-analysis"], [142, "user-code-analysis"], [149, "user-code-analysis"], [150, "user-code-analysis"], [151, "user-code-analysis"], [153, "user-code-analysis"], [156, "user-code-analysis"], [293, "user-code-analysis"], [301, "user-code-analysis"], [311, "user-code-analysis"], [316, "user-code-analysis"], [318, "user-code-analysis"], [330, "user-code-analysis"], [332, "user-code-analysis"], [333, "user-code-analysis"], [336, "user-code-analysis"], [357, "user-code-analysis"], [358, "user-code-analysis"], [359, "user-code-analysis"], [360, "user-code-analysis"], [362, "user-code-analysis"], [363, "user-code-analysis"], [364, "user-code-analysis"], [365, "user-code-analysis"], [370, "user-code-analysis"], [371, "user-code-analysis"]], "Write Yaml config file": [[69, "write-yaml-config-file"], [70, "write-yaml-config-file"], [71, "write-yaml-config-file"], [138, "write-yaml-config-file"], [156, "write-yaml-config-file"], [293, "write-yaml-config-file"], [299, "write-yaml-config-file"], [301, "write-yaml-config-file"], [311, "write-yaml-config-file"], [312, "write-yaml-config-file"], [313, "write-yaml-config-file"], [314, "write-yaml-config-file"], [316, "write-yaml-config-file"], [332, "write-yaml-config-file"], [333, "write-yaml-config-file"], [336, "write-yaml-config-file"], [339, "write-yaml-config-file"], [342, "write-yaml-config-file"], [343, "write-yaml-config-file"], [344, "write-yaml-config-file"], [345, "write-yaml-config-file"], [346, "write-yaml-config-file"], [347, "write-yaml-config-file"], [348, "write-yaml-config-file"], [349, "write-yaml-config-file"], [350, "write-yaml-config-file"], [351, "write-yaml-config-file"], [352, "write-yaml-config-file"], [353, "write-yaml-config-file"], [357, "write-yaml-config-file"], [358, "write-yaml-config-file"], [359, "write-yaml-config-file"], [360, "write-yaml-config-file"], [361, "write-yaml-config-file"], [363, "write-yaml-config-file"], [364, "write-yaml-config-file"], [365, "write-yaml-config-file"], [370, "write-yaml-config-file"], [371, "write-yaml-config-file"]], "code update": [[69, "code-update"], [70, "code-update"], [71, "code-update"], [138, "code-update"], [156, "code-update"], [332, "code-update"], [333, "code-update"], [336, "code-update"], [357, "code-update"], [358, "code-update"]], "2. Dataset": [[70, "dataset"]], "3. Finetune model": [[70, "finetune-model"]], "bert_base MRPC": [[70, "bert-base-mrpc"]], "bert_base Squad": [[70, "bert-base-squad"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on MXNet BERT_base": [[70, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-mxnet-bert-base"]], "SSD-ResNet50_v1-VOC": [[71, "ssd-resnet50-v1-voc"]], "SSD-Mobilenet1.0-VOC": [[71, "ssd-mobilenet1-0-voc"]], "SSD-ResNet50_v1-COCO": [[71, "ssd-resnet50-v1-coco"]], "SSD-Mobilenet1.0-COCO": [[71, "ssd-mobilenet1-0-coco"]], "benchmark": [[71, "benchmark"], [332, "benchmark"], [333, "benchmark"], [336, "benchmark"], [358, "benchmark"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on MXNet Object detection": [[71, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-mxnet-object-detection"]], "Performance of FP32 Vs. INT8 ResNet50 Model": [[72, "performance-of-fp32-vs-int8-resnet50-model"]], "Steps": [[72, "steps"], [75, "steps"]], "Check CPU Support Intel\u00ae Deep Learning Boost": [[72, "check-cpu-support-intel-deep-learning-boost"]], "Setup Environment": [[72, "setup-environment"]], "Script": [[72, "script"]], "Activate Running Environment": [[72, "activate-running-environment"]], "Run Sample": [[72, "run-sample"]], "Check Result": [[72, "check-result"], [73, "check-result"], [74, "check-result"]], "Intel\u00ae Neural Compressor Sample for PyTorch*": [[73, "intel-neural-compressor-sample-for-pytorch"]], "Code": [[73, "code"], [74, "code"]], "Hardware Environment": [[73, "hardware-environment"], [74, "hardware-environment"]], "Running Environment": [[73, "running-environment"], [74, "running-environment"]], "Intel\u00ae DevCloud": [[73, "intel-devcloud"], [74, "intel-devcloud"]], "Getting Started with Intel\u00ae DevCloud": [[73, "getting-started-with-intel-devcloud"], [74, "getting-started-with-intel-devcloud"]], "Setup based on Intel\u00ae oneAPI AI Analytics Toolkit": [[73, "setup-based-on-intel-oneapi-ai-analytics-toolkit"], [74, "setup-based-on-intel-oneapi-ai-analytics-toolkit"]], "Run in Jupyter Notebook in Intel\u00ae DevCloud for oneAPI": [[73, "run-in-jupyter-notebook-in-intel-devcloud-for-oneapi"], [74, "run-in-jupyter-notebook-in-intel-devcloud-for-oneapi"]], "Run in SSH Login Intel\u00ae DevCloud for oneAPI": [[73, "run-in-ssh-login-intel-devcloud-for-oneapi"], [74, "run-in-ssh-login-intel-devcloud-for-oneapi"]], "Job Submit": [[73, "job-submit"], [74, "job-submit"]], "Check job status": [[73, "check-job-status"], [74, "check-job-status"]], "Check Result in Log File": [[73, "check-result-in-log-file"], [74, "check-result-in-log-file"]], "Check Result in PNG file": [[73, "check-result-in-png-file"], [74, "check-result-in-png-file"]], "Customer Server": [[73, "customer-server"], [74, "customer-server"]], "Install by PyPi": [[73, "install-by-pypi"], [74, "install-by-pypi"]], "Install by Conda": [[73, "install-by-conda"], [74, "install-by-conda"]], "Run by SSH": [[73, "run-by-ssh"], [74, "run-by-ssh"]], "Run by Jupyter Notebook": [[73, "run-by-jupyter-notebook"], [74, "run-by-jupyter-notebook"]], "Intel\u00ae Neural Compressor Sample for TensorFlow*": [[74, "intel-neural-compressor-sample-for-tensorflow"]], "Usage Example": [[75, "usage-example"], [227, "usage-example"]], "ONNX model quantization": [[76, "onnx-model-quantization"]], "Dynamic quantization": [[76, "dynamic-quantization"]], "How to use": [[76, "how-to-use"], [76, "id1"]], "Static quantization": [[76, "static-quantization"]], "Operator oriented with QLinearOps": [[76, "operator-oriented-with-qlinearops"]], "Tensor oriented (QDQ format)": [[76, "tensor-oriented-qdq-format"]], "Evaluate performance of ONNX Runtime(Emotion FERPlus)": [[77, "evaluate-performance-of-onnx-runtime-emotion-ferplus"]], "Environment": [[77, "environment"], [78, "environment"], [79, "environment"], [80, "environment"], [81, "environment"], [82, "environment"], [83, "environment"], [84, "environment"], [85, "environment"], [86, "environment"], [87, "environment"], [88, "environment"], [89, "environment"], [90, "environment"], [91, "environment"], [92, "environment"], [93, "environment"], [94, "environment"], [95, "environment"], [96, "environment"], [97, "environment"], [98, "environment"], [99, "environment"], [100, "environment"], [101, "environment"], [102, "environment"], [103, "environment"], [104, "environment"], [105, "environment"], [106, "environment"], [107, "environment"], [108, "environment"], [109, "environment"], [110, "environment"], [111, "environment"], [112, "environment"], [113, "environment"], [114, "environment"], [115, "environment"], [116, "environment"], [117, "environment"], [118, "environment"], [133, "environment"]], "Prepare model": [[77, "prepare-model"], [78, "prepare-model"], [79, "prepare-model"], [80, "prepare-model"], [81, "prepare-model"], [82, "prepare-model"], [83, "prepare-model"], [84, "prepare-model"], [85, "prepare-model"], [86, "prepare-model"], [87, "prepare-model"], [88, "prepare-model"], [89, "prepare-model"], [90, "prepare-model"], [91, "prepare-model"], [92, "prepare-model"], [93, "prepare-model"], [94, "prepare-model"], [95, "prepare-model"], [96, "prepare-model"], [97, "prepare-model"], [98, "prepare-model"], [99, "prepare-model"], [100, "prepare-model"], [101, "prepare-model"], [102, "prepare-model"], [103, "prepare-model"], [104, "prepare-model"], [105, "prepare-model"], [106, "prepare-model"], [108, "prepare-model"], [109, "prepare-model"], [110, "prepare-model"], [111, "prepare-model"], [112, "prepare-model"], [113, "prepare-model"], [114, "prepare-model"], [115, "prepare-model"], [116, "prepare-model"], [117, "prepare-model"], [118, "prepare-model"]], "Evaluate performance of ONNX Runtime(Ultra-lightweight face detection)": [[78, "evaluate-performance-of-onnx-runtime-ultra-lightweight-face-detection"]], "Evaluate performance of ONNX Runtime(Mobilenet v2)": [[79, "evaluate-performance-of-onnx-runtime-mobilenet-v2"]], "Evaluate performance of ONNX Runtime(Mobilenet v3)": [[80, "evaluate-performance-of-onnx-runtime-mobilenet-v3"]], "Evaluate performance of ONNX Runtime(Alexnet)": [[81, "evaluate-performance-of-onnx-runtime-alexnet"]], "Evaluate performance of ONNX Runtime(ArcFace)": [[82, "evaluate-performance-of-onnx-runtime-arcface"]], "Evaluate performance of ONNX Runtime(Caffenet)": [[83, "evaluate-performance-of-onnx-runtime-caffenet"]], "Evaluate performance of ONNX Runtime(Densenet)": [[84, "evaluate-performance-of-onnx-runtime-densenet"]], "Evaluate performance of ONNX Runtime(EfficientNet-Lite4)": [[85, "evaluate-performance-of-onnx-runtime-efficientnet-lite4"]], "Evaluate performance of ONNX Runtime(FCN)": [[86, "evaluate-performance-of-onnx-runtime-fcn"]], "Evaluate performance of ONNX Runtime(Googlenet)": [[87, "evaluate-performance-of-onnx-runtime-googlenet"]], "Evaluate performance of ONNX Runtime(Inception)": [[88, "evaluate-performance-of-onnx-runtime-inception"]], "Evaluate performance of ONNX Runtime(MNIST)": [[89, "evaluate-performance-of-onnx-runtime-mnist"]], "Evaluate performance of ONNX Runtime(Mobilenet)": [[90, "evaluate-performance-of-onnx-runtime-mobilenet"]], "Evaluate performance of ONNX Runtime(ResNet 50)": [[91, "evaluate-performance-of-onnx-runtime-resnet-50"], [96, "evaluate-performance-of-onnx-runtime-resnet-50"]], "Evaluate performance of ONNX Runtime(Shufflenet)": [[92, "evaluate-performance-of-onnx-runtime-shufflenet"]], "Evaluate performance of ONNX Runtime(Squeezenet)": [[93, "evaluate-performance-of-onnx-runtime-squeezenet"]], "Evaluate performance of ONNX Runtime(VGG16)": [[94, "evaluate-performance-of-onnx-runtime-vgg16"], [98, "evaluate-performance-of-onnx-runtime-vgg16"]], "Evaluate performance of ONNX Runtime(ZFNet)": [[95, "evaluate-performance-of-onnx-runtime-zfnet"]], "ResNet 50 from torchvision": [[96, "resnet-50-from-torchvision"]], "ResNet 50 from MLPerf": [[96, "resnet-50-from-mlperf"]], "Evaluate performance of ONNX Runtime(unet)": [[97, "evaluate-performance-of-onnx-runtime-unet"]], "Evaluate performance of ONNX Runtime(BERT)": [[99, "evaluate-performance-of-onnx-runtime-bert"], [105, "evaluate-performance-of-onnx-runtime-bert"]], "Dynamic quantization environment:": [[99, "dynamic-quantization-environment"]], "Static quantization environment:": [[99, "static-quantization-environment"]], "Prepare dataset": [[99, "prepare-dataset"], [100, "prepare-dataset"], [101, "prepare-dataset"], [102, "prepare-dataset"], [103, "prepare-dataset"], [105, "prepare-dataset"], [106, "prepare-dataset"], [107, "prepare-dataset"], [108, "prepare-dataset"], [144, "prepare-dataset"], [147, "prepare-dataset"], [301, "prepare-dataset"], [306, "prepare-dataset"]], "Evaluate performance of ONNX Runtime(DistilBERT)": [[100, "evaluate-performance-of-onnx-runtime-distilbert"]], "Evaluate performance of ONNX Runtime(Huggingface Question Answering)": [[101, "evaluate-performance-of-onnx-runtime-huggingface-question-answering"]], "Evaluate performance of ONNX Runtime(Huggingface Text Classification)": [[102, "evaluate-performance-of-onnx-runtime-huggingface-text-classification"]], "Evaluate performance of ONNX Runtime(MobileBERT)": [[103, "evaluate-performance-of-onnx-runtime-mobilebert"], [107, "evaluate-performance-of-onnx-runtime-mobilebert"]], "Evaluate performance of ONNX Runtime(BiDAF)": [[104, "evaluate-performance-of-onnx-runtime-bidaf"]], "Evaluate performance of ONNX Runtime(GPT2)": [[106, "evaluate-performance-of-onnx-runtime-gpt2"]], "Evaluating": [[106, "evaluating"]], "Evaluate performance of ONNX Runtime(RoBERTa)": [[108, "evaluate-performance-of-onnx-runtime-roberta"]], "Evaluate performance of ONNX Runtime(ResNet101-DUC)": [[109, "evaluate-performance-of-onnx-runtime-resnet101-duc"]], "Evaluate performance of ONNX Runtime(Faster R-CNN)": [[110, "evaluate-performance-of-onnx-runtime-faster-r-cnn"]], "Evaluate performance of ONNX Runtime(Mask R-CNN)": [[111, "evaluate-performance-of-onnx-runtime-mask-r-cnn"]], "Evaluate performance of ONNX Runtime(SSD)": [[112, "evaluate-performance-of-onnx-runtime-ssd"]], "Evaluate performance of ONNX Runtime(SSD Mobilenet v1)": [[113, "evaluate-performance-of-onnx-runtime-ssd-mobilenet-v1"], [117, "evaluate-performance-of-onnx-runtime-ssd-mobilenet-v1"]], "Evaluate performance of ONNX Runtime(Tiny-YOLOv3)": [[114, "evaluate-performance-of-onnx-runtime-tiny-yolov3"]], "Evaluate performance of ONNX Runtime(yolov3)": [[115, "evaluate-performance-of-onnx-runtime-yolov3"]], "Evaluate performance of ONNX Runtime(YOLOv4)": [[116, "evaluate-performance-of-onnx-runtime-yolov4"]], "Evaluate performance of ONNX Runtime(SSD Mobilenet v2)": [[118, "evaluate-performance-of-onnx-runtime-ssd-mobilenet-v2"]], "A example using Textual Inversion method to personalize text2image": [[119, "a-example-using-textual-inversion-method-to-personalize-text2image"]], "Installing the dependencies": [[119, "installing-the-dependencies"]], "Nezha cartoon example": [[119, "nezha-cartoon-example"]], "finetune with CPU using IPEX": [[119, "finetune-with-cpu-using-ipex"]], "Distributed": [[119, "distributed"], [147, "distributed"]], "finetune with GPU using accelerate": [[119, "finetune-with-gpu-using-accelerate"]], "Inference": [[119, "inference"], [264, "inference"], [331, "inference"]], "MLPerf Inference Benchmarks for Medical Image 3D Segmentation": [[120, "mlperf-inference-benchmarks-for-medical-image-3d-segmentation"]], "Supported Models": [[120, "supported-models"]], "Disclaimer": [[120, "disclaimer"]], "Commands": [[120, "commands"]], "Calibration Set": [[120, "calibration-set"]], "running cmd": [[121, "running-cmd"]], "Model Baseline": [[121, "model-baseline"]], "Data format for Inference": [[122, "data-format-for-inference"]], "Dataset conversion instructions": [[123, "dataset-conversion-instructions"]], "How to use decathlon datasets": [[123, "how-to-use-decathlon-datasets"]], "Extending/Changing nnU-Net": [[124, "extending-changing-nnu-net"], [129, "extending-changing-nnu-net"]], "Changes to blueprint parameters": [[124, "changes-to-blueprint-parameters"]], "Changes to Inferred Parameters": [[124, "changes-to-inferred-parameters"]], "Use a different network architecture": [[124, "use-a-different-network-architecture"]], "Example: inference with pretrained nnU-Net models": [[125, "example-inference-with-pretrained-nnu-net-models"]], "Setting up Paths": [[126, "setting-up-paths"]], "How to set environment variables": [[126, "how-to-set-environment-variables"]], "An alternative way of setting these paths": [[126, "an-alternative-way-of-setting-these-paths"]], "Example: 3D U-Net training on the Hippocampus dataset": [[127, "example-3d-u-net-training-on-the-hippocampus-dataset"]], "nnU-Net": [[129, "nnu-net"]], "How to run nnU-Net on a new dataset": [[129, "how-to-run-nnu-net-on-a-new-dataset"]], "Dataset conversion": [[129, "dataset-conversion"]], "Experiment planning and preprocessing": [[129, "experiment-planning-and-preprocessing"]], "Model training": [[129, "model-training"]], "2D U-Net": [[129, "d-u-net"]], "3D full resolution U-Net": [[129, "d-full-resolution-u-net"], [129, "id1"]], "3D U-Net cascade": [[129, "d-u-net-cascade"]], "3D low resolution U-Net": [[129, "d-low-resolution-u-net"]], "Multi GPU training": [[129, "multi-gpu-training"]], "Identifying the best U-Net configuration": [[129, "identifying-the-best-u-net-configuration"]], "Run inference": [[129, "run-inference"]], "How to run inference with pretrained models": [[129, "how-to-run-inference-with-pretrained-models"]], "FAQ": [[129, "faq"]], "Manual Splitting of Data": [[129, "manual-splitting-of-data"]], "Do I need to always run all U-Net configurations?": [[129, "do-i-need-to-always-run-all-u-net-configurations"]], "Sharing Models": [[129, "sharing-models"]], "Can I run nnU-Net on smaller GPUs?": [[129, "can-i-run-nnu-net-on-smaller-gpus"]], "I get the error seg from prev stage missing when running the cascade": [[129, "i-get-the-error-seg-from-prev-stage-missing-when-running-the-cascade"]], "Why am I getting RuntimeError: CUDA error: device-side assert triggered?": [[129, "why-am-i-getting-runtimeerror-cuda-error-device-side-assert-triggered"]], "Why is no 3d_lowres model created?": [[129, "why-is-no-3d-lowres-model-created"]], "CIFAR100 Distillation Example": [[130, "cifar100-distillation-example"], [132, "cifar100-distillation-example"]], "CIFAR10 Distillation Example": [[131, "cifar10-distillation-example"]], "(Generic) EfficientNets for PyTorch": [[133, "generic-efficientnets-for-pytorch"]], "What\u2019s New": [[133, "what-s-new"]], "April 5, 2020": [[133, "april-5-2020"]], "March 23, 2020": [[133, "march-23-2020"]], "Feb 12, 2020": [[133, "feb-12-2020"]], "Jan 22, 2020": [[133, "jan-22-2020"]], "Nov 22, 2019": [[133, "nov-22-2019"]], "Nov 15, 2019": [[133, "nov-15-2019"]], "Oct 30, 2019": [[133, "oct-30-2019"]], "Oct 27, 2019": [[133, "oct-27-2019"]], "Models": [[133, "models"], [171, null], [183, "models"]], "Pretrained": [[133, "pretrained"]], "Ported Weights": [[133, "ported-weights"]], "PyTorch Hub": [[133, "pytorch-hub"]], "Pip": [[133, "pip"]], "Exporting": [[133, "exporting"]], "1. Efficientnet_b0": [[134, "efficientnet-b0"]], "2. Mobilenetv3_rw": [[134, "mobilenetv3-rw"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on PyTorch ResNet": [[134, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-pytorch-resnet"], [137, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-pytorch-resnet"]], "Write Yaml Config File": [[134, "write-yaml-config-file"], [137, "write-yaml-config-file"], [142, "write-yaml-config-file"], [149, "write-yaml-config-file"], [150, "write-yaml-config-file"], [151, "write-yaml-config-file"], [151, "id1"], [153, "write-yaml-config-file"], [318, "write-yaml-config-file"], [330, "write-yaml-config-file"], [362, "write-yaml-config-file"]], "Prepare": [[134, "prepare"], [137, "prepare"], [142, "prepare"], [148, "prepare"], [149, "prepare"], [150, "prepare"], [151, "prepare"], [151, "id2"], [153, "prepare"], [300, "prepare"], [318, "prepare"], [330, "prepare"]], "Code Update": [[134, "code-update"], [137, "code-update"], [142, "code-update"], [148, "code-update"], [149, "code-update"], [151, "code-update"], [151, "id3"], [153, "code-update"], [318, "code-update"], [330, "code-update"], [362, "code-update"]], "Distributed MNIST Example": [[135, "distributed-mnist-example"]], "PeleeNet": [[136, "peleenet"]], "Results on ImageNet ILSVRC 2012": [[136, "results-on-imagenet-ilsvrc-2012"]], "3. Prepare pretrained model": [[137, "prepare-pretrained-model"], [332, "prepare-pretrained-model"], [333, "prepare-pretrained-model"], [336, "prepare-pretrained-model"]], "1. ResNest50": [[138, "resnest50"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on PyTorch ResNest": [[138, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-pytorch-resnest"], [156, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-pytorch-resnest"]], "prepare": [[138, "prepare"], [156, "prepare"], [332, "prepare"], [358, "prepare"]], "ResNeSt": [[139, "resnest"]], "Pypi / GitHub Install": [[139, "pypi-github-install"]], "Pretrained Models": [[139, "pretrained-models"], [140, "pretrained-models"]], "PyTorch Models": [[139, "pytorch-models"], [140, "pytorch-models"]], "Gluon Models": [[139, "gluon-models"], [140, "gluon-models"]], "Transfer Learning Models": [[139, "transfer-learning-models"]], "Detectron Models": [[139, "detectron-models"], [139, "id1"]], "Object Detection on MS-COCO validation set": [[139, "object-detection-on-ms-coco-validation-set"]], "Instance Segmentation": [[139, "instance-segmentation"]], "Panoptic Segmentation": [[139, "panoptic-segmentation"]], "Semantic Segmentation": [[139, "semantic-segmentation"], [139, "id2"]], "Results on ADE20K": [[139, "results-on-ade20k"]], "Results on Cityscapes": [[139, "results-on-cityscapes"]], "Verify Backbone Models:": [[139, "verify-backbone-models"]], "Prepare ImageNet dataset:": [[139, "prepare-imagenet-dataset"]], "Torch Model": [[139, "torch-model"]], "Gluon Model": [[139, "gluon-model"]], "How to Train": [[139, "how-to-train"]], "ImageNet Models": [[139, "imagenet-models"]], "Major Contributors": [[139, "major-contributors"]], "Train ResNeSt with MXNet Gluon": [[141, "train-resnest-with-mxnet-gluon"]], "Install MXNet with Horovod": [[141, "install-mxnet-with-horovod"]], "Prepare ImageNet recordio data format": [[141, "prepare-imagenet-recordio-data-format"]], "Training command": [[141, "training-command"]], "Verify pretrained model": [[141, "verify-pretrained-model"]], "Python First": [[142, "python-first"], [296, "python-first"]], "Install dependency": [[142, "install-dependency"], [293, "install-dependency"], [294, "install-dependency"], [295, "install-dependency"], [297, "install-dependency"], [299, "install-dependency"], [301, "install-dependency"], [302, "install-dependency"], [303, "install-dependency"], [304, "install-dependency"], [305, "install-dependency"], [307, "install-dependency"], [311, "install-dependency"], [312, "install-dependency"], [313, "install-dependency"], [314, "install-dependency"], [316, "install-dependency"]], "Install SE_ResNext model": [[142, "install-se-resnext-model"]], "SE_ResNext50_32x4d": [[142, "se-resnext50-32x4d"]], "Examples of enabling Intel\u00ae Neural Compressor": [[142, "examples-of-enabling-intel-neural-compressor"], [293, "examples-of-enabling-intel-neural-compressor"], [301, "examples-of-enabling-intel-neural-compressor"], [311, "examples-of-enabling-intel-neural-compressor"], [316, "examples-of-enabling-intel-neural-compressor"], [332, "examples-of-enabling-intel-neural-compressor"], [333, "examples-of-enabling-intel-neural-compressor"], [336, "examples-of-enabling-intel-neural-compressor"]], "Original SE_ResNext README": [[142, "original-se-resnext-readme"]], "Pretrained models for Pytorch (Work in progress)": [[143, "pretrained-models-for-pytorch-work-in-progress"]], "Summary": [[143, "summary"]], "Install from pip": [[143, "install-from-pip"]], "Install from repo": [[143, "install-from-repo"]], "Quick examples": [[143, "quick-examples"]], "Few use cases": [[143, "few-use-cases"]], "Compute imagenet logits": [[143, "compute-imagenet-logits"]], "Compute imagenet evaluation metrics": [[143, "compute-imagenet-evaluation-metrics"]], "Evaluation on imagenet": [[143, "evaluation-on-imagenet"]], "Accuracy on validation set (single model)": [[143, "accuracy-on-validation-set-single-model"]], "Reproducing results": [[143, "reproducing-results"]], "Available models": [[143, "available-models"]], "NASNet*": [[143, "nasnet"]], "FaceBook ResNet*": [[143, "facebook-resnet"]], "Caffe ResNet*": [[143, "caffe-resnet"]], "Inception*": [[143, "inception"]], "BNInception": [[143, "bninception"]], "ResNeXt*": [[143, "resnext"]], "DualPathNetworks": [[143, "dualpathnetworks"]], "Xception": [[143, "xception"]], "SENet*": [[143, "senet"]], "PNASNet*": [[143, "pnasnet"]], "PolyNet": [[143, "polynet"]], "TorchVision": [[143, "torchvision"]], "Model API": [[143, "model-api"]], "model.input_size": [[143, "model-input-size"]], "model.input_space": [[143, "model-input-space"]], "model.input_range": [[143, "model-input-range"]], "model.mean": [[143, "model-mean"]], "model.std": [[143, "model-std"]], "model.features": [[143, "model-features"]], "model.logits": [[143, "model-logits"]], "model.forward": [[143, "model-forward"]], "model.last_linear": [[143, "model-last-linear"]], "Reproducing": [[143, "reproducing"]], "Hand porting of ResNet152": [[143, "hand-porting-of-resnet152"]], "Automatic porting of ResNeXt": [[143, "automatic-porting-of-resnext"]], "Hand porting of NASNet, InceptionV4 and InceptionResNetV2": [[143, "hand-porting-of-nasnet-inceptionv4-and-inceptionresnetv2"]], "Acknowledgement": [[143, "acknowledgement"]], "Run pretraining": [[144, "run-pretraining"], [356, "run-pretraining"]], "3. Run": [[145, "run"], [146, "run"], [296, "run"]], "Run prune and PTQ": [[145, "run-prune-and-ptq"]], "Run prune only": [[145, "run-prune-only"]], "Run PTQ only": [[145, "run-ptq-only"]], "4. Scheduler": [[145, "scheduler"], [146, "scheduler"]], "Run qat during prune": [[146, "run-qat-during-prune"]], "Prepare an environment": [[147, "prepare-an-environment"]], "Prepare configuration": [[147, "prepare-configuration"]], "Non-distributed": [[147, "non-distributed"]], "Other notes": [[147, "other-notes"]], "1. ResNet50": [[148, "resnet50"], [149, "resnet50"], [151, "resnet50"], [153, "resnet50"]], "2. ResNet18": [[148, "resnet18"], [149, "resnet18"], [151, "resnet18"], [153, "resnet18"]], "3. ResNext101_32x8d": [[148, "resnext101-32x8d"], [151, "resnext101-32x8d"], [153, "resnext101-32x8d"]], "4. InceptionV3": [[148, "inceptionv3"], [149, "inceptionv3"]], "5. Mobilenet_v2": [[148, "mobilenet-v2"], [149, "mobilenet-v2"]], "6. ResNet50 dump tensors for debug": [[148, "resnet50-dump-tensors-for-debug"]], "Saving and loading model:": [[148, "saving-and-loading-model"], [149, "saving-and-loading-model"], [318, "saving-and-loading-model"]], "Dump tensors for debug": [[148, "dump-tensors-for-debug"], [149, "dump-tensors-for-debug"]], "3. ResNeXt101_32x8d": [[149, "resnext101-32x8d"]], "Examples of enabling Neural Compressor auto tuning on PyTorch ResNet": [[149, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet"], [150, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet"], [318, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet"]], "2. Install pytorch and intel-pytorch-extension": [[150, "install-pytorch-and-intel-pytorch-extension"]], "3. Prepare Dataset": [[150, "prepare-dataset"], [367, "prepare-dataset"]], "1. ResNet18 With Intel PyTorch Extension": [[150, "resnet18-with-intel-pytorch-extension"]], "2. ResNet50 With Intel PyTorch Extension": [[150, "resnet50-with-intel-pytorch-extension"]], "3. ResNext101_32x16d With Intel PyTorch Extension": [[150, "resnext101-32x16d-with-intel-pytorch-extension"]], "Saving model:": [[150, "saving-model"]], "Tuning With Intel PyTorch Extension": [[150, "tuning-with-intel-pytorch-extension"]], "Examples Of Enabling Neural Compressor Auto Tuning On PyTorch ResNet": [[151, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet"], [153, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet"]], "With buildin training function": [[151, "with-buildin-training-function"]], "Without buildin training function": [[151, "without-buildin-training-function"]], "4. MobileNetV2": [[151, "mobilenetv2"]], "distributed example on QAT": [[152, "distributed-example-on-qat"]], "Prepare requirements": [[154, "prepare-requirements"]], "Run self distillation": [[154, "run-self-distillation"]], "CIFAR100 benchmark": [[154, "cifar100-benchmark"]], "Paper:": [[154, "paper"]], "Our results in CIFAR100": [[154, "our-results-in-cifar100"]], "2. Prepare model and Dataset": [[155, "prepare-model-and-dataset"], [156, "prepare-model-and-dataset"]], "model": [[155, "model"], [156, "model"]], "3. Distillation of BlendCNN with BERT-Base as Teacher": [[155, "distillation-of-blendcnn-with-bert-base-as-teacher"], [156, "distillation-of-blendcnn-with-bert-base-as-teacher"]], "3.1 Fine-tune the pretrained BERT-Base model on MRPC dataset": [[155, "fine-tune-the-pretrained-bert-base-model-on-mrpc-dataset"], [156, "fine-tune-the-pretrained-bert-base-model-on-mrpc-dataset"]], "3.2 Distilling the BlendCNN with BERT-Base": [[155, "distilling-the-blendcnn-with-bert-base"], [156, "distilling-the-blendcnn-with-bert-base"]], "dataset": [[156, "dataset"]], "blendcnn": [[156, "blendcnn"]], "Enforcement Responsibilities": [[157, "enforcement-responsibilities"]], "Enforcement Guidelines": [[157, "enforcement-guidelines"]], "1. Correction": [[157, "correction"]], "2. Warning": [[157, "warning"]], "3. Temporary Ban": [[157, "temporary-ban"]], "4. Permanent Ban": [[157, "permanent-ban"]], "How to contribute to transformers?": [[158, "how-to-contribute-to-transformers"]], "You can contribute in so many ways!": [[158, "you-can-contribute-in-so-many-ways"]], "Submitting a new issue or feature request": [[158, "submitting-a-new-issue-or-feature-request"]], "Did you find a bug?": [[158, "did-you-find-a-bug"]], "Do you want to implement a new model?": [[158, "do-you-want-to-implement-a-new-model"]], "Do you want a new feature (that is not a model)?": [[158, "do-you-want-a-new-feature-that-is-not-a-model"]], "Start contributing! (Pull Requests)": [[158, "start-contributing-pull-requests"]], "Checklist": [[158, "checklist"]], "Tests": [[158, "tests"]], "Style guide": [[158, "style-guide"]], "This guide was heavily inspired by the awesome scikit-learn guide to contributing": [[158, "this-guide-was-heavily-inspired-by-the-awesome-scikit-learn-guide-to-contributing"]], "Develop on Windows": [[158, "develop-on-windows"]], "Syncing forked master with upstream (HuggingFace) master": [[158, "syncing-forked-master-with-upstream-huggingface-master"]], "How To Request Support": [[159, "how-to-request-support"]], "The Forums": [[159, "the-forums"]], "The GitHub Issues": [[159, "the-github-issues"]], "Online demos": [[160, "online-demos"]], "Quick tour": [[160, "quick-tour"], [251, "quick-tour"]], "Why should I use transformers?": [[160, "why-should-i-use-transformers"]], "Why shouldn\u2019t I use transformers?": [[160, "why-shouldn-t-i-use-transformers"]], "With pip": [[160, "with-pip"]], "With conda": [[160, "with-conda"], [172, "with-conda"]], "Models architectures": [[160, "models-architectures"]], "Learn more": [[160, "learn-more"]], "Generating the documentation": [[161, "generating-the-documentation"]], "Packages installed": [[161, "packages-installed"]], "Building the documentation": [[161, "building-the-documentation"]], "Adding a new element to the tree (toc-tree)": [[161, "adding-a-new-element-to-the-tree-toc-tree"]], "Preview the documentation in a pull request": [[161, "preview-the-documentation-in-a-pull-request"]], "Writing Documentation - Specification": [[161, "writing-documentation-specification"]], "Adding a new tutorial": [[161, "adding-a-new-tutorial"]], "Adding a new model": [[161, "adding-a-new-model"]], "Writing source documentation": [[161, "writing-source-documentation"]], "Defining arguments in a method": [[161, "defining-arguments-in-a-method"]], "Writing a multi-line code block": [[161, "writing-a-multi-line-code-block"]], "Writing a return block": [[161, "writing-a-return-block"]], "How to add a model to \ud83e\udd17 Transformers?": [[162, "how-to-add-a-model-to-transformers"]], "General overview of \ud83e\udd17 Transformers": [[162, "general-overview-of-transformers"], [288, "general-overview-of-transformers"], [291, "general-overview-of-transformers"]], "Overview of models": [[162, "overview-of-models"], [288, "overview-of-models"], [291, "overview-of-models"]], "Overview of tokenizers": [[162, "overview-of-tokenizers"], [288, "overview-of-tokenizers"], [291, "overview-of-tokenizers"]], "Step-by-step recipe to add a model to \ud83e\udd17 Transformers": [[162, "step-by-step-recipe-to-add-a-model-to-transformers"], [288, "step-by-step-recipe-to-add-a-model-to-transformers"], [291, "step-by-step-recipe-to-add-a-model-to-transformers"]], "1. (Optional) Theoretical aspects of BrandNewBert": [[162, "optional-theoretical-aspects-of-brandnewbert"]], "2. Next prepare your environment": [[162, "next-prepare-your-environment"], [288, "next-prepare-your-environment"], [291, "next-prepare-your-environment"]], "3.-4. Run a pretrained checkpoint using the original repository": [[162, "run-a-pretrained-checkpoint-using-the-original-repository"]], "5.-14. Port BrandNewBert to \ud83e\udd17 Transformers": [[162, "port-brandnewbert-to-transformers"]], "Share your work!!": [[162, "share-your-work"], [288, "share-your-work"], [291, "share-your-work"]], "Benchmarks": [[163, "benchmarks"]], "How to benchmark \ud83e\udd17 Transformer models": [[163, "how-to-benchmark-transformer-models"]], "Benchmark best practices": [[163, "benchmark-best-practices"]], "Sharing your benchmark": [[163, "sharing-your-benchmark"]], "BERTology": [[164, "bertology"]], "Community": [[165, "community"]], "Community resources:": [[165, "community-resources"]], "Community notebooks:": [[165, "community-notebooks"], [285, "community-notebooks"]], "Converting Tensorflow Checkpoints": [[167, "converting-tensorflow-checkpoints"]], "BERT": [[167, "bert"], [195, "bert"], [244, "bert"], [245, "bert"]], "ALBERT": [[167, "albert"], [191, "albert"], [244, "albert"]], "OpenAI GPT": [[167, "openai-gpt"], [214, "openai-gpt"]], "OpenAI GPT-2": [[167, "openai-gpt-2"]], "Transformer-XL": [[167, "transformer-xl"], [244, "transformer-xl"]], "XLNet": [[167, "xlnet"], [242, "xlnet"], [244, "xlnet"], [313, "xlnet"]], "XLM": [[167, "xlm"], [239, "xlm"], [244, "xlm"], [245, "xlm"]], "T5": [[167, "t5"], [235, "t5"], [244, "t5"]], "Fine-tuning with custom datasets": [[168, "fine-tuning-with-custom-datasets"]], "Sequence Classification with IMDb Reviews": [[168, "sequence-classification-with-imdb-reviews"]], "Fine-tuning with Trainer": [[168, "fine-tuning-with-trainer"]], "Fine-tuning with native PyTorch/TensorFlow": [[168, "fine-tuning-with-native-pytorch-tensorflow"]], "Token Classification with W-NUT Emerging Entities": [[168, "token-classification-with-w-nut-emerging-entities"]], "Question Answering with SQuAD 2.0": [[168, "question-answering-with-squad-2-0"]], "Additional Resources": [[168, "additional-resources"]], "Using the \ud83e\udd17 NLP Datasets & Metrics library": [[168, "using-the-nlp-datasets-metrics-library"]], "Glossary": [[170, "glossary"]], "General terms": [[170, "general-terms"]], "Model inputs": [[170, "model-inputs"]], "Input IDs": [[170, "input-ids"]], "Attention mask": [[170, "attention-mask"]], "Token Type IDs": [[170, "token-type-ids"]], "Position IDs": [[170, "position-ids"]], "Labels": [[170, "labels"]], "Decoder input IDs": [[170, "decoder-input-ids"]], "Feed Forward Chunking": [[170, "feed-forward-chunking"]], "Transformers": [[171, "transformers"]], "Features": [[171, "features"]], "Contents": [[171, "contents"]], "Get started": [[171, null]], "Using \ud83e\udd17 Transformers": [[171, null]], "Advanced guides": [[171, null]], "Research": [[171, null]], "Main Classes": [[171, null]], "Internal Helpers": [[171, null]], "Installation with pip": [[172, "installation-with-pip"]], "Installing from source": [[172, "installing-from-source"]], "Editable install": [[172, "editable-install"]], "Caching models": [[172, "caching-models"]], "Note on model downloads (Continuous Integration or large-scale deployments)": [[172, "note-on-model-downloads-continuous-integration-or-large-scale-deployments"]], "Do you want to run a Transformer model on a mobile device?": [[172, "do-you-want-to-run-a-transformer-model-on-a-mobile-device"]], "General Utilities": [[173, "general-utilities"]], "Enums and namedtuples": [[173, "enums-and-namedtuples"], [177, "enums-and-namedtuples"]], "Special Decorators": [[173, "special-decorators"]], "Special Properties": [[173, "special-properties"]], "Other Utilities": [[173, "other-utilities"]], "Utilities for Generation": [[174, "utilities-for-generation"]], "Generate Outputs": [[174, "generate-outputs"]], "GreedySearchOutput": [[174, "greedysearchoutput"]], "SampleOutput": [[174, "sampleoutput"]], "BeamSearchOutput": [[174, "beamsearchoutput"]], "BeamSampleOutput": [[174, "beamsampleoutput"]], "LogitsProcessor": [[174, "logitsprocessor"]], "BeamSearch": [[174, "beamsearch"]], "Utilities": [[174, "utilities"], [176, "utilities"], [178, "utilities"]], "Custom Layers and Utilities": [[175, "custom-layers-and-utilities"]], "Pytorch custom modules": [[175, "pytorch-custom-modules"]], "PyTorch Helper Functions": [[175, "pytorch-helper-functions"]], "TensorFlow custom layers": [[175, "tensorflow-custom-layers"]], "TensorFlow loss functions": [[175, "tensorflow-loss-functions"]], "TensorFlow Helper Functions": [[175, "tensorflow-helper-functions"]], "Utilities for pipelines": [[176, "utilities-for-pipelines"]], "Argument handling": [[176, "argument-handling"]], "Data format": [[176, "data-format"]], "Utilities for Tokenizers": [[177, "utilities-for-tokenizers"]], "PreTrainedTokenizerBase": [[177, "pretrainedtokenizerbase"]], "SpecialTokensMixin": [[177, "specialtokensmixin"]], "Utilities for Trainer": [[178, "utilities-for-trainer"]], "Callbacks internals": [[178, "callbacks-internals"]], "Distributed Evaluation": [[178, "distributed-evaluation"], [178, "id1"]], "Callbacks": [[179, "callbacks"]], "Available Callbacks": [[179, "available-callbacks"]], "TrainerCallback": [[179, "trainercallback"]], "TrainerState": [[179, "trainerstate"]], "TrainerControl": [[179, "trainercontrol"]], "Configuration": [[180, "configuration"], [189, "configuration"]], "PretrainedConfig": [[180, "pretrainedconfig"]], "Feature Extractor": [[181, "feature-extractor"]], "PreTrainedFeatureExtractor": [[181, "pretrainedfeatureextractor"]], "BatchFeature": [[181, "batchfeature"]], "Logging": [[182, "logging"]], "Base setters": [[182, "base-setters"]], "Other functions": [[182, "other-functions"]], "PreTrainedModel": [[183, "pretrainedmodel"]], "ModuleUtilsMixin": [[183, "moduleutilsmixin"]], "TFPreTrainedModel": [[183, "tfpretrainedmodel"]], "TFModelUtilsMixin": [[183, "tfmodelutilsmixin"]], "FlaxPreTrainedModel": [[183, "flaxpretrainedmodel"]], "Generation": [[183, "generation"]], "Optimization": [[184, "optimization"], [391, "optimization"]], "AdamW (PyTorch)": [[184, "adamw-pytorch"]], "AdaFactor (PyTorch)": [[184, "adafactor-pytorch"]], "AdamWeightDecay (TensorFlow)": [[184, "adamweightdecay-tensorflow"]], "Schedules": [[184, "schedules"]], "Learning Rate Schedules (Pytorch)": [[184, "learning-rate-schedules-pytorch"]], "Warmup (TensorFlow)": [[184, "warmup-tensorflow"]], "Gradient Strategies": [[184, "gradient-strategies"]], "GradientAccumulator (TensorFlow)": [[184, "gradientaccumulator-tensorflow"]], "Model outputs": [[185, "model-outputs"]], "ModelOutput": [[185, "modeloutput"]], "BaseModelOutput": [[185, "basemodeloutput"]], "BaseModelOutputWithPooling": [[185, "basemodeloutputwithpooling"]], "BaseModelOutputWithCrossAttentions": [[185, "basemodeloutputwithcrossattentions"]], "BaseModelOutputWithPoolingAndCrossAttentions": [[185, "basemodeloutputwithpoolingandcrossattentions"]], "BaseModelOutputWithPast": [[185, "basemodeloutputwithpast"]], "BaseModelOutputWithPastAndCrossAttentions": [[185, "basemodeloutputwithpastandcrossattentions"]], "Seq2SeqModelOutput": [[185, "seq2seqmodeloutput"]], "CausalLMOutput": [[185, "causallmoutput"]], "CausalLMOutputWithCrossAttentions": [[185, "causallmoutputwithcrossattentions"]], "CausalLMOutputWithPast": [[185, "causallmoutputwithpast"]], "MaskedLMOutput": [[185, "maskedlmoutput"]], "Seq2SeqLMOutput": [[185, "seq2seqlmoutput"]], "NextSentencePredictorOutput": [[185, "nextsentencepredictoroutput"]], "SequenceClassifierOutput": [[185, "sequenceclassifieroutput"]], "Seq2SeqSequenceClassifierOutput": [[185, "seq2seqsequenceclassifieroutput"]], "MultipleChoiceModelOutput": [[185, "multiplechoicemodeloutput"]], "TokenClassifierOutput": [[185, "tokenclassifieroutput"]], "QuestionAnsweringModelOutput": [[185, "questionansweringmodeloutput"]], "Seq2SeqQuestionAnsweringModelOutput": [[185, "seq2seqquestionansweringmodeloutput"]], "TFBaseModelOutput": [[185, "tfbasemodeloutput"]], "TFBaseModelOutputWithPooling": [[185, "tfbasemodeloutputwithpooling"]], "TFBaseModelOutputWithPast": [[185, "tfbasemodeloutputwithpast"]], "TFSeq2SeqModelOutput": [[185, "tfseq2seqmodeloutput"]], "TFCausalLMOutput": [[185, "tfcausallmoutput"]], "TFCausalLMOutputWithPast": [[185, "tfcausallmoutputwithpast"]], "TFMaskedLMOutput": [[185, "tfmaskedlmoutput"]], "TFSeq2SeqLMOutput": [[185, "tfseq2seqlmoutput"]], "TFNextSentencePredictorOutput": [[185, "tfnextsentencepredictoroutput"]], "TFSequenceClassifierOutput": [[185, "tfsequenceclassifieroutput"]], "TFSeq2SeqSequenceClassifierOutput": [[185, "tfseq2seqsequenceclassifieroutput"]], "TFMultipleChoiceModelOutput": [[185, "tfmultiplechoicemodeloutput"]], "TFTokenClassifierOutput": [[185, "tftokenclassifieroutput"]], "TFQuestionAnsweringModelOutput": [[185, "tfquestionansweringmodeloutput"]], "TFSeq2SeqQuestionAnsweringModelOutput": [[185, "tfseq2seqquestionansweringmodeloutput"]], "Pipelines": [[186, "pipelines"]], "The pipeline abstraction": [[186, "the-pipeline-abstraction"]], "The task specific pipelines": [[186, "the-task-specific-pipelines"]], "ConversationalPipeline": [[186, "conversationalpipeline"]], "FeatureExtractionPipeline": [[186, "featureextractionpipeline"]], "FillMaskPipeline": [[186, "fillmaskpipeline"]], "NerPipeline": [[186, "nerpipeline"]], "QuestionAnsweringPipeline": [[186, "questionansweringpipeline"]], "SummarizationPipeline": [[186, "summarizationpipeline"]], "TableQuestionAnsweringPipeline": [[186, "tablequestionansweringpipeline"]], "TextClassificationPipeline": [[186, "textclassificationpipeline"]], "TextGenerationPipeline": [[186, "textgenerationpipeline"]], "Text2TextGenerationPipeline": [[186, "text2textgenerationpipeline"]], "TokenClassificationPipeline": [[186, "tokenclassificationpipeline"]], "TranslationPipeline": [[186, "translationpipeline"]], "ZeroShotClassificationPipeline": [[186, "zeroshotclassificationpipeline"]], "Parent class: Pipeline": [[186, "parent-class-pipeline"]], "Processors": [[187, "processors"], [187, "id1"], [187, "id2"]], "GLUE": [[187, "glue"]], "Example usage": [[187, "example-usage"], [187, "id3"]], "XNLI": [[187, "xnli"], [280, "xnli"]], "SQuAD": [[187, "squad"], [261, "squad"], [298, "squad"]], "Tokenizer": [[188, "tokenizer"]], "PreTrainedTokenizer": [[188, "pretrainedtokenizer"]], "PreTrainedTokenizerFast": [[188, "pretrainedtokenizerfast"]], "BatchEncoding": [[188, "batchencoding"]], "Trainer": [[189, "trainer"], [189, "id1"], [256, "trainer"]], "Seq2SeqTrainer": [[189, "seq2seqtrainer"]], "TFTrainer": [[189, "tftrainer"]], "TrainingArguments": [[189, "trainingarguments"]], "Seq2SeqTrainingArguments": [[189, "seq2seqtrainingarguments"]], "TFTrainingArguments": [[189, "tftrainingarguments"]], "Trainer Integrations": [[189, "trainer-integrations"]], "Installation Notes": [[189, "installation-notes"]], "FairScale": [[189, "fairscale"]], "DeepSpeed": [[189, "deepspeed"]], "Deployment with multiple GPUs": [[189, "deployment-with-multiple-gpus"]], "Deployment with one GPU": [[189, "deployment-with-one-gpu"]], "Deployment in Notebooks": [[189, "deployment-in-notebooks"]], "Shared Configuration": [[189, "shared-configuration"]], "ZeRO": [[189, "zero"]], "Optimizer": [[189, "optimizer"], [317, "optimizer"]], "Scheduler": [[189, "scheduler"]], "Automatic Mixed Precision": [[189, "automatic-mixed-precision"]], "Gradient Accumulation": [[189, "gradient-accumulation"]], "Gradient Clipping": [[189, "gradient-clipping"]], "Notes": [[189, "notes"], [327, "notes"]], "Main DeepSpeed Resources": [[189, "main-deepspeed-resources"]], "Migrating from previous packages": [[190, "migrating-from-previous-packages"]], "Migrating from transformers v3.x to v4.x": [[190, "migrating-from-transformers-v3-x-to-v4-x"]], "1. AutoTokenizers and pipelines now use fast (rust) tokenizers by default.": [[190, "autotokenizers-and-pipelines-now-use-fast-rust-tokenizers-by-default"]], "How to obtain the same behavior as v3.x in v4.x": [[190, "how-to-obtain-the-same-behavior-as-v3-x-in-v4-x"], [190, "id1"], [190, "id2"], [190, "id3"]], "2. SentencePiece is removed from the required dependencies": [[190, "sentencepiece-is-removed-from-the-required-dependencies"]], "3. The architecture of the repo has been updated so that each model resides in its folder": [[190, "the-architecture-of-the-repo-has-been-updated-so-that-each-model-resides-in-its-folder"]], "4. Switching the return_dict argument to True by default": [[190, "switching-the-return-dict-argument-to-true-by-default"]], "5. Removed some deprecated attributes": [[190, "removed-some-deprecated-attributes"]], "Migrating from pytorch-transformers to \ud83e\udd17 Transformers": [[190, "migrating-from-pytorch-transformers-to-transformers"]], "Positional order of some models\u2019 keywords inputs (attention_mask, token_type_ids\u2026) changed": [[190, "positional-order-of-some-models-keywords-inputs-attention-mask-token-type-ids-changed"]], "Migrating from pytorch-pretrained-bert": [[190, "migrating-from-pytorch-pretrained-bert"]], "Models always output tuples": [[190, "models-always-output-tuples"]], "Serialization": [[190, "serialization"]], "Optimizers: BertAdam & OpenAIAdam are now AdamW, schedules are standard PyTorch schedules": [[190, "optimizers-bertadam-openaiadam-are-now-adamw-schedules-are-standard-pytorch-schedules"]], "AlbertConfig": [[191, "albertconfig"]], "AlbertTokenizer": [[191, "alberttokenizer"]], "AlbertTokenizerFast": [[191, "alberttokenizerfast"]], "Albert specific outputs": [[191, "albert-specific-outputs"]], "AlbertModel": [[191, "albertmodel"]], "AlbertForPreTraining": [[191, "albertforpretraining"]], "AlbertForMaskedLM": [[191, "albertformaskedlm"]], "AlbertForSequenceClassification": [[191, "albertforsequenceclassification"]], "AlbertForMultipleChoice": [[191, "albertformultiplechoice"]], "AlbertForTokenClassification": [[191, "albertfortokenclassification"]], "AlbertForQuestionAnswering": [[191, "albertforquestionanswering"]], "TFAlbertModel": [[191, "tfalbertmodel"]], "TFAlbertForPreTraining": [[191, "tfalbertforpretraining"]], "TFAlbertForMaskedLM": [[191, "tfalbertformaskedlm"]], "TFAlbertForSequenceClassification": [[191, "tfalbertforsequenceclassification"]], "TFAlbertForMultipleChoice": [[191, "tfalbertformultiplechoice"]], "TFAlbertForTokenClassification": [[191, "tfalbertfortokenclassification"]], "TFAlbertForQuestionAnswering": [[191, "tfalbertforquestionanswering"]], "Auto Classes": [[192, "auto-classes"]], "AutoConfig": [[192, "autoconfig"]], "AutoTokenizer": [[192, "autotokenizer"]], "AutoModel": [[192, "automodel"]], "AutoModelForPreTraining": [[192, "automodelforpretraining"]], "AutoModelForCausalLM": [[192, "automodelforcausallm"]], "AutoModelForMaskedLM": [[192, "automodelformaskedlm"]], "AutoModelForSeq2SeqLM": [[192, "automodelforseq2seqlm"]], "AutoModelForSequenceClassification": [[192, "automodelforsequenceclassification"]], "AutoModelForMultipleChoice": [[192, "automodelformultiplechoice"]], "AutoModelForNextSentencePrediction": [[192, "automodelfornextsentenceprediction"]], "AutoModelForTokenClassification": [[192, "automodelfortokenclassification"]], "AutoModelForQuestionAnswering": [[192, "automodelforquestionanswering"]], "AutoModelForTableQuestionAnswering": [[192, "automodelfortablequestionanswering"]], "TFAutoModel": [[192, "tfautomodel"]], "TFAutoModelForPreTraining": [[192, "tfautomodelforpretraining"]], "TFAutoModelForCausalLM": [[192, "tfautomodelforcausallm"]], "TFAutoModelForMaskedLM": [[192, "tfautomodelformaskedlm"]], "TFAutoModelForSeq2SeqLM": [[192, "tfautomodelforseq2seqlm"]], "TFAutoModelForSequenceClassification": [[192, "tfautomodelforsequenceclassification"]], "TFAutoModelForMultipleChoice": [[192, "tfautomodelformultiplechoice"]], "TFAutoModelForTokenClassification": [[192, "tfautomodelfortokenclassification"]], "TFAutoModelForQuestionAnswering": [[192, "tfautomodelforquestionanswering"]], "FlaxAutoModel": [[192, "flaxautomodel"]], "BART": [[193, "bart"], [244, "bart"]], "Implementation Notes": [[193, "implementation-notes"], [198, "implementation-notes"], [212, "implementation-notes"], [222, "implementation-notes"], [227, "implementation-notes"]], "Mask Filling": [[193, "mask-filling"]], "BartConfig": [[193, "bartconfig"]], "BartTokenizer": [[193, "barttokenizer"]], "BartTokenizerFast": [[193, "barttokenizerfast"]], "BartModel": [[193, "bartmodel"]], "BartForConditionalGeneration": [[193, "bartforconditionalgeneration"]], "BartForSequenceClassification": [[193, "bartforsequenceclassification"]], "BartForQuestionAnswering": [[193, "bartforquestionanswering"]], "BartForCausalLM": [[193, "bartforcausallm"]], "TFBartModel": [[193, "tfbartmodel"]], "TFBartForConditionalGeneration": [[193, "tfbartforconditionalgeneration"]], "BARThez": [[194, "barthez"]], "BarthezTokenizer": [[194, "bartheztokenizer"]], "BarthezTokenizerFast": [[194, "bartheztokenizerfast"]], "BertConfig": [[195, "bertconfig"]], "BertTokenizer": [[195, "berttokenizer"]], "BertTokenizerFast": [[195, "berttokenizerfast"]], "Bert specific outputs": [[195, "bert-specific-outputs"]], "BertModel": [[195, "bertmodel"]], "BertForPreTraining": [[195, "bertforpretraining"]], "BertModelLMHeadModel": [[195, "bertmodellmheadmodel"]], "BertForMaskedLM": [[195, "bertformaskedlm"]], "BertForNextSentencePrediction": [[195, "bertfornextsentenceprediction"]], "BertForSequenceClassification": [[195, "bertforsequenceclassification"]], "BertForMultipleChoice": [[195, "bertformultiplechoice"]], "BertForTokenClassification": [[195, "bertfortokenclassification"]], "BertForQuestionAnswering": [[195, "bertforquestionanswering"]], "TFBertModel": [[195, "tfbertmodel"]], "TFBertForPreTraining": [[195, "tfbertforpretraining"]], "TFBertModelLMHeadModel": [[195, "tfbertmodellmheadmodel"]], "TFBertForMaskedLM": [[195, "tfbertformaskedlm"]], "TFBertForNextSentencePrediction": [[195, "tfbertfornextsentenceprediction"]], "TFBertForSequenceClassification": [[195, "tfbertforsequenceclassification"]], "TFBertForMultipleChoice": [[195, "tfbertformultiplechoice"]], "TFBertForTokenClassification": [[195, "tfbertfortokenclassification"]], "TFBertForQuestionAnswering": [[195, "tfbertforquestionanswering"]], "FlaxBertModel": [[195, "flaxbertmodel"]], "FlaxBertForMaskedLM": [[195, "flaxbertformaskedlm"]], "BertGeneration": [[196, "bertgeneration"]], "BertGenerationConfig": [[196, "bertgenerationconfig"]], "BertGenerationTokenizer": [[196, "bertgenerationtokenizer"]], "BertGenerationEncoder": [[196, "bertgenerationencoder"]], "BertGenerationDecoder": [[196, "bertgenerationdecoder"]], "Bertweet": [[197, "bertweet"]], "BertweetTokenizer": [[197, "bertweettokenizer"]], "Blenderbot": [[198, "blenderbot"]], "BlenderbotConfig": [[198, "blenderbotconfig"]], "BlenderbotTokenizer": [[198, "blenderbottokenizer"]], "BlenderbotModel": [[198, "blenderbotmodel"]], "BlenderbotForConditionalGeneration": [[198, "blenderbotforconditionalgeneration"]], "BlenderbotForCausalLM": [[198, "blenderbotforcausallm"]], "TFBlenderbotModel": [[198, "tfblenderbotmodel"]], "TFBlenderbotForConditionalGeneration": [[198, "tfblenderbotforconditionalgeneration"]], "Blenderbot Small": [[199, "blenderbot-small"]], "BlenderbotSmallConfig": [[199, "blenderbotsmallconfig"]], "BlenderbotSmallTokenizer": [[199, "blenderbotsmalltokenizer"]], "BlenderbotSmallModel": [[199, "blenderbotsmallmodel"]], "BlenderbotSmallForConditionalGeneration": [[199, "blenderbotsmallforconditionalgeneration"]], "BlenderbotSmallForCausalLM": [[199, "blenderbotsmallforcausallm"]], "TFBlenderbotSmallModel": [[199, "tfblenderbotsmallmodel"]], "TFBlenderbotSmallForConditionalGeneration": [[199, "tfblenderbotsmallforconditionalgeneration"]], "BORT": [[200, "bort"]], "CamemBERT": [[201, "camembert"]], "CamembertConfig": [[201, "camembertconfig"]], "CamembertTokenizer": [[201, "camemberttokenizer"]], "CamembertTokenizerFast": [[201, "camemberttokenizerfast"]], "CamembertModel": [[201, "camembertmodel"]], "CamembertForCausalLM": [[201, "camembertforcausallm"]], "CamembertForMaskedLM": [[201, "camembertformaskedlm"]], "CamembertForSequenceClassification": [[201, "camembertforsequenceclassification"]], "CamembertForMultipleChoice": [[201, "camembertformultiplechoice"]], "CamembertForTokenClassification": [[201, "camembertfortokenclassification"]], "CamembertForQuestionAnswering": [[201, "camembertforquestionanswering"]], "TFCamembertModel": [[201, "tfcamembertmodel"]], "TFCamembertForMaskedLM": [[201, "tfcamembertformaskedlm"]], "TFCamembertForSequenceClassification": [[201, "tfcamembertforsequenceclassification"]], "TFCamembertForMultipleChoice": [[201, "tfcamembertformultiplechoice"]], "TFCamembertForTokenClassification": [[201, "tfcamembertfortokenclassification"]], "TFCamembertForQuestionAnswering": [[201, "tfcamembertforquestionanswering"]], "ConvBERT": [[202, "convbert"], [244, "convbert"]], "ConvBertConfig": [[202, "convbertconfig"]], "ConvBertTokenizer": [[202, "convberttokenizer"]], "ConvBertTokenizerFast": [[202, "convberttokenizerfast"]], "ConvBertModel": [[202, "convbertmodel"]], "ConvBertForMaskedLM": [[202, "convbertformaskedlm"]], "ConvBertForSequenceClassification": [[202, "convbertforsequenceclassification"]], "ConvBertForMultipleChoice": [[202, "convbertformultiplechoice"]], "ConvBertForTokenClassification": [[202, "convbertfortokenclassification"]], "ConvBertForQuestionAnswering": [[202, "convbertforquestionanswering"]], "TFConvBertModel": [[202, "tfconvbertmodel"]], "TFConvBertForMaskedLM": [[202, "tfconvbertformaskedlm"]], "TFConvBertForSequenceClassification": [[202, "tfconvbertforsequenceclassification"]], "TFConvBertForMultipleChoice": [[202, "tfconvbertformultiplechoice"]], "TFConvBertForTokenClassification": [[202, "tfconvbertfortokenclassification"]], "TFConvBertForQuestionAnswering": [[202, "tfconvbertforquestionanswering"]], "CTRL": [[203, "ctrl"], [244, "ctrl"]], "CTRLConfig": [[203, "ctrlconfig"]], "CTRLTokenizer": [[203, "ctrltokenizer"]], "CTRLModel": [[203, "ctrlmodel"]], "CTRLLMHeadModel": [[203, "ctrllmheadmodel"]], "CTRLForSequenceClassification": [[203, "ctrlforsequenceclassification"]], "TFCTRLModel": [[203, "tfctrlmodel"]], "TFCTRLLMHeadModel": [[203, "tfctrllmheadmodel"]], "TFCTRLForSequenceClassification": [[203, "tfctrlforsequenceclassification"]], "DeBERTa": [[204, "deberta"]], "DebertaConfig": [[204, "debertaconfig"]], "DebertaTokenizer": [[204, "debertatokenizer"]], "DebertaModel": [[204, "debertamodel"]], "DebertaPreTrainedModel": [[204, "debertapretrainedmodel"]], "DebertaForMaskedLM": [[204, "debertaformaskedlm"]], "DebertaForSequenceClassification": [[204, "debertaforsequenceclassification"]], "DebertaForTokenClassification": [[204, "debertafortokenclassification"]], "DebertaForQuestionAnswering": [[204, "debertaforquestionanswering"]], "DeBERTa-v2": [[205, "deberta-v2"]], "DebertaV2Config": [[205, "debertav2config"]], "DebertaV2Tokenizer": [[205, "debertav2tokenizer"]], "DebertaV2Model": [[205, "debertav2model"]], "DebertaV2PreTrainedModel": [[205, "debertav2pretrainedmodel"]], "DebertaV2ForMaskedLM": [[205, "debertav2formaskedlm"]], "DebertaV2ForSequenceClassification": [[205, "debertav2forsequenceclassification"]], "DebertaV2ForTokenClassification": [[205, "debertav2fortokenclassification"]], "DebertaV2ForQuestionAnswering": [[205, "debertav2forquestionanswering"]], "DialoGPT": [[206, "dialogpt"]], "DistilBERT": [[207, "distilbert"], [244, "distilbert"]], "DistilBertConfig": [[207, "distilbertconfig"]], "DistilBertTokenizer": [[207, "distilberttokenizer"]], "DistilBertTokenizerFast": [[207, "distilberttokenizerfast"]], "DistilBertModel": [[207, "distilbertmodel"]], "DistilBertForMaskedLM": [[207, "distilbertformaskedlm"]], "DistilBertForSequenceClassification": [[207, "distilbertforsequenceclassification"]], "DistilBertForMultipleChoice": [[207, "distilbertformultiplechoice"]], "DistilBertForTokenClassification": [[207, "distilbertfortokenclassification"]], "DistilBertForQuestionAnswering": [[207, "distilbertforquestionanswering"]], "TFDistilBertModel": [[207, "tfdistilbertmodel"]], "TFDistilBertForMaskedLM": [[207, "tfdistilbertformaskedlm"]], "TFDistilBertForSequenceClassification": [[207, "tfdistilbertforsequenceclassification"]], "TFDistilBertForMultipleChoice": [[207, "tfdistilbertformultiplechoice"]], "TFDistilBertForTokenClassification": [[207, "tfdistilbertfortokenclassification"]], "TFDistilBertForQuestionAnswering": [[207, "tfdistilbertforquestionanswering"]], "DPR": [[208, "dpr"], [244, "dpr"]], "DPRConfig": [[208, "dprconfig"]], "DPRContextEncoderTokenizer": [[208, "dprcontextencodertokenizer"]], "DPRContextEncoderTokenizerFast": [[208, "dprcontextencodertokenizerfast"]], "DPRQuestionEncoderTokenizer": [[208, "dprquestionencodertokenizer"]], "DPRQuestionEncoderTokenizerFast": [[208, "dprquestionencodertokenizerfast"]], "DPRReaderTokenizer": [[208, "dprreadertokenizer"]], "DPRReaderTokenizerFast": [[208, "dprreadertokenizerfast"]], "DPR specific outputs": [[208, "dpr-specific-outputs"]], "DPRContextEncoder": [[208, "dprcontextencoder"]], "DPRQuestionEncoder": [[208, "dprquestionencoder"]], "DPRReader": [[208, "dprreader"]], "TFDPRContextEncoder": [[208, "tfdprcontextencoder"]], "TFDPRQuestionEncoder": [[208, "tfdprquestionencoder"]], "TFDPRReader": [[208, "tfdprreader"]], "ELECTRA": [[209, "electra"], [244, "electra"]], "ElectraConfig": [[209, "electraconfig"]], "ElectraTokenizer": [[209, "electratokenizer"]], "ElectraTokenizerFast": [[209, "electratokenizerfast"]], "Electra specific outputs": [[209, "electra-specific-outputs"]], "ElectraModel": [[209, "electramodel"]], "ElectraForPreTraining": [[209, "electraforpretraining"]], "ElectraForMaskedLM": [[209, "electraformaskedlm"]], "ElectraForSequenceClassification": [[209, "electraforsequenceclassification"]], "ElectraForMultipleChoice": [[209, "electraformultiplechoice"]], "ElectraForTokenClassification": [[209, "electrafortokenclassification"]], "ElectraForQuestionAnswering": [[209, "electraforquestionanswering"]], "TFElectraModel": [[209, "tfelectramodel"]], "TFElectraForPreTraining": [[209, "tfelectraforpretraining"]], "TFElectraForMaskedLM": [[209, "tfelectraformaskedlm"]], "TFElectraForSequenceClassification": [[209, "tfelectraforsequenceclassification"]], "TFElectraForMultipleChoice": [[209, "tfelectraformultiplechoice"]], "TFElectraForTokenClassification": [[209, "tfelectrafortokenclassification"]], "TFElectraForQuestionAnswering": [[209, "tfelectraforquestionanswering"]], "Encoder Decoder Models": [[210, "encoder-decoder-models"]], "EncoderDecoderConfig": [[210, "encoderdecoderconfig"]], "EncoderDecoderModel": [[210, "encoderdecodermodel"]], "FlauBERT": [[211, "flaubert"], [244, "flaubert"]], "FlaubertConfig": [[211, "flaubertconfig"]], "FlaubertTokenizer": [[211, "flauberttokenizer"]], "FlaubertModel": [[211, "flaubertmodel"]], "FlaubertWithLMHeadModel": [[211, "flaubertwithlmheadmodel"]], "FlaubertForSequenceClassification": [[211, "flaubertforsequenceclassification"]], "FlaubertForMultipleChoice": [[211, "flaubertformultiplechoice"]], "FlaubertForTokenClassification": [[211, "flaubertfortokenclassification"]], "FlaubertForQuestionAnsweringSimple": [[211, "flaubertforquestionansweringsimple"]], "FlaubertForQuestionAnswering": [[211, "flaubertforquestionanswering"]], "TFFlaubertModel": [[211, "tfflaubertmodel"]], "TFFlaubertWithLMHeadModel": [[211, "tfflaubertwithlmheadmodel"]], "TFFlaubertForSequenceClassification": [[211, "tfflaubertforsequenceclassification"]], "TFFlaubertForMultipleChoice": [[211, "tfflaubertformultiplechoice"]], "TFFlaubertForTokenClassification": [[211, "tfflaubertfortokenclassification"]], "TFFlaubertForQuestionAnsweringSimple": [[211, "tfflaubertforquestionansweringsimple"]], "FSMT": [[212, "fsmt"]], "FSMTConfig": [[212, "fsmtconfig"]], "FSMTTokenizer": [[212, "fsmttokenizer"]], "FSMTModel": [[212, "fsmtmodel"]], "FSMTForConditionalGeneration": [[212, "fsmtforconditionalgeneration"]], "Funnel Transformer": [[213, "funnel-transformer"], [244, "funnel-transformer"]], "FunnelConfig": [[213, "funnelconfig"]], "FunnelTokenizer": [[213, "funneltokenizer"]], "FunnelTokenizerFast": [[213, "funneltokenizerfast"]], "Funnel specific outputs": [[213, "funnel-specific-outputs"]], "FunnelBaseModel": [[213, "funnelbasemodel"]], "FunnelModel": [[213, "funnelmodel"]], "FunnelModelForPreTraining": [[213, "funnelmodelforpretraining"]], "FunnelForMaskedLM": [[213, "funnelformaskedlm"]], "FunnelForSequenceClassification": [[213, "funnelforsequenceclassification"]], "FunnelForMultipleChoice": [[213, "funnelformultiplechoice"]], "FunnelForTokenClassification": [[213, "funnelfortokenclassification"]], "FunnelForQuestionAnswering": [[213, "funnelforquestionanswering"]], "TFFunnelBaseModel": [[213, "tffunnelbasemodel"]], "TFFunnelModel": [[213, "tffunnelmodel"]], "TFFunnelModelForPreTraining": [[213, "tffunnelmodelforpretraining"]], "TFFunnelForMaskedLM": [[213, "tffunnelformaskedlm"]], "TFFunnelForSequenceClassification": [[213, "tffunnelforsequenceclassification"]], "TFFunnelForMultipleChoice": [[213, "tffunnelformultiplechoice"]], "TFFunnelForTokenClassification": [[213, "tffunnelfortokenclassification"]], "TFFunnelForQuestionAnswering": [[213, "tffunnelforquestionanswering"]], "OpenAIGPTConfig": [[214, "openaigptconfig"]], "OpenAIGPTTokenizer": [[214, "openaigpttokenizer"]], "OpenAIGPTTokenizerFast": [[214, "openaigpttokenizerfast"]], "OpenAI specific outputs": [[214, "openai-specific-outputs"]], "OpenAIGPTModel": [[214, "openaigptmodel"]], "OpenAIGPTLMHeadModel": [[214, "openaigptlmheadmodel"]], "OpenAIGPTDoubleHeadsModel": [[214, "openaigptdoubleheadsmodel"]], "OpenAIGPTForSequenceClassification": [[214, "openaigptforsequenceclassification"]], "TFOpenAIGPTModel": [[214, "tfopenaigptmodel"]], "TFOpenAIGPTLMHeadModel": [[214, "tfopenaigptlmheadmodel"]], "TFOpenAIGPTDoubleHeadsModel": [[214, "tfopenaigptdoubleheadsmodel"]], "TFOpenAIGPTForSequenceClassification": [[214, "tfopenaigptforsequenceclassification"]], "OpenAI GPT2": [[215, "openai-gpt2"]], "GPT2Config": [[215, "gpt2config"]], "GPT2Tokenizer": [[215, "gpt2tokenizer"]], "GPT2TokenizerFast": [[215, "gpt2tokenizerfast"]], "GPT2 specific outputs": [[215, "gpt2-specific-outputs"]], "GPT2Model": [[215, "gpt2model"]], "GPT2LMHeadModel": [[215, "gpt2lmheadmodel"]], "GPT2DoubleHeadsModel": [[215, "gpt2doubleheadsmodel"]], "GPT2ForSequenceClassification": [[215, "gpt2forsequenceclassification"]], "TFGPT2Model": [[215, "tfgpt2model"]], "TFGPT2LMHeadModel": [[215, "tfgpt2lmheadmodel"]], "TFGPT2DoubleHeadsModel": [[215, "tfgpt2doubleheadsmodel"]], "TFGPT2ForSequenceClassification": [[215, "tfgpt2forsequenceclassification"]], "TFSequenceClassifierOutputWithPast": [[215, "tfsequenceclassifieroutputwithpast"]], "herBERT": [[216, "herbert"]], "HerbertTokenizer": [[216, "herberttokenizer"]], "HerbertTokenizerFast": [[216, "herberttokenizerfast"]], "I-BERT": [[217, "i-bert"]], "IBertConfig": [[217, "ibertconfig"]], "IBertModel": [[217, "ibertmodel"]], "IBertForMaskedLM": [[217, "ibertformaskedlm"]], "IBertForSequenceClassification": [[217, "ibertforsequenceclassification"]], "IBertForMultipleChoice": [[217, "ibertformultiplechoice"]], "IBertForTokenClassification": [[217, "ibertfortokenclassification"]], "IBertForQuestionAnswering": [[217, "ibertforquestionanswering"]], "LayoutLM": [[218, "layoutlm"]], "LayoutLMConfig": [[218, "layoutlmconfig"]], "LayoutLMTokenizer": [[218, "layoutlmtokenizer"]], "LayoutLMTokenizerFast": [[218, "layoutlmtokenizerfast"]], "LayoutLMModel": [[218, "layoutlmmodel"]], "LayoutLMForMaskedLM": [[218, "layoutlmformaskedlm"]], "LayoutLMForSequenceClassification": [[218, "layoutlmforsequenceclassification"]], "LayoutLMForTokenClassification": [[218, "layoutlmfortokenclassification"]], "LED": [[219, "led"]], "LEDConfig": [[219, "ledconfig"]], "LEDTokenizer": [[219, "ledtokenizer"]], "LEDTokenizerFast": [[219, "ledtokenizerfast"]], "LED specific outputs": [[219, "led-specific-outputs"]], "LEDModel": [[219, "ledmodel"]], "LEDForConditionalGeneration": [[219, "ledforconditionalgeneration"]], "LEDForSequenceClassification": [[219, "ledforsequenceclassification"]], "LEDForQuestionAnswering": [[219, "ledforquestionanswering"]], "TFLEDModel": [[219, "tfledmodel"]], "TFLEDForConditionalGeneration": [[219, "tfledforconditionalgeneration"]], "Longformer": [[220, "longformer"], [244, "longformer"]], "Longformer Self Attention": [[220, "longformer-self-attention"]], "Training": [[220, "training"], [231, "training"], [235, "training"], [264, "training"]], "LongformerConfig": [[220, "longformerconfig"]], "LongformerTokenizer": [[220, "longformertokenizer"]], "LongformerTokenizerFast": [[220, "longformertokenizerfast"]], "Longformer specific outputs": [[220, "longformer-specific-outputs"]], "LongformerModel": [[220, "longformermodel"]], "LongformerForMaskedLM": [[220, "longformerformaskedlm"]], "LongformerForSequenceClassification": [[220, "longformerforsequenceclassification"]], "LongformerForMultipleChoice": [[220, "longformerformultiplechoice"]], "LongformerForTokenClassification": [[220, "longformerfortokenclassification"]], "LongformerForQuestionAnswering": [[220, "longformerforquestionanswering"]], "TFLongformerModel": [[220, "tflongformermodel"]], "TFLongformerForMaskedLM": [[220, "tflongformerformaskedlm"]], "TFLongformerForQuestionAnswering": [[220, "tflongformerforquestionanswering"]], "TFLongformerForSequenceClassification": [[220, "tflongformerforsequenceclassification"]], "TFLongformerForTokenClassification": [[220, "tflongformerfortokenclassification"]], "TFLongformerForMultipleChoice": [[220, "tflongformerformultiplechoice"]], "LXMERT": [[221, "lxmert"]], "LxmertConfig": [[221, "lxmertconfig"]], "LxmertTokenizer": [[221, "lxmerttokenizer"]], "LxmertTokenizerFast": [[221, "lxmerttokenizerfast"]], "Lxmert specific outputs": [[221, "lxmert-specific-outputs"]], "LxmertModel": [[221, "lxmertmodel"]], "LxmertForPreTraining": [[221, "lxmertforpretraining"]], "LxmertForQuestionAnswering": [[221, "lxmertforquestionanswering"]], "TFLxmertModel": [[221, "tflxmertmodel"]], "TFLxmertForPreTraining": [[221, "tflxmertforpretraining"]], "MarianMT": [[222, "marianmt"], [244, "marianmt"]], "Naming": [[222, "naming"]], "Multilingual Models": [[222, "multilingual-models"]], "Old Style Multi-Lingual Models": [[222, "old-style-multi-lingual-models"]], "MarianConfig": [[222, "marianconfig"]], "MarianTokenizer": [[222, "mariantokenizer"]], "MarianModel": [[222, "marianmodel"]], "MarianMTModel": [[222, "marianmtmodel"]], "MarianForCausalLM": [[222, "marianforcausallm"]], "TFMarianModel": [[222, "tfmarianmodel"]], "TFMarianMTModel": [[222, "tfmarianmtmodel"]], "MBart and MBart-50": [[223, "mbart-and-mbart-50"]], "Overview of MBart": [[223, "overview-of-mbart"]], "Training of MBart": [[223, "training-of-mbart"]], "Overview of MBart-50": [[223, "overview-of-mbart-50"]], "Training of MBart-50": [[223, "training-of-mbart-50"]], "MBartConfig": [[223, "mbartconfig"]], "MBartTokenizer": [[223, "mbarttokenizer"]], "MBartTokenizerFast": [[223, "mbarttokenizerfast"]], "MBart50Tokenizer": [[223, "mbart50tokenizer"]], "MBart50TokenizerFast": [[223, "mbart50tokenizerfast"]], "MBartModel": [[223, "mbartmodel"]], "MBartForConditionalGeneration": [[223, "mbartforconditionalgeneration"]], "MBartForQuestionAnswering": [[223, "mbartforquestionanswering"]], "MBartForSequenceClassification": [[223, "mbartforsequenceclassification"]], "MBartForCausalLM": [[223, "mbartforcausallm"]], "TFMBartModel": [[223, "tfmbartmodel"]], "TFMBartForConditionalGeneration": [[223, "tfmbartforconditionalgeneration"]], "MobileBERT": [[224, "mobilebert"]], "MobileBertConfig": [[224, "mobilebertconfig"]], "MobileBertTokenizer": [[224, "mobileberttokenizer"]], "MobileBertTokenizerFast": [[224, "mobileberttokenizerfast"]], "MobileBert specific outputs": [[224, "mobilebert-specific-outputs"]], "MobileBertModel": [[224, "mobilebertmodel"]], "MobileBertForPreTraining": [[224, "mobilebertforpretraining"]], "MobileBertForMaskedLM": [[224, "mobilebertformaskedlm"]], "MobileBertForNextSentencePrediction": [[224, "mobilebertfornextsentenceprediction"]], "MobileBertForSequenceClassification": [[224, "mobilebertforsequenceclassification"]], "MobileBertForMultipleChoice": [[224, "mobilebertformultiplechoice"]], "MobileBertForTokenClassification": [[224, "mobilebertfortokenclassification"]], "MobileBertForQuestionAnswering": [[224, "mobilebertforquestionanswering"]], "TFMobileBertModel": [[224, "tfmobilebertmodel"]], "TFMobileBertForPreTraining": [[224, "tfmobilebertforpretraining"]], "TFMobileBertForMaskedLM": [[224, "tfmobilebertformaskedlm"]], "TFMobileBertForNextSentencePrediction": [[224, "tfmobilebertfornextsentenceprediction"]], "TFMobileBertForSequenceClassification": [[224, "tfmobilebertforsequenceclassification"]], "TFMobileBertForMultipleChoice": [[224, "tfmobilebertformultiplechoice"]], "TFMobileBertForTokenClassification": [[224, "tfmobilebertfortokenclassification"]], "TFMobileBertForQuestionAnswering": [[224, "tfmobilebertforquestionanswering"]], "MPNet": [[225, "mpnet"]], "MPNetConfig": [[225, "mpnetconfig"]], "MPNetTokenizer": [[225, "mpnettokenizer"]], "MPNetTokenizerFast": [[225, "mpnettokenizerfast"]], "MPNetModel": [[225, "mpnetmodel"]], "MPNetForMaskedLM": [[225, "mpnetformaskedlm"]], "MPNetForSequenceClassification": [[225, "mpnetforsequenceclassification"]], "MPNetForMultipleChoice": [[225, "mpnetformultiplechoice"]], "MPNetForTokenClassification": [[225, "mpnetfortokenclassification"]], "MPNetForQuestionAnswering": [[225, "mpnetforquestionanswering"]], "TFMPNetModel": [[225, "tfmpnetmodel"]], "TFMPNetForMaskedLM": [[225, "tfmpnetformaskedlm"]], "TFMPNetForSequenceClassification": [[225, "tfmpnetforsequenceclassification"]], "TFMPNetForMultipleChoice": [[225, "tfmpnetformultiplechoice"]], "TFMPNetForTokenClassification": [[225, "tfmpnetfortokenclassification"]], "TFMPNetForQuestionAnswering": [[225, "tfmpnetforquestionanswering"]], "MT5": [[226, "mt5"], [244, "mt5"]], "MT5Config": [[226, "mt5config"]], "MT5Tokenizer": [[226, "mt5tokenizer"]], "MT5TokenizerFast": [[226, "mt5tokenizerfast"]], "MT5Model": [[226, "mt5model"]], "MT5ForConditionalGeneration": [[226, "mt5forconditionalgeneration"]], "MT5EncoderModel": [[226, "mt5encodermodel"]], "TFMT5Model": [[226, "tfmt5model"]], "TFMT5ForConditionalGeneration": [[226, "tfmt5forconditionalgeneration"]], "TFMT5EncoderModel": [[226, "tfmt5encodermodel"]], "Pegasus": [[227, "pegasus"], [244, "pegasus"], [276, "pegasus"]], "Checkpoints": [[227, "checkpoints"]], "PegasusConfig": [[227, "pegasusconfig"]], "PegasusTokenizer": [[227, "pegasustokenizer"]], "PegasusTokenizerFast": [[227, "pegasustokenizerfast"]], "PegasusModel": [[227, "pegasusmodel"]], "PegasusForConditionalGeneration": [[227, "pegasusforconditionalgeneration"]], "PegasusForCausalLM": [[227, "pegasusforcausallm"]], "TFPegasusModel": [[227, "tfpegasusmodel"]], "TFPegasusForConditionalGeneration": [[227, "tfpegasusforconditionalgeneration"]], "PhoBERT": [[228, "phobert"]], "PhobertTokenizer": [[228, "phoberttokenizer"]], "ProphetNet": [[229, "prophetnet"], [244, "prophetnet"]], "ProphetNetConfig": [[229, "prophetnetconfig"]], "ProphetNetTokenizer": [[229, "prophetnettokenizer"]], "ProphetNet specific outputs": [[229, "prophetnet-specific-outputs"]], "ProphetNetModel": [[229, "prophetnetmodel"]], "ProphetNetEncoder": [[229, "prophetnetencoder"]], "ProphetNetDecoder": [[229, "prophetnetdecoder"]], "ProphetNetForConditionalGeneration": [[229, "prophetnetforconditionalgeneration"]], "ProphetNetForCausalLM": [[229, "prophetnetforcausallm"]], "RAG": [[230, "rag"], [244, "rag"]], "RagConfig": [[230, "ragconfig"]], "RagTokenizer": [[230, "ragtokenizer"]], "Rag specific outputs": [[230, "rag-specific-outputs"]], "RagRetriever": [[230, "ragretriever"]], "RagModel": [[230, "ragmodel"]], "RagSequenceForGeneration": [[230, "ragsequenceforgeneration"]], "RagTokenForGeneration": [[230, "ragtokenforgeneration"]], "Reformer": [[231, "reformer"], [244, "reformer"]], "Axial Positional Encodings": [[231, "axial-positional-encodings"]], "LSH Self Attention": [[231, "lsh-self-attention"]], "Local Self Attention": [[231, "local-self-attention"]], "ReformerConfig": [[231, "reformerconfig"]], "ReformerTokenizer": [[231, "reformertokenizer"]], "ReformerTokenizerFast": [[231, "reformertokenizerfast"]], "ReformerModel": [[231, "reformermodel"]], "ReformerModelWithLMHead": [[231, "reformermodelwithlmhead"]], "ReformerForMaskedLM": [[231, "reformerformaskedlm"]], "ReformerForSequenceClassification": [[231, "reformerforsequenceclassification"]], "ReformerForQuestionAnswering": [[231, "reformerforquestionanswering"]], "RetriBERT": [[232, "retribert"]], "RetriBertConfig": [[232, "retribertconfig"]], "RetriBertTokenizer": [[232, "retriberttokenizer"]], "RetriBertTokenizerFast": [[232, "retriberttokenizerfast"]], "RetriBertModel": [[232, "retribertmodel"]], "RoBERTa": [[233, "roberta"], [244, "roberta"]], "RobertaConfig": [[233, "robertaconfig"]], "RobertaTokenizer": [[233, "robertatokenizer"]], "RobertaTokenizerFast": [[233, "robertatokenizerfast"]], "RobertaModel": [[233, "robertamodel"]], "RobertaForCausalLM": [[233, "robertaforcausallm"]], "RobertaForMaskedLM": [[233, "robertaformaskedlm"]], "RobertaForSequenceClassification": [[233, "robertaforsequenceclassification"]], "RobertaForMultipleChoice": [[233, "robertaformultiplechoice"]], "RobertaForTokenClassification": [[233, "robertafortokenclassification"]], "RobertaForQuestionAnswering": [[233, "robertaforquestionanswering"]], "TFRobertaModel": [[233, "tfrobertamodel"]], "TFRobertaForMaskedLM": [[233, "tfrobertaformaskedlm"]], "TFRobertaForSequenceClassification": [[233, "tfrobertaforsequenceclassification"]], "TFRobertaForMultipleChoice": [[233, "tfrobertaformultiplechoice"]], "TFRobertaForTokenClassification": [[233, "tfrobertafortokenclassification"]], "TFRobertaForQuestionAnswering": [[233, "tfrobertaforquestionanswering"]], "FlaxRobertaModel": [[233, "flaxrobertamodel"]], "SqueezeBERT": [[234, "squeezebert"]], "SqueezeBertConfig": [[234, "squeezebertconfig"]], "SqueezeBertTokenizer": [[234, "squeezeberttokenizer"]], "SqueezeBertTokenizerFast": [[234, "squeezeberttokenizerfast"]], "SqueezeBertModel": [[234, "squeezebertmodel"]], "SqueezeBertForMaskedLM": [[234, "squeezebertformaskedlm"]], "SqueezeBertForSequenceClassification": [[234, "squeezebertforsequenceclassification"]], "SqueezeBertForMultipleChoice": [[234, "squeezebertformultiplechoice"]], "SqueezeBertForTokenClassification": [[234, "squeezebertfortokenclassification"]], "SqueezeBertForQuestionAnswering": [[234, "squeezebertforquestionanswering"]], "T5Config": [[235, "t5config"]], "T5Tokenizer": [[235, "t5tokenizer"]], "T5TokenizerFast": [[235, "t5tokenizerfast"]], "T5Model": [[235, "t5model"]], "T5ForConditionalGeneration": [[235, "t5forconditionalgeneration"]], "T5EncoderModel": [[235, "t5encodermodel"]], "TFT5Model": [[235, "tft5model"]], "TFT5ForConditionalGeneration": [[235, "tft5forconditionalgeneration"]], "TFT5EncoderModel": [[235, "tft5encodermodel"]], "TAPAS": [[236, "tapas"]], "Usage: fine-tuning": [[236, "usage-fine-tuning"]], "Usage: inference": [[236, "usage-inference"]], "Tapas specific outputs": [[236, "tapas-specific-outputs"]], "TapasConfig": [[236, "tapasconfig"]], "TapasTokenizer": [[236, "tapastokenizer"]], "TapasModel": [[236, "tapasmodel"]], "TapasForMaskedLM": [[236, "tapasformaskedlm"]], "TapasForSequenceClassification": [[236, "tapasforsequenceclassification"]], "TapasForQuestionAnswering": [[236, "tapasforquestionanswering"]], "Transformer XL": [[237, "transformer-xl"]], "TransfoXLConfig": [[237, "transfoxlconfig"]], "TransfoXLTokenizer": [[237, "transfoxltokenizer"]], "TransfoXL specific outputs": [[237, "transfoxl-specific-outputs"]], "TransfoXLModel": [[237, "transfoxlmodel"]], "TransfoXLLMHeadModel": [[237, "transfoxllmheadmodel"]], "TransfoXLForSequenceClassification": [[237, "transfoxlforsequenceclassification"]], "TFTransfoXLModel": [[237, "tftransfoxlmodel"]], "TFTransfoXLLMHeadModel": [[237, "tftransfoxllmheadmodel"]], "TFTransfoXLForSequenceClassification": [[237, "tftransfoxlforsequenceclassification"]], "Internal Layers": [[237, "internal-layers"]], "Wav2Vec2": [[238, "wav2vec2"]], "Wav2Vec2Config": [[238, "wav2vec2config"]], "Wav2Vec2CTCTokenizer": [[238, "wav2vec2ctctokenizer"]], "Wav2Vec2FeatureExtractor": [[238, "wav2vec2featureextractor"]], "Wav2Vec2Processor": [[238, "wav2vec2processor"]], "Wav2Vec2Model": [[238, "wav2vec2model"]], "Wav2Vec2ForCTC": [[238, "wav2vec2forctc"]], "XLMConfig": [[239, "xlmconfig"]], "XLMTokenizer": [[239, "xlmtokenizer"]], "XLM specific outputs": [[239, "xlm-specific-outputs"]], "XLMModel": [[239, "xlmmodel"]], "XLMWithLMHeadModel": [[239, "xlmwithlmheadmodel"]], "XLMForSequenceClassification": [[239, "xlmforsequenceclassification"]], "XLMForMultipleChoice": [[239, "xlmformultiplechoice"]], "XLMForTokenClassification": [[239, "xlmfortokenclassification"]], "XLMForQuestionAnsweringSimple": [[239, "xlmforquestionansweringsimple"]], "XLMForQuestionAnswering": [[239, "xlmforquestionanswering"]], "TFXLMModel": [[239, "tfxlmmodel"]], "TFXLMWithLMHeadModel": [[239, "tfxlmwithlmheadmodel"]], "TFXLMForSequenceClassification": [[239, "tfxlmforsequenceclassification"]], "TFXLMForMultipleChoice": [[239, "tfxlmformultiplechoice"]], "TFXLMForTokenClassification": [[239, "tfxlmfortokenclassification"]], "TFXLMForQuestionAnsweringSimple": [[239, "tfxlmforquestionansweringsimple"]], "XLM-ProphetNet": [[240, "xlm-prophetnet"], [244, "xlm-prophetnet"]], "XLMProphetNetConfig": [[240, "xlmprophetnetconfig"]], "XLMProphetNetTokenizer": [[240, "xlmprophetnettokenizer"]], "XLMProphetNetModel": [[240, "xlmprophetnetmodel"]], "XLMProphetNetEncoder": [[240, "xlmprophetnetencoder"]], "XLMProphetNetDecoder": [[240, "xlmprophetnetdecoder"]], "XLMProphetNetForConditionalGeneration": [[240, "xlmprophetnetforconditionalgeneration"]], "XLMProphetNetForCausalLM": [[240, "xlmprophetnetforcausallm"]], "XLM-RoBERTa": [[241, "xlm-roberta"], [244, "xlm-roberta"], [245, "xlm-roberta"]], "XLMRobertaConfig": [[241, "xlmrobertaconfig"]], "XLMRobertaTokenizer": [[241, "xlmrobertatokenizer"]], "XLMRobertaTokenizerFast": [[241, "xlmrobertatokenizerfast"]], "XLMRobertaModel": [[241, "xlmrobertamodel"]], "XLMRobertaForCausalLM": [[241, "xlmrobertaforcausallm"]], "XLMRobertaForMaskedLM": [[241, "xlmrobertaformaskedlm"]], "XLMRobertaForSequenceClassification": [[241, "xlmrobertaforsequenceclassification"]], "XLMRobertaForMultipleChoice": [[241, "xlmrobertaformultiplechoice"]], "XLMRobertaForTokenClassification": [[241, "xlmrobertafortokenclassification"]], "XLMRobertaForQuestionAnswering": [[241, "xlmrobertaforquestionanswering"]], "TFXLMRobertaModel": [[241, "tfxlmrobertamodel"]], "TFXLMRobertaForMaskedLM": [[241, "tfxlmrobertaformaskedlm"]], "TFXLMRobertaForSequenceClassification": [[241, "tfxlmrobertaforsequenceclassification"]], "TFXLMRobertaForMultipleChoice": [[241, "tfxlmrobertaformultiplechoice"]], "TFXLMRobertaForTokenClassification": [[241, "tfxlmrobertafortokenclassification"]], "TFXLMRobertaForQuestionAnswering": [[241, "tfxlmrobertaforquestionanswering"]], "XLNetConfig": [[242, "xlnetconfig"]], "XLNetTokenizer": [[242, "xlnettokenizer"]], "XLNetTokenizerFast": [[242, "xlnettokenizerfast"]], "XLNet specific outputs": [[242, "xlnet-specific-outputs"]], "XLNetModel": [[242, "xlnetmodel"]], "XLNetLMHeadModel": [[242, "xlnetlmheadmodel"]], "XLNetForSequenceClassification": [[242, "xlnetforsequenceclassification"]], "XLNetForMultipleChoice": [[242, "xlnetformultiplechoice"]], "XLNetForTokenClassification": [[242, "xlnetfortokenclassification"]], "XLNetForQuestionAnsweringSimple": [[242, "xlnetforquestionansweringsimple"]], "XLNetForQuestionAnswering": [[242, "xlnetforquestionanswering"]], "TFXLNetModel": [[242, "tfxlnetmodel"]], "TFXLNetLMHeadModel": [[242, "tfxlnetlmheadmodel"]], "TFXLNetForSequenceClassification": [[242, "tfxlnetforsequenceclassification"]], "TFLNetForMultipleChoice": [[242, "tflnetformultiplechoice"]], "TFXLNetForTokenClassification": [[242, "tfxlnetfortokenclassification"]], "TFXLNetForQuestionAnsweringSimple": [[242, "tfxlnetforquestionansweringsimple"]], "Model sharing and uploading": [[243, "model-sharing-and-uploading"]], "Prepare your model for uploading": [[243, "prepare-your-model-for-uploading"]], "Model versioning": [[243, "model-versioning"]], "Basic steps": [[243, "basic-steps"]], "Make your model work on all frameworks": [[243, "make-your-model-work-on-all-frameworks"]], "Check the directory before pushing to the model hub.": [[243, "check-the-directory-before-pushing-to-the-model-hub"]], "Uploading your files": [[243, "uploading-your-files"]], "Add a model card": [[243, "add-a-model-card"]], "Using your model": [[243, "using-your-model"]], "Workflow in a Colab notebook": [[243, "workflow-in-a-colab-notebook"]], "Summary of the models": [[244, "summary-of-the-models"]], "Autoregressive models": [[244, "autoregressive-models"]], "Original GPT": [[244, "original-gpt"]], "GPT-2": [[244, "gpt-2"]], "Autoencoding models": [[244, "autoencoding-models"]], "Sequence-to-sequence models": [[244, "sequence-to-sequence-models"]], "MBart": [[244, "mbart"]], "Multimodal models": [[244, "multimodal-models"]], "MMBT": [[244, "mmbt"]], "Retrieval-based models": [[244, "retrieval-based-models"]], "More technical aspects": [[244, "more-technical-aspects"]], "Full vs sparse attention": [[244, "full-vs-sparse-attention"]], "Other tricks": [[244, "other-tricks"]], "Multi-lingual models": [[245, "multi-lingual-models"]], "XLM & Language Embeddings": [[245, "xlm-language-embeddings"]], "XLM without Language Embeddings": [[245, "xlm-without-language-embeddings"]], "Perplexity of fixed-length models": [[247, "perplexity-of-fixed-length-models"]], "Calculating PPL with fixed-length models": [[247, "calculating-ppl-with-fixed-length-models"]], "Example: Calculating perplexity with GPT-2 in \ud83e\udd17 Transformers": [[247, "example-calculating-perplexity-with-gpt-2-in-transformers"]], "Philosophy": [[248, "philosophy"]], "Main concepts": [[248, "main-concepts"]], "Preprocessing data": [[249, "preprocessing-data"]], "Base use": [[249, "base-use"]], "Preprocessing pairs of sentences": [[249, "preprocessing-pairs-of-sentences"]], "Everything you always wanted to know about padding and truncation": [[249, "everything-you-always-wanted-to-know-about-padding-and-truncation"]], "Pre-tokenized inputs": [[249, "pre-tokenized-inputs"]], "Pretrained models": [[250, "pretrained-models"]], "Getting started on a task with a pipeline": [[251, "getting-started-on-a-task-with-a-pipeline"]], "Under the hood: pretrained models": [[251, "under-the-hood-pretrained-models"]], "Using the tokenizer": [[251, "using-the-tokenizer"]], "Using the model": [[251, "using-the-model"]], "Accessing the code": [[251, "accessing-the-code"]], "Customizing the model": [[251, "customizing-the-model"]], "Exporting transformers models": [[252, "exporting-transformers-models"]], "ONNX / ONNXRuntime": [[252, "onnx-onnxruntime"]], "Optimizations": [[252, "optimizations"]], "TorchScript": [[252, "torchscript"]], "Implications": [[252, "implications"]], "TorchScript flag and tied weights": [[252, "torchscript-flag-and-tied-weights"]], "Dummy inputs and standard lengths": [[252, "dummy-inputs-and-standard-lengths"]], "Using TorchScript in Python": [[252, "using-torchscript-in-python"]], "Saving a model": [[252, "saving-a-model"]], "Loading a model": [[252, "loading-a-model"]], "Using a traced model for inference": [[252, "using-a-traced-model-for-inference"]], "Summary of the tasks": [[253, "summary-of-the-tasks"]], "Sequence Classification": [[253, "sequence-classification"]], "Extractive Question Answering": [[253, "extractive-question-answering"]], "Language Modeling": [[253, "language-modeling"]], "Masked Language Modeling": [[253, "masked-language-modeling"]], "Causal Language Modeling": [[253, "causal-language-modeling"]], "Text Generation": [[253, "text-generation"]], "Named Entity Recognition": [[253, "named-entity-recognition"]], "Summarization": [[253, "summarization"], [279, "summarization"]], "Translation": [[253, "translation"], [279, "translation"]], "Testing": [[254, "testing"]], "How transformers are tested": [[254, "how-transformers-are-tested"]], "Running tests": [[254, "running-tests"]], "Choosing which tests to run": [[254, "choosing-which-tests-to-run"]], "Getting the list of all tests": [[254, "getting-the-list-of-all-tests"]], "Run a specific test module": [[254, "run-a-specific-test-module"]], "Run specific tests": [[254, "run-specific-tests"]], "Run only modified tests": [[254, "run-only-modified-tests"]], "Automatically rerun failed tests on source modification": [[254, "automatically-rerun-failed-tests-on-source-modification"]], "Skip a test module": [[254, "skip-a-test-module"]], "Clearing state": [[254, "clearing-state"]], "Running tests in parallel": [[254, "running-tests-in-parallel"]], "Test order and repetition": [[254, "test-order-and-repetition"]], "Repeat tests": [[254, "repeat-tests"]], "Run tests in a random order": [[254, "run-tests-in-a-random-order"]], "Look and feel variations": [[254, "look-and-feel-variations"]], "pytest-sugar": [[254, "pytest-sugar"]], "Report each sub-test name and its progress": [[254, "report-each-sub-test-name-and-its-progress"]], "Instantly shows failed tests": [[254, "instantly-shows-failed-tests"]], "To GPU or not to GPU": [[254, "to-gpu-or-not-to-gpu"]], "Distributed training": [[254, "distributed-training"], [261, "distributed-training"]], "Output capture": [[254, "output-capture"]], "Color control": [[254, "color-control"]], "Sending test report to online pastebin service": [[254, "sending-test-report-to-online-pastebin-service"]], "Writing tests": [[254, "writing-tests"]], "Parametrization": [[254, "parametrization"]], "Files and directories": [[254, "files-and-directories"]], "Temporary files and directories": [[254, "temporary-files-and-directories"]], "Skipping tests": [[254, "skipping-tests"]], "Implementation": [[254, "implementation"]], "Slow tests": [[254, "slow-tests"]], "Testing the stdout/stderr output": [[254, "testing-the-stdout-stderr-output"]], "Capturing logger stream": [[254, "capturing-logger-stream"]], "Testing with environment variables": [[254, "testing-with-environment-variables"]], "Getting reproducible results": [[254, "getting-reproducible-results"]], "Debugging tests": [[254, "debugging-tests"]], "Testing Experimental CI Features": [[254, "testing-experimental-ci-features"]], "Summary of the tokenizers": [[255, "summary-of-the-tokenizers"]], "Subword tokenization": [[255, "subword-tokenization"]], "Byte-Pair Encoding (BPE)": [[255, "byte-pair-encoding-bpe"]], "Byte-level BPE": [[255, "byte-level-bpe"]], "WordPiece": [[255, "wordpiece"]], "Unigram": [[255, "unigram"]], "SentencePiece": [[255, "sentencepiece"]], "Training and fine-tuning": [[256, "training-and-fine-tuning"]], "Fine-tuning in native PyTorch": [[256, "fine-tuning-in-native-pytorch"]], "Freezing the encoder": [[256, "freezing-the-encoder"]], "Fine-tuning in native TensorFlow 2": [[256, "fine-tuning-in-native-tensorflow-2"]], "Additional resources": [[256, "additional-resources"], [288, "additional-resources"], [291, "additional-resources"]], "Important note": [[257, "important-note"]], "The Big Table of Tasks": [[257, "the-big-table-of-tasks"]], "Distributed training and mixed precision": [[257, "distributed-training-and-mixed-precision"]], "Running on TPUs": [[257, "running-on-tpus"]], "Logging & Experiment tracking": [[257, "logging-experiment-tracking"]], "Weights & Biases": [[257, "weights-biases"]], "Comet.ml": [[257, "comet-ml"]], "\ud83e\udd17 Benchmark results": [[258, "benchmark-results"]], "Language model training": [[259, "language-model-training"]], "GPT-2/GPT and causal language modeling": [[259, "gpt-2-gpt-and-causal-language-modeling"]], "RoBERTa/BERT/DistilBERT and masked language modeling": [[259, "roberta-bert-distilbert-and-masked-language-modeling"]], "Whole word masking": [[259, "whole-word-masking"]], "XLNet and permutation language modeling": [[259, "xlnet-and-permutation-language-modeling"]], "Multiple Choice": [[260, "multiple-choice"]], "Fine-tuning on SWAG": [[260, "fine-tuning-on-swag"]], "Run it in colab": [[260, "run-it-in-colab"]], "Fine-tuning BERT on SQuAD1.0": [[261, "fine-tuning-bert-on-squad1-0"]], "Fine-tuning XLNet with beam search on SQuAD": [[261, "fine-tuning-xlnet-with-beam-search-on-squad"]], "Command for SQuAD1.0:": [[261, "command-for-squad1-0"]], "Command for SQuAD2.0:": [[261, "command-for-squad2-0"]], "Results for SQuAD1.0 with the previously defined hyper-parameters:": [[261, "results-for-squad1-0-with-the-previously-defined-hyper-parameters"]], "Results for SQuAD2.0 with the previously defined hyper-parameters:": [[261, "results-for-squad2-0-with-the-previously-defined-hyper-parameters"]], "Fine-tuning BERT on SQuAD1.0 with relative position embeddings": [[261, "fine-tuning-bert-on-squad1-0-with-relative-position-embeddings"]], "Base models fine-tuning": [[261, "base-models-fine-tuning"]], "Large models fine-tuning": [[261, "large-models-fine-tuning"]], "SQuAD with the Tensorflow Trainer": [[261, "squad-with-the-tensorflow-trainer"]], "Research projects": [[262, "research-projects"]], "Adversarial evaluation of model performances": [[263, "adversarial-evaluation-of-model-performances"]], "Patience-based Early Exit": [[264, "patience-based-early-exit"]], "Results": [[264, "results"], [298, "results"], [303, "results"], [308, "results"], [309, "results"]], "Text Summarization with Pretrained Encoders": [[265, "text-summarization-with-pretrained-encoders"]], "Setup": [[265, "setup"], [267, "setup"], [272, "setup"], [274, "setup"]], "Reproduce the authors\u2019  ROUGE score": [[265, "reproduce-the-authors-rouge-score"]], "Summarize any text": [[265, "summarize-any-text"]], "DeeBERT: Early Exiting for *BERT": [[266, "deebert-early-exiting-for-bert"]], "train_deebert.sh": [[266, "train-deebert-sh"]], "eval_deebert.sh": [[266, "eval-deebert-sh"]], "entropy_eval.sh": [[266, "entropy-eval-sh"]], "Distil*": [[267, "distil"]], "What is Distil*": [[267, "what-is-distil"]], "How to use DistilBERT": [[267, "how-to-use-distilbert"]], "How to train Distil*": [[267, "how-to-train-distil"]], "A. Preparing the data": [[267, "a-preparing-the-data"]], "B. Training": [[267, "b-training"]], "Long Form Question Answering": [[268, "long-form-question-answering"]], "LXMERT DEMO": [[269, "lxmert-demo"]], "Whole Word Mask Language Model": [[270, "whole-word-mask-language-model"]], "MM-IMDb": [[271, "mm-imdb"]], "Training on MM-IMDb": [[271, "training-on-mm-imdb"]], "Movement Pruning: Adaptive Sparsity by Fine-Tuning": [[272, "movement-pruning-adaptive-sparsity-by-fine-tuning"]], "Extreme sparsity and efficient storage": [[272, "extreme-sparsity-and-efficient-storage"]], "Fine-pruned models": [[272, "fine-pruned-models"]], "How to fine-prune?": [[272, "how-to-fine-prune"]], "Fine-pruning with movement pruning": [[272, "fine-pruning-with-movement-pruning"]], "Fine-pruning with other methods": [[272, "fine-pruning-with-other-methods"]], "After fine-pruning": [[272, "after-fine-pruning"]], "Hyper-parameters": [[272, "hyper-parameters"]], "Inference speed": [[272, "inference-speed"]], "Performer fine-tuning": [[273, "performer-fine-tuning"]], "Requirements": [[273, "requirements"], [380, "requirements"], [384, "requirements"]], "Plug and Play Language Models: a Simple Approach to Controlled Text Generation": [[274, "plug-and-play-language-models-a-simple-approach-to-controlled-text-generation"]], "PPLM-BoW": [[274, "pplm-bow"]], "Example command for bag-of-words control": [[274, "example-command-for-bag-of-words-control"]], "Tuning hyperparameters for bag-of-words control": [[274, "tuning-hyperparameters-for-bag-of-words-control"]], "PPLM-Discrim": [[274, "pplm-discrim"]], "Example command for discriminator based sentiment control": [[274, "example-command-for-discriminator-based-sentiment-control"]], "Tuning hyperparameters for discriminator control": [[274, "tuning-hyperparameters-for-discriminator-control"]], "Intro": [[275, "intro"], [298, "intro"], [308, "intro"]], "Finetuning": [[275, "finetuning"]], "Document Retrieval": [[275, "document-retrieval"]], "Evaluation": [[275, "evaluation"], [276, "evaluation"]], "Retrieval evaluation": [[275, "retrieval-evaluation"]], "End-to-end evaluation": [[275, "end-to-end-evaluation"]], "Use your own knowledge source": [[275, "use-your-own-knowledge-source"]], "Sequence to Sequence Training and Evaluation": [[276, "sequence-to-sequence-training-and-evaluation"], [279, "sequence-to-sequence-training-and-evaluation"]], "Supported Architectures": [[276, "supported-architectures"], [279, "supported-architectures"]], "Datasets": [[276, "datasets"]], "XSUM": [[276, "xsum"]], "CNN/DailyMail": [[276, "cnn-dailymail"]], "WMT16 English-Romanian Translation Data": [[276, "wmt16-english-romanian-translation-data"]], "WMT English-German": [[276, "wmt-english-german"]], "FSMT datasets (wmt)": [[276, "fsmt-datasets-wmt"]], "Pegasus (multiple datasets)": [[276, "pegasus-multiple-datasets"]], "Your Data": [[276, "your-data"]], "Potential issues": [[276, "potential-issues"]], "Tips and Tricks": [[276, "tips-and-tricks"]], "Finetuning Scripts": [[276, "finetuning-scripts"]], "Finetuning Training Params": [[276, "finetuning-training-params"]], "Summarization Finetuning": [[276, "summarization-finetuning"]], "Translation Finetuning": [[276, "translation-finetuning"]], "Finetuning Outputs": [[276, "finetuning-outputs"]], "Converting pytorch-lightning checkpoints": [[276, "converting-pytorch-lightning-checkpoints"]], "Experimental Features": [[276, "experimental-features"]], "Dynamic Batch Size for MT": [[276, "dynamic-batch-size-for-mt"]], "DistilBART": [[276, "distilbart"]], "Recommended Workflow": [[276, "recommended-workflow"]], "Initialization": [[276, "initialization"]], "SFT (No Teacher Distillation)": [[276, "sft-no-teacher-distillation"]], "Pseudo-Labeling": [[276, "pseudo-labeling"]], "Direct Knowledge Distillation (KD)": [[276, "direct-knowledge-distillation-kd"]], "Saved Pseudo-Labels": [[277, "saved-pseudo-labels"]], "Available Pseudo-labels": [[277, "available-pseudo-labels"]], "Generating New Pseudolabels": [[277, "generating-new-pseudolabels"]], "Contributions": [[277, "contributions"]], "Zero-shot classifier distillation": [[278, "zero-shot-classifier-distillation"]], "Example: Topic classification": [[278, "example-topic-classification"]], "Custom CSV Files": [[279, "custom-csv-files"]], "Custom JSONFILES Files": [[279, "custom-jsonfiles-files"]], "Text classification examples": [[280, "text-classification-examples"]], "PyTorch version": [[280, "pytorch-version"]], "Mixed precision training": [[280, "mixed-precision-training"]], "Run TensorFlow 2.0 version": [[280, "run-tensorflow-2-0-version"]], "Run generic text classification script in TensorFlow": [[280, "run-generic-text-classification-script-in-tensorflow"]], "Fine-tuning on XNLI": [[280, "fine-tuning-on-xnli"]], "Language generation": [[281, "language-generation"]], "Token classification": [[282, "token-classification"]], "Old version of the script": [[282, "old-version-of-the-script"]], "TensorFlow version": [[282, "tensorflow-version"]], "GermEval 2014 (German NER) dataset": [[282, "germeval-2014-german-ner-dataset"]], "Data (Download and pre-processing steps)": [[282, "data-download-and-pre-processing-steps"]], "Prepare the run": [[282, "prepare-the-run"]], "\ud83d\udd25 Model cards now live inside each huggingface.co model repo \ud83d\udd25": [[283, "model-cards-now-live-inside-each-huggingface-co-model-repo"]], "How to update a model card": [[283, "how-to-update-a-model-card"]], "What happened to the model cards here?": [[283, "what-happened-to-the-model-cards-here"]], "TAPAS base model": [[284, "tapas-base-model"]], "Model description": [[284, "model-description"]], "Intended uses & limitations": [[284, "intended-uses-limitations"]], "Training data": [[284, "training-data"]], "Training procedure": [[284, "training-procedure"]], "Preprocessing": [[284, "preprocessing"]], "Pretraining": [[284, "pretraining"]], "BibTeX entry and citation info": [[284, "bibtex-entry-and-citation-info"]], "\ud83e\udd17 Transformers Notebooks": [[285, "transformers-notebooks"]], "Hugging Face\u2019s notebooks \ud83e\udd17": [[285, "hugging-face-s-notebooks"]], "Upload converted models": [[286, "upload-converted-models"]], "Modifications": [[286, "modifications"]], "How to add a new example script in \ud83e\udd17 Transformers": [[287, "how-to-add-a-new-example-script-in-transformers"]], "TEMPLATE": [[288, "template"]], "How to add [camelcase name of model] to \ud83e\udd17 Transformers?": [[288, "how-to-add-camelcase-name-of-model-to-transformers"]], "1. (Optional) Theoretical aspects of [camelcase name of model]": [[288, "optional-theoretical-aspects-of-camelcase-name-of-model"]], "Make sure you\u2019ve understood the fundamental aspects of [camelcase name of model]": [[288, "make-sure-you-ve-understood-the-fundamental-aspects-of-camelcase-name-of-model"]], "Run a pretrained checkpoint using the original repository": [[288, "run-a-pretrained-checkpoint-using-the-original-repository"], [291, "run-a-pretrained-checkpoint-using-the-original-repository"]], "More details on how to create a debugging environment for [camelcase name of model]": [[288, "more-details-on-how-to-create-a-debugging-environment-for-camelcase-name-of-model"]], "Port [camelcase name of model] to \ud83e\udd17 Transformers": [[288, "port-camelcase-name-of-model-to-transformers"]], "Using cookiecutter to generate models": [[289, "using-cookiecutter-to-generate-models"]], "{{cookiecutter.modelname}}": [[290, "cookiecutter-modelname"]], "{{cookiecutter.camelcase_modelname}}Config": [[290, "cookiecutter-camelcase-modelname-config"]], "{{cookiecutter.camelcase_modelname}}Tokenizer": [[290, "cookiecutter-camelcase-modelname-tokenizer"]], "{{cookiecutter.camelcase_modelname}}TokenizerFast": [[290, "cookiecutter-camelcase-modelname-tokenizerfast"]], "{{cookiecutter.camelcase_modelname}}ForMaskedLM": [[290, "cookiecutter-camelcase-modelname-formaskedlm"]], "{{cookiecutter.camelcase_modelname}}ForSequenceClassification": [[290, "cookiecutter-camelcase-modelname-forsequenceclassification"], [290, "id1"]], "{{cookiecutter.camelcase_modelname}}ForMultipleChoice": [[290, "cookiecutter-camelcase-modelname-formultiplechoice"]], "{{cookiecutter.camelcase_modelname}}ForTokenClassification": [[290, "cookiecutter-camelcase-modelname-fortokenclassification"]], "{{cookiecutter.camelcase_modelname}}ForQuestionAnswering": [[290, "cookiecutter-camelcase-modelname-forquestionanswering"], [290, "id2"]], "{{cookiecutter.camelcase_modelname}}ForCausalLM": [[290, "cookiecutter-camelcase-modelname-forcausallm"]], "TF{{cookiecutter.camelcase_modelname}}Model": [[290, "tf-cookiecutter-camelcase-modelname-model"]], "TF{{cookiecutter.camelcase_modelname}}ForCausalLM": [[290, "tf-cookiecutter-camelcase-modelname-forcausallm"]], "TF{{cookiecutter.camelcase_modelname}}ForSequenceClassification": [[290, "tf-cookiecutter-camelcase-modelname-forsequenceclassification"]], "TF{{cookiecutter.camelcase_modelname}}ForMultipleChoice": [[290, "tf-cookiecutter-camelcase-modelname-formultiplechoice"]], "TF{{cookiecutter.camelcase_modelname}}ForTokenClassification": [[290, "tf-cookiecutter-camelcase-modelname-fortokenclassification"]], "TF{{cookiecutter.camelcase_modelname}}ForQuestionAnswering": [[290, "tf-cookiecutter-camelcase-modelname-forquestionanswering"]], "How to add BigBird to \ud83e\udd17 Transformers?": [[291, "how-to-add-bigbird-to-transformers"]], "1. (Optional) Theoretical aspects of BigBird": [[291, "optional-theoretical-aspects-of-bigbird"]], "Make sure you\u2019ve understood the fundamental aspects of BigBird": [[291, "make-sure-you-ve-understood-the-fundamental-aspects-of-bigbird"]], "(Important) More details on how to create a debugging environment for BigBird": [[291, "important-more-details-on-how-to-create-a-debugging-environment-for-bigbird"]], "Port BigBird to \ud83e\udd17 Transformers": [[291, "port-bigbird-to-transformers"]], "Python Version": [[293, "python-version"], [294, "python-version"], [295, "python-version"], [297, "python-version"], [299, "python-version"], [301, "python-version"], [302, "python-version"], [303, "python-version"], [304, "python-version"], [305, "python-version"], [307, "python-version"], [311, "python-version"], [312, "python-version"], [313, "python-version"], [314, "python-version"], [316, "python-version"]], "Install transformers": [[293, "install-transformers"], [301, "install-transformers"], [311, "install-transformers"], [316, "install-transformers"]], "Install PyTorch": [[293, "install-pytorch"], [296, "install-pytorch"], [299, "install-pytorch"], [301, "install-pytorch"], [311, "install-pytorch"], [312, "install-pytorch"], [313, "install-pytorch"], [314, "install-pytorch"], [316, "install-pytorch"]], "2. Prepare pretrained model": [[293, "prepare-pretrained-model"], [296, "prepare-pretrained-model"], [301, "prepare-pretrained-model"], [311, "prepare-pretrained-model"], [312, "prepare-pretrained-model"], [313, "prepare-pretrained-model"], [314, "prepare-pretrained-model"]], "Language-modeling": [[293, "language-modeling"]], "Finetune command": [[293, "finetune-command"]], "Start to neural_compressor tune for Model Quantization": [[293, "start-to-neural-compressor-tune-for-model-quantization"], [299, "start-to-neural-compressor-tune-for-model-quantization"], [301, "start-to-neural-compressor-tune-for-model-quantization"], [311, "start-to-neural-compressor-tune-for-model-quantization"], [312, "start-to-neural-compressor-tune-for-model-quantization"], [313, "start-to-neural-compressor-tune-for-model-quantization"], [314, "start-to-neural-compressor-tune-for-model-quantization"], [316, "start-to-neural-compressor-tune-for-model-quantization"]], "Glue task": [[293, "glue-task"], [311, "glue-task"], [312, "glue-task"], [313, "glue-task"], [314, "glue-task"]], "Seq2seq task": [[293, "seq2seq-task"]], "Language-modeling task": [[293, "language-modeling-task"]], "Code Prepare": [[293, "code-prepare"], [299, "code-prepare"], [301, "code-prepare"], [311, "code-prepare"], [312, "code-prepare"], [313, "code-prepare"], [314, "code-prepare"], [316, "code-prepare"]], "Start to neural_compressor tune for Model Distillation": [[294, "start-to-neural-compressor-tune-for-model-distillation"], [302, "start-to-neural-compressor-tune-for-model-distillation"]], "SQuAD task": [[294, "squad-task"], [295, "squad-task"], [297, "squad-task"]], "Start running neural_compressor implementation of Prune Once For All": [[295, "start-running-neural-compressor-implementation-of-prune-once-for-all"], [304, "start-running-neural-compressor-implementation-of-prune-once-for-all"]], "Install neural_compressor": [[296, "install-neural-compressor"]], "Install BERT dependency": [[296, "install-bert-dependency"]], "1. Prepare Dataset": [[296, "prepare-dataset"]], "Original BERT README": [[296, "original-bert-readme"]], "Start to neural_compressor tune for Model Pruning": [[297, "start-to-neural-compressor-tune-for-model-pruning"], [305, "start-to-neural-compressor-tune-for-model-pruning"], [307, "start-to-neural-compressor-tune-for-model-pruning"]], "Pytorch Pruner": [[298, "pytorch-pruner"], [308, "pytorch-pruner"]], "Write a config yaml file": [[298, "write-a-config-yaml-file"], [308, "write-a-config-yaml-file"]], "Coding template:": [[298, "coding-template"], [308, "coding-template"]], "References": [[298, "references"], [308, "references"]], "Install BERT model": [[299, "install-bert-model"], [312, "install-bert-model"], [313, "install-bert-model"], [314, "install-bert-model"]], "This is a tutorial of how to enable NLP model with Intel\u00ae Neural Compressor.": [[299, "this-is-a-tutorial-of-how-to-enable-nlp-model-with-intel-neural-compressor"], [312, "this-is-a-tutorial-of-how-to-enable-nlp-model-with-intel-neural-compressor"], [313, "this-is-a-tutorial-of-how-to-enable-nlp-model-with-intel-neural-compressor"], [314, "this-is-a-tutorial-of-how-to-enable-nlp-model-with-intel-neural-compressor"]], "Intel\u00ae Neural Compressor supports two usages:": [[299, "intel-neural-compressor-supports-two-usages"], [312, "intel-neural-compressor-supports-two-usages"], [313, "intel-neural-compressor-supports-two-usages"], [314, "intel-neural-compressor-supports-two-usages"]], "Step by step": [[300, "step-by-step"]], "Bert-Large Inference": [[300, "bert-large-inference"]], "Distilbert-base Inference": [[300, "distilbert-base-inference"]], "Seq2seq": [[301, "seq2seq"]], "summarization_billsum task": [[301, "summarization-billsum-task"]], "SST-2 task": [[302, "sst-2-task"], [303, "sst-2-task"], [304, "sst-2-task"], [305, "sst-2-task"], [307, "sst-2-task"]], "MNLI task": [[302, "mnli-task"], [303, "mnli-task"], [304, "mnli-task"], [307, "mnli-task"]], "QQP task": [[302, "qqp-task"], [303, "qqp-task"], [304, "qqp-task"], [307, "qqp-task"]], "COLA task": [[302, "cola-task"]], "Start running neural_compressor implementation of distillation for quantization": [[303, "start-running-neural-compressor-implementation-of-distillation-for-quantization"]], "QNLI task": [[303, "qnli-task"], [304, "qnli-task"], [307, "qnli-task"]], "Prepare environment": [[306, "prepare-environment"]], "Glue": [[308, "glue"]], "MRPC": [[308, "mrpc"]], "SST-2": [[308, "sst-2"]], "\u201cPruning while distillation\u201d step by step": [[309, "pruning-while-distillation-step-by-step"]], "1 Requirements": [[309, "requirements"]], "2 Run the example on SST2 and external datasets": [[309, "run-the-example-on-sst2-and-external-datasets"]], "2.1 Modify the configurations": [[309, "modify-the-configurations"]], "2.2 Run the code": [[309, "run-the-code"]], "2.3 Reference": [[309, "reference"]], "Notice": [[310, "notice"]], "1. To get the tuned model and its accuracy:": [[311, "to-get-the-tuned-model-and-its-accuracy"], [312, "to-get-the-tuned-model-and-its-accuracy"], [314, "to-get-the-tuned-model-and-its-accuracy"]], "2. To get the benchmark of tuned model, includes batch_size and throughput:": [[311, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"]], "HuggingFace model hub": [[311, "huggingface-model-hub"], [312, "huggingface-model-hub"], [314, "huggingface-model-hub"], [315, "huggingface-model-hub"]], "To upstream into HuggingFace model hub": [[311, "to-upstream-into-huggingface-model-hub"], [312, "to-upstream-into-huggingface-model-hub"], [314, "to-upstream-into-huggingface-model-hub"], [315, "to-upstream-into-huggingface-model-hub"]], "To download into HuggingFace model hub": [[311, "to-download-into-huggingface-model-hub"], [312, "to-download-into-huggingface-model-hub"], [314, "to-download-into-huggingface-model-hub"], [315, "to-download-into-huggingface-model-hub"]], "Using Shapley MSE as Objective": [[311, "using-shapley-mse-as-objective"]], "2. To get the benchmark of tuned model, includes Batch_size and Throughput:": [[312, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"], [314, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"]], "2. Prepare fine-tuned model": [[315, "prepare-fine-tuned-model"]], "1. Enable bert-base-cased/uncased example with the auto quantization aware training strategy of Neural Compressor.": [[315, "enable-bert-base-cased-uncased-example-with-the-auto-quantization-aware-training-strategy-of-neural-compressor"]], "2. To get the tuned model and its accuracy:": [[315, "to-get-the-tuned-model-and-its-accuracy"], [326, "to-get-the-tuned-model-and-its-accuracy"], [329, "to-get-the-tuned-model-and-its-accuracy"], [337, "to-get-the-tuned-model-and-its-accuracy"]], "3. To get the benchmark of tuned model, includes Batch_size and Throughput:": [[315, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"], [326, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"], [329, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"], [337, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"]], "1. Problem": [[317, "problem"]], "2. Directions": [[317, "directions"]], "Steps to configure machine": [[317, "steps-to-configure-machine"]], "Steps to download data": [[317, "steps-to-download-data"]], "Steps to run benchmark.": [[317, "steps-to-run-benchmark"]], "3. Dataset/Environment": [[317, "dataset-environment"]], "Publication/Attribution": [[317, "publication-attribution"], [317, "id1"]], "Data preprocessing": [[317, "data-preprocessing"]], "Training and test data separation": [[317, "training-and-test-data-separation"]], "Training data order": [[317, "training-data-order"]], "Test data order": [[317, "test-data-order"]], "4. Model": [[317, "model"]], "List of layers": [[317, "list-of-layers"]], "Weight and bias initialization": [[317, "weight-and-bias-initialization"]], "Loss function": [[317, "loss-function"]], "5. Quality": [[317, "quality"]], "Quality metric": [[317, "quality-metric"]], "Quality target": [[317, "quality-target"]], "Evaluation frequency": [[317, "evaluation-frequency"]], "Evaluation thoroughness": [[317, "evaluation-thoroughness"]], "Prepare weights": [[318, "prepare-weights"]], "Abstractions": [[319, "abstractions"], [322, "abstractions"]], "ImageList": [[319, "imagelist"]], "BoxList": [[319, "boxlist"]], "Requirements:": [[320, "requirements"]], "Option 1: Step-by-step installation": [[320, "option-1-step-by-step-installation"]], "Option 2: Docker Image (Requires CUDA, Linux only)": [[320, "option-2-docker-image-requires-cuda-linux-only"]], "Model Zoo and Baselines": [[321, "model-zoo-and-baselines"], [322, "model-zoo-and-baselines"]], "Hardware": [[321, "hardware"]], "Software": [[321, "software"]], "End-to-end Faster and Mask R-CNN baselines": [[321, "end-to-end-faster-and-mask-r-cnn-baselines"]], "Comparison with Detectron and mmdetection": [[321, "comparison-with-detectron-and-mmdetection"]], "Training speed": [[321, "training-speed"]], "Training memory": [[321, "training-memory"]], "Accuracy": [[321, "accuracy"]], "Faster R-CNN and Mask R-CNN in PyTorch 1.0": [[322, "faster-r-cnn-and-mask-r-cnn-in-pytorch-1-0"]], "Highlights": [[322, "highlights"]], "Webcam and Jupyter notebook demo": [[322, "webcam-and-jupyter-notebook-demo"]], "Inference in a few lines": [[322, "inference-in-a-few-lines"]], "Perform training on COCO dataset": [[322, "perform-training-on-coco-dataset"]], "Single GPU training": [[322, "single-gpu-training"]], "Multi-GPU training": [[322, "multi-gpu-training"]], "Adding your own dataset": [[322, "adding-your-own-dataset"]], "Note:": [[322, "note"]], "Finetuning from Detectron weights on custom datasets": [[322, "finetuning-from-detectron-weights-on-custom-datasets"]], "Troubleshooting": [[322, "troubleshooting"], [323, "troubleshooting"]], "Citations": [[322, "citations"]], "Projects using maskrcnn-benchmark": [[322, "projects-using-maskrcnn-benchmark"]], "Compilation errors when compiling the library": [[323, "compilation-errors-when-compiling-the-library"]], "ImportError: No module named maskrcnn_benchmark.config when running webcam.py": [[323, "importerror-no-module-named-maskrcnn-benchmark-config-when-running-webcam-py"]], "ImportError: Undefined symbol: __cudaPopCallConfiguration error when import _C": [[323, "importerror-undefined-symbol-cudapopcallconfiguration-error-when-import-c"]], "Segmentation fault (core dumped) when running the library": [[323, "segmentation-fault-core-dumped-when-running-the-library"]], "Setting Up Datasets": [[324, "setting-up-datasets"]], "Creating Symlinks for PASCAL VOC": [[324, "creating-symlinks-for-pascal-voc"]], "PASCAL VOC Annotations in COCO Format": [[324, "pascal-voc-annotations-in-coco-format"]], "Creating Symlinks for Cityscapes:": [[324, "creating-symlinks-for-cityscapes"]], "Steps to convert Cityscapes Annotations to COCO Format": [[324, "steps-to-convert-cityscapes-annotations-to-coco-format"]], "Utility functions": [[325, "utility-functions"]], "3. Prepare pre-trained model": [[326, "prepare-pre-trained-model"], [337, "prepare-pre-trained-model"], [358, "prepare-pre-trained-model"]], "1. Enable ssd_resnet34 example with the auto dynamic quantization strategy of Neural Compressor.": [[326, "enable-ssd-resnet34-example-with-the-auto-dynamic-quantization-strategy-of-neural-compressor"]], "4. The following is the brief output information:": [[326, "the-following-is-the-brief-output-information"], [337, "the-following-is-the-brief-output-information"]], "Upscaled COCO Dataset": [[327, "upscaled-coco-dataset"]], "Parameters": [[327, "parameters"]], "How to run": [[327, "how-to-run"]], "SSD-ResNet34 Inference": [[328, "ssd-resnet34-inference"]], "Model Specific Setup": [[328, "model-specific-setup"]], "2. Download Dataset": [[329, "download-dataset"]], "3. Train the Model": [[329, "train-the-model"]], "1. Enable ssd_resnet34 example with quant aware training strategy of Neural Compressor.": [[329, "enable-ssd-resnet34-example-with-quant-aware-training-strategy-of-neural-compressor"]], "3. Prepare Weights": [[330, "prepare-weights"]], "Examples Of Enabling Neural Compressor Auto Tuning On PyTorch YOLOV3": [[330, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-yolov3"]], "PyTorch-YOLOv3": [[331, "pytorch-yolov3"]], "Clone and install requirements": [[331, "clone-and-install-requirements"]], "Download pretrained weights": [[331, "download-pretrained-weights"]], "Download COCO": [[331, "download-coco"]], "Test": [[331, "test"]], "Train": [[331, "train"], [331, "id1"]], "Example (COCO)": [[331, "example-coco"]], "Training log": [[331, "training-log"]], "Tensorboard": [[331, "tensorboard"]], "Train on Custom Dataset": [[331, "train-on-custom-dataset"]], "Classes": [[331, "classes"]], "Image Folder": [[331, "image-folder"]], "Annotation Folder": [[331, "annotation-folder"]], "Define Train and Validation Sets": [[331, "define-train-and-validation-sets"]], "Credit": [[331, "credit"]], "YOLOv3: An Incremental Improvement": [[331, "yolov3-an-incremental-improvement"]], "tune with INC": [[332, "tune-with-inc"], [333, "tune-with-inc"], [336, "tune-with-inc"]], "Code of Conduct": [[334, "code-of-conduct"]], "Contributing to DLRM": [[335, "contributing-to-dlrm"]], "Pull Requests": [[335, "pull-requests"]], "Contributor License Agreement (\u201dCLA\u201d)": [[335, "contributor-license-agreement-cla"]], "Issues": [[335, "issues"]], "Coding Style": [[335, "coding-style"]], "1. Enable RNNT example with the auto dynamic quantization strategy of Neural Compressor.": [[337, "enable-rnnt-example-with-the-auto-dynamic-quantization-strategy-of-neural-compressor"]], "1. Wav2vec2.0": [[338, "wav2vec2-0"]], "2. Hubert": [[338, "hubert"]], "2. Install Intel Tensorflow": [[339, "install-intel-tensorflow"], [342, "install-intel-tensorflow"], [343, "install-intel-tensorflow"], [345, "install-intel-tensorflow"], [346, "install-intel-tensorflow"], [347, "install-intel-tensorflow"], [348, "install-intel-tensorflow"], [349, "install-intel-tensorflow"], [350, "install-intel-tensorflow"], [351, "install-intel-tensorflow"], [352, "install-intel-tensorflow"], [353, "install-intel-tensorflow"], [357, "install-intel-tensorflow"], [359, "install-intel-tensorflow"], [360, "install-intel-tensorflow"], [361, "install-intel-tensorflow"], [363, "install-intel-tensorflow"], [365, "install-intel-tensorflow"], [366, "install-intel-tensorflow"], [368, "install-intel-tensorflow"], [369, "install-intel-tensorflow"], [370, "install-intel-tensorflow"], [371, "install-intel-tensorflow"]], "3. Install Intel Extension for Tensorflow": [[339, "install-intel-extension-for-tensorflow"], [342, "install-intel-extension-for-tensorflow"], [343, "install-intel-extension-for-tensorflow"], [344, "install-intel-extension-for-tensorflow"], [345, "install-intel-extension-for-tensorflow"], [346, "install-intel-extension-for-tensorflow"], [347, "install-intel-extension-for-tensorflow"], [348, "install-intel-extension-for-tensorflow"], [349, "install-intel-extension-for-tensorflow"], [350, "install-intel-extension-for-tensorflow"], [351, "install-intel-extension-for-tensorflow"], [352, "install-intel-extension-for-tensorflow"], [353, "install-intel-extension-for-tensorflow"], [359, "install-intel-extension-for-tensorflow"], [360, "install-intel-extension-for-tensorflow"], [361, "install-intel-extension-for-tensorflow"], [363, "install-intel-extension-for-tensorflow"], [364, "install-intel-extension-for-tensorflow"], [368, "install-intel-extension-for-tensorflow"], [369, "install-intel-extension-for-tensorflow"], [370, "install-intel-extension-for-tensorflow"]], "Quantizing the model on Intel GPU": [[339, "quantizing-the-model-on-intel-gpu"], [342, "quantizing-the-model-on-intel-gpu"], [343, "quantizing-the-model-on-intel-gpu"], [344, "quantizing-the-model-on-intel-gpu"], [345, "quantizing-the-model-on-intel-gpu"], [346, "quantizing-the-model-on-intel-gpu"], [347, "quantizing-the-model-on-intel-gpu"], [348, "quantizing-the-model-on-intel-gpu"], [349, "quantizing-the-model-on-intel-gpu"], [350, "quantizing-the-model-on-intel-gpu"], [351, "quantizing-the-model-on-intel-gpu"], [352, "quantizing-the-model-on-intel-gpu"], [353, "quantizing-the-model-on-intel-gpu"], [357, "quantizing-the-model-on-intel-gpu"], [359, "quantizing-the-model-on-intel-gpu"], [360, "quantizing-the-model-on-intel-gpu"], [361, "quantizing-the-model-on-intel-gpu"], [363, "quantizing-the-model-on-intel-gpu"], [364, "quantizing-the-model-on-intel-gpu"], [365, "quantizing-the-model-on-intel-gpu"], [366, "quantizing-the-model-on-intel-gpu"], [367, "quantizing-the-model-on-intel-gpu"], [368, "quantizing-the-model-on-intel-gpu"], [369, "quantizing-the-model-on-intel-gpu"], [370, "quantizing-the-model-on-intel-gpu"], [371, "quantizing-the-model-on-intel-gpu"]], "Quantizing the model on Intel CPU(Experimental)": [[339, "quantizing-the-model-on-intel-cpu-experimental"], [342, "quantizing-the-model-on-intel-cpu-experimental"], [343, "quantizing-the-model-on-intel-cpu-experimental"], [344, "quantizing-the-model-on-intel-cpu-experimental"], [345, "quantizing-the-model-on-intel-cpu-experimental"], [346, "quantizing-the-model-on-intel-cpu-experimental"], [347, "quantizing-the-model-on-intel-cpu-experimental"], [348, "quantizing-the-model-on-intel-cpu-experimental"], [349, "quantizing-the-model-on-intel-cpu-experimental"], [350, "quantizing-the-model-on-intel-cpu-experimental"], [351, "quantizing-the-model-on-intel-cpu-experimental"], [352, "quantizing-the-model-on-intel-cpu-experimental"], [353, "quantizing-the-model-on-intel-cpu-experimental"], [357, "quantizing-the-model-on-intel-cpu-experimental"], [359, "quantizing-the-model-on-intel-cpu-experimental"], [360, "quantizing-the-model-on-intel-cpu-experimental"], [361, "quantizing-the-model-on-intel-cpu-experimental"], [363, "quantizing-the-model-on-intel-cpu-experimental"], [364, "quantizing-the-model-on-intel-cpu-experimental"], [365, "quantizing-the-model-on-intel-cpu-experimental"], [366, "quantizing-the-model-on-intel-cpu-experimental"], [367, "quantizing-the-model-on-intel-cpu-experimental"], [368, "quantizing-the-model-on-intel-cpu-experimental"], [369, "quantizing-the-model-on-intel-cpu-experimental"], [370, "quantizing-the-model-on-intel-cpu-experimental"], [371, "quantizing-the-model-on-intel-cpu-experimental"]], "4. Prepare Pretrained model": [[339, "prepare-pretrained-model"], [342, "prepare-pretrained-model"], [343, "prepare-pretrained-model"], [344, "prepare-pretrained-model"], [345, "prepare-pretrained-model"], [346, "prepare-pretrained-model"], [347, "prepare-pretrained-model"], [348, "prepare-pretrained-model"], [349, "prepare-pretrained-model"], [350, "prepare-pretrained-model"], [351, "prepare-pretrained-model"], [352, "prepare-pretrained-model"], [353, "prepare-pretrained-model"]], "2. Install requirements": [[340, "install-requirements"]], "3. Train and save a ViT model": [[340, "train-and-save-a-vit-model"]], "Run command to prune the model": [[340, "run-command-to-prune-the-model"], [341, "run-command-to-prune-the-model"], [354, "run-command-to-prune-the-model"]], "1. Install Intel\u00ae Neural Compressor": [[341, "install-intel-neural-compressor"], [362, "install-intel-neural-compressor"]], "2. Install other requirements": [[341, "install-other-requirements"]], "2. Install Intel Tensorflow and TensorFlow Model Optimization": [[344, "install-intel-tensorflow-and-tensorflow-model-optimization"]], "5. Prepare QAT model": [[344, "prepare-qat-model"]], "5. Prepare dataset": [[348, "prepare-dataset"]], "2. Install TensorFlow 2.10.0 or above.": [[354, "install-tensorflow-2-10-0-or-above"]], "3. Train and save a ResNet-V2 model": [[354, "train-and-save-a-resnet-v2-model"]], "2. Install Intel Tensorflow 2.4.0 or above.": [[355, "install-intel-tensorflow-2-4-0-or-above"]], "3. Install tensorflow_model_optimization": [[355, "install-tensorflow-model-optimization"]], "3. Installation Dependency packages": [[357, "installation-dependency-packages"], [365, "installation-dependency-packages"], [366, "installation-dependency-packages"]], "4. Install Intel Extension for Tensorflow": [[357, "install-intel-extension-for-tensorflow"], [366, "install-intel-extension-for-tensorflow"], [371, "install-intel-extension-for-tensorflow"]], "5. Prepare Dataset": [[357, "prepare-dataset"], [368, "prepare-dataset"], [371, "prepare-dataset"]], "6. Prepare pre-trained model": [[357, "prepare-pre-trained-model"]], "Install Intel Tensorflow 1.15 up2": [[357, "install-intel-tensorflow-1-15-up2"]], "1. ResNet50 V1.0": [[357, "resnet50-v1-0"]], "2. ResNet50 V1.5": [[357, "resnet50-v1-5"]], "3. ResNet101": [[357, "resnet101"]], "4. MobileNet V1": [[357, "mobilenet-v1"]], "5. MobileNet V2*": [[357, "mobilenet-v2"]], "6. Inception V1*": [[357, "inception-v1"]], "7. Inception V2*": [[357, "inception-v2"]], "8. Inception V3": [[357, "inception-v3"]], "9. Inception V4": [[357, "inception-v4"]], "10. Inception ResNet V2*": [[357, "inception-resnet-v2"]], "11. VGG 16*": [[357, "vgg-16"]], "12. VGG 19*": [[357, "vgg-19"]], "13. ResNet v2 50": [[357, "resnet-v2-50"]], "14. ResNet v2 101": [[357, "resnet-v2-101"]], "15. ResNet v2 152": [[357, "resnet-v2-152"]], "16. Densenet-121": [[357, "densenet-121"]], "17. Densenet-161": [[357, "densenet-161"]], "18. Densenet-169": [[357, "densenet-169"]], "19. Nasnet-mobile*": [[357, "nasnet-mobile"]], "20. EfficientNet-b0": [[357, "efficientnet-b0"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on TensorFlow ResNet50 V1.5": [[357, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-tensorflow-resnet50-v1-5"]], "preparation": [[357, "preparation"]], "tune": [[358, "tune"]], "1. resnet_v1_50": [[358, "resnet-v1-50"]], "2. resnet_v1_101": [[358, "resnet-v1-101"]], "3. resnet_v1_152": [[358, "resnet-v1-152"]], "4. resnet_v2_50": [[358, "resnet-v2-50"]], "5. resnet_v2_101": [[358, "resnet-v2-101"]], "6. resnet_v2_152": [[358, "resnet-v2-152"]], "7. inception_v1": [[358, "inception-v1"]], "8. inception_v2": [[358, "inception-v2"]], "9. inception_v3": [[358, "inception-v3"]], "10. inception_v4": [[358, "inception-v4"]], "11. vgg16": [[358, "vgg16"]], "12. vgg19": [[358, "vgg19"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on TensorFlow Inception V1": [[358, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-tensorflow-inception-v1"]], "4. Prepare Dataset": [[359, "prepare-dataset"], [360, "prepare-dataset"], [361, "prepare-dataset"], [370, "prepare-dataset"]], "Automatic dataset download": [[359, "automatic-dataset-download"], [360, "automatic-dataset-download"], [361, "automatic-dataset-download"], [365, "automatic-dataset-download"], [366, "automatic-dataset-download"]], "5. Prepare pretrained model": [[359, "prepare-pretrained-model"]], "Automatic model download": [[359, "automatic-model-download"], [360, "automatic-model-download"]], "Details of enabling Intel\u00ae Neural Compressor on bert model for Tensorflow.": [[359, "details-of-enabling-intel-neural-compressor-on-bert-model-for-tensorflow"], [360, "details-of-enabling-intel-neural-compressor-on-bert-model-for-tensorflow"]], "Code update": [[359, "code-update"], [360, "code-update"], [363, "code-update"], [364, "code-update"], [365, "code-update"], [371, "code-update"]], "Tune": [[359, "tune"], [360, "tune"], [370, "tune"]], "5. Prepare Pretrained model": [[360, "prepare-pretrained-model"], [361, "prepare-pretrained-model"]], "Manual approach": [[360, "manual-approach"], [365, "manual-approach"], [371, "manual-approach"]], "Prepare frozen pb from checkpoint": [[360, "prepare-frozen-pb-from-checkpoint"]], "Run Tuning": [[361, "run-tuning"]], "Run Benchmark": [[361, "run-benchmark"]], "Model Details": [[362, "model-details"]], "Dataset Details": [[362, "dataset-details"]], "2. Install TensorFlow 2.11.dev202242": [[362, "install-tensorflow-2-11-dev202242"]], "3. Install Requirements": [[362, "install-requirements"]], "4. Install Intel\u00ae Extension for TensorFlow": [[362, "install-intel-extension-for-tensorflow"]], "Quantizing the model on Intel GPU:": [[362, "quantizing-the-model-on-intel-gpu"]], "Quantizing the model on Intel CPU (Experimental):": [[362, "quantizing-the-model-on-intel-cpu-experimental"]], "5. Download Dataset": [[362, "download-dataset"]], "Run Tuning:": [[362, "run-tuning"], [364, "run-tuning"]], "Run Benchmark:": [[362, "run-benchmark"], [364, "run-benchmark"]], "Details of enabling Intel\u00ae Neural Compressor on DistilBERT base for TensorFlow": [[362, "details-of-enabling-intel-neural-compressor-on-distilbert-base-for-tensorflow"]], "q_dataloader Part Adaption": [[362, "q-dataloader-part-adaption"], [363, "q-dataloader-part-adaption"], [364, "q-dataloader-part-adaption"], [365, "q-dataloader-part-adaption"]], "4. Prepare Dataset & Pretrained model": [[363, "prepare-dataset-pretrained-model"]], "Automatic dataset & model download": [[363, "automatic-dataset-model-download"]], "Details of enabling Intel\u00ae Neural Compressor on transformer-lt for Tensorflow.": [[363, "details-of-enabling-intel-neural-compressor-on-transformer-lt-for-tensorflow"]], "Evaluation Part Adaption": [[363, "evaluation-part-adaption"], [364, "evaluation-part-adaption"], [365, "evaluation-part-adaption"], [371, "evaluation-part-adaption"]], "2. Install TensorFlow": [[364, "install-tensorflow"]], "4. Prepare Dataset & Frozen Model": [[364, "prepare-dataset-frozen-model"]], "Details of enabling Intel\u00ae Neural Compressor on Transformer_LT_mlperf for Tensorflow.": [[364, "details-of-enabling-intel-neural-compressor-on-transformer-lt-mlperf-for-tensorflow"]], "4. Install Protocol Buffer Compiler": [[365, "install-protocol-buffer-compiler"]], "5. Install Intel Extension for Tensorflow": [[365, "install-intel-extension-for-tensorflow"]], "6. Prepare Dataset": [[365, "prepare-dataset"]], "Manual dataset download": [[365, "manual-dataset-download"], [366, "manual-dataset-download"]], "7. Download Model": [[365, "download-model"]], "Automated approach": [[365, "automated-approach"], [371, "automated-approach"]], "ssd_resnet50_v1": [[365, "ssd-resnet50-v1"]], "ssd_mobilenet_V1": [[365, "ssd-mobilenet-v1"]], "faster_rcnn_inception_resnet_v2": [[365, "faster-rcnn-inception-resnet-v2"]], "faster_rcnn_resnet101": [[365, "faster-rcnn-resnet101"]], "faster_rcnn_resnet50": [[365, "faster-rcnn-resnet50"]], "mask_rcnn_inception_v2": [[365, "mask-rcnn-inception-v2"]], "ssd_resnet34": [[365, "ssd-resnet34"]], "For PB model": [[365, "for-pb-model"]], "For ckpt model": [[365, "for-ckpt-model"]], "Details of enabling Intel\u00ae Neural Compressor on ssd_resnet50_v1 for Tensorflow.": [[365, "details-of-enabling-intel-neural-compressor-on-ssd-resnet50-v1-for-tensorflow"]], "5. Downloaded Yolo-v3 model": [[366, "downloaded-yolo-v3-model"]], "6. Download COCO Class Names File": [[366, "download-coco-class-names-file"]], "7. Download Model Weights (Full):": [[366, "download-model-weights-full"]], "8. Generate PB:": [[366, "generate-pb"]], "9. Prepare Dataset": [[366, "prepare-dataset"]], "Get Quantized Yolo-v3 model with Neural Compressor": [[366, "get-quantized-yolo-v3-model-with-neural-compressor"]], "1.Config the yolo_v3.yaml with the valid cocoraw data path or the yolo_v3_itex.yaml if using the Intel Extension for Tensorflow.": [[366, "config-the-yolo-v3-yaml-with-the-valid-cocoraw-data-path-or-the-yolo-v3-itex-yaml-if-using-the-intel-extension-for-tensorflow"]], "2.Config the yaml file": [[366, "config-the-yaml-file"]], "3.Run below command one by one.": [[366, "run-below-command-one-by-one"]], "2. Install Intel Extension for Tensorflow": [[367, "install-intel-extension-for-tensorflow"]], "4. Prepare pre-trained model": [[367, "prepare-pre-trained-model"]], "5. Config the yaml file": [[367, "config-the-yaml-file"]], "run tuning": [[367, "run-tuning"]], "run benchmarking": [[367, "run-benchmarking"]], "4. Install Additional Dependency packages": [[368, "install-additional-dependency-packages"]], "6. Process Dataset": [[368, "process-dataset"]], "7. Download Frozen PB": [[368, "download-frozen-pb"]], "8. Config the yaml file": [[368, "config-the-yaml-file"]], "9. Run Command": [[368, "run-command"]], "The cmd of running WnD": [[368, "the-cmd-of-running-wnd"]], "Other": [[368, "other"]], "4. Download BraTS 2019 dataset": [[369, "download-brats-2019-dataset"]], "5. Download Pre-trained model": [[369, "download-pre-trained-model"]], "6. Prepare Calibration set": [[369, "prepare-calibration-set"]], "7. Config the yaml file": [[369, "config-the-yaml-file"]], "8. Test command": [[369, "test-command"]], "5. Prepare pre-trained model": [[370, "prepare-pre-trained-model"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on Deeplab model for tensorflow": [[370, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-deeplab-model-for-tensorflow"]], "3. Install Additional Dependency packages": [[371, "install-additional-dependency-packages"]], "6. Prepare Pretrained model": [[371, "prepare-pretrained-model"]], "Quantize with neural_compressor": [[371, "quantize-with-neural-compressor"]], "1. Tune model with neural_compressor": [[371, "tune-model-with-neural-compressor"]], "2. check benchmark of tuned model": [[371, "check-benchmark-of-tuned-model"]], "Details of enabling Intel\u00ae Neural Compressor on style transfer for Tensorflow.": [[371, "details-of-enabling-intel-neural-compressor-on-style-transfer-for-tensorflow"]], "Intel\u00ae Neural Compressor Documentation": [[372, "intel-neural-compressor-documentation"]], "Sections": [[372, "sections"]], "Neural Coder": [[373, "neural-coder"]], "What do we offer?": [[373, "what-do-we-offer"]], "Getting Started!": [[373, "getting-started"], [381, "getting-started"]], "Jupyter Lab Extension": [[373, "jupyter-lab-extension"]], "Python API": [[373, "python-api"]], "Contact": [[373, "contact"]], "Intel CPU Platforms: Best Performance Setting": [[374, "intel-cpu-platforms-best-performance-setting"]], "Install MKL, OpenMP and JEMALLOC": [[374, "install-mkl-openmp-and-jemalloc"]], "Install NUMA Controller": [[374, "install-numa-controller"]], "Environment Variables": [[374, "environment-variables"]], "Frequency Governers": [[374, "frequency-governers"]], "Neural Coder as Python API": [[375, "neural-coder-as-python-api"]], "Enable": [[375, "enable"]], "Bench": [[375, "bench"]], "SuperBench": [[375, "superbench"]], "Python Launcher": [[376, "python-launcher"]], "Quick-Start": [[376, "quick-start"]], "Launcher Arguments (Optional)": [[376, "launcher-arguments-optional"]], "Neural Coder for Quantization": [[377, "neural-coder-for-quantization"]], "Features Supported": [[377, "features-supported"]], "Models Supported": [[377, "models-supported"]], "PyPI distribution:": [[377, "pypi-distribution"]], "Supported Optimization Features": [[378, "supported-optimization-features"]], "Changelog": [[379, "changelog"], [383, "changelog"]], "neural_compressor_ext_lab": [[380, "neural-compressor-ext-lab"]], "Install": [[380, "install"], [384, "install"]], "Uninstall": [[380, "uninstall"], [384, "uninstall"]], "Contributing": [[380, "contributing"], [384, "contributing"]], "Development install": [[380, "development-install"], [384, "development-install"]], "Development uninstall": [[380, "development-uninstall"], [384, "development-uninstall"]], "Packaging the extension": [[380, "packaging-the-extension"], [384, "packaging-the-extension"]], "Intel\u00ae Neural Compressor as JupyterLab Extension": [[381, "intel-neural-compressor-as-jupyterlab-extension"]], "Auto-enable a feature": [[381, "auto-enable-a-feature"]], "Or let us help you auto-select the best feature": [[381, "or-let-us-help-you-auto-select-the-best-feature"]], "Pre-requisites": [[381, "pre-requisites"]], "Making a new release of neural_compressor_ext_lab": [[382, "making-a-new-release-of-neural-compressor-ext-lab"]], "Manual release": [[382, "manual-release"], [385, "manual-release"]], "Python package": [[382, "python-package"], [385, "python-package"]], "NPM package": [[382, "npm-package"], [385, "npm-package"]], "Automated releases with the Jupyter Releaser": [[382, "automated-releases-with-the-jupyter-releaser"], [385, "automated-releases-with-the-jupyter-releaser"]], "Publishing to conda-forge": [[382, "publishing-to-conda-forge"], [385, "publishing-to-conda-forge"]], "neural_compressor_ext_lab_alibaba": [[384, "neural-compressor-ext-lab-alibaba"]], "Making a new release of neural_compressor_ext_lab_alibaba": [[385, "making-a-new-release-of-neural-compressor-ext-lab-alibaba"]], "Execute benchmark endpoint": [[387, "execute-benchmark-endpoint"]], "Request": [[387, "request"]], "Configuration for predefined models": [[388, "configuration-for-predefined-models"]], "Configuration for imported models": [[388, "configuration-for-imported-models"]], "Database migration": [[389, "database-migration"]], "Gui": [[390, "gui"]], "Development server": [[390, "development-server"]], "Code scaffolding": [[390, "code-scaffolding"]], "Build": [[390, "build"]], "Running unit tests": [[390, "running-unit-tests"]], "Running end-to-end tests": [[390, "running-end-to-end-tests"]], "Further help": [[390, "further-help"]], "Endpoints": [[391, "endpoints"]], "Project": [[391, "project"]], "Create project": [[391, "create-project"]], "Delete project": [[391, "delete-project"]], "Get project details": [[391, "get-project-details"]], "Add notes to project": [[391, "add-notes-to-project"]], "List projects": [[391, "list-projects"]], "Add dataset to project": [[391, "add-dataset-to-project"]], "Get dataset details": [[391, "get-dataset-details"]], "List datasets": [[391, "list-datasets"]], "Add optimization to project": [[391, "add-optimization-to-project"]], "Get optimization details": [[391, "get-optimization-details"]], "Edit optimization": [[391, "edit-optimization"]], "List optimizations": [[391, "list-optimizations"]], "Execute optimization": [[391, "execute-optimization"]], "Pin accuracy benchmark to optimization": [[391, "pin-accuracy-benchmark-to-optimization"]], "Pin performance benchmark to optimization": [[391, "pin-performance-benchmark-to-optimization"]], "Add benchmark to project": [[391, "add-benchmark-to-project"]], "Get benchmark details": [[391, "get-benchmark-details"]], "Edit benchmark": [[391, "edit-benchmark"]], "List benchmarks": [[391, "list-benchmarks"]], "Execute benchmark": [[391, "execute-benchmark"]], "Profiling": [[391, "profiling"]], "Add profiling to project": [[391, "add-profiling-to-project"]], "Get profiling details": [[391, "get-profiling-details"]], "Edit profiling": [[391, "edit-profiling"]], "Get profiling result as csv": [[391, "get-profiling-result-as-csv"]], "List profilings": [[391, "list-profilings"]], "Execute profiling": [[391, "execute-profiling"]], "List example models": [[391, "list-example-models"], [391, "id2"]], "Create project from examples": [[391, "create-project-from-examples"], [391, "id3"]], "List models": [[391, "list-models"]], "Get model\u2019s boundary nodes": [[391, "get-model-s-boundary-nodes"]], "Get model\u2019s graph": [[391, "get-model-s-graph"]], "Dictionaries": [[391, "dictionaries"]], "Domains": [[391, "domains"]], "Domain flavours": [[391, "domain-flavours"]], "Optimization Types": [[391, "optimization-types"]], "Optimization Types and support for specific precision": [[391, "optimization-types-and-support-for-specific-precision"]], "Precisions": [[391, "precisions"]], "Dataloaders": [[391, "dataloaders"]], "Get all dataloaders": [[391, "get-all-dataloaders"]], "Get dataloaders for specified framework": [[391, "get-dataloaders-for-specified-framework"]], "Transforms": [[391, "transforms"]], "Get all transforms": [[391, "get-all-transforms"]], "Get transforms for specified framework": [[391, "get-transforms-for-specified-framework"]], "Get transforms for specified domain": [[391, "get-transforms-for-specified-domain"]]}, "indexentries": {}})