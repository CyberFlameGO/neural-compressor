Search.setIndex({"docnames": [".github/pull_request_template", "README", "SECURITY", "api-documentation/api-reference", "api-documentation/apis", "api-documentation/benchmark-api", "api-documentation/objective-api", "api-documentation/pruning-api", "api-documentation/quantization-api", "docker/README", "docs/CODE_OF_CONDUCT", "docs/FX", "docs/NAS", "docs/PTQ", "docs/QAT", "docs/adaptor", "docs/api-introduction", "docs/backend_quant", "docs/bench", "docs/benchmark", "docs/contributions", "docs/dataloader", "docs/dataset", "docs/design", "docs/distillation", "docs/distillation_quantization", "docs/distributed", "docs/doclist", "docs/dynamic_quantization", "docs/examples_readme", "docs/faq", "docs/getting_started", "docs/graph_optimization", "docs/incompatible_changes", "docs/infrastructure", "docs/installation_guide", "docs/legal_information", "docs/metric", "docs/mixed_precision", "docs/model", "docs/model_conversion", "docs/objective", "docs/orchestration", "docs/platform_configuration", "docs/pruning", "docs/publication_list", "docs/quantization", "docs/quantization_mixed_precision", "docs/reference_examples", "docs/releases_info", "docs/sigopt_strategy", "docs/tensorboard", "docs/transform", "docs/tuning_strategies", "docs/validated_model_list", "docs/welcome", "examples/README", "examples/helloworld/README", "examples/helloworld/tf_example1/README", "examples/helloworld/tf_example2/README", "examples/helloworld/tf_example3/README", "examples/helloworld/tf_example4/README", "examples/helloworld/tf_example5/README", "examples/helloworld/tf_example6/README", "examples/helloworld/tf_example7/README", "examples/helloworld/tf_example8/README", "examples/mxnet/image_recognition/cnn_models/quantization/ptq/README", "examples/mxnet/language_translation/bert/quantization/ptq/README", "examples/mxnet/object_detection/ssd_models/quantization/ptq/README", "examples/notebook/perf_fp32_int8_tf/README", "examples/notebook/pytorch/alexnet_fashion_mnist/README", "examples/notebook/tensorflow/alexnet_mnist/README", "examples/notebook/usage_example", "examples/onnxrt/README", "examples/onnxrt/body_analysis/onnx_model_zoo/emotion_ferplus/quantization/ptq/README", "examples/onnxrt/body_analysis/onnx_model_zoo/ultraface/quantization/ptq/README", "examples/onnxrt/image_recognition/mobilenet_v2/quantization/ptq/README", "examples/onnxrt/image_recognition/mobilenet_v3/quantization/ptq/readme", "examples/onnxrt/image_recognition/onnx_model_zoo/alexnet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/arcface/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/caffenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/densenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/efficientnet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/fcn/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/googlenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/inception/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/mnist/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/mobilenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/resnet50/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/shufflenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/squeezenet/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/vgg16/quantization/ptq/README", "examples/onnxrt/image_recognition/onnx_model_zoo/zfnet/quantization/ptq/README", "examples/onnxrt/image_recognition/resnet50/quantization/ptq/README", "examples/onnxrt/image_recognition/unet/quantization/ptq/readme", "examples/onnxrt/image_recognition/vgg16/quantization/ptq/README", "examples/onnxrt/nlp/bert/quantization/ptq/README", "examples/onnxrt/nlp/distilbert/quantization/ptq/readme", "examples/onnxrt/nlp/huggingface_model/question_answering/quantization/ptq/README", "examples/onnxrt/nlp/huggingface_model/text_classification/quantization/ptq/README", "examples/onnxrt/nlp/mobilebert/quantization/ptq/readme", "examples/onnxrt/nlp/onnx_model_zoo/BiDAF/quantization/ptq/README", "examples/onnxrt/nlp/onnx_model_zoo/bert-squad/quantization/ptq/readme", "examples/onnxrt/nlp/onnx_model_zoo/gpt2/quantization/ptq/readme", "examples/onnxrt/nlp/onnx_model_zoo/mobilebert/quantization/ptq/readme", "examples/onnxrt/nlp/roberta/quantization/ptq/readme", "examples/onnxrt/object_detection/onnx_model_zoo/DUC/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/faster_rcnn/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/mask_rcnn/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/ssd/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/ssd_mobilenet_v1/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/tiny_yolov3/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/yolov3/quantization/ptq/README", "examples/onnxrt/object_detection/onnx_model_zoo/yolov4/quantization/ptq/README", "examples/onnxrt/object_detection/ssd_mobilenet_v1/quantization/ptq/readme", "examples/onnxrt/object_detection/ssd_mobilenet_v2/quantization/ptq/readme", "examples/pytorch/diffusion_model/diffusers/textual_inversion/README", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/3DUnet_README", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/README", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/data_format_inference", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/dataset_conversion", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/extending_nnunet", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/inference_example_Prostate", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/setting_up_paths", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/training_example_Hippocampus", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/nnunet/experiment_planning/alternative_experiment_planning/readme", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/readme", "examples/pytorch/image_recognition/CNN-2/distillation/eager/README", "examples/pytorch/image_recognition/MobileNetV2-0.35/distillation/eager/README", "examples/pytorch/image_recognition/VGG-8/distillation/eager/README", "examples/pytorch/image_recognition/efficientnet/quantization/ptq/eager/Efficientnet_README", "examples/pytorch/image_recognition/efficientnet/quantization/ptq/eager/README", "examples/pytorch/image_recognition/mnist/README", "examples/pytorch/image_recognition/peleenet/quantization/ptq/eager/PeleeNet_README", "examples/pytorch/image_recognition/peleenet/quantization/ptq/eager/README", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/README", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/ResNest_README", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/ablation", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/scripts/gluon/README", "examples/pytorch/image_recognition/se_resnext/quantization/ptq/eager/README", "examples/pytorch/image_recognition/se_resnext/quantization/ptq/eager/SE_ResNext_README", "examples/pytorch/image_recognition/torchvision_models/distillation/eager/README", "examples/pytorch/image_recognition/torchvision_models/optimization_pipeline/prune_and_ptq/eager/README", "examples/pytorch/image_recognition/torchvision_models/optimization_pipeline/qat_during_prune/eager/README", "examples/pytorch/image_recognition/torchvision_models/pruning/magnitude/eager/README", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/eager/README", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/fx/README", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/ipex/README", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/eager/README", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/eager/distributed/README", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/fx/README", "examples/pytorch/image_recognition/torchvision_models/self_distillation/eager/README", "examples/pytorch/nlp/blendcnn/distillation/eager/README", "examples/pytorch/nlp/blendcnn/quantization/ptq/eager/README", "examples/pytorch/nlp/huggingface_models/common/CODE_OF_CONDUCT", "examples/pytorch/nlp/huggingface_models/common/CONTRIBUTING", "examples/pytorch/nlp/huggingface_models/common/ISSUES", "examples/pytorch/nlp/huggingface_models/common/README", "examples/pytorch/nlp/huggingface_models/common/docs/README", "examples/pytorch/nlp/huggingface_models/common/docs/source/add_new_model", "examples/pytorch/nlp/huggingface_models/common/docs/source/benchmarks", "examples/pytorch/nlp/huggingface_models/common/docs/source/bertology", "examples/pytorch/nlp/huggingface_models/common/docs/source/community", "examples/pytorch/nlp/huggingface_models/common/docs/source/contributing", "examples/pytorch/nlp/huggingface_models/common/docs/source/converting_tensorflow_models", "examples/pytorch/nlp/huggingface_models/common/docs/source/custom_datasets", "examples/pytorch/nlp/huggingface_models/common/docs/source/examples", "examples/pytorch/nlp/huggingface_models/common/docs/source/glossary", "examples/pytorch/nlp/huggingface_models/common/docs/source/index", "examples/pytorch/nlp/huggingface_models/common/docs/source/installation", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/file_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/generation_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/modeling_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/pipelines_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/tokenization_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/trainer_utils", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/callback", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/configuration", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/feature_extractor", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/logging", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/model", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/optimizer_schedules", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/output", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/pipelines", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/processors", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/tokenizer", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/trainer", "examples/pytorch/nlp/huggingface_models/common/docs/source/migration", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/albert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/auto", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bart", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/barthez", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bertgeneration", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bertweet", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/blenderbot", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/blenderbot_small", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bort", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/camembert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/convbert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/ctrl", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/deberta", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/deberta_v2", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/dialogpt", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/distilbert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/dpr", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/electra", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/encoderdecoder", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/flaubert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/fsmt", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/funnel", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/gpt", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/gpt2", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/herbert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/ibert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/layoutlm", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/led", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/longformer", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/lxmert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/marian", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mbart", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mobilebert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mpnet", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mt5", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/pegasus", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/phobert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/prophetnet", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/rag", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/reformer", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/retribert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/roberta", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/squeezebert", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/t5", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/tapas", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/transformerxl", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/wav2vec2", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlm", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlmprophetnet", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlmroberta", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlnet", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_sharing", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_summary", "examples/pytorch/nlp/huggingface_models/common/docs/source/multilingual", "examples/pytorch/nlp/huggingface_models/common/docs/source/notebooks", "examples/pytorch/nlp/huggingface_models/common/docs/source/perplexity", "examples/pytorch/nlp/huggingface_models/common/docs/source/philosophy", "examples/pytorch/nlp/huggingface_models/common/docs/source/preprocessing", "examples/pytorch/nlp/huggingface_models/common/docs/source/pretrained_models", "examples/pytorch/nlp/huggingface_models/common/docs/source/quicktour", "examples/pytorch/nlp/huggingface_models/common/docs/source/serialization", "examples/pytorch/nlp/huggingface_models/common/docs/source/task_summary", "examples/pytorch/nlp/huggingface_models/common/docs/source/testing", "examples/pytorch/nlp/huggingface_models/common/docs/source/tokenizer_summary", "examples/pytorch/nlp/huggingface_models/common/docs/source/training", "examples/pytorch/nlp/huggingface_models/common/examples/README", "examples/pytorch/nlp/huggingface_models/common/examples/benchmarking/README", "examples/pytorch/nlp/huggingface_models/common/examples/language-modeling/README", "examples/pytorch/nlp/huggingface_models/common/examples/multiple-choice/README", "examples/pytorch/nlp/huggingface_models/common/examples/question-answering/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/adversarial/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/bert-loses-patience/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/bertabs/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/deebert/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/distillation/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/longform-qa/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/lxmert/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/mlm_wwm/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/mm-imdb/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/movement-pruning/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/performer/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/pplm/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/rag/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/seq2seq-distillation/README", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/seq2seq-distillation/precomputed_pseudo_labels", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/zero-shot-distillation/README", "examples/pytorch/nlp/huggingface_models/common/examples/seq2seq/README", "examples/pytorch/nlp/huggingface_models/common/examples/text-classification/README", "examples/pytorch/nlp/huggingface_models/common/examples/text-generation/README", "examples/pytorch/nlp/huggingface_models/common/examples/token-classification/README", "examples/pytorch/nlp/huggingface_models/common/model_cards/README", "examples/pytorch/nlp/huggingface_models/common/model_cards/google/tapas-base/README", "examples/pytorch/nlp/huggingface_models/common/notebooks/README", "examples/pytorch/nlp/huggingface_models/common/scripts/tatoeba/README", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_example_script/README", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/ADD_NEW_MODEL_PROPOSAL_TEMPLATE", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/README", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/{{cookiecutter.lowercase_modelname}}", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/open_model_proposals/ADD_BIG_BIRD", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/open_model_proposals/README", "examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/eager/README", "examples/pytorch/nlp/huggingface_models/question-answering/distillation/eager/README", "examples/pytorch/nlp/huggingface_models/question-answering/optimization_pipeline/prune_once_for_all/fx/README", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/group_lasso/eager/README", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/pattern_lock/eager/README", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/pytorch_pruner/eager/README", "examples/pytorch/nlp/huggingface_models/question-answering/quantization/ptq_static/fx/README", "examples/pytorch/nlp/huggingface_models/question-answering/quantization/ptq_static/ipex/README", "examples/pytorch/nlp/huggingface_models/summarization/quantization/ptq_dynamic/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/distillation/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/optimization_pipeline/distillation_for_quantization/fx/README", "examples/pytorch/nlp/huggingface_models/text-classification/optimization_pipeline/prune_once_for_all/fx/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/gradient_sensitivity/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/magnitude/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/pattern_lock/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/pytorch_pruner/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning_while_distillation/group_lasso/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/pruning_while_distillation/group_lasso/eager/bert-mini/README", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_dynamic/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_dynamic/fx/README", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/eager/README", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/fx/README", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/qat/fx/README", "examples/pytorch/nlp/huggingface_models/translation/quantization/ptq_dynamic/eager/README", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/MASKRCNN_README", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/README", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/ABSTRACTIONS", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/INSTALL", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/MODEL_ZOO", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/README", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/TROUBLESHOOTING", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/maskrcnn_benchmark/data/README", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/maskrcnn_benchmark/utils/README", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/fx/README", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/fx/upscale_coco/README", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/ipex/README", "examples/pytorch/object_detection/ssd_resnet34/quantization/qat/fx/README", "examples/pytorch/object_detection/yolo_v3/quantization/ptq/eager/README", "examples/pytorch/object_detection/yolo_v3/quantization/ptq/eager/YOLOV3_README", "examples/pytorch/recommendation/dlrm/quantization/ptq/eager/README", "examples/pytorch/recommendation/dlrm/quantization/ptq/fx/README", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/CODE_OF_CONDUCT", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/CONTRIBUTING", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/README", "examples/pytorch/speech_recognition/rnnt/quantization/ptq_dynamic/eager/README", "examples/pytorch/speech_recognition/torchaudio_models/quantization/ptq_dynamic/eager/README", "examples/tensorflow/image_recognition/SavedModel/quantization/ptq/README", "examples/tensorflow/image_recognition/ViT/pruning/magnitude/README", "examples/tensorflow/image_recognition/inception_v3/pruning/magnitude/README", "examples/tensorflow/image_recognition/keras_models/inception_resnet_v2/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/inception_v3/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/mnist/quantization/qat/README", "examples/tensorflow/image_recognition/keras_models/mobilenet_v2/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/resnet101/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/resnet50/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/resnet50_fashion/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/resnetv2_101/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/resnetv2_50/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/vgg16/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/vgg19/quantization/ptq/README", "examples/tensorflow/image_recognition/keras_models/xception/quantization/ptq/README", "examples/tensorflow/image_recognition/resnet_v2/pruning/magnitude/README", "examples/tensorflow/image_recognition/resnet_v2/quantization/qat/README", "examples/tensorflow/image_recognition/tensorflow_models/distillation/README", "examples/tensorflow/image_recognition/tensorflow_models/quantization/ptq/README", "examples/tensorflow/image_recognition/tensorflow_models/quantization/ptq/slim/README", "examples/tensorflow/nlp/bert_base_mrpc/quantization/ptq/README", "examples/tensorflow/nlp/bert_large_squad/quantization/ptq/README", "examples/tensorflow/nlp/bert_large_squad_model_zoo/quantization/ptq/README", "examples/tensorflow/nlp/distilbert_base/quantization/ptq/README", "examples/tensorflow/nlp/transformer_lt/quantization/ptq/README", "examples/tensorflow/nlp/transformer_lt_mlperf/quantization/ptq/README", "examples/tensorflow/object_detection/tensorflow_models/quantization/ptq/README", "examples/tensorflow/object_detection/yolo_v3/quantization/ptq/README", "examples/tensorflow/oob_models/quantization/ptq/README", "examples/tensorflow/recommendation/wide_deep_large_ds/quantization/ptq/README", "examples/tensorflow/semantic_image_segmentation/3dunet-mlperf/quantization/ptq/README", "examples/tensorflow/semantic_image_segmentation/deeplab/quantization/ptq/README", "examples/tensorflow/style_transfer/arbitrary_style_transfer/quantization/ptq/README", "index", "neural_coder/README", "neural_coder/docs/IntelCPU_PerformanceSetting", "neural_coder/docs/PythonAPI", "neural_coder/docs/PythonLauncher", "neural_coder/docs/Quantization", "neural_coder/docs/SupportMatrix", "neural_coder/extensions/neural_compressor_ext_lab/CHANGELOG", "neural_coder/extensions/neural_compressor_ext_lab/DEVELOP", "neural_coder/extensions/neural_compressor_ext_lab/README", "neural_coder/extensions/neural_compressor_ext_lab/RELEASE", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/CHANGELOG", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/DEVELOP", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/RELEASE", "neural_compressor/conf/README", "neural_compressor/ux/components/benchmark/README", "neural_compressor/ux/components/configuration_wizard/README", "neural_compressor/ux/components/db_manager/README", "neural_compressor/ux/gui/README", "neural_compressor/ux/web/README"], "filenames": [".github/pull_request_template.md", "README.md", "SECURITY.md", "api-documentation/api-reference.rst", "api-documentation/apis.rst", "api-documentation/benchmark-api.rst", "api-documentation/objective-api.rst", "api-documentation/pruning-api.rst", "api-documentation/quantization-api.rst", "docker/README.md", "docs/CODE_OF_CONDUCT.md", "docs/FX.md", "docs/NAS.md", "docs/PTQ.md", "docs/QAT.md", "docs/adaptor.md", "docs/api-introduction.md", "docs/backend_quant.md", "docs/bench.md", "docs/benchmark.md", "docs/contributions.md", "docs/dataloader.md", "docs/dataset.md", "docs/design.md", "docs/distillation.md", "docs/distillation_quantization.md", "docs/distributed.md", "docs/doclist.rst", "docs/dynamic_quantization.md", "docs/examples_readme.md", "docs/faq.md", "docs/getting_started.md", "docs/graph_optimization.md", "docs/incompatible_changes.md", "docs/infrastructure.md", "docs/installation_guide.md", "docs/legal_information.md", "docs/metric.md", "docs/mixed_precision.md", "docs/model.md", "docs/model_conversion.md", "docs/objective.md", "docs/orchestration.md", "docs/platform_configuration.md", "docs/pruning.md", "docs/publication_list.md", "docs/quantization.md", "docs/quantization_mixed_precision.md", "docs/reference_examples.md", "docs/releases_info.md", "docs/sigopt_strategy.md", "docs/tensorboard.md", "docs/transform.md", "docs/tuning_strategies.md", "docs/validated_model_list.md", "docs/welcome.md", "examples/README.md", "examples/helloworld/README.md", "examples/helloworld/tf_example1/README.md", "examples/helloworld/tf_example2/README.md", "examples/helloworld/tf_example3/README.md", "examples/helloworld/tf_example4/README.md", "examples/helloworld/tf_example5/README.md", "examples/helloworld/tf_example6/README.md", "examples/helloworld/tf_example7/README.md", "examples/helloworld/tf_example8/README.md", "examples/mxnet/image_recognition/cnn_models/quantization/ptq/README.md", "examples/mxnet/language_translation/bert/quantization/ptq/README.md", "examples/mxnet/object_detection/ssd_models/quantization/ptq/README.md", "examples/notebook/perf_fp32_int8_tf/README.md", "examples/notebook/pytorch/alexnet_fashion_mnist/README.md", "examples/notebook/tensorflow/alexnet_mnist/README.md", "examples/notebook/usage_example.md", "examples/onnxrt/README.md", "examples/onnxrt/body_analysis/onnx_model_zoo/emotion_ferplus/quantization/ptq/README.md", "examples/onnxrt/body_analysis/onnx_model_zoo/ultraface/quantization/ptq/README.md", "examples/onnxrt/image_recognition/mobilenet_v2/quantization/ptq/README.md", "examples/onnxrt/image_recognition/mobilenet_v3/quantization/ptq/readme.md", "examples/onnxrt/image_recognition/onnx_model_zoo/alexnet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/arcface/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/caffenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/densenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/efficientnet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/fcn/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/googlenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/inception/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/mnist/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/mobilenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/resnet50/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/shufflenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/squeezenet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/vgg16/quantization/ptq/README.md", "examples/onnxrt/image_recognition/onnx_model_zoo/zfnet/quantization/ptq/README.md", "examples/onnxrt/image_recognition/resnet50/quantization/ptq/README.md", "examples/onnxrt/image_recognition/unet/quantization/ptq/readme.md", "examples/onnxrt/image_recognition/vgg16/quantization/ptq/README.md", "examples/onnxrt/nlp/bert/quantization/ptq/README.md", "examples/onnxrt/nlp/distilbert/quantization/ptq/readme.md", "examples/onnxrt/nlp/huggingface_model/question_answering/quantization/ptq/README.md", "examples/onnxrt/nlp/huggingface_model/text_classification/quantization/ptq/README.md", "examples/onnxrt/nlp/mobilebert/quantization/ptq/readme.md", "examples/onnxrt/nlp/onnx_model_zoo/BiDAF/quantization/ptq/README.md", "examples/onnxrt/nlp/onnx_model_zoo/bert-squad/quantization/ptq/readme.md", "examples/onnxrt/nlp/onnx_model_zoo/gpt2/quantization/ptq/readme.md", "examples/onnxrt/nlp/onnx_model_zoo/mobilebert/quantization/ptq/readme.md", "examples/onnxrt/nlp/roberta/quantization/ptq/readme.md", "examples/onnxrt/object_detection/onnx_model_zoo/DUC/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/faster_rcnn/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/mask_rcnn/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/ssd/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/ssd_mobilenet_v1/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/tiny_yolov3/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/yolov3/quantization/ptq/README.md", "examples/onnxrt/object_detection/onnx_model_zoo/yolov4/quantization/ptq/README.md", "examples/onnxrt/object_detection/ssd_mobilenet_v1/quantization/ptq/readme.md", "examples/onnxrt/object_detection/ssd_mobilenet_v2/quantization/ptq/readme.md", "examples/pytorch/diffusion_model/diffusers/textual_inversion/README.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/3DUnet_README.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/README.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/data_format_inference.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/dataset_conversion.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/extending_nnunet.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/inference_example_Prostate.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/setting_up_paths.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/documentation/training_example_Hippocampus.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/nnunet/experiment_planning/alternative_experiment_planning/readme.md", "examples/pytorch/image_recognition/3d-unet/quantization/ptq/eager/nnUnet/readme.md", "examples/pytorch/image_recognition/CNN-2/distillation/eager/README.md", "examples/pytorch/image_recognition/MobileNetV2-0.35/distillation/eager/README.md", "examples/pytorch/image_recognition/VGG-8/distillation/eager/README.md", "examples/pytorch/image_recognition/efficientnet/quantization/ptq/eager/Efficientnet_README.md", "examples/pytorch/image_recognition/efficientnet/quantization/ptq/eager/README.md", "examples/pytorch/image_recognition/mnist/README.md", "examples/pytorch/image_recognition/peleenet/quantization/ptq/eager/PeleeNet_README.md", "examples/pytorch/image_recognition/peleenet/quantization/ptq/eager/README.md", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/README.md", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/ResNest_README.md", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/ablation.md", "examples/pytorch/image_recognition/resnest/quantization/ptq/eager/scripts/gluon/README.md", "examples/pytorch/image_recognition/se_resnext/quantization/ptq/eager/README.md", "examples/pytorch/image_recognition/se_resnext/quantization/ptq/eager/SE_ResNext_README.md", "examples/pytorch/image_recognition/torchvision_models/distillation/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/optimization_pipeline/prune_and_ptq/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/optimization_pipeline/qat_during_prune/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/pruning/magnitude/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/fx/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/ptq/cpu/ipex/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/eager/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/eager/distributed/README.md", "examples/pytorch/image_recognition/torchvision_models/quantization/qat/fx/README.md", "examples/pytorch/image_recognition/torchvision_models/self_distillation/eager/README.md", "examples/pytorch/nlp/blendcnn/distillation/eager/README.md", "examples/pytorch/nlp/blendcnn/quantization/ptq/eager/README.md", "examples/pytorch/nlp/huggingface_models/common/CODE_OF_CONDUCT.md", "examples/pytorch/nlp/huggingface_models/common/CONTRIBUTING.md", "examples/pytorch/nlp/huggingface_models/common/ISSUES.md", "examples/pytorch/nlp/huggingface_models/common/README.md", "examples/pytorch/nlp/huggingface_models/common/docs/README.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/add_new_model.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/benchmarks.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/bertology.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/community.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/contributing.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/converting_tensorflow_models.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/custom_datasets.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/examples.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/glossary.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/index.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/installation.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/file_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/generation_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/modeling_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/pipelines_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/tokenization_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/internal/trainer_utils.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/callback.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/configuration.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/feature_extractor.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/logging.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/model.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/optimizer_schedules.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/output.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/pipelines.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/processors.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/tokenizer.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/main_classes/trainer.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/migration.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/albert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/auto.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bart.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/barthez.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bertgeneration.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bertweet.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/blenderbot.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/blenderbot_small.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/bort.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/camembert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/convbert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/ctrl.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/deberta.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/deberta_v2.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/dialogpt.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/distilbert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/dpr.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/electra.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/encoderdecoder.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/flaubert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/fsmt.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/funnel.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/gpt.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/gpt2.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/herbert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/ibert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/layoutlm.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/led.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/longformer.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/lxmert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/marian.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mbart.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mobilebert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mpnet.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/mt5.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/pegasus.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/phobert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/prophetnet.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/rag.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/reformer.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/retribert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/roberta.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/squeezebert.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/t5.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/tapas.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/transformerxl.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/wav2vec2.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlm.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlmprophetnet.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlmroberta.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_doc/xlnet.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_sharing.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/model_summary.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/multilingual.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/notebooks.md", "examples/pytorch/nlp/huggingface_models/common/docs/source/perplexity.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/philosophy.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/preprocessing.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/pretrained_models.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/quicktour.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/serialization.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/task_summary.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/testing.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/tokenizer_summary.rst", "examples/pytorch/nlp/huggingface_models/common/docs/source/training.rst", "examples/pytorch/nlp/huggingface_models/common/examples/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/benchmarking/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/language-modeling/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/multiple-choice/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/question-answering/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/adversarial/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/bert-loses-patience/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/bertabs/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/deebert/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/distillation/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/longform-qa/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/lxmert/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/mlm_wwm/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/mm-imdb/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/movement-pruning/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/performer/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/pplm/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/rag/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/seq2seq-distillation/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/seq2seq-distillation/precomputed_pseudo_labels.md", "examples/pytorch/nlp/huggingface_models/common/examples/research_projects/zero-shot-distillation/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/seq2seq/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/text-classification/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/text-generation/README.md", "examples/pytorch/nlp/huggingface_models/common/examples/token-classification/README.md", "examples/pytorch/nlp/huggingface_models/common/model_cards/README.md", "examples/pytorch/nlp/huggingface_models/common/model_cards/google/tapas-base/README.md", "examples/pytorch/nlp/huggingface_models/common/notebooks/README.md", "examples/pytorch/nlp/huggingface_models/common/scripts/tatoeba/README.md", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_example_script/README.md", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/ADD_NEW_MODEL_PROPOSAL_TEMPLATE.md", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/README.md", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/{{cookiecutter.lowercase_modelname}}.rst", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/open_model_proposals/ADD_BIG_BIRD.md", "examples/pytorch/nlp/huggingface_models/common/templates/adding_a_new_model/open_model_proposals/README.md", "examples/pytorch/nlp/huggingface_models/language-modeling/quantization/ptq_static/eager/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/distillation/eager/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/optimization_pipeline/prune_once_for_all/fx/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/group_lasso/eager/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/pattern_lock/eager/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/pruning/pytorch_pruner/eager/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/quantization/ptq_static/fx/README.md", "examples/pytorch/nlp/huggingface_models/question-answering/quantization/ptq_static/ipex/README.md", "examples/pytorch/nlp/huggingface_models/summarization/quantization/ptq_dynamic/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/distillation/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/optimization_pipeline/distillation_for_quantization/fx/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/optimization_pipeline/prune_once_for_all/fx/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/gradient_sensitivity/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/magnitude/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/pattern_lock/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning/pytorch_pruner/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning_while_distillation/group_lasso/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/pruning_while_distillation/group_lasso/eager/bert-mini/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_dynamic/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_dynamic/fx/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/eager/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/ptq_static/fx/README.md", "examples/pytorch/nlp/huggingface_models/text-classification/quantization/qat/fx/README.md", "examples/pytorch/nlp/huggingface_models/translation/quantization/ptq_dynamic/eager/README.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/MASKRCNN_README.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/README.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/ABSTRACTIONS.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/INSTALL.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/MODEL_ZOO.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/README.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/TROUBLESHOOTING.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/maskrcnn_benchmark/data/README.md", "examples/pytorch/object_detection/maskrcnn/quantization/ptq/fx/pytorch/maskrcnn_benchmark/utils/README.md", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/fx/README.md", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/fx/upscale_coco/README.md", "examples/pytorch/object_detection/ssd_resnet34/quantization/ptq/ipex/README.md", "examples/pytorch/object_detection/ssd_resnet34/quantization/qat/fx/README.md", "examples/pytorch/object_detection/yolo_v3/quantization/ptq/eager/README.md", "examples/pytorch/object_detection/yolo_v3/quantization/ptq/eager/YOLOV3_README.md", "examples/pytorch/recommendation/dlrm/quantization/ptq/eager/README.md", "examples/pytorch/recommendation/dlrm/quantization/ptq/fx/README.md", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/CODE_OF_CONDUCT.md", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/CONTRIBUTING.md", "examples/pytorch/recommendation/dlrm/quantization/ptq/ipex/README.md", "examples/pytorch/speech_recognition/rnnt/quantization/ptq_dynamic/eager/README.md", "examples/pytorch/speech_recognition/torchaudio_models/quantization/ptq_dynamic/eager/README.md", "examples/tensorflow/image_recognition/SavedModel/quantization/ptq/README.md", "examples/tensorflow/image_recognition/ViT/pruning/magnitude/README.md", "examples/tensorflow/image_recognition/inception_v3/pruning/magnitude/README.md", "examples/tensorflow/image_recognition/keras_models/inception_resnet_v2/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/inception_v3/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/mnist/quantization/qat/README.md", "examples/tensorflow/image_recognition/keras_models/mobilenet_v2/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/resnet101/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/resnet50/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/resnet50_fashion/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/resnetv2_101/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/resnetv2_50/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/vgg16/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/vgg19/quantization/ptq/README.md", "examples/tensorflow/image_recognition/keras_models/xception/quantization/ptq/README.md", "examples/tensorflow/image_recognition/resnet_v2/pruning/magnitude/README.md", "examples/tensorflow/image_recognition/resnet_v2/quantization/qat/README.md", "examples/tensorflow/image_recognition/tensorflow_models/distillation/README.md", "examples/tensorflow/image_recognition/tensorflow_models/quantization/ptq/README.md", "examples/tensorflow/image_recognition/tensorflow_models/quantization/ptq/slim/README.md", "examples/tensorflow/nlp/bert_base_mrpc/quantization/ptq/README.md", "examples/tensorflow/nlp/bert_large_squad/quantization/ptq/README.md", "examples/tensorflow/nlp/bert_large_squad_model_zoo/quantization/ptq/README.md", "examples/tensorflow/nlp/distilbert_base/quantization/ptq/README.md", "examples/tensorflow/nlp/transformer_lt/quantization/ptq/README.md", "examples/tensorflow/nlp/transformer_lt_mlperf/quantization/ptq/README.md", "examples/tensorflow/object_detection/tensorflow_models/quantization/ptq/README.md", "examples/tensorflow/object_detection/yolo_v3/quantization/ptq/README.md", "examples/tensorflow/oob_models/quantization/ptq/README.md", "examples/tensorflow/recommendation/wide_deep_large_ds/quantization/ptq/README.md", "examples/tensorflow/semantic_image_segmentation/3dunet-mlperf/quantization/ptq/README.md", "examples/tensorflow/semantic_image_segmentation/deeplab/quantization/ptq/README.md", "examples/tensorflow/style_transfer/arbitrary_style_transfer/quantization/ptq/README.md", "index.rst", "neural_coder/README.md", "neural_coder/docs/IntelCPU_PerformanceSetting.md", "neural_coder/docs/PythonAPI.md", "neural_coder/docs/PythonLauncher.md", "neural_coder/docs/Quantization.md", "neural_coder/docs/SupportMatrix.md", "neural_coder/extensions/neural_compressor_ext_lab/CHANGELOG.md", "neural_coder/extensions/neural_compressor_ext_lab/DEVELOP.md", "neural_coder/extensions/neural_compressor_ext_lab/README.md", "neural_coder/extensions/neural_compressor_ext_lab/RELEASE.md", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/CHANGELOG.md", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/DEVELOP.md", "neural_coder/extensions/neural_compressor_ext_lab_alibaba/RELEASE.md", "neural_compressor/conf/README.md", "neural_compressor/ux/components/benchmark/README.md", "neural_compressor/ux/components/configuration_wizard/README.md", "neural_compressor/ux/components/db_manager/README.md", "neural_compressor/ux/gui/README.md", "neural_compressor/ux/web/README.md"], "titles": ["Type of Change", "Intel\u00ae Neural Compressor", "Security Policy", "API Reference", "APIs", "Benchmark", "Objective", "Pruning", "Quantization", "build <code class=\"docutils literal notranslate\"><span class=\"pre\">Neural</span> <span class=\"pre\">Compressor(INC)</span></code> Containers:", "Contributor Covenant Code of Conduct", "FX", "Neural Architecture Search", "PTQ", "Quantization-aware Training", "Adaptor", "API Documentation", "Quantization Support Matrix", "Intel\u00ae Neural Compressor Bench", "Benchmarking", "Contribution Guidelines", "DataLoader", "Dataset", "Design", "Distillation", "Distillation for Quantization", "Distributed Training and Inference (Evaluation)", "Developer Documentation", "Dynamic Quantization", "Examples", "Frequently Asked Questions", "Getting Started", "Graph Optimization", "Incompatible changes between v1.2 and v1.1", "Infrastructure of Intel\u00ae Neural Compressor", "Installation", "Legal Information", "Metrics", "Mixed Precision", "Model", "Model Conversion", "Objective", "Optimization Orchestration", "SYSTEM CONFIGURATION", "Pruning", "Full Publications/Events (44)", "Quantization", "Turn ON Auto Mixed Precision during Quantization", "Reference Examples", "Release", "SigOpt Strategy", "TensorBoard", "Transform", "Tuning Strategies", "Validated Models", "Introduction to Intel\u00ae Neural Compressor", "Examples", "Hello World Examples", "tf_example1 example", "tf_example2 example", "tf_example3 example", "tf_example4 example", "tf_example5 example", "tf_example6 example", "tf_example7 example", "tf_example8 example", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Performance of FP32 Vs. INT8 ResNet50 Model", "Intel\u00ae Neural Compressor Sample for PyTorch*", "Intel\u00ae Neural Compressor Sample for TensorFlow*", "Usage Example", "ONNX model quantization", "Evaluate performance of ONNX Runtime(Emotion FERPlus)", "Evaluate performance of ONNX Runtime(Ultra-lightweight face detection)", "Evaluate performance of ONNX Runtime(Mobilenet v2)", "Evaluate performance of ONNX Runtime(Mobilenet v3)", "Evaluate performance of ONNX Runtime(Alexnet)", "Evaluate performance of ONNX Runtime(ArcFace)", "Evaluate performance of ONNX Runtime(Caffenet)", "Evaluate performance of ONNX Runtime(Densenet)", "Evaluate performance of ONNX Runtime(EfficientNet-Lite4)", "Evaluate performance of ONNX Runtime(FCN)", "Evaluate performance of ONNX Runtime(Googlenet)", "Evaluate performance of ONNX Runtime(Inception)", "Evaluate performance of ONNX Runtime(MNIST)", "Evaluate performance of ONNX Runtime(Mobilenet)", "Evaluate performance of ONNX Runtime(ResNet 50)", "Evaluate performance of ONNX Runtime(Shufflenet)", "Evaluate performance of ONNX Runtime(Squeezenet)", "Evaluate performance of ONNX Runtime(VGG16)", "Evaluate performance of ONNX Runtime(ZFNet)", "Evaluate performance of ONNX Runtime(ResNet 50)", "Evaluate performance of ONNX Runtime(unet)", "Evaluate performance of ONNX Runtime(VGG16)", "Evaluate performance of ONNX Runtime(BERT)", "Evaluate performance of ONNX Runtime(DistilBERT)", "Evaluate performance of ONNX Runtime(Huggingface Question Answering)", "Evaluate performance of ONNX Runtime(Huggingface Text Classification)", "Evaluate performance of ONNX Runtime(MobileBERT)", "Evaluate performance of ONNX Runtime(BiDAF)", "Evaluate performance of ONNX Runtime(BERT)", "Evaluate performance of ONNX Runtime(GPT2)", "Evaluate performance of ONNX Runtime(MobileBERT)", "Evaluate performance of ONNX Runtime(RoBERTa)", "Evaluate performance of ONNX Runtime(ResNet101-DUC)", "Evaluate performance of ONNX Runtime(Faster R-CNN)", "Evaluate performance of ONNX Runtime(Mask R-CNN)", "Evaluate performance of ONNX Runtime(SSD)", "Evaluate performance of ONNX Runtime(SSD Mobilenet v1)", "Evaluate performance of ONNX Runtime(Tiny-YOLOv3)", "Evaluate performance of ONNX Runtime(yolov3)", "Evaluate performance of ONNX Runtime(YOLOv4)", "Evaluate performance of ONNX Runtime(SSD Mobilenet v1)", "Evaluate performance of ONNX Runtime(SSD Mobilenet v2)", "A example using Textual Inversion method to personalize text2image", "MLPerf Inference Benchmarks for Medical Image 3D Segmentation", "Introduction", "Data format for Inference", "Dataset conversion instructions", "Extending/Changing nnU-Net", "Example: inference with pretrained nnU-Net models", "Setting up Paths", "Example: 3D U-Net training on the Hippocampus dataset", "&lt;no title&gt;", "nnU-Net", "CIFAR100 Distillation Example", "CIFAR10 Distillation Example", "CIFAR100 Distillation Example", "(Generic) EfficientNets for PyTorch", "Step-by-Step", "Distributed MNIST Example", "PeleeNet", "Step-by-Step", "Step-by-Step", "ResNeSt", "Pretrained Models", "Train ResNeSt with MXNet Gluon", "Step-by-Step", "Pretrained models for Pytorch (Work in progress)", "Prepare dataset", "Step-by-Step", "Step-by-Step", "Prepare an environment", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "distributed example on QAT", "Step-by-Step", "Prepare requirements", "Step-by-Step", "Step-by-Step", "Contributor Covenant Code of Conduct", "How to contribute to transformers?", "How To Request Support", "Online demos", "Generating the documentation", "How to add a model to \ud83e\udd17 Transformers?", "Benchmarks", "BERTology", "Community", "&lt;no title&gt;", "Converting Tensorflow Checkpoints", "Fine-tuning with custom datasets", "&lt;no title&gt;", "Glossary", "Transformers", "Installation", "General Utilities", "Utilities for Generation", "Custom Layers and Utilities", "Utilities for pipelines", "Utilities for Tokenizers", "Utilities for Trainer", "Callbacks", "Configuration", "Feature Extractor", "Logging", "Models", "Optimization", "Model outputs", "Pipelines", "Processors", "Tokenizer", "Trainer", "Migrating from previous packages", "ALBERT", "Auto Classes", "BART", "BARThez", "BERT", "BertGeneration", "Bertweet", "Blenderbot", "Blenderbot Small", "BORT", "CamemBERT", "ConvBERT", "CTRL", "DeBERTa", "DeBERTa-v2", "DialoGPT", "DistilBERT", "DPR", "ELECTRA", "Encoder Decoder Models", "FlauBERT", "FSMT", "Funnel Transformer", "OpenAI GPT", "OpenAI GPT2", "herBERT", "I-BERT", "LayoutLM", "LED", "Longformer", "LXMERT", "MarianMT", "MBart and MBart-50", "MobileBERT", "MPNet", "MT5", "Pegasus", "PhoBERT", "ProphetNet", "RAG", "Reformer", "RetriBERT", "RoBERTa", "SqueezeBERT", "T5", "TAPAS", "Transformer XL", "Wav2Vec2", "XLM", "XLM-ProphetNet", "XLM-RoBERTa", "XLNet", "Model sharing and uploading", "Summary of the models", "Multi-lingual models", "&lt;no title&gt;", "Perplexity of fixed-length models", "Philosophy", "Preprocessing data", "Pretrained models", "Quick tour", "Exporting transformers models", "Summary of the tasks", "Testing", "Summary of the tokenizers", "Training and fine-tuning", "Examples", "\ud83e\udd17 Benchmark results", "Language model training", "Multiple Choice", "SQuAD", "Research projects", "Adversarial evaluation of model performances", "Patience-based Early Exit", "Text Summarization with Pretrained Encoders", "DeeBERT: Early Exiting for *BERT", "Distil*", "Long Form Question Answering", "LXMERT DEMO", "Whole Word Mask Language Model", "MM-IMDb", "Movement Pruning: Adaptive Sparsity by Fine-Tuning", "Performer fine-tuning", "Plug and Play Language Models: a Simple Approach to Controlled Text Generation", "Intro", "Sequence to Sequence Training and Evaluation", "Saved Pseudo-Labels", "Zero-shot classifier distillation", "Sequence to Sequence Training and Evaluation", "Text classification examples", "Language generation", "Token classification", "\ud83d\udd25 Model cards now live inside each huggingface.co model repo \ud83d\udd25", "TAPAS base model", "\ud83e\udd17 Transformers Notebooks", "Upload converted models", "How to add a new example script in \ud83e\udd17 Transformers", "<strong>TEMPLATE</strong>", "Using <code class=\"docutils literal notranslate\"><span class=\"pre\">cookiecutter</span></code> to generate models", "{{cookiecutter.modelname}}", "How to add BigBird to \ud83e\udd17 Transformers?", "&lt;no title&gt;", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Pytorch Pruner", "Step-by-Step", "Step by step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Prepare dataset", "Step-by-Step", "Pytorch Pruner", "\u201cPruning while distillation\u201d step by step", "Notice", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "1. Problem", "Step-by-Step", "Abstractions", "Installation", "Model Zoo and Baselines", "Faster R-CNN and Mask R-CNN in PyTorch 1.0", "Troubleshooting", "Setting Up Datasets", "Utility functions", "Step-by-Step", "Upscaled COCO Dataset", "SSD-ResNet34 Inference", "Step-by-Step", "Step-by-Step", "PyTorch-YOLOv3", "Step-by-Step", "Step-by-Step", "Code of Conduct", "Contributing to DLRM", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Run pretraining", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Prerequisite", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Step-by-Step", "Intel\u00ae Neural Compressor Documentation", "Neural Coder", "Intel CPU Platforms: Best Performance Setting", "Neural Coder as Python API", "Python Launcher", "Neural Coder for Quantization", "Supported Optimization Features", "Changelog", "neural_compressor_ext_lab", "Intel\u00ae Neural Compressor as JupyterLab Extension", "Making a new release of neural_compressor_ext_lab", "Changelog", "neural_compressor_ext_lab_alibaba", "Making a new release of neural_compressor_ext_lab_alibaba", "Introduction", "Execute benchmark endpoint", "Configuration for predefined models", "Database migration", "Gui", "Intel\u00ae Neural Compressor Bench"], "terms": {"featur": [0, 13, 19, 20, 21, 23, 24, 32, 38, 39, 45, 49, 52, 121, 156, 159, 160, 161, 165, 167, 169, 176, 183, 184, 186, 187, 190, 194, 200, 211, 212, 215, 218, 225, 241, 248, 253, 254, 258, 279, 281, 285, 288, 295, 305, 337, 338, 351, 352, 370, 372, 373, 383], "bug": [0, 20, 118, 156, 159, 165, 169, 186, 219, 233, 251, 252, 264, 273, 285, 288, 332], "fix": [0, 20, 22, 27, 53, 130, 140, 155, 156, 157, 159, 165, 168, 169, 181, 186, 233, 234, 241, 249, 251, 264, 273, 285, 286, 288, 372], "document": [0, 4, 17, 26, 28, 38, 49, 52, 66, 67, 68, 116, 126, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 152, 153, 155, 156, 157, 159, 162, 164, 165, 167, 168, 171, 179, 182, 186, 187, 197, 198, 203, 211, 215, 216, 217, 219, 224, 227, 238, 239, 240, 241, 247, 248, 249, 250, 251, 252, 254, 262, 273, 275, 284, 285, 286, 288, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 312, 313, 315, 323, 326, 327, 329, 330, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 379, 382], "other": [0, 10, 11, 16, 18, 20, 28, 32, 34, 36, 39, 41, 43, 44, 46, 52, 53, 54, 66, 69, 72, 73, 98, 99, 120, 121, 122, 123, 126, 131, 133, 134, 135, 139, 140, 153, 154, 155, 156, 157, 159, 165, 167, 168, 176, 180, 183, 186, 187, 190, 195, 196, 197, 207, 208, 209, 210, 213, 217, 219, 224, 227, 228, 231, 232, 233, 235, 240, 245, 248, 249, 250, 251, 252, 253, 264, 268, 272, 273, 274, 275, 276, 277, 281, 285, 288, 308, 317, 321, 335, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 383], "api": [0, 14, 21, 32, 34, 40, 49, 50, 53, 56, 57, 63, 65, 72, 130, 145, 146, 147, 156, 157, 162, 168, 183, 186, 187, 190, 197, 233, 240, 245, 246, 248, 251, 254, 256, 267, 275, 279, 286, 288, 293, 295, 305, 308, 309, 311, 312, 314, 315, 316, 317, 332, 355, 369, 374, 375, 384, 388], "detail": [0, 1, 10, 20, 33, 37, 38, 44, 49, 50, 51, 53, 54, 68, 70, 71, 76, 93, 95, 96, 97, 100, 105, 110, 114, 115, 131, 134, 135, 139, 141, 142, 143, 145, 147, 148, 151, 153, 155, 156, 157, 158, 159, 160, 167, 183, 186, 187, 202, 218, 223, 233, 238, 241, 242, 246, 247, 248, 249, 251, 253, 254, 269, 279, 281, 283, 297, 319, 327, 329, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 353, 354, 358, 363, 364, 365, 366, 367, 370], "jira": 0, "ticket": 0, "xxx": [0, 15, 22, 24, 70, 71, 122, 124, 126, 158, 251, 323], "trigger": [0, 32, 148, 155, 270, 327], "reproduc": [0, 20, 66, 67, 68, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 152, 153, 155, 156, 157, 159, 187, 208, 211, 245, 269, 273, 285, 288, 290, 291, 292, 294, 296, 297, 298, 299, 301, 302, 304, 308, 309, 310, 311, 312, 313, 315, 323, 326, 327, 329, 330, 332, 333, 334, 335, 337, 338, 341, 345, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "includ": [0, 1, 10, 15, 18, 20, 22, 27, 31, 35, 36, 37, 44, 46, 47, 51, 53, 55, 56, 57, 70, 71, 116, 117, 120, 121, 130, 131, 134, 135, 139, 140, 142, 143, 145, 146, 147, 148, 150, 154, 155, 156, 157, 158, 159, 161, 165, 169, 178, 183, 184, 186, 187, 192, 202, 210, 213, 215, 225, 238, 239, 241, 244, 249, 250, 251, 252, 253, 254, 264, 268, 275, 277, 282, 285, 286, 288, 295, 305, 316, 320, 335, 361, 370, 371, 374, 378], "hardwar": [0, 15, 24, 32, 34, 38, 43, 44, 45, 69, 155, 186, 197, 249, 269, 277, 385], "inform": [0, 1, 2, 4, 10, 15, 20, 24, 28, 39, 44, 47, 49, 51, 54, 66, 67, 116, 121, 122, 123, 126, 131, 133, 134, 135, 139, 147, 153, 154, 155, 156, 157, 159, 160, 161, 162, 165, 167, 168, 171, 179, 182, 186, 198, 200, 202, 203, 207, 212, 215, 217, 218, 222, 228, 232, 236, 238, 241, 248, 249, 250, 251, 254, 256, 263, 264, 269, 271, 277, 281, 285, 288, 292, 297, 300, 301, 316, 319, 354, 355, 361, 362, 369, 379, 382], "ani": [0, 10, 11, 18, 20, 21, 26, 69, 70, 71, 117, 120, 121, 123, 126, 154, 155, 156, 157, 158, 159, 160, 162, 164, 165, 169, 183, 186, 187, 207, 214, 218, 233, 240, 241, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254, 259, 267, 269, 275, 276, 277, 280, 281, 282, 285, 288, 314, 332, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 373, 387], "librari": [0, 1, 16, 17, 27, 31, 35, 55, 116, 126, 155, 156, 157, 158, 159, 160, 162, 164, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 179, 180, 183, 184, 185, 186, 187, 215, 219, 228, 240, 241, 242, 245, 248, 249, 250, 251, 252, 253, 254, 256, 258, 259, 264, 265, 267, 269, 276, 277, 278, 279, 284, 285, 286, 288, 322, 378], "introduc": [0, 15, 27, 44, 46, 49, 187, 191, 192, 204, 205, 208, 209, 213, 216, 217, 220, 222, 223, 226, 227, 228, 232, 233, 237, 241, 251, 252, 281, 316], "remov": [0, 10, 13, 19, 20, 32, 44, 51, 66, 67, 68, 130, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 154, 155, 156, 158, 159, 224, 230, 233, 240, 241, 246, 247, 250, 251, 252, 270, 273, 285, 288, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 319, 327, 329, 330, 333, 334, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 377, 381, 388], "an": [1, 3, 10, 12, 13, 14, 15, 16, 19, 20, 21, 23, 28, 32, 37, 38, 41, 50, 51, 52, 53, 55, 56, 58, 61, 62, 63, 65, 66, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 126, 130, 133, 136, 137, 140, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 168, 169, 171, 181, 182, 183, 184, 186, 187, 189, 190, 191, 193, 195, 196, 197, 201, 202, 206, 207, 208, 213, 214, 215, 216, 217, 218, 219, 220, 221, 224, 226, 228, 232, 233, 236, 237, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 258, 260, 262, 264, 269, 271, 272, 273, 275, 276, 277, 279, 280, 281, 284, 285, 288, 293, 295, 302, 305, 306, 308, 309, 311, 312, 316, 319, 354, 355, 357, 370, 372, 373, 383], "open": [1, 10, 16, 18, 20, 30, 55, 70, 71, 121, 123, 126, 154, 155, 156, 157, 158, 159, 162, 165, 168, 169, 195, 196, 197, 203, 205, 214, 215, 227, 229, 241, 249, 250, 255, 280, 282, 285, 288, 319, 332, 364, 379, 382], "sourc": [1, 11, 16, 36, 40, 55, 69, 70, 71, 116, 117, 118, 123, 140, 147, 155, 156, 157, 159, 162, 168, 184, 186, 197, 200, 209, 214, 219, 220, 230, 247, 248, 249, 254, 266, 273, 274, 276, 277, 285, 286, 288, 314, 315, 317, 332, 354, 359, 360, 361, 377, 379, 381, 382, 387, 388], "popular": [1, 15, 16, 22, 24, 44, 46, 53, 55, 72, 157, 159, 221, 233, 250, 252, 285, 288], "compress": [1, 15, 24, 34, 41, 42, 44, 46, 55, 56, 157, 168, 197, 210, 221, 244, 264, 269, 324], "techniqu": [1, 13, 14, 34, 42, 44, 46, 56, 188, 201, 202, 215, 228, 231, 232, 241, 264, 267, 273, 370], "all": [1, 10, 11, 13, 14, 15, 16, 18, 20, 21, 22, 26, 31, 32, 35, 42, 43, 44, 45, 46, 47, 52, 53, 120, 121, 122, 124, 130, 131, 134, 135, 136, 139, 140, 145, 148, 153, 154, 155, 156, 157, 158, 159, 160, 161, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 179, 180, 182, 183, 184, 185, 186, 187, 192, 198, 199, 203, 206, 209, 210, 212, 216, 217, 219, 223, 224, 226, 232, 233, 235, 237, 239, 241, 242, 245, 246, 248, 250, 252, 253, 254, 256, 262, 264, 267, 269, 272, 273, 274, 276, 281, 282, 283, 285, 286, 288, 293, 316, 318, 319, 320, 327, 328, 329, 337, 338, 351, 370, 378, 379, 382], "mainstream": 1, "deep": [1, 15, 16, 17, 21, 31, 34, 35, 38, 45, 46, 53, 55, 56, 70, 71, 121, 126, 140, 157, 159, 167, 168, 192, 210, 241, 250, 253, 285, 288, 365, 370, 373, 374, 378], "learn": [1, 15, 16, 17, 21, 22, 27, 31, 33, 34, 35, 38, 44, 45, 46, 51, 53, 55, 70, 71, 72, 121, 126, 140, 154, 156, 159, 165, 167, 168, 186, 187, 188, 191, 195, 196, 199, 200, 202, 204, 205, 206, 208, 211, 215, 218, 230, 232, 233, 234, 235, 236, 238, 239, 240, 241, 245, 248, 252, 253, 256, 261, 264, 269, 273, 281, 285, 288, 306, 319, 356, 370, 373, 374, 378, 379, 382], "framework": [1, 15, 16, 17, 18, 21, 22, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 44, 45, 46, 52, 53, 54, 55, 59, 66, 67, 68, 72, 73, 117, 118, 121, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 157, 159, 160, 167, 168, 205, 214, 215, 218, 232, 235, 241, 245, 249, 250, 253, 285, 288, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 375, 384, 385], "tensorflow": [1, 13, 15, 16, 18, 24, 26, 27, 29, 31, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 50, 53, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 69, 72, 93, 114, 115, 117, 130, 131, 134, 135, 136, 139, 140, 155, 157, 158, 159, 160, 162, 167, 168, 169, 176, 178, 180, 186, 189, 194, 225, 240, 245, 246, 248, 249, 250, 251, 254, 285, 286, 287, 288, 375, 384, 385, 388], "pytorch": [1, 11, 15, 16, 24, 26, 28, 29, 31, 34, 35, 38, 39, 44, 45, 46, 49, 53, 55, 66, 76, 77, 93, 95, 117, 118, 126, 133, 138, 139, 142, 143, 145, 151, 152, 155, 157, 158, 159, 160, 162, 164, 167, 168, 169, 176, 178, 180, 182, 186, 189, 200, 203, 209, 212, 214, 219, 233, 240, 245, 246, 248, 249, 250, 251, 254, 255, 264, 269, 272, 279, 281, 285, 286, 287, 288, 291, 294, 297, 299, 302, 303, 304, 307, 312, 316, 317, 318, 320, 323, 325, 326, 329, 330, 333, 334, 335, 354, 355, 362, 367, 370, 374, 375, 385], "mxnet": [1, 15, 16, 29, 31, 34, 38, 39, 53, 55, 131, 134, 135, 136, 139, 140, 354, 355, 362, 367, 385, 388], "formerli": [1, 31, 55, 168, 250], "known": [1, 44, 51, 53, 55, 159, 168, 186, 221, 250, 252, 267, 272, 285, 288], "low": [1, 14, 15, 16, 19, 22, 26, 27, 38, 45, 46, 53, 55, 70, 71, 116, 121, 123, 157, 159, 168, 184, 238, 277, 285, 288], "precis": [1, 14, 15, 16, 17, 18, 19, 25, 26, 27, 34, 45, 46, 53, 55, 70, 71, 116, 117, 118, 126, 159, 187, 214, 227, 241, 248, 249, 251, 253, 272, 273, 281, 285, 288, 293, 327, 328, 370, 374, 375, 384], "optim": [1, 12, 13, 14, 16, 24, 26, 27, 31, 34, 35, 36, 39, 43, 44, 45, 46, 47, 50, 51, 53, 55, 58, 62, 63, 65, 67, 69, 70, 71, 76, 93, 95, 121, 130, 148, 150, 155, 157, 162, 165, 168, 192, 197, 221, 224, 226, 228, 230, 231, 233, 237, 241, 251, 253, 269, 281, 295, 305, 312, 323, 326, 334, 352, 354, 355, 357, 358, 360, 362, 364, 365, 367, 370, 372, 373, 378, 384], "tool": [1, 11, 15, 21, 32, 36, 45, 46, 55, 61, 77, 93, 104, 126, 131, 155, 159, 160, 169, 205, 240, 241, 245, 246, 249, 250, 251, 253, 269, 285, 288, 308, 310, 315, 319, 321, 354, 355, 357, 364, 377, 381], "i": [1, 4, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 26, 27, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 150, 153, 154, 156, 158, 159, 160, 161, 164, 165, 167, 168, 169, 171, 176, 178, 179, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 258, 259, 260, 261, 262, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 312, 313, 314, 315, 316, 317, 319, 320, 321, 326, 327, 328, 329, 330, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 371, 373, 374, 377, 378, 379, 381, 382, 386], "run": [1, 14, 15, 18, 20, 26, 27, 30, 32, 38, 44, 45, 46, 49, 50, 51, 53, 55, 76, 86, 93, 95, 96, 97, 100, 103, 105, 116, 117, 120, 121, 122, 123, 124, 127, 128, 129, 130, 155, 156, 158, 160, 164, 168, 186, 204, 214, 217, 231, 233, 240, 244, 249, 256, 258, 259, 262, 263, 264, 267, 269, 271, 272, 273, 274, 275, 281, 282, 283, 284, 286, 290, 296, 298, 303, 308, 309, 310, 311, 313, 317, 319, 321, 328, 366, 372, 373, 374, 377, 378, 379, 381, 382, 386], "which": [1, 10, 12, 14, 15, 16, 18, 19, 20, 21, 22, 24, 26, 28, 31, 32, 34, 37, 38, 39, 40, 42, 44, 46, 47, 49, 51, 52, 53, 54, 55, 66, 67, 68, 70, 71, 72, 116, 118, 120, 121, 122, 123, 126, 131, 134, 135, 139, 140, 142, 143, 145, 146, 147, 148, 150, 153, 154, 155, 156, 157, 158, 159, 160, 162, 165, 167, 169, 176, 180, 183, 184, 185, 186, 187, 188, 191, 192, 197, 199, 200, 202, 204, 206, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 221, 222, 224, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 256, 258, 260, 261, 262, 263, 264, 267, 269, 272, 273, 275, 276, 277, 281, 284, 285, 286, 288, 290, 292, 295, 296, 298, 301, 305, 308, 309, 310, 311, 313, 315, 316, 317, 319, 320, 327, 329, 330, 333, 337, 341, 345, 351, 352, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 373, 378], "deliv": [1, 45, 55], "unifi": [1, 16, 21, 33, 34, 39, 55, 157, 168, 208, 223, 232, 241, 245, 249], "interfac": [1, 12, 16, 27, 34, 46, 49, 55, 72, 130, 131, 134, 135, 139, 140, 142, 143, 145, 153, 164, 249, 251, 253, 329, 330, 333, 362, 387], "across": [1, 16, 23, 44, 55, 126, 160, 184, 212, 215, 227, 241, 250, 286], "network": [1, 12, 13, 18, 24, 25, 45, 46, 55, 70, 71, 101, 124, 126, 133, 136, 140, 151, 157, 159, 167, 168, 206, 210, 221, 231, 249, 252, 253, 269, 281, 285, 288, 295, 305, 316, 328], "technologi": [1, 43, 55, 70, 71, 159, 231, 250, 285, 288], "prune": [1, 3, 26, 27, 34, 42, 45, 46, 55, 72, 144, 161, 180, 245, 293, 295, 305], "knowledg": [1, 25, 34, 39, 55, 56, 159, 162, 191, 195, 196, 204, 215, 221, 227, 241, 264, 285, 288, 295, 305], "distil": [1, 34, 42, 55, 156, 157, 168, 190, 195, 204, 212, 224, 241, 247, 250, 269, 274, 292, 295, 297, 301, 305, 359], "thi": [1, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 28, 32, 34, 36, 37, 38, 39, 40, 44, 46, 47, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 145, 146, 147, 148, 150, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 182, 184, 185, 186, 187, 189, 190, 191, 193, 195, 196, 197, 198, 199, 200, 201, 202, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 221, 222, 223, 224, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 258, 259, 260, 261, 262, 263, 264, 265, 267, 269, 271, 272, 273, 274, 275, 276, 277, 279, 281, 284, 285, 286, 288, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 312, 313, 315, 317, 319, 320, 321, 322, 323, 326, 327, 328, 329, 330, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 371, 373, 374, 377, 379, 381, 382, 387], "automat": [1, 11, 16, 18, 22, 27, 34, 38, 42, 52, 53, 55, 67, 69, 121, 122, 126, 131, 134, 135, 139, 142, 143, 145, 153, 155, 158, 159, 167, 169, 189, 203, 228, 232, 233, 240, 245, 246, 248, 250, 254, 275, 277, 281, 285, 288, 295, 305, 310, 327, 329, 330, 333, 345, 370, 373, 374, 377, 378, 379, 381, 382, 386, 387], "accuraci": [1, 12, 13, 14, 16, 18, 19, 21, 25, 26, 27, 28, 31, 32, 37, 38, 40, 41, 42, 44, 45, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 130, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 192, 205, 214, 228, 231, 233, 236, 238, 253, 269, 275, 277, 290, 296, 298, 305, 306, 310, 313, 315, 319, 325, 327, 329, 330, 333, 337, 341, 351, 354, 355, 356, 357, 359, 361, 362, 365, 367, 368, 384], "driven": [1, 16, 38, 41, 51, 55, 249], "tune": [1, 11, 14, 16, 18, 21, 22, 26, 27, 28, 31, 34, 36, 38, 41, 44, 45, 47, 49, 50, 51, 55, 58, 60, 62, 63, 64, 70, 71, 72, 97, 100, 105, 116, 118, 139, 140, 145, 157, 159, 162, 168, 169, 181, 190, 191, 192, 193, 197, 203, 204, 207, 208, 209, 211, 215, 216, 218, 219, 221, 222, 224, 227, 232, 235, 240, 241, 245, 246, 247, 248, 249, 250, 254, 256, 261, 263, 264, 267, 272, 273, 275, 276, 279, 281, 282, 285, 288, 292, 297, 300, 301, 325, 335, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 360, 362, 363, 365, 366, 383, 388], "strategi": [1, 15, 26, 27, 34, 45, 46, 47, 49, 55, 66, 67, 68, 121, 131, 134, 135, 139, 145, 146, 147, 148, 150, 159, 165, 168, 195, 196, 218, 241, 244, 246, 250, 254, 269, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 362, 367, 373, 388], "help": [1, 13, 16, 21, 31, 39, 53, 55, 60, 68, 69, 70, 71, 121, 126, 140, 155, 156, 159, 160, 161, 167, 169, 188, 205, 218, 224, 231, 248, 250, 251, 259, 261, 264, 270, 272, 273, 277, 285, 288, 308, 319, 362, 368, 370, 374, 388], "user": [1, 11, 12, 13, 15, 24, 28, 32, 34, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 55, 56, 57, 58, 60, 62, 63, 69, 70, 71, 72, 73, 116, 118, 120, 123, 126, 130, 142, 143, 145, 155, 156, 157, 158, 159, 160, 165, 168, 169, 187, 194, 200, 203, 206, 217, 231, 240, 245, 250, 251, 270, 277, 284, 285, 288, 296, 309, 310, 311, 312, 323, 345, 370, 372, 373, 374, 378, 383, 385], "quickli": [1, 16, 53, 55, 155, 156, 157, 159, 169, 245, 248, 250, 251, 273, 285, 286, 288], "find": [1, 12, 15, 16, 18, 44, 50, 51, 53, 55, 120, 121, 123, 126, 133, 145, 146, 152, 153, 156, 157, 159, 167, 169, 186, 202, 227, 230, 233, 241, 248, 250, 251, 252, 255, 256, 261, 263, 264, 269, 270, 273, 276, 279, 282, 284, 285, 288, 371, 377, 381], "out": [1, 11, 16, 20, 22, 46, 55, 70, 71, 123, 126, 140, 155, 156, 157, 159, 160, 165, 167, 168, 169, 187, 206, 210, 211, 213, 232, 233, 236, 241, 244, 246, 248, 251, 254, 269, 271, 275, 276, 278, 285, 288, 295, 305, 319, 370, 373, 377, 378, 379, 381, 382, 387], "best": [1, 10, 12, 14, 16, 20, 31, 35, 41, 46, 52, 53, 55, 66, 67, 68, 120, 130, 131, 134, 135, 145, 146, 148, 150, 152, 153, 154, 155, 156, 158, 159, 164, 168, 186, 188, 191, 195, 196, 213, 215, 218, 225, 230, 231, 233, 235, 236, 240, 251, 252, 261, 267, 273, 284, 285, 288, 315, 319, 327, 354, 356, 357, 359, 360, 361, 362, 368, 370, 374], "It": [1, 13, 15, 16, 18, 19, 24, 32, 44, 46, 50, 53, 55, 59, 60, 69, 101, 120, 121, 123, 126, 131, 134, 135, 136, 139, 140, 142, 143, 145, 146, 153, 155, 156, 157, 158, 159, 167, 169, 176, 183, 184, 186, 188, 190, 192, 197, 198, 200, 201, 202, 203, 204, 205, 208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 220, 221, 227, 230, 231, 232, 233, 234, 236, 238, 240, 241, 242, 246, 248, 249, 250, 251, 252, 256, 258, 261, 262, 264, 267, 269, 273, 275, 276, 277, 279, 281, 285, 286, 288, 291, 292, 294, 299, 300, 301, 304, 308, 316, 327, 328, 329, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 371, 374, 378], "also": [1, 12, 13, 15, 18, 19, 20, 21, 24, 31, 32, 34, 37, 41, 42, 44, 46, 47, 53, 55, 58, 60, 62, 63, 72, 116, 120, 121, 122, 123, 124, 126, 130, 131, 134, 135, 139, 142, 143, 145, 146, 148, 153, 154, 155, 156, 157, 158, 159, 165, 167, 171, 178, 179, 180, 182, 186, 187, 188, 190, 191, 193, 197, 200, 206, 209, 213, 215, 216, 217, 218, 228, 233, 234, 238, 240, 241, 244, 246, 248, 249, 250, 251, 252, 253, 256, 262, 263, 269, 272, 273, 275, 276, 277, 282, 283, 285, 288, 290, 292, 293, 295, 298, 300, 301, 305, 308, 309, 310, 311, 312, 316, 319, 323, 327, 328, 329, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 373, 377, 378, 381, 387], "implement": [1, 14, 16, 19, 21, 22, 49, 51, 53, 55, 59, 72, 116, 117, 118, 121, 126, 130, 131, 133, 134, 135, 136, 139, 142, 143, 145, 148, 150, 153, 157, 159, 162, 165, 167, 168, 174, 176, 177, 180, 185, 186, 187, 197, 198, 199, 200, 202, 205, 206, 214, 228, 230, 234, 238, 241, 249, 253, 261, 264, 272, 280, 284, 285, 286, 288, 295, 296, 305, 306, 309, 310, 311, 318, 319, 327, 328, 329, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "differ": [1, 10, 11, 12, 13, 16, 18, 20, 21, 22, 24, 26, 29, 31, 32, 33, 34, 37, 39, 40, 41, 44, 46, 51, 52, 53, 55, 119, 120, 122, 126, 130, 140, 154, 156, 159, 160, 165, 167, 184, 186, 187, 190, 195, 208, 209, 212, 213, 217, 218, 220, 224, 227, 230, 231, 232, 233, 236, 238, 241, 242, 244, 248, 249, 250, 251, 252, 253, 255, 256, 258, 261, 263, 264, 270, 272, 276, 277, 278, 281, 282, 285, 286, 288, 295, 305, 308, 316, 318, 377, 381], "weight": [1, 13, 14, 15, 16, 17, 18, 25, 27, 33, 37, 41, 44, 46, 51, 53, 54, 55, 58, 72, 76, 93, 95, 116, 122, 123, 126, 134, 145, 146, 152, 153, 155, 159, 161, 162, 164, 165, 168, 171, 181, 186, 187, 189, 190, 195, 201, 202, 228, 240, 245, 248, 250, 251, 253, 262, 264, 269, 270, 273, 285, 288, 295, 296, 305, 306, 308, 309, 311, 312, 318, 329, 330, 333, 356, 357, 359, 360, 361, 362, 383], "algorithm": [1, 12, 15, 24, 34, 44, 46, 51, 53, 55, 58, 121, 126, 159, 167, 197, 233, 246, 252, 285, 288, 292, 295, 300, 301, 302, 305, 319, 354, 355, 362, 374, 378], "gener": [1, 15, 18, 21, 24, 32, 37, 38, 41, 43, 44, 45, 46, 47, 51, 52, 53, 55, 57, 59, 65, 70, 71, 116, 118, 121, 126, 145, 146, 156, 157, 162, 168, 182, 184, 190, 191, 192, 193, 195, 196, 199, 200, 203, 204, 206, 207, 211, 212, 213, 216, 219, 220, 221, 224, 226, 227, 231, 232, 233, 234, 236, 237, 239, 241, 242, 248, 249, 251, 252, 254, 267, 272, 273, 275, 281, 282, 284, 303, 316, 319, 323, 325, 332, 341, 345, 354, 356, 357, 359, 360, 361, 362, 365, 368, 370, 373, 377, 379, 381, 382, 386, 387], "predefin": [1, 55, 165, 248, 388], "sparsiti": [1, 16, 22, 27, 34, 44, 54, 55, 292, 293, 294, 295, 301, 304, 305, 306], "goal": [1, 42, 46, 53, 55, 140, 159, 212, 233, 245, 246, 248, 250, 285, 288], "from": [1, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 24, 25, 26, 29, 30, 32, 34, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 58, 59, 60, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 98, 99, 101, 102, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 130, 131, 134, 135, 136, 137, 139, 144, 145, 146, 147, 148, 150, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 168, 171, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 258, 260, 261, 262, 263, 264, 269, 270, 272, 273, 274, 275, 276, 277, 279, 280, 281, 282, 283, 285, 286, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 321, 323, 325, 326, 327, 328, 329, 330, 332, 333, 334, 336, 354, 355, 356, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 372, 373, 374, 385, 386], "teacher": [1, 24, 25, 54, 55, 56, 127, 128, 129, 141, 151, 168, 221, 232, 241, 264, 269, 275, 292, 295, 300, 301, 305, 306, 353], "student": [1, 22, 24, 25, 54, 55, 56, 127, 128, 129, 241, 264, 273, 275, 285, 306], "critic": [1, 10, 20, 179], "ai": [1, 27, 45, 47, 56, 130, 157, 165, 168, 247, 249, 308, 370], "compon": [1, 12, 16, 20, 21, 26, 27, 36, 42, 43, 72, 121, 130, 159, 218, 219, 224, 251, 272, 285, 288, 370, 384, 387], "oneapi": [1, 27, 31, 35, 45], "analyt": [1, 27, 31, 35, 45], "toolkit": [1, 11, 27, 31, 35, 45, 126, 136, 138, 186, 209, 370], "visit": [1, 54, 116, 136, 138, 293], "onlin": [1, 10, 20, 50, 154, 213, 263, 328], "websit": [1, 31, 35, 70, 71, 126, 240, 247, 262, 277, 280, 362, 363], "http": [1, 9, 10, 13, 18, 22, 31, 32, 35, 36, 49, 55, 58, 60, 61, 62, 63, 65, 70, 71, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 122, 126, 130, 131, 133, 134, 135, 136, 139, 140, 142, 143, 145, 147, 148, 151, 152, 153, 154, 155, 156, 157, 159, 161, 165, 169, 184, 186, 191, 199, 201, 202, 209, 220, 240, 247, 250, 251, 254, 262, 263, 269, 271, 272, 273, 274, 276, 279, 283, 285, 286, 288, 293, 297, 298, 299, 302, 314, 317, 319, 320, 321, 323, 326, 327, 328, 329, 332, 334, 335, 354, 355, 357, 358, 360, 361, 362, 363, 364, 365, 367, 368, 374, 379, 382, 387, 388], "github": [1, 13, 18, 20, 22, 29, 31, 35, 36, 49, 55, 61, 70, 71, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 118, 121, 126, 130, 140, 147, 151, 155, 159, 165, 169, 186, 190, 195, 199, 201, 202, 209, 217, 219, 220, 224, 226, 228, 232, 233, 237, 240, 249, 250, 251, 254, 261, 262, 269, 271, 273, 280, 281, 283, 285, 286, 288, 293, 314, 317, 319, 320, 321, 326, 328, 332, 354, 357, 358, 360, 361, 362, 363, 364, 365, 367, 374, 379, 382], "io": [1, 21, 63, 126, 165, 169, 251, 293, 357, 358], "version": [1, 9, 10, 11, 15, 18, 20, 31, 35, 36, 43, 45, 53, 66, 67, 68, 75, 76, 93, 95, 98, 99, 116, 118, 126, 130, 139, 140, 146, 147, 150, 154, 155, 156, 157, 159, 160, 162, 167, 168, 169, 184, 186, 187, 198, 202, 204, 208, 210, 212, 214, 221, 225, 233, 241, 244, 245, 248, 249, 250, 251, 254, 258, 259, 264, 267, 269, 273, 281, 283, 285, 288, 293, 295, 297, 305, 314, 315, 317, 318, 319, 320, 323, 325, 326, 329, 330, 333, 334, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 355, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 377, 379, 381, 382, 385, 386, 387], "3": [1, 13, 14, 15, 22, 24, 26, 31, 32, 37, 38, 41, 44, 46, 48, 52, 53, 54, 55, 56, 76, 93, 95, 97, 103, 105, 116, 117, 118, 120, 122, 126, 130, 133, 136, 139, 140, 155, 157, 160, 164, 165, 168, 169, 186, 197, 201, 202, 211, 215, 219, 220, 231, 233, 234, 235, 236, 238, 241, 247, 249, 251, 253, 254, 257, 258, 261, 264, 268, 269, 271, 273, 274, 275, 276, 277, 279, 281, 283, 285, 288, 290, 291, 292, 294, 296, 297, 298, 299, 300, 301, 302, 304, 305, 308, 309, 310, 311, 313, 316, 318, 328, 370, 372, 377, 381, 383, 385, 387, 388], "7": [1, 19, 21, 30, 31, 32, 35, 46, 49, 53, 55, 57, 62, 63, 96, 97, 103, 116, 126, 130, 131, 133, 134, 135, 136, 139, 140, 145, 146, 147, 159, 169, 186, 192, 197, 199, 201, 202, 221, 231, 233, 241, 249, 258, 261, 264, 269, 274, 285, 286, 288, 290, 293, 295, 300, 317, 318, 319, 328, 357, 384, 388], "8": [1, 9, 11, 13, 14, 31, 35, 41, 45, 54, 55, 56, 78, 86, 97, 100, 103, 105, 126, 129, 130, 133, 136, 140, 146, 147, 148, 150, 157, 159, 160, 167, 168, 186, 201, 202, 212, 224, 234, 235, 238, 241, 247, 248, 249, 254, 258, 260, 261, 264, 269, 272, 273, 274, 285, 288, 292, 293, 295, 312, 315, 318, 319, 320, 323, 326, 328, 364, 383, 387], "9": [1, 11, 13, 14, 31, 35, 44, 54, 64, 70, 71, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 100, 102, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 128, 130, 133, 152, 153, 159, 186, 195, 196, 201, 202, 205, 211, 220, 228, 236, 238, 242, 247, 248, 250, 251, 261, 264, 269, 273, 277, 285, 288, 295, 300, 301, 305, 314, 317, 318, 320, 328, 387, 388], "10": [1, 13, 15, 18, 22, 31, 35, 48, 52, 56, 60, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 121, 126, 127, 130, 136, 138, 140, 148, 151, 159, 160, 165, 179, 184, 186, 203, 228, 242, 247, 248, 249, 250, 252, 258, 262, 269, 271, 273, 274, 275, 277, 281, 285, 288, 293, 295, 296, 297, 298, 299, 305, 313, 316, 317, 318, 319, 323, 325, 330, 359, 361, 388], "releas": [1, 16, 31, 35, 56, 69, 70, 71, 120, 122, 136, 156, 157, 164, 168, 169, 184, 191, 193, 198, 199, 200, 201, 202, 203, 213, 230, 231, 232, 238, 242, 249, 264, 267, 269, 281, 317, 319, 369, 374, 377, 381], "binari": [1, 30, 37, 55, 167, 233, 253, 314, 379, 382], "stabl": [1, 18, 35, 45, 94, 116, 131, 134, 135, 139, 142, 143, 145, 147, 148, 153, 297, 327, 329], "basic": [1, 15, 34, 35, 50, 66, 67, 68, 72, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 155, 159, 179, 186, 221, 233, 241, 251, 261, 285, 288, 290, 296, 298, 303, 308, 309, 310, 311, 313, 315, 320, 327, 329, 330, 333, 354, 355, 362, 367, 388], "pip": [1, 18, 26, 30, 31, 35, 49, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 116, 118, 121, 126, 127, 128, 129, 131, 132, 134, 135, 136, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 164, 168, 186, 187, 211, 247, 251, 254, 259, 262, 264, 266, 269, 271, 273, 283, 284, 285, 286, 288, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 308, 309, 310, 311, 312, 313, 315, 317, 323, 325, 326, 327, 329, 330, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 377, 379, 381, 382], "Or": [1, 68, 70, 71, 159, 240, 254, 285, 288, 315], "full": [1, 16, 18, 22, 30, 31, 35, 36, 121, 122, 123, 124, 155, 156, 157, 165, 185, 186, 187, 210, 214, 220, 222, 224, 228, 233, 240, 245, 247, 250, 251, 264, 275, 293, 319, 331], "nightli": [1, 18, 35, 273, 317], "git": [1, 18, 31, 35, 61, 94, 118, 121, 126, 136, 140, 147, 155, 156, 159, 169, 186, 240, 251, 254, 262, 271, 280, 283, 285, 286, 288, 293, 314, 317, 321, 326, 328, 354, 362, 363, 364, 367], "clone": [1, 18, 31, 35, 61, 94, 116, 118, 121, 126, 140, 147, 155, 156, 159, 169, 186, 240, 244, 249, 254, 262, 271, 273, 283, 285, 286, 288, 293, 314, 317, 321, 325, 354, 363, 364, 367, 377, 381], "com": [1, 9, 10, 13, 18, 20, 22, 31, 32, 35, 36, 49, 50, 54, 55, 58, 61, 62, 63, 65, 70, 71, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 118, 122, 126, 130, 136, 140, 147, 151, 155, 156, 159, 169, 186, 199, 201, 202, 209, 240, 250, 251, 254, 262, 269, 271, 272, 273, 279, 283, 285, 286, 288, 293, 297, 314, 317, 319, 320, 321, 326, 328, 332, 354, 357, 358, 360, 361, 362, 363, 364, 365, 367, 368, 370, 374], "cd": [1, 18, 26, 31, 35, 59, 94, 97, 100, 105, 118, 126, 131, 134, 135, 136, 138, 139, 140, 142, 143, 145, 146, 147, 148, 150, 152, 153, 155, 156, 159, 169, 186, 240, 254, 262, 271, 273, 283, 285, 286, 288, 290, 293, 296, 298, 303, 308, 309, 310, 311, 312, 313, 314, 315, 317, 319, 321, 323, 325, 326, 327, 328, 329, 330, 333, 334, 335, 354, 355, 356, 357, 358, 360, 362, 363, 364, 365, 367, 368], "r": [1, 18, 31, 35, 43, 46, 54, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 116, 127, 128, 129, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 165, 167, 168, 194, 200, 225, 228, 238, 250, 251, 254, 259, 264, 266, 269, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 303, 304, 306, 308, 309, 310, 311, 312, 313, 314, 315, 323, 325, 326, 327, 328, 329, 330, 333, 334, 335, 337, 338, 354, 355, 359, 362, 363, 365, 367, 368], "txt": [1, 18, 22, 31, 35, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 102, 104, 116, 117, 118, 127, 128, 129, 131, 132, 134, 135, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 156, 158, 164, 240, 254, 259, 260, 262, 264, 266, 267, 269, 272, 273, 275, 279, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 303, 304, 306, 307, 308, 309, 310, 311, 312, 313, 315, 323, 325, 326, 327, 328, 329, 330, 333, 334, 335, 337, 338, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 367, 368, 388], "test": [1, 11, 18, 20, 35, 54, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 120, 122, 126, 130, 133, 136, 140, 152, 153, 157, 158, 159, 160, 165, 168, 169, 184, 186, 192, 215, 219, 231, 233, 235, 239, 244, 256, 260, 264, 267, 272, 273, 275, 277, 279, 285, 286, 288, 315, 319, 327, 332, 335, 337, 351, 362, 363, 368, 388], "pypi": [1, 9, 18, 35, 186, 379, 382], "org": [1, 9, 10, 18, 35, 60, 93, 114, 115, 118, 130, 131, 134, 135, 139, 142, 143, 145, 148, 152, 153, 154, 157, 159, 161, 191, 219, 220, 240, 247, 250, 263, 271, 272, 293, 302, 317, 320, 321, 323, 327, 329, 334, 335, 354, 355, 362, 364, 367, 368, 379, 382], "simpl": [1, 13, 18, 35, 50, 53, 76, 93, 95, 97, 100, 105, 110, 114, 115, 122, 126, 156, 158, 159, 165, 183, 186, 192, 205, 212, 215, 221, 245, 249, 250, 251, 252, 253, 254, 264, 269, 270, 273, 282, 285, 288, 319], "more": [1, 2, 12, 13, 14, 15, 18, 22, 24, 26, 31, 32, 34, 35, 37, 38, 41, 42, 44, 47, 53, 54, 55, 67, 68, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 120, 122, 123, 126, 130, 133, 147, 155, 156, 158, 159, 160, 165, 167, 168, 169, 182, 186, 187, 199, 200, 202, 203, 204, 206, 207, 210, 212, 215, 217, 219, 224, 227, 228, 232, 233, 236, 238, 244, 246, 248, 249, 250, 251, 252, 254, 256, 258, 261, 264, 269, 271, 272, 273, 275, 277, 279, 280, 281, 282, 283, 292, 295, 297, 300, 301, 305, 319, 328, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 379, 382, 387], "method": [1, 11, 12, 13, 14, 19, 21, 24, 25, 27, 28, 37, 42, 44, 46, 47, 52, 53, 70, 71, 73, 121, 123, 126, 130, 136, 140, 155, 157, 159, 164, 165, 167, 168, 169, 171, 174, 176, 177, 179, 180, 184, 185, 186, 187, 188, 189, 200, 204, 205, 206, 213, 214, 215, 217, 220, 222, 231, 232, 233, 234, 235, 236, 239, 240, 241, 245, 246, 248, 249, 250, 251, 252, 256, 258, 261, 264, 265, 273, 275, 282, 285, 288, 290, 295, 298, 305, 308, 309, 310, 311, 313, 316, 355, 388], "can": [1, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 24, 26, 27, 28, 31, 32, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 47, 50, 51, 52, 53, 56, 59, 65, 66, 67, 68, 70, 71, 72, 73, 76, 93, 95, 116, 120, 121, 122, 123, 124, 125, 130, 140, 145, 146, 147, 148, 152, 153, 156, 157, 158, 159, 160, 162, 164, 165, 167, 168, 169, 171, 176, 179, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254, 255, 256, 258, 260, 261, 262, 263, 264, 265, 267, 269, 270, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 290, 295, 297, 298, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 319, 321, 323, 331, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 372, 373, 374, 377, 378, 379, 381, 382, 383, 387], "found": [1, 16, 38, 53, 56, 68, 121, 122, 124, 125, 126, 130, 155, 156, 159, 160, 165, 170, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 248, 250, 251, 258, 262, 273, 275, 281, 285, 288, 306, 317, 319, 321, 354, 355, 359, 361, 373, 388], "guid": [1, 22, 24, 27, 31, 35, 70, 71, 76, 93, 95, 96, 97, 100, 105, 123, 126, 157, 165, 169, 186, 253, 370], "pleas": [1, 2, 9, 12, 14, 15, 18, 22, 25, 26, 35, 37, 38, 41, 44, 47, 49, 50, 62, 63, 67, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 121, 126, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 153, 155, 156, 157, 159, 167, 169, 184, 186, 203, 217, 240, 249, 250, 251, 255, 261, 263, 264, 269, 271, 273, 276, 277, 280, 282, 285, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 313, 315, 319, 320, 323, 327, 329, 330, 331, 332, 333, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 373], "check": [1, 13, 14, 18, 20, 26, 32, 35, 126, 133, 147, 155, 157, 158, 159, 162, 165, 167, 169, 186, 187, 191, 236, 241, 244, 246, 250, 251, 258, 269, 271, 272, 279, 285, 288, 297, 317, 319, 320, 323, 334, 354, 371, 373, 379, 382, 386, 387], "our": [1, 12, 13, 15, 116, 120, 121, 126, 133, 136, 140, 155, 156, 157, 159, 165, 167, 168, 169, 171, 182, 187, 188, 191, 193, 194, 195, 196, 204, 205, 206, 208, 209, 211, 214, 215, 216, 217, 218, 227, 230, 232, 233, 234, 236, 238, 242, 244, 246, 248, 249, 250, 252, 253, 254, 256, 263, 264, 267, 269, 270, 272, 273, 275, 276, 278, 279, 285, 286, 288, 295, 305, 308, 309, 310, 311, 312, 318, 319, 323, 326, 334, 356, 357, 359, 360, 361, 362], "faq": [1, 10, 20, 154, 277], "A": [1, 12, 13, 21, 29, 31, 37, 39, 44, 45, 52, 53, 126, 130, 133, 136, 140, 145, 146, 154, 155, 157, 158, 159, 160, 162, 164, 165, 167, 168, 171, 178, 184, 185, 186, 187, 188, 190, 194, 200, 205, 216, 217, 220, 223, 229, 230, 233, 235, 240, 241, 242, 244, 245, 246, 250, 251, 252, 253, 267, 272, 273, 275, 278, 285, 288, 319, 328, 357, 358, 377, 378, 381], "exampl": [1, 9, 10, 11, 16, 18, 20, 22, 27, 28, 33, 34, 40, 47, 49, 52, 53, 55, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 123, 130, 136, 137, 142, 143, 144, 145, 152, 154, 155, 156, 157, 158, 159, 160, 161, 164, 165, 166, 167, 168, 169, 171, 176, 179, 182, 183, 186, 187, 194, 195, 197, 198, 200, 206, 207, 209, 211, 212, 213, 215, 220, 225, 228, 230, 233, 238, 239, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 253, 256, 257, 258, 260, 262, 264, 267, 269, 272, 273, 274, 276, 278, 279, 281, 285, 286, 288, 291, 292, 293, 294, 296, 299, 300, 301, 302, 303, 304, 307, 309, 310, 311, 316, 319, 320, 321, 325, 335, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 383, 385], "prepar": [1, 13, 14, 22, 26, 46, 57, 67, 69, 72, 157, 165, 168, 178, 185, 233, 253, 359], "fp32": [1, 15, 27, 31, 37, 38, 46, 47, 48, 49, 50, 51, 53, 54, 56, 66, 67, 68, 70, 71, 116, 117, 118, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 214, 224, 277, 290, 296, 298, 300, 308, 309, 310, 311, 313, 315, 323, 327, 329, 330, 333, 334, 341, 354, 355, 356, 357, 359, 360, 361, 362, 364, 367, 368, 375, 383, 384, 388], "wget": [1, 32, 58, 60, 62, 63, 65, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 165, 272, 273, 283, 293, 297, 298, 299, 323, 334, 335, 354, 355, 357, 358, 360, 362, 363, 365, 367, 368], "storag": [1, 32, 37, 58, 62, 63, 65, 102, 104, 354, 357, 358, 360, 362, 364, 365, 368], "googleapi": [1, 32, 58, 62, 63, 65, 102, 104, 354, 357, 358, 360, 362, 364, 365, 368], "v1_6": [1, 32, 58, 62, 63, 65, 354, 365], "mobilenet_v1_1": [1, 58, 62, 63, 65, 72, 354], "0_224_frozen": [1, 58, 62, 63, 65, 72, 354], "pb": [1, 16, 26, 32, 39, 51, 54, 56, 57, 58, 62, 63, 64, 65, 70, 71, 72, 93, 114, 115, 130, 354, 355, 358, 359, 360, 361, 364, 367, 368, 384, 385, 388], "import": [1, 11, 12, 13, 14, 16, 19, 21, 22, 24, 26, 32, 37, 38, 39, 40, 41, 42, 44, 46, 47, 51, 52, 58, 59, 60, 62, 63, 64, 66, 67, 68, 72, 73, 76, 93, 95, 116, 123, 126, 130, 131, 134, 135, 136, 137, 139, 140, 145, 146, 147, 148, 150, 153, 156, 157, 159, 160, 161, 164, 165, 167, 168, 169, 171, 179, 182, 186, 187, 190, 194, 195, 196, 213, 215, 219, 220, 224, 225, 230, 233, 240, 241, 242, 244, 246, 248, 249, 250, 251, 252, 253, 262, 264, 273, 275, 281, 283, 285, 290, 295, 296, 298, 305, 308, 309, 310, 311, 312, 313, 315, 316, 319, 323, 326, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 370, 372, 374], "tf": [1, 13, 18, 26, 39, 47, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 117, 126, 130, 155, 157, 159, 165, 169, 186, 205, 240, 245, 246, 248, 249, 250, 251, 253, 254, 277, 285, 288, 354, 355, 357, 358, 362, 363, 364, 367], "neural_compressor": [1, 11, 12, 14, 16, 19, 21, 22, 24, 26, 32, 33, 37, 38, 39, 40, 41, 42, 44, 46, 47, 49, 52, 53, 58, 60, 62, 63, 64, 66, 67, 68, 72, 73, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 295, 305, 312, 315, 323, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 384], "experiment": [1, 11, 12, 14, 19, 22, 24, 26, 32, 38, 39, 40, 41, 42, 44, 47, 49, 52, 58, 60, 62, 64, 66, 67, 68, 72, 73, 94, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 168, 186, 222, 225, 226, 237, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 318, 327, 329, 330, 333, 355], "common": [1, 10, 14, 16, 19, 20, 21, 22, 24, 26, 27, 31, 32, 33, 35, 39, 40, 44, 46, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 72, 121, 123, 131, 134, 135, 139, 140, 142, 143, 145, 146, 147, 148, 150, 154, 155, 159, 165, 167, 174, 177, 180, 185, 186, 210, 213, 223, 228, 244, 245, 251, 252, 253, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 314, 315, 319, 320, 327, 329, 330, 333, 354, 356, 359, 360, 361, 362, 367], "dataset": [1, 12, 14, 15, 16, 19, 21, 26, 27, 28, 31, 32, 37, 46, 53, 54, 56, 57, 59, 61, 64, 65, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 127, 128, 129, 132, 140, 151, 155, 156, 157, 159, 162, 168, 184, 186, 190, 191, 205, 212, 213, 215, 216, 218, 222, 223, 224, 226, 230, 231, 232, 233, 237, 241, 244, 247, 248, 250, 251, 253, 254, 256, 258, 260, 262, 263, 264, 265, 267, 268, 270, 272, 274, 275, 276, 277, 281, 283, 285, 288, 290, 295, 296, 297, 305, 308, 309, 310, 311, 313, 339, 340, 342, 343, 346, 347, 350, 351, 383, 385], "dummi": [1, 18, 22, 32, 37, 56, 57, 61, 65, 69, 94, 159, 253, 285, 288, 364, 388], "shape": [1, 18, 22, 32, 52, 65, 121, 126, 158, 159, 165, 242, 248, 285, 288, 296, 309, 311, 388], "1": [1, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 28, 31, 32, 37, 38, 41, 42, 43, 44, 46, 48, 49, 51, 52, 53, 55, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 122, 126, 127, 128, 130, 133, 136, 140, 144, 151, 155, 156, 157, 158, 160, 165, 167, 169, 176, 182, 184, 186, 192, 197, 199, 200, 201, 202, 206, 212, 215, 217, 219, 220, 221, 226, 228, 231, 233, 234, 235, 237, 238, 239, 240, 241, 242, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 258, 261, 264, 269, 271, 272, 273, 274, 275, 277, 279, 281, 286, 291, 292, 295, 297, 299, 301, 304, 305, 316, 318, 320, 321, 325, 328, 371, 383, 384, 385, 388], "224": [1, 19, 21, 22, 26, 32, 52, 53, 58, 60, 62, 63, 65, 72, 76, 93, 95, 117, 130, 131, 134, 135, 136, 138, 139, 140, 145, 146, 147, 354, 355, 370, 383, 388], "calib_dataload": [1, 16, 21, 22, 33, 37, 46, 59, 61, 65, 66, 67, 68, 72, 148, 153, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 356, 359, 360, 361, 362], "dataload": [1, 15, 16, 18, 22, 26, 32, 33, 37, 38, 40, 46, 51, 52, 53, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 72, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 165, 186, 233, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 328, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 383, 385], "fit": [1, 11, 14, 16, 21, 22, 24, 26, 33, 37, 39, 41, 42, 44, 46, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 72, 121, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 155, 159, 165, 186, 250, 253, 256, 285, 286, 288, 290, 296, 298, 309, 311, 313, 315, 327, 329, 330, 333, 354, 356, 357, 359, 360, 361, 362, 367, 368], "search": [1, 34, 37, 45, 51, 53, 130, 155, 156, 169, 186, 197, 248, 251, 252, 285, 370, 378], "jupyt": [1, 159, 254, 285, 288, 317, 377, 378, 381], "lab": [1, 140, 248, 377, 378, 379, 381, 382], "manag": [1, 130, 159, 185, 186, 220, 234, 251, 285, 288, 370, 378], "one": [1, 12, 15, 16, 18, 21, 24, 25, 26, 31, 32, 34, 35, 37, 38, 41, 42, 44, 46, 49, 52, 53, 69, 72, 116, 119, 120, 122, 123, 124, 126, 130, 136, 140, 142, 143, 155, 156, 157, 159, 160, 165, 167, 169, 176, 179, 182, 189, 192, 197, 203, 206, 209, 210, 211, 212, 215, 218, 219, 220, 222, 224, 226, 227, 228, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 256, 258, 262, 264, 269, 272, 273, 274, 275, 276, 277, 281, 284, 285, 288, 290, 293, 295, 305, 308, 310, 328, 354, 356, 357, 359, 360, 361, 362, 368, 370, 373, 374, 377, 378, 381], "click": [1, 18, 34, 45, 51, 155, 156, 158, 159, 285, 288, 370, 378], "12": [1, 9, 18, 31, 48, 67, 74, 75, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 102, 104, 106, 107, 108, 109, 111, 112, 136, 140, 147, 152, 153, 156, 159, 164, 211, 224, 238, 247, 249, 252, 258, 264, 269, 273, 277, 285, 288, 292, 294, 297, 305, 335, 367, 388], "0": [1, 11, 13, 14, 15, 16, 18, 19, 21, 22, 24, 26, 28, 31, 36, 37, 38, 41, 43, 44, 46, 48, 50, 51, 52, 53, 55, 56, 57, 59, 64, 67, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 122, 124, 126, 127, 128, 129, 130, 131, 133, 134, 135, 138, 139, 140, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 164, 167, 168, 169, 182, 184, 186, 187, 192, 193, 194, 197, 199, 201, 202, 215, 217, 218, 219, 220, 221, 224, 225, 228, 233, 234, 235, 240, 241, 242, 244, 245, 246, 248, 249, 250, 251, 253, 254, 257, 260, 261, 262, 264, 269, 271, 272, 273, 274, 275, 276, 281, 283, 285, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 301, 304, 305, 308, 309, 310, 311, 313, 314, 315, 316, 317, 318, 320, 324, 325, 327, 328, 329, 330, 333, 336, 341, 355, 356, 357, 359, 360, 361, 362, 366, 367, 368, 371, 377, 381, 383, 388], "onnxruntim": [1, 15, 28, 34, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 168], "raw": [1, 37, 53, 68, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 119, 120, 122, 123, 124, 126, 131, 134, 135, 136, 139, 142, 143, 145, 146, 147, 148, 150, 165, 200, 235, 244, 252, 254, 256, 267, 281, 290, 321, 329, 330, 333, 335, 354, 355, 357, 363], "main": [1, 13, 26, 46, 67, 68, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 101, 102, 104, 106, 107, 108, 109, 110, 111, 112, 113, 127, 128, 129, 131, 134, 135, 142, 143, 144, 145, 146, 147, 148, 150, 156, 159, 169, 176, 179, 185, 187, 209, 241, 246, 251, 252, 263, 279, 285, 288, 315, 316, 319, 323, 326, 337, 338, 351, 355, 360, 372, 374], "vision": [1, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 106, 107, 108, 109, 110, 111, 112, 113, 133, 140, 157, 168, 210, 218, 231, 250, 314, 317, 337, 372], "classif": [1, 24, 37, 45, 56, 66, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 131, 133, 134, 135, 139, 145, 146, 147, 148, 150, 153, 157, 158, 159, 162, 167, 168, 187, 190, 194, 206, 208, 210, 211, 215, 218, 231, 232, 233, 235, 236, 241, 242, 247, 248, 253, 254, 281, 282, 285, 288, 296, 308, 309, 310, 311, 312, 314, 315, 337, 374], "resnet": [1, 26, 32, 54, 56, 66, 135, 136, 139, 145, 241, 328, 339, 352, 355, 362, 364], "resnet50": [1, 13, 26, 31, 32, 46, 50, 54, 56, 68, 83, 88, 93, 140, 141, 142, 143, 144, 149, 151, 314, 344, 345, 362, 364, 370, 372], "v1": [1, 9, 16, 26, 37, 39, 49, 50, 54, 56, 59, 66, 68, 72, 85, 88, 94, 101, 116, 130, 184, 192, 213, 221, 244, 247, 256, 264, 267, 269, 288, 290, 291, 292, 293, 297, 299, 301, 336, 357, 358, 362, 364], "inc_bench": [1, 18], "xeon": [1, 31, 32, 36, 38, 43, 45, 46, 47, 48, 54, 69, 70, 71], "scalabl": [1, 31, 32, 38, 43, 45, 46, 47, 48, 54, 70, 71, 210, 240, 280], "skylak": [1, 31], "cascad": [1, 31, 32, 121, 136], "lake": [1, 31, 32, 38, 45], "cooper": [1, 31, 38, 162, 308], "icelak": [1, 31], "futur": [1, 31, 34, 38, 40, 122, 126, 155, 156, 157, 159, 167, 168, 169, 226, 232, 233, 237, 240, 241, 264, 273, 275, 277, 281, 285, 288], "code": [1, 11, 15, 16, 21, 22, 24, 26, 27, 31, 33, 34, 36, 37, 41, 42, 44, 45, 46, 50, 51, 52, 53, 58, 64, 69, 72, 73, 116, 117, 118, 121, 126, 130, 136, 142, 143, 155, 156, 157, 159, 160, 165, 168, 169, 170, 171, 172, 173, 174, 175, 176, 183, 186, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 245, 246, 249, 250, 251, 253, 254, 258, 262, 263, 264, 265, 267, 269, 271, 273, 277, 283, 285, 286, 288, 314, 319, 320, 322, 328, 337, 338, 351, 370, 372, 373, 374, 378, 386], "name": [1, 9, 11, 13, 15, 18, 19, 22, 26, 28, 31, 32, 36, 37, 39, 43, 49, 50, 51, 53, 54, 61, 63, 66, 67, 68, 72, 73, 76, 93, 95, 119, 120, 121, 122, 126, 127, 128, 129, 130, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 155, 156, 157, 158, 159, 160, 165, 168, 183, 186, 187, 189, 194, 198, 206, 213, 222, 225, 226, 233, 237, 240, 241, 246, 248, 249, 253, 254, 264, 270, 272, 275, 276, 277, 279, 283, 286, 287, 288, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 317, 321, 327, 328, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 364, 365, 367, 368, 371, 377, 381, 387, 388], "sapphir": [1, 31], "rapid": [1, 31], "data": [1, 13, 15, 18, 21, 22, 26, 27, 28, 31, 32, 35, 37, 38, 46, 47, 50, 51, 52, 53, 56, 66, 67, 69, 73, 74, 75, 79, 94, 96, 97, 99, 100, 105, 118, 120, 121, 122, 123, 124, 136, 139, 140, 144, 156, 157, 159, 160, 165, 167, 168, 171, 182, 184, 186, 195, 196, 198, 200, 201, 202, 203, 206, 209, 210, 211, 212, 214, 217, 224, 228, 230, 232, 233, 235, 236, 238, 240, 242, 244, 245, 247, 248, 249, 250, 251, 252, 253, 258, 267, 269, 272, 275, 276, 277, 282, 284, 285, 288, 290, 292, 293, 298, 299, 300, 301, 303, 308, 310, 319, 321, 324, 325, 327, 328, 329, 330, 333, 354, 355, 356, 357, 358, 360, 361, 364, 365, 366, 384, 388], "center": [1, 2, 52, 53, 140, 214], "flex": 1, "seri": [1, 52, 66, 131, 135, 139, 145, 146, 147, 148, 150, 153, 154, 213, 218, 354], "amd": [1, 34, 54], "arm": [1, 34, 54, 214], "nvidia": [1, 34, 44, 46, 54, 117, 126, 133, 186, 273, 277, 293, 314, 317, 318], "refer": [1, 4, 9, 14, 15, 16, 19, 22, 25, 26, 31, 33, 36, 37, 38, 41, 44, 46, 49, 52, 53, 69, 70, 71, 72, 76, 93, 95, 96, 97, 100, 102, 104, 105, 110, 114, 115, 116, 117, 120, 121, 124, 126, 131, 132, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 153, 155, 156, 157, 169, 186, 197, 198, 200, 203, 217, 230, 238, 241, 247, 250, 252, 254, 258, 262, 264, 267, 273, 277, 283, 284, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 313, 315, 319, 320, 326, 327, 329, 330, 333, 359, 363, 365, 367, 370, 373], "list": [1, 13, 15, 17, 31, 41, 47, 51, 53, 66, 67, 117, 120, 126, 130, 136, 137, 139, 140, 152, 153, 156, 157, 158, 159, 160, 165, 167, 170, 171, 172, 173, 174, 175, 176, 184, 186, 187, 217, 219, 228, 233, 245, 246, 247, 248, 250, 254, 255, 261, 264, 269, 272, 275, 282, 283, 285, 288, 290, 291, 292, 294, 295, 296, 298, 299, 300, 301, 302, 304, 305, 308, 309, 310, 311, 312, 313, 316, 319, 320, 323, 326, 329, 330, 333, 334, 337, 338, 341, 345, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 370, 373, 377, 378, 381], "o": [1, 13, 20, 31, 43, 70, 71, 122, 126, 138, 145, 146, 155, 165, 186, 217, 219, 220, 221, 228, 250, 251, 276, 283, 297, 315, 316, 334, 354], "cento": [1, 31], "4": [1, 10, 13, 15, 19, 20, 21, 30, 31, 34, 35, 37, 43, 44, 48, 52, 53, 54, 55, 67, 94, 116, 117, 118, 119, 120, 124, 126, 129, 130, 131, 133, 134, 135, 137, 139, 140, 147, 155, 156, 160, 176, 186, 192, 199, 201, 202, 206, 209, 211, 214, 221, 231, 233, 235, 236, 241, 247, 248, 249, 250, 252, 258, 261, 262, 264, 269, 272, 273, 275, 276, 277, 285, 288, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 305, 313, 317, 318, 320, 328, 332, 383, 384, 388], "ubuntu": [1, 43, 69, 123, 126, 138, 186], "20": [1, 14, 31, 43, 48, 52, 54, 58, 60, 65, 72, 124, 130, 140, 179, 205, 239, 247, 252, 256, 264, 268, 274, 277, 293, 299, 300, 316, 318, 319, 356, 388], "04": [1, 31, 43, 54, 116, 120, 130, 136, 140, 248, 271, 277, 364, 388], "2": [1, 9, 13, 14, 15, 17, 22, 24, 26, 31, 32, 34, 36, 37, 38, 41, 42, 43, 44, 46, 48, 49, 52, 53, 55, 56, 57, 70, 71, 99, 103, 117, 118, 119, 120, 126, 127, 128, 129, 130, 133, 140, 144, 156, 157, 160, 161, 162, 167, 168, 169, 171, 182, 186, 192, 193, 194, 195, 196, 197, 201, 202, 203, 211, 212, 214, 215, 217, 218, 219, 221, 224, 225, 228, 230, 233, 235, 238, 239, 242, 245, 247, 248, 249, 250, 251, 252, 257, 258, 261, 263, 264, 267, 269, 271, 273, 274, 275, 278, 279, 281, 286, 291, 292, 294, 295, 297, 303, 316, 318, 319, 320, 328, 370, 384, 388], "11": [1, 18, 32, 37, 38, 48, 74, 75, 76, 77, 79, 82, 93, 95, 101, 104, 111, 114, 115, 126, 130, 136, 140, 159, 160, 186, 238, 273, 277, 285, 288, 293, 297, 315, 318, 333], "6": [1, 13, 15, 18, 31, 46, 54, 55, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 126, 130, 133, 139, 140, 152, 153, 157, 159, 160, 169, 190, 192, 201, 202, 219, 221, 246, 247, 250, 251, 254, 258, 261, 264, 269, 272, 273, 274, 277, 281, 285, 288, 290, 291, 292, 293, 294, 296, 298, 299, 301, 302, 304, 305, 308, 309, 310, 311, 313, 318, 320, 329, 334, 364, 367, 383], "note": [1, 9, 12, 13, 16, 18, 19, 26, 27, 28, 31, 32, 44, 46, 48, 51, 53, 54, 55, 58, 60, 62, 63, 66, 67, 68, 70, 71, 72, 103, 116, 117, 118, 120, 122, 124, 126, 130, 131, 134, 135, 136, 139, 140, 142, 143, 145, 147, 148, 153, 155, 158, 159, 165, 167, 168, 184, 196, 211, 215, 217, 228, 233, 241, 244, 246, 248, 249, 250, 251, 252, 253, 256, 258, 264, 269, 273, 274, 275, 276, 279, 285, 288, 290, 292, 296, 297, 298, 301, 308, 309, 310, 311, 313, 317, 320, 323, 325, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 360, 361, 362, 363, 364, 365, 366, 367, 368, 373, 377, 381, 383], "set": [1, 9, 10, 12, 13, 14, 16, 18, 19, 20, 21, 22, 26, 32, 33, 34, 37, 38, 46, 50, 53, 55, 58, 60, 64, 65, 66, 67, 68, 70, 71, 72, 122, 124, 126, 130, 131, 133, 134, 135, 137, 139, 145, 146, 147, 148, 150, 154, 155, 156, 159, 160, 162, 165, 167, 169, 179, 184, 186, 187, 191, 203, 205, 213, 216, 217, 219, 220, 222, 227, 228, 231, 233, 234, 235, 239, 241, 244, 246, 248, 249, 250, 251, 252, 253, 254, 261, 262, 264, 269, 272, 273, 274, 275, 277, 279, 281, 285, 288, 290, 292, 295, 296, 297, 298, 301, 305, 306, 308, 309, 310, 311, 313, 314, 315, 316, 319, 324, 325, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 370, 372], "variabl": [1, 18, 55, 76, 93, 95, 121, 126, 140, 155, 160, 169, 179, 186, 249, 254, 273, 277, 279, 327], "tf_enable_onednn_opt": [1, 18], "enabl": [1, 13, 18, 26, 27, 32, 38, 43, 44, 45, 47, 55, 56, 57, 58, 60, 64, 72, 126, 130, 145, 149, 157, 186, 187, 191, 203, 216, 234, 239, 249, 251, 252, 254, 269, 272, 295, 303, 305, 336, 339, 340, 342, 343, 344, 346, 347, 348, 349, 350, 370, 373, 374], "onednn": [1, 17, 55], "you": [1, 11, 14, 15, 16, 18, 19, 20, 21, 22, 26, 27, 31, 35, 36, 37, 49, 50, 51, 53, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 98, 102, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 133, 136, 138, 140, 145, 146, 152, 153, 156, 157, 158, 159, 161, 164, 165, 168, 170, 171, 172, 173, 174, 175, 176, 179, 182, 184, 186, 187, 189, 190, 195, 202, 204, 209, 211, 215, 217, 219, 220, 222, 224, 226, 228, 230, 232, 233, 237, 240, 241, 242, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 258, 259, 261, 262, 263, 264, 265, 267, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 286, 290, 293, 295, 297, 298, 303, 305, 306, 308, 309, 310, 311, 315, 317, 319, 320, 323, 325, 331, 332, 337, 338, 351, 354, 355, 356, 357, 358, 362, 367, 368, 370, 371, 373, 377, 381, 383, 387], "ar": [1, 3, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 31, 33, 34, 36, 37, 38, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 62, 63, 66, 70, 71, 72, 73, 117, 118, 120, 121, 122, 123, 124, 125, 126, 130, 131, 134, 135, 136, 139, 140, 142, 143, 145, 146, 147, 148, 150, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 168, 170, 171, 172, 173, 174, 175, 176, 179, 180, 182, 183, 184, 185, 186, 189, 190, 191, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 221, 224, 225, 227, 228, 231, 232, 233, 234, 235, 236, 238, 239, 240, 241, 242, 244, 245, 246, 248, 249, 250, 252, 253, 254, 256, 259, 263, 264, 269, 270, 271, 272, 273, 274, 275, 276, 277, 279, 280, 281, 282, 285, 286, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 322, 323, 324, 325, 326, 328, 334, 336, 354, 355, 359, 361, 362, 365, 366, 367, 368, 370, 371, 373, 378], "us": [1, 10, 11, 12, 13, 14, 15, 16, 18, 20, 22, 24, 25, 26, 27, 28, 31, 33, 35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 158, 160, 161, 162, 164, 167, 169, 170, 171, 172, 173, 174, 175, 176, 179, 181, 182, 183, 184, 185, 186, 188, 189, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 244, 245, 247, 250, 251, 252, 253, 254, 256, 258, 259, 260, 261, 262, 263, 265, 267, 269, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 282, 284, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 306, 307, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 320, 322, 323, 324, 325, 327, 328, 329, 330, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 370, 372, 373, 377, 379, 381, 382, 383, 386, 387, 388], "v2": [1, 13, 26, 54, 56, 89, 99, 130, 133, 145, 146, 157, 165, 168, 184, 192, 201, 221, 240, 247, 249, 261, 274, 293, 336, 339, 342, 352, 355, 362, 364, 374], "default": [1, 15, 18, 19, 21, 22, 28, 34, 37, 40, 41, 47, 50, 52, 53, 56, 57, 58, 60, 63, 66, 67, 68, 72, 79, 116, 121, 123, 124, 126, 130, 131, 134, 135, 139, 140, 145, 146, 147, 148, 150, 153, 155, 158, 159, 160, 169, 176, 179, 186, 195, 211, 224, 232, 233, 234, 246, 248, 249, 250, 251, 253, 254, 258, 263, 264, 272, 273, 275, 276, 285, 288, 290, 293, 296, 298, 308, 309, 310, 311, 313, 315, 317, 319, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 373, 377, 381], "420": [1, 34, 130], "perform": [1, 12, 14, 15, 16, 18, 19, 21, 23, 25, 27, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 54, 56, 57, 62, 63, 64, 70, 71, 117, 118, 126, 131, 134, 135, 136, 139, 145, 146, 147, 148, 150, 151, 157, 167, 168, 169, 184, 186, 188, 190, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 206, 210, 211, 213, 214, 219, 220, 223, 224, 227, 228, 230, 233, 234, 238, 239, 241, 245, 249, 250, 251, 252, 258, 261, 264, 269, 272, 273, 275, 292, 301, 316, 321, 324, 325, 327, 328, 336, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 357, 359, 361, 367, 370, 374, 378, 384, 386], "speedup": [1, 34, 46, 214, 231, 254, 269, 272, 273, 275, 277, 292, 301], "geomean": [1, 34], "2x": [1, 34, 43, 133, 165, 254, 277, 319], "up": [1, 13, 16, 18, 26, 31, 32, 34, 45, 46, 50, 52, 56, 70, 71, 121, 155, 156, 159, 162, 165, 167, 185, 186, 190, 212, 214, 216, 232, 233, 234, 241, 244, 249, 250, 251, 252, 253, 261, 264, 277, 281, 285, 288, 308, 309, 311, 312, 319, 324, 379, 382], "vnni": [1, 34, 46, 69, 70, 71], "while": [1, 14, 15, 18, 21, 32, 34, 38, 46, 56, 121, 126, 156, 157, 159, 161, 165, 167, 169, 186, 187, 188, 191, 193, 195, 196, 199, 200, 204, 206, 211, 214, 215, 218, 220, 221, 228, 231, 233, 235, 241, 244, 249, 251, 252, 256, 258, 264, 269, 272, 273, 274, 275, 285, 288, 319, 320, 355, 370, 373, 386], "minim": [1, 24, 37, 44, 46, 53, 121, 130, 156, 186, 211, 251, 269, 273, 274, 328, 362, 377, 381], "loss": [1, 13, 14, 24, 25, 26, 28, 31, 37, 38, 44, 46, 53, 66, 67, 68, 70, 71, 121, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 158, 165, 167, 168, 171, 182, 186, 187, 188, 193, 204, 217, 220, 228, 232, 233, 241, 244, 248, 252, 253, 254, 256, 264, 269, 271, 290, 295, 296, 298, 305, 306, 308, 309, 310, 311, 313, 315, 327, 328, 329, 330, 333, 351, 354, 355, 356, 362, 363, 367], "over": [1, 13, 14, 34, 37, 53, 70, 71, 126, 130, 140, 157, 159, 167, 168, 186, 191, 200, 203, 204, 206, 220, 222, 228, 233, 235, 238, 239, 241, 242, 244, 247, 250, 251, 252, 256, 264, 273, 275, 285, 288, 314, 316, 319, 388], "30": [1, 14, 19, 21, 31, 34, 48, 52, 54, 131, 135, 136, 137, 140, 144, 145, 146, 147, 150, 155, 168, 179, 195, 196, 215, 245, 247, 250, 262, 271, 273, 281, 306, 319, 364, 388], "sampl": [1, 12, 16, 21, 22, 27, 34, 46, 52, 53, 54, 56, 58, 59, 60, 72, 116, 121, 126, 131, 134, 135, 139, 145, 146, 147, 153, 156, 159, 171, 206, 209, 224, 241, 250, 252, 256, 263, 271, 272, 281, 285, 288, 296, 309, 311, 315, 323, 328, 354, 355, 362, 365, 367, 388], "avail": [1, 3, 4, 10, 18, 31, 34, 43, 50, 53, 56, 57, 124, 126, 136, 154, 155, 158, 159, 160, 164, 165, 167, 168, 183, 184, 185, 186, 187, 191, 193, 195, 196, 198, 201, 202, 206, 208, 210, 212, 213, 215, 219, 231, 232, 233, 236, 238, 241, 242, 244, 247, 250, 251, 253, 254, 256, 258, 262, 264, 272, 273, 275, 278, 281, 282, 285, 288, 289, 318, 319, 377, 381], "here": [1, 9, 11, 13, 14, 15, 16, 18, 22, 26, 31, 37, 41, 44, 46, 49, 50, 53, 56, 66, 67, 68, 116, 119, 120, 121, 122, 123, 124, 126, 130, 131, 134, 135, 136, 139, 140, 145, 146, 147, 148, 150, 153, 155, 156, 157, 158, 159, 160, 164, 165, 167, 169, 171, 176, 179, 182, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 258, 260, 264, 270, 272, 273, 274, 275, 276, 277, 279, 281, 282, 285, 286, 287, 288, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 316, 318, 319, 320, 321, 327, 329, 330, 332, 333, 354, 355, 356, 357, 360, 361, 362, 366, 367, 368, 373, 379, 382], "overview": [1, 158, 165, 168], "transform": [1, 11, 16, 19, 21, 22, 24, 25, 26, 27, 44, 45, 47, 51, 53, 56, 58, 60, 62, 63, 72, 97, 100, 103, 105, 131, 134, 135, 139, 140, 145, 146, 147, 156, 158, 161, 162, 165, 167, 170, 171, 179, 182, 186, 190, 192, 193, 194, 195, 198, 200, 202, 203, 204, 206, 208, 209, 211, 212, 213, 214, 216, 217, 218, 219, 220, 221, 223, 224, 225, 228, 231, 232, 233, 236, 238, 239, 240, 242, 245, 246, 247, 248, 250, 252, 253, 254, 258, 259, 262, 264, 265, 269, 271, 273, 275, 276, 278, 281, 283, 286, 296, 297, 300, 309, 310, 311, 312, 316, 319, 337, 354, 355, 357, 361, 367, 368, 370, 373, 374, 383], "metric": [1, 12, 15, 16, 18, 19, 21, 26, 27, 32, 38, 50, 51, 53, 54, 56, 57, 58, 60, 62, 63, 66, 67, 68, 72, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 186, 244, 253, 254, 264, 272, 273, 277, 290, 296, 298, 300, 308, 309, 310, 311, 313, 315, 327, 328, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 388], "object": [1, 3, 11, 12, 13, 15, 16, 18, 19, 21, 22, 27, 30, 37, 38, 39, 42, 46, 52, 53, 56, 59, 72, 76, 83, 93, 95, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 133, 156, 158, 159, 160, 165, 167, 171, 176, 181, 182, 183, 186, 187, 190, 192, 200, 203, 208, 210, 211, 212, 213, 218, 220, 221, 226, 230, 231, 232, 233, 236, 237, 241, 246, 248, 250, 251, 253, 256, 281, 285, 288, 295, 305, 314, 315, 316, 319, 327, 329, 330, 333, 356, 357, 359, 360, 361, 362, 364, 388], "dive": [1, 31, 157, 159, 244, 285, 288], "mix": [1, 15, 27, 34, 126, 199, 241, 248, 250, 253, 273, 370, 374, 375], "orchestr": [1, 34], "benchmark": [1, 3, 21, 27, 32, 39, 40, 53, 54, 56, 57, 62, 63, 64, 69, 121, 126, 131, 134, 135, 139, 147, 152, 153, 168, 184, 188, 191, 193, 197, 202, 204, 205, 206, 211, 213, 221, 223, 226, 232, 237, 238, 241, 249, 264, 269, 277, 282, 297, 303, 317, 320, 321, 325, 335, 341, 351, 354, 365, 366, 370, 372, 378], "distribut": [1, 13, 24, 31, 35, 46, 49, 53, 126, 136, 156, 168, 186, 248, 250, 264, 272, 273, 274, 275, 292, 301, 315, 319, 337, 338, 351, 379, 382], "train": [1, 12, 13, 15, 16, 17, 22, 24, 25, 27, 32, 34, 38, 40, 42, 44, 45, 53, 54, 56, 57, 64, 70, 71, 76, 93, 95, 116, 117, 118, 120, 121, 122, 123, 127, 128, 129, 130, 131, 132, 134, 135, 139, 140, 142, 143, 144, 145, 146, 147, 150, 152, 153, 155, 156, 157, 159, 160, 161, 162, 164, 165, 167, 168, 169, 176, 186, 187, 188, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 212, 213, 215, 218, 219, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 245, 247, 248, 249, 250, 252, 257, 260, 262, 263, 265, 267, 269, 272, 274, 275, 279, 282, 284, 285, 288, 291, 292, 293, 294, 295, 299, 300, 301, 304, 305, 321, 322, 324, 338, 341, 356, 361, 362, 363, 365, 370, 374, 388], "convers": [1, 15, 27, 38, 46, 47, 103, 122, 157, 158, 159, 162, 164, 168, 178, 184, 187, 195, 196, 203, 206, 233, 247, 249, 283, 285, 288, 341], "tensorboard": [1, 15, 27, 53, 127, 128, 129, 145, 146, 176, 186, 253, 254], "coder": [1, 34, 45, 373, 378], "advanc": [1, 10, 20, 21, 31, 46, 53, 58, 60, 131, 133, 134, 135, 139, 154, 158, 185, 252, 254, 263, 345, 354, 355, 362, 367], "topic": [1, 271], "adaptor": [1, 27, 34, 47, 49, 51, 53, 355, 360], "fast": [1, 45, 126, 130, 137, 165, 168, 185, 186, 204, 213, 219, 241, 245, 251, 258, 261, 264, 279, 318, 319, 328], "approach": [1, 11, 12, 15, 24, 28, 34, 45, 53, 56, 73, 148, 150, 156, 157, 160, 168, 169, 186, 195, 196, 206, 208, 211, 214, 220, 221, 230, 232, 233, 236, 239, 241, 244, 250, 251, 264, 269, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315], "achiev": [1, 16, 27, 37, 42, 44, 45, 46, 51, 53, 126, 159, 186, 190, 199, 201, 202, 208, 211, 214, 215, 216, 217, 218, 221, 222, 224, 226, 227, 228, 230, 231, 232, 233, 234, 235, 237, 238, 239, 241, 251, 269, 273, 285, 288, 328], "signific": [1, 13, 45, 46, 185, 191, 193, 230, 231, 238, 251, 269, 275], "speed": [1, 13, 31, 32, 45, 46, 56, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 133, 136, 156, 160, 162, 185, 186, 188, 216, 241, 249, 251, 261, 275], "sota": [1, 45, 224, 233], "nov": [1, 45], "2022": [1, 54, 70, 71, 388], "person": [1, 10, 20, 45, 154, 156, 159, 195, 196, 233, 248, 250, 277, 285, 288, 318], "diffus": [1, 45, 94, 116], "few": [1, 18, 45, 53, 126, 155, 156, 157, 159, 161, 168, 169, 180, 186, 187, 217, 219, 234, 239, 241, 242, 244, 245, 250, 251, 253, 264, 269, 270, 277, 283, 285, 288, 316, 320], "shot": [1, 12, 34, 44, 45, 56, 264, 295, 305, 319], "fine": [1, 14, 22, 44, 45, 46, 97, 100, 105, 116, 126, 140, 156, 157, 159, 162, 168, 169, 181, 187, 190, 191, 192, 193, 197, 203, 204, 207, 208, 209, 211, 215, 216, 218, 219, 221, 222, 224, 227, 232, 235, 240, 241, 245, 246, 247, 248, 249, 250, 251, 254, 256, 261, 263, 264, 267, 272, 273, 275, 276, 279, 281, 282, 285, 288, 290, 291, 292, 294, 297, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 320, 371], "meet": [1, 9, 11, 32, 41, 45, 46, 51, 53, 66, 67, 68, 131, 134, 135, 139, 145, 146, 147, 263, 286, 290, 296, 298, 308, 309, 310, 311, 313, 315, 329, 330, 333, 354, 355, 362, 367], "innov": [1, 45], "oct": [1, 45, 157, 190, 191], "infer": [1, 13, 14, 15, 16, 17, 21, 24, 27, 32, 38, 41, 44, 45, 46, 51, 53, 56, 59, 66, 68, 69, 70, 71, 93, 118, 136, 157, 159, 160, 168, 183, 186, 192, 198, 204, 208, 214, 215, 221, 225, 228, 239, 241, 242, 245, 248, 250, 253, 255, 260, 262, 263, 272, 275, 282, 284, 285, 288, 315, 318, 323, 324, 326, 333, 334, 354, 359, 360, 361, 362, 367], "acceler": [1, 24, 44, 45, 47, 53, 56, 69, 70, 71, 126, 221, 249, 263, 337, 338, 351, 370], "new": [1, 16, 19, 20, 26, 27, 38, 45, 46, 49, 50, 52, 58, 60, 62, 63, 66, 70, 71, 116, 121, 123, 131, 134, 135, 136, 139, 140, 156, 157, 159, 160, 161, 162, 165, 167, 169, 180, 185, 186, 187, 188, 190, 191, 192, 193, 199, 201, 202, 205, 206, 208, 209, 213, 215, 216, 217, 219, 223, 226, 232, 233, 236, 237, 240, 241, 245, 247, 248, 250, 251, 252, 254, 267, 273, 275, 285, 286, 288, 319, 328, 354, 355, 362, 367, 378, 387, 388], "plug": [1, 45, 126, 261], "wa": [1, 15, 18, 45, 53, 121, 123, 126, 140, 154, 156, 157, 159, 165, 184, 186, 187, 188, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 245, 246, 248, 249, 250, 251, 252, 256, 258, 260, 273, 277, 281, 285, 287, 288, 359, 365, 387], "cover": [1, 12, 16, 20, 33, 45, 72, 121, 126, 130, 223, 232, 247, 248, 251, 279], "twitter": [1, 45, 155, 162, 165], "linkedin": [1, 45], "develop": [1, 11, 16, 20, 35, 38, 45, 46, 47, 50, 55, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 121, 123, 126, 130, 134, 135, 139, 153, 156, 157, 159, 161, 162, 168, 186, 193, 203, 210, 214, 228, 249, 251, 277, 282, 285, 288, 295, 305, 317, 329, 369, 370, 374], "zone": [1, 45, 120, 122], "hug": [1, 45, 116, 156, 157, 159, 162, 165, 169, 190, 203, 211, 212, 245, 249, 250, 252, 280, 281, 285, 288, 359], "face": [1, 10, 20, 45, 49, 56, 57, 63, 79, 116, 156, 157, 159, 162, 165, 169, 190, 203, 211, 212, 245, 249, 250, 280, 281, 285, 288, 320, 359, 370, 372], "successfulli": [1, 11, 26, 45, 70, 71, 159, 215, 251, 254, 285, 288, 306, 356], "land": [1, 45], "gcp": [1, 45], "aw": [1, 45, 54, 177, 180, 185], "azur": [1, 45], "marketplac": [1, 45], "One": [1, 16, 18, 21, 26, 34, 44, 45, 56, 155, 160, 161, 165, 186, 234, 241, 248, 251, 252, 269, 279], "No": [1, 30, 43, 45, 69, 122, 134, 135, 139, 148, 153, 154, 155, 156, 158, 159, 190, 220, 254, 285, 288, 329], "solut": [1, 15, 16, 30, 45, 53, 186, 214, 220, 252, 319, 320, 374, 378], "pat": [1, 45, 388], "keynot": [1, 45], "intelon": [1, 45], "sep": [1, 45, 165, 167, 193, 204, 222, 233, 246, 249, 250, 275, 281], "alibaba": [1, 45, 375, 381, 382], "cloud": [1, 45, 69, 70, 71, 187, 276, 281, 354], "better": [1, 14, 16, 25, 37, 38, 44, 45, 46, 50, 53, 69, 72, 125, 126, 130, 156, 159, 161, 188, 194, 197, 201, 202, 221, 222, 228, 231, 233, 234, 239, 241, 244, 248, 252, 258, 264, 273, 285, 288, 310, 318, 325, 328], "product": [1, 16, 27, 34, 38, 43, 45, 46, 50, 53, 157, 159, 168, 169, 228, 241, 245, 264, 273, 285, 288, 370, 387], "effici": [1, 12, 21, 24, 42, 45, 130, 133, 151, 157, 159, 167, 168, 192, 199, 201, 202, 205, 206, 208, 210, 214, 221, 228, 231, 233, 236, 241, 246, 249, 275, 282, 285, 288, 300, 319, 370], "text": [1, 36, 45, 52, 54, 56, 101, 102, 123, 145, 146, 156, 157, 158, 159, 162, 165, 167, 168, 180, 184, 190, 192, 193, 194, 198, 200, 203, 206, 207, 208, 210, 211, 212, 215, 218, 220, 221, 222, 223, 225, 228, 229, 231, 232, 233, 234, 239, 241, 242, 244, 246, 247, 248, 249, 252, 254, 256, 264, 267, 272, 275, 276, 278, 279, 281, 282, 285, 286, 288, 296, 308, 309, 310, 311, 312, 329, 330, 331, 333, 374], "view": [1, 13, 16, 18, 20, 29, 31, 49, 55, 242, 253, 326], "contribut": [1, 10, 126, 154, 157, 159, 163, 169, 218, 241, 285, 286, 288, 369], "guidelin": [1, 2, 155, 156, 157, 369], "legal": [1, 369], "secur": [1, 43, 45, 154, 250, 332], "polici": [1, 10, 20, 32, 43], "we": [1, 10, 11, 13, 14, 15, 16, 20, 21, 26, 31, 32, 37, 40, 41, 42, 44, 46, 50, 51, 53, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 94, 102, 104, 116, 120, 121, 122, 123, 126, 131, 134, 135, 136, 139, 145, 146, 147, 148, 150, 153, 154, 155, 156, 157, 158, 159, 161, 165, 167, 168, 169, 171, 182, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 221, 222, 223, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 248, 249, 250, 251, 252, 253, 254, 256, 258, 261, 262, 263, 264, 267, 269, 272, 273, 275, 277, 279, 280, 282, 284, 285, 288, 290, 292, 293, 295, 296, 297, 298, 300, 301, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 326, 327, 328, 329, 330, 331, 332, 333, 334, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 372, 379, 382], "activ": [1, 13, 14, 15, 17, 18, 25, 27, 28, 31, 43, 46, 51, 53, 58, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 126, 130, 157, 159, 169, 186, 187, 228, 241, 248, 251, 254, 266, 269, 285, 288, 296, 317, 332, 354, 355, 356, 357, 362], "send": [1, 20, 126, 155, 156, 246, 248, 272, 276], "your": [1, 15, 18, 19, 20, 22, 26, 36, 50, 51, 53, 57, 116, 120, 121, 122, 123, 124, 126, 133, 138, 140, 151, 155, 156, 157, 158, 162, 164, 165, 168, 169, 179, 186, 204, 217, 222, 230, 233, 236, 242, 245, 246, 248, 249, 250, 251, 253, 254, 255, 256, 258, 259, 261, 262, 265, 267, 270, 274, 276, 277, 279, 280, 282, 283, 284, 286, 293, 295, 305, 314, 315, 317, 320, 321, 323, 325, 328, 329, 330, 332, 333, 334, 354, 355, 356, 357, 358, 367, 368, 370, 371, 372, 373, 377, 378, 379, 381, 382], "resum": [1, 138, 292, 301], "inc": [1, 14, 45, 49, 56, 70, 71, 116, 133, 250, 295, 305, 306, 310, 370, 375, 386], "maintain": [1, 10, 20, 39, 44, 49, 56, 155, 156, 157, 159, 195, 196, 210, 254, 259, 285, 288, 332, 370, 379, 382], "interest": [1, 10, 20, 51, 159, 206, 233, 249, 250, 253, 264, 275, 281, 282], "issu": [2, 10, 18, 20, 35, 46, 51, 121, 126, 130, 140, 154, 157, 159, 169, 186, 187, 190, 195, 198, 209, 213, 217, 219, 220, 224, 226, 227, 228, 232, 233, 237, 249, 251, 276, 280, 285, 288, 319, 320], "intel": [2, 3, 10, 12, 15, 16, 20, 23, 24, 25, 27, 29, 31, 32, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 56, 57, 58, 59, 62, 63, 65, 99, 142, 143, 145, 146, 148, 150, 152, 292, 293, 294, 297, 301, 304, 312, 315, 323, 326, 327, 334, 335, 337, 351, 370, 373, 375], "For": [2, 9, 10, 11, 13, 14, 15, 18, 20, 25, 26, 32, 34, 44, 47, 51, 53, 54, 67, 68, 69, 116, 120, 121, 123, 126, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 144, 145, 146, 148, 150, 153, 154, 155, 156, 157, 158, 159, 160, 165, 167, 168, 176, 179, 186, 189, 193, 194, 203, 210, 215, 216, 217, 220, 227, 228, 231, 232, 233, 240, 241, 242, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 258, 264, 267, 269, 271, 272, 273, 274, 275, 276, 277, 280, 281, 285, 288, 290, 293, 295, 297, 298, 300, 305, 310, 312, 313, 318, 319, 320, 327, 329, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 363, 364, 365, 366, 367, 368, 370, 371, 373], "how": [2, 13, 15, 16, 18, 19, 20, 22, 24, 26, 27, 33, 44, 46, 52, 53, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 72, 116, 121, 122, 124, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 157, 158, 162, 165, 167, 168, 169, 179, 186, 190, 215, 216, 220, 231, 233, 240, 244, 246, 248, 249, 250, 252, 253, 254, 256, 258, 272, 276, 277, 281, 282, 290, 293, 298, 300, 306, 308, 313, 315, 316, 319, 320, 321, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 378, 379, 382], "work": [2, 16, 21, 24, 44, 47, 49, 51, 69, 70, 71, 116, 121, 123, 126, 130, 133, 155, 156, 157, 161, 165, 167, 186, 187, 190, 191, 195, 196, 197, 204, 205, 206, 214, 216, 217, 218, 224, 228, 231, 232, 236, 241, 244, 245, 246, 248, 249, 250, 251, 252, 254, 258, 259, 261, 267, 273, 274, 279, 286, 295, 305, 319, 332, 362, 363, 379, 382], "resolv": [2, 156, 159, 234, 251, 283, 285, 288], "see": [2, 10, 11, 13, 18, 20, 32, 36, 40, 44, 51, 54, 67, 68, 69, 70, 71, 120, 121, 122, 123, 124, 126, 130, 140, 154, 155, 156, 157, 158, 159, 162, 164, 165, 167, 169, 171, 176, 182, 183, 185, 186, 187, 190, 195, 200, 207, 209, 212, 215, 216, 217, 219, 220, 222, 223, 224, 226, 228, 232, 233, 237, 239, 240, 241, 244, 246, 247, 248, 249, 250, 251, 252, 253, 269, 273, 275, 276, 281, 285, 288, 319, 320, 377, 378, 381, 383], "handl": [2, 11, 16, 21, 72, 121, 126, 130, 155, 159, 165, 167, 168, 176, 184, 186, 187, 242, 246, 253, 285, 288], "read": [3, 22, 27, 47, 50, 116, 120, 123, 126, 156, 158, 159, 165, 167, 176, 178, 186, 210, 231, 241, 251, 272, 273, 285, 288, 295, 305, 306, 324, 331], "introduct": [3, 165, 168, 241, 248], "neural": [3, 11, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 42, 45, 46, 49, 51, 52, 53, 56, 58, 59, 60, 64, 69, 72, 73, 101, 118, 130, 133, 142, 143, 145, 151, 152, 157, 167, 168, 193, 195, 196, 197, 201, 202, 203, 210, 220, 227, 231, 234, 241, 245, 249, 252, 253, 281, 291, 292, 293, 294, 297, 299, 300, 301, 302, 304, 335, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 358, 364, 365, 366, 373, 375, 377, 379, 381, 382], "compressor": [3, 11, 12, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 49, 51, 52, 53, 56, 58, 59, 60, 64, 69, 72, 73, 118, 142, 143, 145, 152, 291, 292, 293, 294, 297, 299, 300, 301, 302, 304, 335, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 358, 364, 365, 366, 370, 373, 375, 377, 379, 381, 382], "The": [3, 4, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 44, 46, 47, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 63, 66, 67, 68, 69, 70, 71, 72, 76, 93, 95, 97, 100, 105, 110, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 130, 131, 133, 134, 135, 136, 139, 140, 142, 143, 145, 146, 147, 148, 150, 153, 154, 155, 157, 158, 159, 160, 164, 165, 167, 168, 169, 171, 176, 177, 180, 181, 182, 184, 185, 186, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 256, 258, 260, 261, 262, 263, 264, 267, 269, 271, 272, 273, 275, 276, 277, 279, 281, 283, 285, 286, 287, 288, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 303, 304, 308, 309, 310, 311, 312, 313, 314, 315, 316, 318, 319, 324, 325, 326, 327, 328, 329, 330, 333, 335, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 366, 367, 368, 371, 373, 377, 378, 379, 381, 382, 387, 388], "follow": [3, 4, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 27, 28, 31, 32, 35, 36, 37, 39, 40, 42, 44, 46, 51, 53, 57, 58, 61, 62, 63, 69, 70, 71, 72, 76, 93, 95, 97, 100, 105, 110, 114, 115, 116, 117, 119, 120, 122, 123, 124, 126, 127, 128, 129, 132, 136, 138, 140, 142, 143, 149, 152, 153, 154, 155, 156, 157, 158, 159, 160, 167, 168, 169, 171, 176, 179, 184, 186, 188, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 246, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 260, 261, 262, 264, 265, 267, 269, 272, 273, 275, 276, 277, 279, 281, 283, 284, 285, 286, 287, 288, 289, 292, 293, 295, 297, 301, 312, 316, 317, 318, 319, 320, 321, 324, 326, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 377, 381], "quantiz": [3, 13, 18, 19, 21, 22, 26, 27, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 49, 51, 52, 53, 55, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 100, 103, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 153, 214, 235, 269, 292, 301, 314, 315, 325, 326, 327, 329, 330, 333, 335, 352, 355, 370, 373, 375, 378, 383, 388], "inc_ver": 9, "must": [9, 11, 15, 16, 31, 32, 35, 52, 53, 72, 103, 119, 120, 121, 122, 123, 124, 126, 140, 155, 157, 159, 160, 165, 169, 186, 225, 228, 233, 241, 249, 250, 251, 253, 273, 275, 277, 279, 281, 283, 285, 288, 314, 354, 355], "valid": [9, 12, 15, 22, 24, 34, 36, 44, 46, 49, 56, 66, 68, 70, 71, 75, 76, 77, 78, 80, 81, 82, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 120, 124, 126, 130, 131, 133, 148, 155, 165, 251, 256, 264, 267, 273, 276, 279, 314, 323, 354, 355, 359, 362, 366, 388], "publish": [9, 10, 20, 36, 38, 133, 154, 157, 230, 263, 264, 272], "project": [9, 10, 20, 45, 50, 53, 155, 156, 184, 186, 202, 206, 217, 228, 229, 249, 251, 254, 328, 331, 332, 369, 387], "histori": [9, 53, 337, 367, 388], "python": [9, 11, 16, 18, 20, 22, 26, 31, 35, 47, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 73, 77, 93, 94, 97, 98, 99, 100, 103, 104, 105, 114, 115, 116, 118, 120, 121, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 155, 156, 157, 159, 160, 168, 169, 185, 186, 187, 211, 215, 245, 251, 254, 256, 257, 258, 260, 261, 262, 264, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 283, 285, 286, 288, 295, 297, 305, 312, 317, 319, 320, 321, 323, 324, 325, 327, 329, 334, 337, 338, 339, 340, 341, 342, 343, 346, 347, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 362, 363, 364, 365, 366, 367, 368, 378, 384, 388], "python3": [9, 67, 117, 126, 140, 169, 251, 264, 279, 295, 305, 328], "image_nam": [9, 22], "image_tag": 9, "docker": [9, 117, 314], "arg": [9, 11, 12, 13, 16, 21, 22, 24, 26, 39, 44, 46, 51, 52, 59, 68, 72, 130, 139, 148, 153, 158, 160, 165, 184, 186, 187, 219, 251, 253, 272, 273, 295, 296, 305, 308, 309, 311, 315, 317, 333, 354, 355, 359, 360, 361, 362, 367, 368, 374], "f": [9, 13, 24, 26, 46, 118, 122, 126, 147, 152, 153, 159, 165, 219, 248, 250, 251, 253, 264, 273, 279, 285, 288, 293, 297, 337], "dockerfil": 9, "t": [9, 11, 13, 15, 18, 19, 21, 24, 26, 38, 44, 53, 54, 56, 58, 60, 62, 63, 66, 69, 116, 120, 121, 122, 124, 126, 131, 134, 135, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 150, 155, 156, 158, 159, 165, 167, 169, 171, 182, 184, 186, 187, 190, 204, 206, 209, 211, 217, 219, 222, 230, 233, 240, 241, 242, 244, 245, 246, 248, 250, 251, 252, 253, 258, 267, 272, 273, 279, 280, 284, 285, 286, 288, 290, 292, 301, 310, 314, 317, 327, 328, 329, 330, 332, 333, 354, 355, 360, 361, 367, 368, 388], "inc_branch": 9, "branch": [9, 155, 159, 240, 251, 269, 273, 285, 288, 332, 359], "otherwis": [9, 10, 20, 22, 52, 126, 154, 156, 159, 176, 241, 251, 253, 256, 273, 285, 286, 288, 295, 305, 345, 379, 382, 388], "fail": [9, 11, 70, 71, 126, 156, 159, 186, 273, 285, 288, 320], "If": [9, 11, 15, 16, 18, 20, 22, 26, 32, 35, 36, 37, 38, 41, 42, 46, 50, 51, 52, 53, 68, 69, 70, 71, 72, 116, 117, 120, 121, 122, 123, 126, 133, 155, 156, 157, 158, 159, 165, 167, 169, 186, 187, 190, 195, 209, 211, 219, 220, 224, 226, 237, 240, 241, 244, 245, 246, 248, 249, 250, 251, 253, 254, 255, 256, 259, 261, 262, 264, 269, 271, 272, 273, 275, 276, 277, 282, 285, 286, 288, 297, 306, 308, 319, 320, 332, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 371, 378, 379, 382, 388], "devel": 9, "doe": [9, 13, 14, 22, 28, 37, 49, 52, 53, 120, 126, 139, 148, 150, 155, 159, 161, 165, 167, 222, 224, 238, 240, 241, 246, 249, 250, 251, 252, 269, 272, 273, 274, 275, 285, 286, 288, 290, 296, 298, 308, 309, 310, 311, 313, 323, 329, 330, 333], "tag": [9, 51, 156, 165, 194, 198, 225, 240, 246, 248, 254, 273, 276, 279, 280, 281, 284, 354], "requir": [9, 12, 13, 14, 15, 16, 18, 19, 21, 25, 26, 32, 35, 38, 39, 43, 46, 49, 51, 53, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 116, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 134, 135, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 153, 155, 156, 157, 158, 159, 160, 164, 165, 167, 176, 183, 186, 193, 195, 196, 197, 200, 206, 210, 211, 216, 218, 219, 233, 238, 242, 244, 245, 246, 247, 249, 250, 251, 254, 259, 264, 266, 267, 269, 271, 273, 275, 276, 281, 283, 285, 286, 288, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 303, 304, 307, 308, 309, 310, 311, 312, 313, 315, 319, 321, 323, 325, 326, 327, 329, 330, 333, 334, 335, 354, 355, 362, 363, 365, 366, 367, 368, 378, 388], "describ": [9, 15, 18, 51, 68, 126, 131, 134, 135, 142, 143, 145, 146, 147, 148, 150, 152, 153, 155, 158, 159, 186, 190, 209, 223, 224, 228, 240, 250, 252, 269, 273, 281, 285, 288, 293, 297, 314, 315, 321, 327, 335, 363], "doc": [9, 37, 44, 131, 134, 135, 139, 142, 143, 145, 148, 153, 155, 158, 159, 162, 165, 167, 186, 233, 241, 276, 283, 285, 286, 288, 327, 329, 379, 382], "engin": [9, 15, 156, 159, 186, 215, 245, 285, 288], "commandlin": 9, "modifi": [9, 11, 16, 18, 19, 26, 58, 60, 62, 63, 121, 126, 131, 134, 135, 139, 140, 155, 157, 171, 186, 223, 230, 241, 249, 250, 263, 273, 275, 283, 286, 317, 319, 324, 354, 355, 367, 368], "so": [9, 11, 15, 28, 30, 34, 37, 46, 47, 51, 52, 53, 66, 67, 68, 69, 94, 116, 118, 119, 120, 121, 122, 124, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 156, 157, 158, 159, 160, 165, 167, 169, 171, 179, 182, 186, 188, 189, 192, 193, 197, 200, 203, 211, 212, 217, 218, 221, 227, 228, 231, 232, 233, 235, 240, 241, 244, 245, 247, 248, 249, 250, 251, 252, 253, 267, 273, 275, 276, 277, 279, 280, 281, 282, 285, 286, 288, 290, 296, 298, 308, 309, 310, 311, 313, 315, 317, 319, 323, 325, 331, 354, 355, 368, 371, 373, 383], "met": [9, 12, 38, 46, 51, 53, 121, 148, 150, 251, 327], "replac": [9, 11, 13, 26, 32, 49, 126, 140, 158, 159, 165, 186, 187, 190, 199, 201, 202, 206, 216, 217, 228, 231, 240, 241, 246, 248, 250, 252, 256, 258, 276, 281, 285, 288, 326, 328], "imag": [9, 13, 14, 18, 22, 26, 32, 51, 52, 54, 56, 58, 60, 62, 63, 68, 69, 70, 72, 75, 76, 77, 78, 80, 81, 82, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 116, 119, 120, 121, 122, 126, 130, 131, 133, 134, 135, 136, 139, 140, 142, 143, 145, 146, 147, 148, 150, 157, 162, 167, 168, 215, 218, 241, 247, 268, 314, 315, 316, 319, 321, 323, 324, 336, 337, 354, 355, 357, 362, 364, 366, 367, 368, 388], "grep": [9, 69, 159, 186, 251, 279, 285, 288, 320], "5c0dc1371312": 9, "5": [9, 13, 15, 22, 31, 37, 43, 52, 54, 55, 56, 67, 70, 71, 97, 100, 105, 116, 118, 120, 122, 124, 126, 133, 138, 140, 165, 186, 192, 197, 209, 212, 219, 221, 228, 233, 234, 236, 240, 247, 248, 250, 251, 252, 253, 254, 257, 258, 261, 262, 264, 268, 269, 271, 272, 273, 274, 277, 281, 283, 285, 288, 291, 292, 293, 295, 299, 301, 302, 304, 305, 306, 310, 312, 318, 324, 328, 334, 337, 388], "minut": [9, 235, 251, 256, 273], "ago": 9, "76gb": 9, "303de7f7c38d": 9, "36": [9, 48, 54, 130, 136, 247, 318, 323, 388], "61gb": 9, "In": [10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 24, 26, 32, 37, 40, 41, 42, 44, 46, 47, 50, 51, 52, 53, 60, 66, 67, 68, 70, 71, 72, 116, 123, 126, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 153, 155, 156, 158, 159, 160, 161, 165, 167, 179, 186, 187, 189, 191, 193, 201, 202, 203, 204, 205, 206, 208, 210, 211, 213, 214, 215, 216, 217, 218, 221, 222, 223, 226, 228, 231, 232, 233, 236, 237, 239, 240, 241, 245, 246, 248, 249, 250, 251, 252, 253, 254, 256, 263, 264, 269, 273, 276, 280, 281, 285, 288, 290, 292, 296, 298, 301, 307, 308, 309, 310, 311, 313, 315, 316, 318, 319, 327, 328, 329, 330, 332, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 375, 377, 378, 381], "foster": [10, 20, 198], "welcom": [10, 20, 154, 155, 169, 240, 332, 369], "environ": [10, 18, 20, 53, 55, 116, 126, 154, 155, 156, 157, 160, 169, 179, 186, 233, 240, 249, 254, 255, 273, 279, 286, 317, 354, 355, 377, 381, 385], "make": [10, 11, 13, 15, 18, 20, 21, 37, 46, 47, 53, 62, 63, 107, 108, 109, 110, 111, 112, 113, 116, 117, 118, 120, 121, 122, 123, 124, 126, 154, 155, 156, 157, 158, 159, 160, 165, 167, 169, 185, 186, 195, 196, 197, 198, 200, 211, 216, 217, 222, 233, 236, 238, 241, 242, 244, 248, 249, 250, 251, 252, 253, 254, 256, 261, 266, 267, 272, 273, 275, 276, 284, 286, 316, 317, 323, 328, 332, 354, 355, 356, 357, 358, 361, 362, 373, 377, 381], "particip": [10, 20, 126, 154, 209, 331], "commun": [10, 18, 20, 126, 140, 154, 155, 156, 157, 159, 160, 168, 186, 197, 208, 240, 241, 248, 249, 250, 253, 255, 272, 275, 285, 288], "harass": [10, 20, 154], "free": [10, 16, 20, 37, 41, 50, 72, 121, 154, 159, 169, 248, 250, 273, 274, 285, 286, 288, 319, 374, 378], "experi": [10, 16, 20, 50, 53, 121, 154, 156, 157, 159, 162, 186, 194, 199, 202, 204, 206, 208, 209, 219, 226, 233, 235, 237, 239, 241, 249, 251, 264, 269, 271, 272, 273, 285, 288, 300, 319, 337, 370], "everyon": [10, 20, 154, 155, 157, 159, 168, 240, 285, 288], "regardless": [10, 20, 154, 251], "ag": [10, 20, 154, 233, 275, 281], "bodi": [10, 20, 56, 154, 248, 320, 384, 388], "size": [10, 13, 18, 19, 20, 21, 22, 26, 30, 32, 41, 44, 48, 52, 53, 54, 62, 63, 68, 117, 121, 126, 130, 131, 134, 135, 136, 138, 139, 140, 144, 145, 146, 147, 154, 160, 165, 167, 182, 186, 188, 195, 196, 197, 202, 204, 206, 208, 212, 215, 217, 221, 224, 228, 230, 233, 241, 242, 244, 247, 248, 249, 250, 251, 252, 253, 258, 260, 261, 262, 269, 270, 275, 277, 281, 296, 306, 308, 309, 311, 312, 315, 316, 319, 323, 324, 325, 326, 334, 356, 357, 359, 361, 363, 366, 383, 388], "disabl": [10, 20, 154, 246, 251], "ethnic": [10, 20, 154], "sex": [10, 20, 154], "characterist": [10, 20, 154, 159, 285, 288], "gender": [10, 20, 154], "ident": [10, 13, 20, 24, 32, 120, 140, 154, 159, 186, 190, 206, 219, 237, 251, 273, 285, 288, 295, 305], "express": [10, 20, 154, 249, 251, 281, 295, 305, 383], "level": [10, 13, 15, 20, 53, 154, 157, 159, 165, 179, 208, 210, 215, 216, 217, 230, 234, 241, 251, 267, 269, 285, 288], "educ": [10, 20, 154, 157, 168, 245], "socio": [10, 20, 154], "econom": [10, 20, 154], "statu": [10, 20, 41, 154, 240, 250, 251, 320, 388], "nation": [10, 20, 154, 208, 220], "appear": [10, 18, 20, 140, 154, 155, 250, 252, 281, 286, 295, 305, 378], "race": [10, 20, 154, 188, 201, 202, 230, 254], "religion": [10, 20, 154], "sexual": [10, 20, 154], "orient": [10, 20, 154, 249], "behavior": [10, 15, 16, 20, 24, 39, 51, 53, 130, 140, 154, 155, 176, 186, 200, 246, 249, 251, 276, 286, 383], "creat": [10, 12, 15, 16, 20, 22, 28, 31, 32, 39, 40, 46, 50, 51, 53, 58, 60, 61, 62, 63, 65, 70, 71, 118, 120, 121, 123, 130, 155, 156, 157, 158, 159, 164, 165, 167, 169, 186, 189, 190, 192, 193, 203, 211, 212, 220, 232, 233, 240, 242, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255, 260, 264, 272, 280, 281, 282, 286, 293, 316, 317, 319, 328, 332, 354, 355, 357, 358, 377, 379, 381, 382, 386], "posit": [10, 18, 20, 37, 154, 156, 157, 159, 165, 168, 169, 188, 192, 200, 201, 202, 203, 204, 211, 212, 215, 219, 221, 222, 224, 231, 233, 234, 238, 239, 241, 248, 250, 267, 271, 272, 285, 288, 370], "inclus": [10, 20, 154], "languag": [10, 20, 45, 56, 96, 97, 98, 99, 100, 102, 103, 104, 105, 154, 157, 158, 162, 165, 167, 168, 171, 183, 184, 188, 190, 191, 192, 193, 194, 197, 198, 199, 200, 201, 202, 203, 204, 206, 208, 209, 210, 211, 212, 213, 214, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 230, 231, 232, 233, 234, 236, 237, 238, 239, 241, 244, 247, 248, 249, 252, 253, 254, 260, 261, 264, 269, 270, 273, 275, 276, 277, 281, 282, 283, 292, 301, 303, 361, 388], "Being": [10, 20, 154], "respect": [10, 20, 25, 44, 126, 154, 155, 159, 160, 197, 201, 202, 218, 220, 226, 237, 241, 250, 251, 272, 285, 288, 328, 356], "viewpoint": [10, 20, 154], "gracefulli": [10, 20, 154, 260], "accept": [10, 15, 18, 20, 38, 116, 126, 154, 158, 159, 165, 167, 187, 235, 246, 248, 272, 285, 288, 316, 332], "construct": [10, 19, 20, 22, 26, 53, 67, 68, 72, 148, 154, 210, 252, 275], "focus": [10, 15, 20, 32, 154, 156, 168, 188, 220, 233, 251], "what": [10, 18, 20, 120, 121, 126, 154, 155, 156, 157, 158, 159, 161, 165, 167, 168, 184, 186, 187, 231, 233, 240, 241, 246, 248, 250, 251, 252, 270, 273, 276, 285, 288, 317, 319, 331], "show": [10, 13, 18, 19, 20, 24, 26, 31, 44, 53, 70, 71, 72, 116, 120, 126, 133, 158, 159, 160, 165, 188, 191, 194, 195, 196, 200, 201, 202, 203, 204, 205, 208, 214, 215, 216, 218, 220, 221, 222, 225, 226, 230, 233, 235, 236, 237, 238, 240, 246, 248, 249, 250, 252, 253, 258, 269, 282, 285, 288, 293, 319, 328, 354, 362, 368, 371, 385, 388], "empathi": [10, 20, 154, 195, 196], "toward": [10, 14, 20, 24, 151, 154, 186, 269], "member": [10, 15, 20, 154, 158, 159, 219, 240, 286, 362], "unaccept": [10, 20, 154], "imageri": [10, 20, 154], "unwelcom": [10, 20, 154], "attent": [10, 15, 20, 24, 136, 154, 157, 159, 161, 162, 168, 171, 180, 182, 187, 193, 199, 200, 201, 202, 212, 216, 218, 221, 226, 231, 232, 233, 234, 237, 239, 245, 246, 248, 249, 250, 258, 285, 288, 306], "troll": [10, 20, 154], "insult": [10, 20, 154], "derogatori": [10, 20, 154], "comment": [10, 20, 22, 37, 52, 154, 156, 159, 203, 250, 273, 277, 285, 288], "polit": [10, 20, 154], "attack": [10, 20, 154], "public": [10, 20, 61, 120, 139, 154, 155, 156, 158, 159, 168, 194, 197, 225, 233, 285, 288, 290, 310, 319, 332, 379, 382], "privat": [10, 20, 154, 156, 157, 169, 230], "physic": [10, 20, 154, 359, 361], "electron": [10, 20], "address": [10, 18, 20, 38, 45, 154, 155, 156, 157, 186, 188, 198, 216, 217, 222, 251, 263, 292, 301], "without": [10, 11, 16, 18, 20, 21, 24, 26, 32, 37, 44, 45, 46, 53, 58, 65, 69, 71, 126, 140, 154, 155, 156, 157, 158, 160, 165, 187, 192, 202, 213, 214, 220, 233, 234, 238, 241, 245, 248, 249, 250, 251, 252, 254, 264, 269, 272, 273, 275, 288, 292, 301, 319, 356, 368, 388], "explicit": [10, 20, 154, 156, 200, 227, 251], "permiss": [10, 20, 154, 156], "could": [10, 16, 20, 25, 32, 40, 42, 44, 46, 53, 66, 67, 68, 70, 71, 118, 121, 131, 134, 135, 139, 140, 142, 143, 145, 146, 147, 148, 150, 153, 154, 155, 156, 159, 186, 204, 207, 233, 241, 244, 245, 248, 251, 252, 267, 272, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 315, 321, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "reason": [10, 20, 21, 51, 53, 126, 154, 156, 158, 159, 186, 218, 234, 240, 249, 251, 252, 273, 281, 285, 288, 319], "consid": [10, 11, 20, 21, 24, 53, 120, 126, 133, 154, 155, 156, 165, 167, 182, 198, 231, 241, 252, 253, 261, 269, 271, 275, 281, 293, 319], "inappropri": [10, 20, 154], "profession": [10, 20, 154], "clarifi": [10, 20, 154], "expect": [10, 16, 20, 27, 30, 46, 53, 72, 120, 126, 156, 157, 159, 160, 165, 167, 168, 169, 187, 215, 220, 224, 233, 239, 246, 248, 250, 251, 253, 256, 272, 273, 285, 286, 288, 321, 328, 331], "take": [10, 12, 16, 20, 21, 24, 44, 46, 47, 52, 53, 118, 123, 124, 154, 156, 159, 160, 164, 165, 167, 176, 186, 187, 200, 212, 222, 224, 231, 232, 241, 245, 246, 248, 250, 251, 252, 253, 256, 262, 273, 274, 281, 285, 288, 292, 300, 301, 308, 365, 383], "appropri": [10, 20, 123, 154, 167, 195, 196, 217, 233, 242, 250, 252, 354, 355], "fair": [10, 20, 154, 209, 213], "correct": [10, 13, 18, 20, 121, 122, 123, 124, 126, 155, 158, 159, 165, 186, 187, 206, 232, 236, 238, 250, 251, 253, 285, 288, 341, 370], "action": [10, 20, 32, 154, 155, 176, 241, 251, 331, 379, 382], "instanc": [10, 11, 12, 15, 18, 20, 31, 48, 53, 54, 62, 63, 121, 140, 154, 157, 158, 159, 167, 169, 171, 179, 182, 189, 232, 240, 241, 245, 246, 248, 252, 253, 254, 269, 272, 275, 285, 288, 307, 316, 319, 384, 388], "have": [10, 13, 16, 18, 20, 21, 26, 36, 37, 38, 41, 44, 46, 70, 71, 116, 120, 121, 122, 123, 125, 126, 130, 131, 134, 135, 136, 138, 139, 142, 143, 145, 153, 154, 155, 156, 157, 158, 159, 160, 161, 164, 165, 167, 168, 169, 171, 182, 186, 187, 188, 190, 191, 193, 194, 195, 197, 198, 199, 204, 208, 214, 215, 217, 220, 222, 227, 228, 230, 231, 233, 234, 236, 240, 241, 242, 244, 246, 248, 249, 250, 251, 252, 253, 254, 256, 258, 261, 263, 264, 267, 269, 272, 273, 274, 275, 276, 277, 279, 280, 285, 286, 288, 290, 295, 305, 306, 316, 319, 320, 323, 328, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370], "right": [10, 11, 18, 20, 21, 52, 126, 154, 156, 157, 159, 167, 168, 186, 188, 190, 192, 200, 203, 211, 212, 215, 221, 228, 231, 232, 233, 234, 240, 241, 244, 248, 250, 251, 252, 273, 285, 288, 317, 323, 334], "edit": [10, 11, 20, 126, 154, 155, 156, 168, 186, 251, 280, 286, 312, 323, 326, 334], "reject": [10, 20, 154], "commit": [10, 20, 118, 154, 155, 156, 158, 159, 169, 240, 251, 269, 273, 280, 285, 288], "wiki": [10, 20, 154, 233, 267, 272], "align": [10, 20, 52, 120, 154, 185, 218], "ban": [10, 20], "temporarili": [10, 20, 123], "perman": [10, 20, 123, 250], "thei": [10, 19, 20, 24, 37, 41, 44, 69, 70, 71, 117, 120, 121, 125, 126, 130, 154, 155, 156, 157, 158, 159, 165, 167, 168, 169, 176, 184, 185, 186, 187, 190, 195, 196, 206, 208, 215, 218, 219, 221, 228, 233, 240, 241, 242, 244, 246, 248, 249, 250, 251, 252, 254, 259, 267, 269, 273, 274, 280, 281, 285, 286, 288, 314, 316, 366, 373], "deem": [10, 20, 154, 250], "threaten": [10, 20, 154], "offens": [10, 20, 154], "harm": [10, 20, 154], "appli": [10, 14, 15, 18, 20, 42, 44, 46, 47, 50, 53, 126, 133, 147, 148, 150, 154, 157, 159, 167, 168, 197, 202, 208, 221, 233, 241, 244, 246, 248, 250, 252, 253, 264, 275, 285, 288, 292, 295, 301, 305, 318, 356, 357, 359, 360, 361, 362, 368, 370], "both": [10, 12, 14, 15, 20, 21, 25, 46, 69, 126, 142, 157, 158, 159, 160, 165, 167, 169, 184, 185, 186, 192, 193, 199, 203, 206, 214, 217, 218, 220, 227, 232, 233, 234, 240, 241, 246, 248, 249, 250, 251, 252, 253, 256, 258, 262, 267, 272, 273, 277, 285, 286, 288, 295, 305, 314, 320, 354, 362, 367], "within": [10, 11, 20, 38, 45, 120, 154, 156, 167, 169, 203, 212, 217, 250, 251, 354, 377, 381], "space": [10, 12, 15, 20, 21, 44, 46, 53, 58, 60, 121, 126, 131, 134, 135, 139, 140, 154, 155, 156, 185, 190, 205, 235, 241, 252, 332, 354, 355, 362, 367], "when": [10, 12, 14, 16, 18, 20, 21, 22, 28, 32, 44, 46, 52, 53, 66, 72, 120, 121, 122, 131, 134, 135, 139, 140, 152, 153, 154, 155, 156, 157, 158, 159, 160, 165, 167, 169, 171, 180, 182, 185, 186, 187, 188, 190, 195, 196, 205, 206, 216, 218, 227, 228, 231, 233, 234, 235, 240, 241, 242, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 261, 264, 267, 269, 272, 273, 275, 284, 285, 288, 295, 296, 305, 328, 354, 355, 362, 366, 367, 377, 378, 381, 386, 388], "individu": [10, 12, 20, 154, 159, 167, 241, 251, 269, 280, 285, 288], "repres": [10, 20, 22, 46, 53, 73, 140, 154, 167, 168, 201, 202, 215, 217, 218, 228, 232, 241, 242, 246, 248, 249, 252, 316], "its": [10, 12, 18, 20, 21, 24, 36, 37, 38, 43, 44, 50, 52, 53, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 120, 121, 126, 131, 155, 156, 157, 158, 159, 165, 167, 169, 186, 191, 199, 201, 202, 204, 216, 217, 219, 220, 223, 228, 233, 239, 240, 241, 244, 245, 246, 248, 249, 250, 252, 254, 263, 271, 272, 273, 275, 276, 280, 285, 288, 295, 300, 305, 321, 360, 361, 377, 381], "offici": [10, 18, 20, 31, 37, 55, 70, 71, 76, 93, 95, 130, 154, 156, 157, 159, 169, 186, 203, 217, 245, 261, 273, 278, 282, 285, 288, 293, 306, 314, 360, 362, 363], "e": [10, 20, 24, 26, 32, 53, 121, 126, 130, 140, 154, 155, 156, 157, 158, 159, 160, 167, 168, 169, 178, 185, 186, 187, 193, 213, 214, 215, 216, 217, 218, 219, 220, 222, 224, 231, 232, 233, 236, 239, 241, 244, 246, 247, 248, 250, 251, 252, 260, 264, 271, 272, 273, 280, 281, 283, 285, 286, 288, 291, 292, 294, 299, 300, 301, 304, 317, 320, 321, 370, 373, 374, 377, 381], "mail": [10, 20, 154, 250, 254, 262], "post": [10, 13, 14, 15, 16, 20, 25, 26, 27, 31, 34, 35, 42, 51, 53, 56, 117, 142, 154, 155, 156, 159, 165, 186, 204, 228, 229, 244, 248, 249, 250, 265, 269, 280, 285, 288, 300, 370, 374, 388], "via": [10, 20, 26, 32, 34, 50, 121, 130, 147, 151, 154, 157, 159, 160, 168, 176, 186, 187, 194, 200, 210, 218, 221, 232, 233, 250, 251, 254, 274, 281, 285, 288, 297, 312, 321, 323, 326, 334, 354, 367, 370, 387], "social": [10, 20, 154, 231], "media": [10, 20, 123, 138, 154, 363], "account": [10, 20, 50, 53, 70, 71, 154, 155, 159, 162, 167, 240, 248, 252, 285, 288, 354, 355], "act": [10, 20, 154, 155], "appoint": [10, 20, 154], "offlin": [10, 20, 46, 117, 154], "event": [10, 20, 51, 154], "represent": [10, 20, 25, 41, 46, 121, 140, 157, 161, 167, 168, 184, 188, 192, 204, 205, 206, 208, 210, 218, 235, 238, 241, 242, 248, 249, 252, 258, 277, 281], "mai": [10, 16, 20, 21, 30, 36, 38, 43, 45, 46, 120, 123, 126, 140, 145, 146, 154, 155, 156, 158, 169, 186, 187, 206, 233, 240, 241, 244, 245, 250, 251, 254, 256, 258, 261, 262, 267, 270, 273, 283, 286, 308, 314, 320, 377, 381], "further": [10, 20, 38, 39, 156, 158, 188, 208, 210, 218, 231, 233, 250, 263, 264, 269, 279, 319, 370, 378], "defin": [10, 12, 13, 14, 15, 18, 20, 22, 24, 34, 37, 41, 42, 44, 46, 50, 51, 53, 60, 67, 68, 72, 121, 142, 143, 157, 159, 160, 165, 167, 180, 186, 206, 217, 233, 235, 242, 244, 248, 250, 251, 252, 253, 256, 257, 261, 277, 279, 285, 288, 295, 305, 355, 359, 361, 385], "abus": [10, 20, 154], "report": [10, 18, 20, 50, 70, 71, 130, 136, 140, 154, 155, 156, 176, 179, 186, 230, 233, 244, 264, 269, 273, 277, 319], "contact": [10, 20, 49, 50, 157, 159, 169, 259, 285, 288], "mlp": [10, 20], "mlpc": [10, 20], "dl": [10, 16, 20, 31, 33, 45, 70, 71, 251, 272, 354, 372], "complaint": [10, 20, 154], "review": [10, 20, 154, 155, 159, 168, 213, 241, 285, 288], "investig": [10, 20, 154, 156, 161, 204, 227, 245, 250, 264], "result": [10, 12, 13, 15, 16, 18, 19, 20, 21, 24, 26, 28, 32, 34, 36, 37, 41, 44, 45, 46, 50, 51, 52, 53, 54, 59, 62, 63, 66, 67, 68, 72, 117, 118, 120, 121, 122, 123, 126, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 152, 153, 156, 157, 158, 159, 160, 164, 165, 167, 188, 190, 191, 192, 193, 194, 195, 196, 206, 208, 213, 214, 215, 216, 217, 218, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 236, 237, 240, 241, 244, 245, 248, 249, 250, 252, 253, 254, 257, 260, 262, 263, 264, 267, 269, 273, 275, 277, 279, 285, 288, 290, 291, 292, 293, 294, 296, 297, 298, 299, 301, 302, 304, 308, 309, 310, 311, 312, 313, 315, 319, 321, 323, 324, 326, 327, 329, 330, 333, 334, 335, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 373, 374], "necessari": [10, 12, 16, 20, 39, 50, 53, 64, 72, 122, 124, 155, 158, 159, 167, 204, 216, 218, 249, 262, 285, 288, 292, 301, 319, 362], "circumst": [10, 20], "team": [10, 20, 47, 157, 159, 168, 280, 281, 285, 286, 288], "oblig": [10, 20, 154, 156], "confidenti": [10, 18, 20], "regard": [10, 20, 47, 157, 159, 169, 186, 187, 221, 231, 233, 285, 288], "incid": [10, 20, 154], "specif": [10, 12, 13, 15, 18, 20, 24, 28, 31, 33, 37, 38, 39, 41, 66, 67, 68, 70, 71, 119, 120, 121, 126, 130, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 155, 156, 157, 159, 161, 162, 164, 165, 167, 168, 169, 182, 186, 187, 197, 200, 204, 209, 213, 225, 240, 241, 244, 246, 248, 249, 250, 252, 253, 254, 259, 264, 269, 276, 285, 288, 290, 291, 292, 294, 296, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 313, 315, 316, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 370, 372, 373, 378], "separ": [10, 16, 18, 20, 33, 36, 42, 72, 117, 120, 126, 144, 155, 156, 159, 160, 165, 167, 186, 204, 206, 217, 222, 230, 233, 241, 244, 249, 250, 252, 261, 272, 275, 279, 285, 288, 366, 388], "who": [10, 20, 155, 156, 233, 245, 249, 250, 272], "do": [10, 16, 18, 20, 22, 26, 32, 34, 37, 41, 47, 49, 53, 58, 59, 60, 67, 68, 94, 121, 122, 123, 124, 130, 131, 134, 135, 139, 140, 142, 143, 145, 148, 153, 156, 158, 159, 165, 167, 168, 171, 182, 185, 186, 187, 189, 233, 240, 242, 244, 246, 248, 249, 250, 251, 252, 253, 254, 264, 269, 273, 274, 275, 276, 285, 286, 288, 295, 300, 305, 306, 317, 319, 320, 327, 329, 332, 345, 356, 364, 379, 382], "good": [10, 20, 28, 46, 53, 121, 126, 140, 155, 156, 159, 161, 186, 195, 196, 204, 206, 210, 228, 244, 250, 251, 264, 285, 288, 328, 356], "faith": [10, 20], "temporari": [10, 20], "repercuss": [10, 20], "determin": [10, 13, 20, 28, 121, 126, 154, 165, 238, 241, 250, 252, 261, 275, 281, 295, 305], "": [10, 12, 13, 19, 20, 24, 26, 27, 28, 31, 32, 34, 35, 38, 42, 43, 44, 45, 46, 49, 50, 69, 70, 71, 72, 76, 93, 95, 116, 126, 133, 134, 135, 139, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 167, 168, 169, 171, 176, 177, 180, 182, 185, 186, 187, 188, 191, 192, 193, 195, 197, 198, 200, 201, 202, 203, 204, 206, 208, 209, 211, 212, 214, 215, 216, 217, 219, 221, 224, 228, 230, 231, 233, 234, 236, 238, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 259, 262, 264, 267, 273, 274, 275, 276, 277, 279, 280, 281, 285, 286, 288, 290, 292, 295, 296, 298, 301, 305, 306, 308, 309, 310, 311, 313, 315, 318, 319, 321, 328, 329, 330, 332, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 373, 377, 381], "leadership": [10, 20], "adapt": [10, 20, 116, 121, 123, 126, 140, 154, 157, 159, 161, 186, 191, 218, 227, 234, 240, 241, 248, 250, 285, 288], "www": [10, 22, 54, 118, 154, 157, 184, 202, 263, 321, 335], "html": [10, 118, 130, 131, 134, 135, 139, 142, 143, 145, 148, 152, 153, 154, 156, 158, 276, 293, 320, 327, 329, 379, 382], "answer": [10, 20, 52, 54, 56, 101, 154, 155, 156, 157, 159, 162, 167, 168, 183, 184, 190, 192, 205, 211, 213, 216, 218, 221, 229, 232, 233, 239, 241, 242, 246, 247, 248, 254, 258, 269, 272, 281, 282, 284, 285, 288, 293], "question": [10, 15, 20, 35, 52, 54, 56, 121, 154, 155, 156, 157, 159, 162, 167, 168, 183, 184, 186, 190, 192, 205, 211, 213, 216, 218, 221, 226, 229, 230, 232, 233, 237, 239, 241, 242, 246, 247, 248, 254, 258, 267, 269, 272, 281, 282, 284, 285, 288, 293, 370], "about": [10, 18, 20, 21, 28, 47, 54, 70, 71, 101, 121, 124, 126, 154, 155, 156, 157, 159, 160, 165, 168, 183, 186, 197, 202, 219, 224, 230, 231, 232, 233, 240, 244, 248, 249, 256, 272, 274, 275, 281, 284, 285, 286, 287, 288, 318], "nn": [11, 13, 14, 16, 39, 44, 51, 130, 140, 148, 150, 157, 159, 187, 219, 245, 248, 250, 253, 285, 288], "modul": [11, 13, 14, 18, 19, 24, 34, 37, 39, 47, 51, 130, 134, 139, 140, 145, 146, 148, 150, 156, 157, 159, 168, 179, 181, 187, 227, 241, 245, 248, 249, 253, 269, 285, 288, 295, 305, 310, 355, 383, 387], "With": [11, 14, 15, 21, 41, 44, 45, 46, 54, 70, 71, 140, 159, 160, 168, 194, 210, 211, 212, 225, 239, 241, 244, 252, 253, 272, 275, 278, 285, 288, 295, 305, 373, 377, 381], "convert": [11, 13, 14, 16, 27, 32, 38, 40, 46, 47, 52, 58, 60, 62, 63, 70, 71, 74, 75, 77, 83, 93, 101, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 120, 122, 124, 126, 140, 159, 165, 167, 168, 169, 184, 185, 186, 206, 219, 224, 232, 233, 240, 241, 245, 246, 248, 249, 250, 252, 253, 264, 269, 285, 288, 319, 334, 341, 354, 355, 362, 363, 367], "torch": [11, 13, 14, 16, 26, 38, 39, 44, 46, 51, 76, 93, 95, 116, 118, 126, 130, 135, 137, 140, 148, 150, 152, 153, 155, 156, 158, 159, 165, 169, 182, 186, 187, 194, 213, 224, 225, 233, 242, 244, 245, 248, 249, 250, 251, 253, 254, 258, 264, 272, 273, 274, 285, 288, 290, 292, 293, 296, 298, 301, 308, 309, 310, 311, 313, 316, 319, 323, 327, 333, 334, 370], "graphmodul": [11, 47], "insert": [11, 13, 34, 46, 47, 51, 160, 186, 241, 275, 287, 310, 319, 329, 341, 370], "quant": [11, 13, 46, 269, 310, 341], "dequant": [11, 13, 51, 310, 341], "oper": [11, 13, 18, 41, 46, 52, 53, 121, 123, 126, 131, 134, 135, 139, 142, 143, 145, 148, 153, 159, 169, 204, 210, 214, 216, 217, 228, 231, 233, 241, 249, 269, 285, 288, 316, 324, 327, 329], "symbolic_trac": 11, "fake": [11, 14, 46, 368], "valu": [11, 13, 14, 18, 21, 22, 28, 37, 41, 44, 46, 52, 53, 58, 60, 66, 72, 120, 121, 126, 131, 134, 135, 136, 139, 140, 145, 146, 153, 155, 158, 159, 161, 167, 169, 171, 179, 182, 184, 186, 187, 200, 212, 217, 218, 228, 233, 242, 246, 248, 249, 250, 251, 269, 271, 275, 276, 285, 288, 295, 305, 308, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 371, 388], "call": [11, 12, 15, 16, 18, 21, 33, 44, 46, 51, 52, 53, 69, 70, 71, 121, 126, 140, 156, 157, 158, 159, 160, 161, 165, 167, 168, 187, 191, 192, 197, 204, 206, 208, 226, 231, 232, 233, 237, 241, 244, 246, 248, 250, 251, 252, 253, 264, 273, 275, 276, 283, 285, 288, 345, 362, 374], "proxi": [11, 267, 281], "fed": [11, 167, 184, 232, 241, 245, 246, 248, 249, 253, 275], "model": [11, 12, 14, 15, 16, 19, 21, 22, 24, 25, 26, 27, 28, 32, 33, 34, 36, 37, 38, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 55, 56, 57, 68, 70, 71, 72, 104, 116, 120, 121, 123, 124, 127, 128, 129, 131, 133, 135, 142, 143, 144, 148, 150, 151, 161, 162, 164, 165, 171, 172, 173, 177, 178, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 245, 246, 251, 252, 253, 254, 255, 261, 262, 263, 264, 270, 272, 273, 274, 275, 276, 277, 278, 279, 282, 284, 289, 292, 295, 297, 300, 301, 305, 306, 307, 322, 327, 335, 352, 370, 373, 378, 383, 384], "record": [11, 13, 22, 50, 51, 53, 58, 60, 62, 63, 72, 93, 155, 197, 249, 276, 323, 334, 354, 355, 357, 358, 362, 363], "Then": [11, 15, 16, 18, 32, 122, 123, 124, 157, 159, 206, 221, 226, 237, 240, 246, 248, 250, 251, 252, 253, 254, 262, 267, 273, 275, 285, 288, 319, 357, 358, 377, 379, 381, 382], "get": [11, 15, 18, 19, 21, 22, 34, 35, 51, 53, 55, 60, 66, 67, 68, 69, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 122, 124, 136, 137, 145, 146, 147, 148, 155, 156, 158, 159, 164, 165, 169, 171, 176, 179, 182, 185, 186, 190, 233, 240, 241, 246, 250, 252, 253, 273, 275, 277, 281, 282, 283, 285, 288, 290, 296, 297, 298, 310, 314, 315, 317, 319, 337, 338, 341, 351, 352, 354, 355, 359, 361, 364, 368, 371, 387], "sure": [11, 13, 18, 62, 63, 107, 108, 109, 110, 111, 112, 113, 116, 120, 121, 122, 123, 124, 126, 155, 156, 157, 158, 159, 160, 164, 165, 185, 186, 233, 236, 240, 248, 251, 252, 254, 256, 267, 272, 276, 286, 317, 323, 332, 354, 355, 356, 357, 358, 361, 362], "backend": [11, 16, 17, 26, 28, 33, 34, 46, 52, 117, 118, 131, 134, 135, 139, 146, 147, 150, 157, 189, 248, 251, 297, 312, 315, 323, 326, 328, 330, 333, 354, 355, 362, 367, 374], "pytorch_fx": [11, 296, 309, 311, 330], "conf": [11, 12, 14, 16, 19, 21, 24, 32, 33, 53, 61, 64, 66, 67, 68, 72, 73, 118, 134, 135, 139, 141, 144, 145, 146, 147, 148, 150, 151, 290, 296, 298, 303, 308, 309, 310, 311, 312, 313, 315, 323, 326, 327, 328, 329, 330, 333, 334, 353, 368], "yaml": [11, 14, 15, 16, 22, 24, 28, 32, 33, 37, 40, 41, 44, 51, 52, 53, 61, 65, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 141, 142, 143, 144, 145, 149, 151, 291, 292, 293, 294, 299, 300, 301, 302, 303, 304, 306, 312, 319, 323, 326, 334, 353, 383, 384, 388], "usual": [11, 14, 21, 24, 42, 46, 158, 159, 167, 169, 171, 182, 188, 192, 200, 203, 211, 212, 217, 219, 221, 228, 231, 233, 240, 241, 245, 246, 248, 250, 251, 252, 253, 254, 273, 277, 280, 281, 285, 288, 292, 301], "_": [11, 13, 14, 15, 16, 17, 24, 26, 28, 32, 37, 38, 39, 41, 44, 46, 47, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 96, 97, 100, 105, 107, 108, 109, 110, 111, 112, 113, 117, 119, 120, 121, 122, 123, 124, 126, 130, 131, 134, 135, 139, 140, 144, 145, 146, 147, 148, 150, 152, 153, 154, 158, 228, 253, 254, 260, 263, 272, 273, 274, 275, 276, 277, 285, 288, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 315, 319, 320, 321, 323, 326, 327, 329, 330, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 374, 377, 379, 381, 382, 383, 384], "shown": [11, 12, 18, 24, 32, 37, 41, 42, 53, 69, 126, 160, 195, 196, 199, 203, 207, 227, 233, 241, 244, 249, 250, 251, 254, 266, 337, 338, 351, 359, 361, 378], "below": [11, 12, 14, 15, 16, 17, 20, 24, 26, 32, 33, 37, 41, 42, 44, 46, 51, 53, 66, 67, 68, 70, 71, 72, 116, 120, 121, 126, 131, 133, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 152, 153, 155, 164, 165, 168, 171, 179, 182, 184, 185, 186, 187, 241, 244, 246, 248, 249, 250, 251, 253, 255, 256, 262, 267, 269, 272, 273, 276, 277, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 308, 309, 310, 311, 313, 315, 321, 327, 328, 329, 330, 333, 335, 354, 355, 356, 357, 358, 359, 360, 361, 362, 367, 370, 377, 378, 381], "eval": [11, 13, 14, 51, 66, 67, 68, 130, 131, 134, 135, 138, 139, 140, 145, 146, 147, 148, 150, 153, 165, 224, 249, 253, 257, 263, 273, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 326, 327, 329, 330, 333, 354, 355, 356, 357, 358, 359, 360, 361, 362, 365, 367, 368, 370], "q_model": [11, 14, 16, 21, 22, 26, 33, 37, 39, 40, 41, 46, 59, 66, 67, 68, 72, 131, 134, 135, 139, 145, 146, 148, 150, 153, 290, 298, 308, 309, 310, 311, 312, 313, 315, 327, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368], "save": [11, 12, 13, 15, 16, 32, 33, 38, 39, 40, 44, 46, 57, 59, 62, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 123, 126, 138, 148, 159, 160, 164, 176, 177, 180, 185, 187, 193, 202, 206, 207, 210, 228, 240, 241, 245, 248, 251, 252, 253, 261, 263, 268, 272, 273, 275, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 324, 330, 333, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 355, 356, 357, 359, 360, 361, 363, 367, 373, 377, 381, 385], "tuned_checkpoint": [11, 148, 290, 310, 312, 315], "return": [11, 12, 13, 14, 15, 16, 22, 26, 37, 38, 39, 41, 46, 51, 53, 59, 66, 67, 68, 72, 131, 134, 135, 139, 145, 146, 148, 150, 153, 156, 157, 159, 165, 167, 171, 176, 182, 184, 186, 187, 215, 218, 233, 244, 246, 248, 250, 251, 253, 272, 279, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 315, 316, 319, 320, 327, 330, 333, 337, 354, 356, 357, 359, 360, 361, 362, 368, 388], "now": [11, 12, 15, 22, 26, 32, 40, 52, 53, 116, 122, 124, 126, 130, 155, 156, 157, 158, 159, 164, 165, 168, 169, 186, 194, 198, 202, 225, 228, 240, 242, 246, 248, 250, 251, 252, 253, 264, 273, 275, 277, 285, 288, 290, 303, 308, 314, 319, 320, 357, 362], "support": [11, 12, 13, 16, 18, 19, 27, 28, 31, 32, 40, 45, 47, 50, 53, 54, 55, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 120, 123, 126, 130, 131, 134, 135, 139, 144, 145, 146, 147, 148, 150, 153, 155, 157, 160, 168, 169, 186, 216, 219, 224, 242, 245, 246, 249, 251, 254, 262, 264, 272, 275, 281, 290, 292, 295, 298, 301, 302, 303, 305, 308, 313, 315, 316, 319, 320, 327, 328, 329, 330, 333, 334, 336, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 373, 378, 383], "auto": [11, 27, 145, 155, 156, 168, 187, 220, 232, 239, 241, 248, 250, 251, 278, 286, 325, 364, 370, 371, 373], "avoid": [11, 51, 154, 155, 156, 186, 222, 241, 264, 323], "log": [11, 18, 50, 51, 53, 117, 138, 156, 165, 168, 176, 178, 186, 187, 202, 228, 240, 244, 251, 252, 253, 257, 258, 270, 273, 305, 314, 317, 326], "output": [11, 13, 14, 15, 16, 18, 21, 24, 26, 32, 33, 37, 39, 44, 46, 51, 52, 53, 67, 69, 70, 71, 72, 76, 77, 93, 95, 104, 114, 115, 117, 119, 121, 122, 126, 130, 140, 144, 145, 146, 148, 150, 157, 159, 160, 161, 165, 167, 168, 185, 186, 193, 194, 198, 201, 202, 213, 219, 224, 225, 228, 232, 235, 238, 241, 242, 244, 247, 248, 249, 250, 252, 253, 260, 264, 272, 275, 281, 285, 288, 290, 294, 295, 296, 302, 304, 305, 308, 310, 321, 324, 354, 355, 356, 357, 359, 360, 361, 362, 368, 385, 388], "symbol": [11, 16, 39, 159, 167, 246, 248, 252, 285, 288, 317], "trace": [11, 159, 240, 285, 288, 323, 333, 375], "info": [11, 18, 20, 32, 39, 68, 70, 71, 72, 159, 179, 233, 249, 251, 255, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 360, 361], "entir": [11, 13, 14, 16, 44, 120, 126, 165, 167, 191, 214, 244, 250, 251, 281, 295, 305, 314, 361, 383], "conduct": [11, 155, 191, 193, 221, 226, 237, 241, 373], "combin": [11, 15, 28, 34, 42, 45, 47, 52, 53, 66, 131, 134, 135, 139, 143, 153, 156, 162, 167, 186, 192, 193, 196, 204, 209, 216, 217, 218, 219, 227, 232, 241, 248, 251, 252, 269, 273, 281, 354, 355, 362, 367], "imper": [11, 131, 134, 135, 139, 142, 143, 145, 153, 327, 329], "control": [11, 15, 16, 18, 43, 53, 126, 155, 157, 158, 168, 200, 239, 240, 241, 246, 269, 272, 273, 279, 383], "flow": [11, 12, 156], "therefor": [11, 14, 46, 49, 120, 122, 123, 126, 155, 159, 167, 186, 193, 199, 200, 203, 206, 210, 211, 212, 216, 221, 228, 231, 233, 234, 241, 249, 250, 251, 252, 256, 276, 285, 288, 295, 305, 306], "int8": [11, 14, 15, 17, 18, 22, 25, 27, 31, 46, 47, 48, 49, 50, 51, 52, 53, 56, 58, 61, 62, 63, 65, 70, 71, 118, 147, 148, 153, 214, 249, 290, 297, 300, 308, 309, 311, 312, 323, 325, 326, 329, 330, 333, 334, 357, 358, 359, 361, 373, 375, 378, 384, 388], "consist": [11, 16, 18, 20, 53, 122, 125, 155, 157, 158, 159, 186, 187, 188, 195, 196, 201, 202, 203, 213, 216, 217, 218, 225, 233, 234, 240, 241, 245, 250, 252, 264, 272, 273, 280, 285, 288, 324, 332], "lot": [11, 28, 126, 155, 156, 186, 241, 248, 264, 281, 283, 288, 319], "higher": [11, 14, 16, 24, 37, 38, 44, 46, 50, 72, 139, 146, 150, 199, 214, 221, 241, 244, 250, 251, 273, 275, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 313, 318, 320, 323, 326, 329, 330, 333, 334, 354, 355, 362, 363, 364, 367], "between": [11, 13, 15, 16, 19, 24, 27, 32, 34, 37, 46, 49, 50, 52, 53, 130, 140, 157, 159, 160, 165, 167, 168, 169, 174, 185, 187, 197, 215, 218, 220, 221, 222, 230, 231, 238, 239, 240, 241, 244, 245, 248, 249, 250, 251, 252, 253, 256, 264, 273, 285, 288, 308], "don": [11, 18, 53, 69, 120, 121, 139, 155, 156, 158, 159, 165, 169, 171, 182, 184, 186, 187, 204, 211, 217, 222, 230, 233, 240, 242, 244, 245, 248, 251, 252, 253, 267, 273, 280, 284, 285, 286, 288, 290, 310, 328, 360, 361, 368], "need": [11, 14, 15, 16, 18, 19, 21, 22, 24, 26, 34, 38, 41, 44, 46, 47, 49, 52, 53, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 130, 131, 134, 135, 136, 139, 140, 145, 146, 147, 148, 150, 152, 153, 155, 156, 157, 158, 159, 164, 165, 167, 169, 176, 186, 187, 199, 204, 211, 215, 217, 222, 230, 232, 233, 240, 241, 245, 246, 248, 249, 250, 251, 252, 253, 256, 259, 262, 267, 269, 270, 272, 273, 275, 277, 279, 283, 284, 285, 286, 288, 290, 292, 296, 298, 301, 306, 308, 309, 310, 311, 312, 313, 315, 317, 319, 320, 323, 324, 326, 327, 329, 330, 332, 333, 334, 337, 338, 351, 354, 355, 356, 357, 358, 362, 367, 368, 370, 371, 374, 377, 378, 379, 381, 382], "becaus": [11, 44, 46, 52, 53, 67, 68, 69, 120, 121, 122, 123, 126, 155, 156, 159, 165, 167, 171, 182, 186, 206, 241, 244, 246, 249, 250, 252, 253, 267, 273, 274, 285, 286, 288, 290, 319, 324, 360, 361, 362, 368, 383], "As": [11, 18, 21, 24, 28, 44, 53, 66, 68, 72, 119, 126, 130, 131, 134, 135, 139, 140, 145, 146, 147, 148, 150, 153, 155, 156, 159, 165, 186, 188, 192, 204, 206, 220, 232, 234, 241, 245, 246, 248, 249, 250, 251, 252, 254, 269, 273, 275, 281, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 314, 328, 337, 338, 351, 354, 355, 368, 378], "cannot": [11, 30, 51, 121, 126, 130, 156, 159, 176, 187, 200, 214, 221, 244, 323], "tensor": [11, 13, 22, 27, 44, 46, 49, 51, 52, 53, 54, 126, 158, 159, 165, 167, 178, 182, 194, 214, 217, 225, 233, 238, 242, 246, 248, 249, 250, 253, 264, 277, 285, 288, 316, 319, 320, 327, 356, 357, 360, 361, 362, 368], "iter": [11, 12, 14, 15, 21, 24, 44, 51, 53, 66, 68, 144, 150, 157, 159, 188, 244, 250, 269, 285, 288, 295, 305, 318, 319, 356, 357, 359, 361, 362, 364, 366, 367, 388], "might": [11, 18, 20, 53, 125, 155, 156, 159, 186, 233, 240, 246, 252, 253, 254, 273, 277, 280, 285, 288, 319, 320], "failur": [11, 156, 195, 196, 251], "sometim": [11, 44, 46, 126, 165, 167, 244, 246, 250, 275, 276], "order": [11, 16, 37, 44, 51, 53, 60, 126, 155, 158, 159, 161, 165, 167, 169, 179, 184, 190, 203, 233, 239, 240, 241, 247, 249, 250, 256, 269, 273, 275, 285, 288, 316, 319, 332], "suggest": [11, 50, 240, 248, 280], "two": [11, 12, 16, 18, 19, 22, 24, 26, 32, 37, 38, 42, 44, 46, 47, 50, 53, 66, 67, 68, 73, 119, 122, 126, 131, 134, 135, 139, 142, 143, 145, 148, 150, 153, 156, 157, 158, 159, 160, 165, 167, 171, 182, 183, 184, 185, 186, 187, 188, 193, 194, 201, 202, 206, 207, 209, 218, 219, 225, 227, 228, 236, 238, 240, 241, 242, 245, 246, 248, 249, 250, 251, 252, 264, 269, 272, 273, 276, 279, 281, 285, 288, 290, 292, 298, 301, 308, 313, 316, 319, 323, 327, 329, 330, 333, 334, 337, 338, 351, 354, 355, 361, 362, 365, 367, 368], "preprocess": [11, 21, 26, 52, 117, 118, 121, 123, 124, 130, 157, 165, 168, 219, 248, 252, 273, 276, 279, 282, 284, 323, 354, 355, 361, 365, 366], "non": [11, 13, 43, 44, 53, 156, 162, 167, 197, 227, 233, 244, 246, 249, 251, 260, 269], "traceabl": 11, "class": [11, 12, 13, 16, 19, 21, 22, 24, 28, 32, 37, 41, 42, 51, 53, 59, 68, 72, 120, 121, 126, 130, 140, 145, 146, 147, 154, 155, 156, 157, 158, 159, 160, 162, 165, 171, 174, 176, 177, 180, 181, 182, 184, 185, 186, 187, 195, 210, 215, 233, 240, 245, 246, 248, 249, 250, 251, 253, 254, 264, 275, 281, 285, 286, 288, 308, 309, 311, 312, 314, 315, 316, 319, 320, 327, 329, 330, 333, 354, 359, 360, 361, 362, 367, 387], "select": [11, 12, 18, 31, 34, 35, 46, 51, 53, 117, 122, 126, 130, 156, 159, 167, 204, 205, 217, 218, 233, 236, 239, 241, 245, 246, 250, 251, 267, 269, 272, 276, 286, 288, 295, 305, 316, 366, 385], "pass": [11, 13, 14, 15, 16, 19, 21, 22, 24, 26, 33, 37, 41, 44, 46, 47, 53, 59, 62, 63, 126, 131, 134, 135, 139, 140, 155, 157, 159, 160, 165, 167, 171, 182, 186, 187, 190, 218, 220, 227, 233, 241, 242, 244, 246, 248, 249, 250, 251, 253, 254, 270, 272, 273, 275, 276, 283, 285, 286, 288, 319, 323, 332, 354, 355, 366, 367], "them": [11, 16, 21, 33, 42, 44, 53, 69, 72, 118, 120, 121, 122, 123, 125, 126, 140, 145, 146, 155, 156, 157, 158, 159, 165, 167, 169, 184, 185, 186, 187, 206, 211, 212, 227, 233, 240, 241, 245, 246, 247, 248, 250, 251, 252, 253, 254, 256, 259, 264, 267, 272, 273, 276, 277, 279, 281, 284, 285, 286, 288, 308, 309, 310, 311, 312, 320, 329, 330, 333, 362, 363], "dict": [11, 37, 51, 53, 165, 187, 246, 388], "These": [11, 13, 16, 34, 122, 125, 126, 155, 157, 158, 167, 183, 184, 186, 200, 215, 218, 219, 230, 242, 249, 250, 251, 256, 267, 269, 273, 274, 277, 292, 300, 301], "function": [11, 12, 14, 15, 16, 18, 19, 21, 24, 33, 34, 35, 37, 38, 44, 46, 50, 51, 53, 58, 60, 62, 63, 66, 67, 68, 70, 71, 72, 121, 123, 126, 131, 134, 135, 140, 145, 146, 150, 153, 156, 158, 159, 165, 167, 168, 170, 171, 173, 174, 175, 186, 215, 228, 232, 241, 245, 248, 250, 251, 253, 273, 285, 288, 290, 296, 298, 306, 308, 309, 310, 311, 313, 315, 316, 319, 320, 323, 326, 327, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "conv2d": [11, 13, 15, 51, 295, 305, 362], "won": [11, 116, 156, 157, 186, 248, 251, 292, 301, 317], "detect": [11, 18, 56, 83, 93, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 133, 169, 186, 206, 241, 250, 251, 314, 315, 317, 318, 319, 327, 328, 362, 364, 370, 388], "maskrcnn": [11, 108, 315, 317, 320, 321, 362], "net": [11, 13, 67, 68, 120, 123, 125, 130, 136, 137, 157, 197, 245, 315, 354, 355], "py": [11, 12, 13, 15, 18, 26, 31, 35, 40, 46, 49, 51, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 86, 94, 97, 98, 99, 100, 103, 105, 116, 117, 118, 121, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 155, 156, 159, 160, 161, 164, 170, 179, 184, 186, 187, 200, 211, 212, 219, 224, 239, 240, 242, 249, 250, 251, 254, 256, 257, 258, 260, 261, 262, 264, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 283, 285, 286, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 304, 305, 308, 309, 310, 311, 312, 313, 315, 317, 319, 321, 323, 324, 325, 326, 327, 328, 329, 330, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 372, 373, 374, 379, 382, 384, 388], "prepare_custom_config_dict": [11, 315], "non_traceable_module_class": [11, 315], "anchorgener": [11, 315], "rpnpostprocessor": [11, 315], "pooler": [11, 295, 305, 315], "postprocessor": [11, 315], "maskrcnnfpnfeatureextractor": [11, 315], "maskpostprocessor": [11, 315], "fpn": [11, 315, 318, 319, 362, 364], "rpnhead": [11, 315], "decor": [11, 12, 15, 53, 168, 251], "wrap": [11, 26, 186, 220, 240, 323, 379, 382], "untrac": 11, "part": [11, 21, 24, 31, 32, 35, 38, 44, 56, 72, 121, 122, 126, 156, 157, 159, 164, 165, 167, 168, 186, 187, 194, 198, 200, 215, 220, 225, 233, 240, 241, 245, 246, 248, 249, 250, 251, 252, 253, 254, 256, 262, 264, 267, 279, 280, 285, 288, 323, 334, 345, 354, 367, 379, 382], "like": [11, 12, 15, 18, 20, 24, 27, 28, 32, 34, 40, 42, 44, 46, 53, 66, 67, 68, 70, 71, 76, 93, 95, 97, 100, 105, 116, 117, 119, 120, 121, 122, 126, 130, 131, 134, 135, 136, 139, 145, 146, 148, 150, 153, 154, 155, 156, 157, 158, 159, 161, 165, 167, 169, 176, 185, 186, 187, 188, 190, 199, 200, 203, 204, 207, 208, 210, 214, 219, 221, 228, 229, 236, 239, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255, 262, 267, 269, 272, 273, 275, 279, 281, 282, 285, 286, 288, 290, 292, 293, 296, 298, 301, 308, 309, 310, 311, 313, 315, 316, 319, 320, 327, 329, 330, 333, 355, 356, 357, 362, 373], "global": [11, 53, 126, 130, 158, 199, 216, 217, 240, 241, 251, 288, 295, 305, 319], "want": [11, 15, 16, 18, 19, 22, 26, 37, 41, 42, 50, 51, 53, 68, 69, 72, 122, 126, 145, 146, 156, 157, 158, 159, 165, 168, 186, 189, 211, 219, 233, 240, 242, 244, 245, 248, 249, 250, 251, 262, 267, 270, 272, 273, 276, 280, 285, 288, 295, 305, 306, 308, 317, 319, 332, 337, 338, 351, 356, 357, 373], "move": [11, 49, 130, 156, 157, 159, 168, 169, 244, 253, 254, 256, 262, 269, 273, 285, 288, 328, 354, 355], "keep": [11, 15, 49, 66, 67, 68, 126, 130, 131, 134, 135, 139, 142, 143, 144, 145, 146, 147, 148, 150, 153, 156, 159, 164, 169, 171, 187, 241, 249, 252, 253, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 315, 323, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "should": [11, 12, 13, 15, 16, 18, 22, 26, 37, 41, 46, 52, 53, 58, 60, 62, 63, 72, 98, 102, 120, 121, 123, 124, 126, 131, 134, 135, 139, 144, 155, 156, 158, 159, 160, 167, 169, 176, 186, 187, 190, 193, 195, 196, 210, 211, 215, 217, 219, 220, 228, 232, 233, 238, 240, 241, 242, 244, 246, 248, 249, 250, 251, 252, 254, 256, 264, 267, 269, 273, 274, 275, 276, 277, 285, 286, 288, 290, 292, 293, 296, 298, 301, 303, 306, 308, 309, 310, 311, 313, 319, 320, 325, 328, 332, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 371, 379, 382, 386], "try": [11, 46, 70, 71, 126, 140, 156, 159, 167, 186, 195, 240, 241, 249, 250, 251, 273, 278, 285, 288, 310, 320], "ssd": [11, 54, 56, 123, 323, 326, 328, 362, 364, 388], "resnet34": [11, 54, 56, 140, 141, 144, 151, 323, 326, 362, 364], "ptq": [11, 26, 27, 34, 46, 51, 56, 131, 134, 135, 139, 145, 146, 147, 148, 153, 315, 323, 325, 327, 329, 330, 333, 354, 355, 356, 357, 358, 360, 362, 363, 365, 367, 368], "r34": [11, 323], "def": [11, 12, 13, 14, 15, 16, 22, 24, 26, 37, 41, 44, 46, 51, 53, 59, 67, 68, 72, 148, 150, 158, 159, 165, 186, 215, 233, 251, 253, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 315, 319, 327, 329, 330, 333, 337, 354, 359, 360, 361, 362, 368], "bboxes_labels_scor": 11, "bbox": [11, 37, 136, 215, 315, 316, 321, 326, 362], "prob": [11, 250], "criteria": [11, 16, 27, 53], "45": [11, 31, 48, 54, 136, 157, 281, 320], "max_output": 11, "200": [11, 53, 54, 127, 128, 129, 130, 136, 140, 262, 274, 316, 355, 364], "box": [11, 16, 18, 37, 51, 52, 53, 126, 156, 157, 187, 215, 218, 232, 248, 254, 269, 275, 314, 316, 318, 319, 328, 370, 378], "label": [11, 16, 22, 37, 44, 52, 59, 72, 78, 80, 84, 85, 90, 92, 107, 108, 109, 110, 111, 112, 113, 117, 120, 126, 138, 157, 162, 165, 169, 182, 184, 186, 187, 193, 211, 217, 218, 220, 228, 232, 233, 235, 242, 244, 246, 248, 250, 253, 275, 277, 279, 281, 316, 319, 327, 328, 354, 355, 359, 360, 362, 388], "score": [11, 37, 41, 44, 50, 53, 126, 130, 157, 158, 161, 169, 171, 192, 199, 221, 238, 241, 244, 248, 250, 256, 258, 264, 269, 272, 273, 274, 275, 276, 295, 305, 316, 324, 330, 351, 360, 361], "zip": [11, 102, 104, 152, 153, 165, 233, 250, 299, 315, 321, 323, 357, 358], "split": [11, 52, 136, 159, 165, 167, 185, 187, 188, 190, 193, 219, 241, 242, 244, 246, 248, 250, 252, 256, 273, 279, 285, 288, 319, 359], "squeez": [11, 130, 233, 388], "dbox": 11, "dlabel": 11, "dscore": 11, "decode_singl": 11, "append": [11, 13, 41, 42, 122, 142, 143, 165, 232, 233, 244, 273, 329, 330, 333], "process": [12, 14, 15, 16, 18, 19, 21, 22, 24, 25, 26, 27, 32, 42, 44, 46, 51, 52, 53, 55, 56, 58, 60, 62, 63, 70, 71, 72, 117, 121, 126, 133, 140, 148, 155, 156, 157, 159, 160, 164, 165, 167, 168, 178, 184, 186, 191, 192, 193, 198, 201, 202, 204, 208, 210, 211, 214, 216, 217, 221, 224, 228, 231, 232, 240, 241, 244, 246, 248, 249, 250, 251, 252, 256, 264, 267, 269, 272, 273, 276, 280, 281, 285, 288, 292, 295, 300, 301, 305, 306, 319, 327, 332, 354, 355, 388], "autom": [12, 126, 130, 155, 233, 370], "design": [12, 16, 44, 46, 69, 126, 156, 159, 162, 192, 199, 221, 223, 228, 230, 231, 233, 241, 245, 253, 285, 288, 308, 328, 373], "artifici": 12, "ann": 12, "ha": [12, 15, 18, 21, 27, 32, 34, 38, 46, 47, 50, 55, 72, 118, 119, 120, 121, 122, 124, 126, 130, 131, 133, 134, 135, 139, 140, 142, 143, 145, 146, 147, 153, 155, 156, 157, 159, 162, 165, 167, 168, 169, 171, 179, 182, 186, 188, 193, 194, 195, 196, 201, 202, 204, 207, 208, 210, 213, 214, 219, 220, 221, 224, 228, 230, 231, 232, 233, 234, 235, 236, 239, 240, 241, 242, 244, 246, 248, 249, 250, 251, 252, 258, 263, 264, 267, 269, 272, 273, 275, 276, 277, 279, 281, 285, 286, 288, 297, 315, 316, 320, 321, 327, 328, 329, 331, 332, 354, 362, 371, 388], "been": [12, 16, 18, 24, 32, 38, 55, 126, 130, 140, 156, 157, 158, 159, 160, 162, 165, 167, 168, 169, 171, 182, 186, 191, 193, 198, 207, 208, 214, 215, 227, 231, 233, 240, 241, 246, 248, 249, 250, 251, 252, 264, 267, 269, 273, 275, 281, 285, 288, 320, 356, 366, 388], "par": [12, 191, 228, 233], "outperform": [12, 191, 194, 199, 205, 206, 208, 209, 210, 211, 216, 217, 222, 225, 227, 233, 235, 236, 238, 239, 241], "hand": [12, 18, 72, 126, 156, 168, 213, 245, 249], "simplest": [12, 24, 371], "launcher": [12, 16, 24, 44, 72, 186, 254], "configur": [12, 13, 15, 16, 18, 19, 22, 25, 27, 37, 41, 49, 52, 54, 58, 60, 62, 63, 73, 120, 121, 124, 130, 131, 134, 135, 139, 145, 146, 147, 153, 155, 158, 159, 160, 164, 168, 180, 187, 224, 233, 240, 245, 248, 249, 250, 251, 253, 254, 272, 274, 285, 286, 288, 291, 292, 294, 295, 299, 300, 301, 304, 305, 307, 308, 309, 311, 312, 315, 319, 321, 323, 326, 327, 334, 354, 355, 359, 361, 367, 372, 383], "agent": [12, 156], "path": [12, 13, 15, 16, 18, 19, 21, 22, 24, 26, 32, 33, 37, 39, 40, 44, 52, 53, 60, 62, 63, 66, 68, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 122, 124, 130, 131, 134, 135, 139, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 153, 155, 159, 160, 164, 165, 169, 186, 187, 189, 240, 251, 257, 258, 260, 261, 262, 263, 267, 268, 272, 275, 285, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 308, 310, 315, 317, 319, 321, 323, 324, 325, 326, 327, 328, 329, 330, 333, 335, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 353, 354, 355, 357, 358, 359, 360, 361, 362, 365, 366, 367, 368, 371, 374, 383, 384, 388], "syntax": [12, 16, 158, 186, 275, 328], "dyna": [12, 34], "section": [12, 18, 24, 44, 116, 121, 157, 158, 159, 160, 165, 168, 186, 233, 241, 242, 246, 247, 250, 253, 273, 279, 281, 285, 288, 318, 325], "option": [12, 16, 19, 21, 22, 28, 32, 38, 52, 53, 58, 60, 62, 63, 66, 68, 72, 79, 120, 122, 126, 131, 134, 135, 136, 138, 139, 148, 150, 153, 158, 160, 167, 171, 182, 186, 204, 233, 240, 246, 249, 251, 253, 254, 262, 264, 271, 272, 273, 275, 277, 319, 321, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 378], "search_algorithm": 12, "nsga2": 12, "seed": [12, 21, 28, 53, 66, 67, 128, 131, 134, 135, 139, 153, 251, 260, 277, 279, 291, 292, 294, 299, 301, 302, 304, 305, 354, 355, 362, 367, 388], "42": [12, 43, 54, 130, 136, 137, 215, 246, 251, 260, 264, 274, 300, 304, 318, 388], "supernet": 12, "ofa_mbv3_d234_e346_k357_w1": 12, "acc": [12, 13, 31, 48, 51, 54, 67, 133, 140, 253, 269, 277, 290, 296, 298, 300, 308, 309, 310, 311, 313, 357], "mac": 12, "popul": [12, 126, 233, 273], "50": [12, 31, 32, 54, 56, 60, 116, 126, 136, 137, 138, 145, 146, 147, 148, 150, 157, 168, 179, 241, 247, 250, 251, 252, 261, 262, 271, 273, 306, 316, 318, 319, 323, 328, 347, 355, 357, 364, 367, 388], "num_ev": 12, "250": [12, 130, 140, 250], "results_csv_path": 12, "search_result": 12, "csv": [12, 18, 160, 233, 272, 277, 283, 365], "batch_siz": [12, 13, 16, 19, 21, 22, 26, 32, 33, 46, 58, 59, 60, 62, 63, 66, 67, 68, 72, 76, 93, 95, 131, 134, 135, 139, 145, 146, 147, 153, 158, 160, 165, 167, 233, 242, 262, 279, 292, 293, 296, 300, 301, 315, 327, 328, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 364, 365, 367, 368, 370, 383, 384, 388], "64": [12, 13, 31, 52, 54, 126, 130, 138, 140, 151, 165, 244, 247, 253, 264, 273, 277, 318, 328, 354, 357, 361, 388], "dataset_path": [12, 388], "imagenet": [12, 14, 31, 51, 52, 54, 58, 60, 62, 63, 66, 72, 76, 77, 78, 80, 81, 82, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 130, 131, 134, 135, 139, 141, 142, 143, 144, 145, 146, 147, 148, 150, 318, 328, 353, 354, 355, 374], "ilsvrc2012": [12, 138], "nasconfig": 12, "argument": [12, 19, 24, 32, 72, 126, 130, 156, 160, 165, 167, 168, 183, 186, 195, 200, 212, 216, 228, 233, 246, 248, 250, 251, 253, 254, 264, 270, 272, 273, 275, 276, 292, 301, 319, 333, 362, 368], "config": [12, 18, 22, 24, 26, 32, 34, 39, 44, 47, 51, 53, 56, 57, 62, 63, 64, 65, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 130, 141, 144, 145, 149, 151, 152, 155, 158, 159, 160, 164, 167, 186, 189, 216, 217, 228, 233, 240, 244, 248, 249, 250, 251, 273, 285, 288, 294, 297, 299, 302, 303, 304, 306, 307, 312, 319, 322, 323, 328, 353, 383, 384, 388], "under": [12, 13, 18, 22, 32, 36, 37, 42, 44, 46, 51, 53, 55, 68, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 120, 155, 156, 158, 159, 160, 167, 168, 186, 204, 219, 222, 239, 240, 249, 251, 258, 264, 271, 272, 273, 280, 282, 285, 288, 308, 319, 332, 356, 357, 359, 360, 361, 367, 370, 373, 374, 386], "file": [12, 15, 16, 18, 22, 26, 30, 32, 33, 36, 37, 39, 41, 44, 51, 52, 53, 69, 73, 76, 93, 95, 102, 104, 117, 119, 120, 121, 122, 123, 126, 130, 145, 155, 156, 157, 158, 159, 160, 164, 165, 168, 169, 170, 177, 178, 180, 184, 185, 186, 187, 190, 195, 209, 215, 217, 219, 220, 224, 226, 228, 232, 233, 237, 249, 250, 256, 259, 260, 262, 263, 264, 267, 269, 272, 273, 275, 277, 279, 285, 286, 288, 291, 292, 293, 294, 299, 300, 301, 304, 307, 312, 317, 319, 321, 323, 324, 326, 328, 332, 334, 371, 379, 382, 383, 385, 386, 387], "input": [12, 15, 16, 18, 21, 22, 24, 26, 32, 33, 37, 38, 39, 44, 46, 51, 52, 70, 71, 72, 76, 93, 95, 114, 115, 117, 119, 122, 126, 130, 138, 140, 155, 157, 158, 159, 164, 165, 168, 171, 180, 182, 184, 185, 186, 188, 192, 193, 194, 195, 198, 199, 200, 202, 203, 204, 206, 210, 211, 212, 215, 218, 220, 221, 222, 224, 225, 228, 231, 232, 233, 234, 235, 236, 238, 239, 241, 242, 244, 248, 250, 251, 252, 253, 256, 272, 273, 276, 281, 285, 288, 316, 324, 328, 354, 355, 356, 357, 359, 360, 361, 362, 366, 368, 370, 373, 384, 385, 388], "aim": [12, 21, 53, 157, 198, 224, 240, 272, 319, 370], "accord": [12, 15, 22, 26, 44, 47, 52, 53, 62, 63, 159, 167, 186, 190, 220, 224, 233, 244, 249, 250, 251, 252, 256, 285, 286, 288, 319, 337, 351, 385], "regist": [12, 15, 16, 19, 22, 26, 37, 41, 53, 58, 60, 62, 63, 66, 70, 71, 72, 116, 120, 131, 134, 135, 139, 251, 354, 355, 367], "__new__": 12, "self": [12, 13, 15, 16, 18, 22, 34, 37, 41, 50, 51, 53, 56, 59, 72, 121, 155, 157, 159, 162, 165, 167, 168, 186, 187, 188, 191, 199, 216, 218, 221, 226, 231, 233, 235, 237, 241, 251, 258, 281, 285, 288, 315, 319, 327, 329, 330, 333, 354, 355, 359, 360, 361, 362, 367], "conf_fname_or_obj": [12, 16], "kwarg": [12, 187, 315, 355], "current": [12, 13, 15, 16, 18, 26, 27, 28, 37, 41, 44, 46, 53, 73, 121, 123, 126, 136, 140, 148, 156, 157, 159, 160, 168, 169, 179, 185, 186, 241, 242, 249, 250, 251, 252, 254, 264, 269, 275, 285, 286, 288, 289, 292, 295, 301, 305, 319, 321, 323, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 372, 384, 386], "built": [12, 15, 16, 19, 26, 27, 41, 52, 53, 56, 57, 58, 60, 62, 63, 66, 72, 131, 133, 134, 135, 139, 145, 146, 147, 148, 150, 153, 155, 157, 158, 165, 167, 186, 202, 240, 245, 248, 253, 254, 269, 270, 273, 317, 325, 354, 355, 357, 367, 377, 381], "inherit": [12, 15, 21, 121, 159, 181, 184, 222, 224, 245, 251, 273, 285, 288], "base": [12, 15, 22, 25, 26, 27, 28, 31, 43, 50, 51, 53, 54, 56, 67, 69, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 120, 121, 122, 123, 124, 126, 130, 155, 157, 158, 159, 160, 162, 164, 165, 167, 168, 177, 180, 182, 184, 185, 186, 187, 189, 190, 191, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 209, 210, 212, 213, 214, 216, 217, 221, 223, 225, 226, 227, 230, 231, 233, 237, 238, 239, 240, 242, 245, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 260, 263, 264, 267, 268, 269, 270, 272, 275, 277, 278, 279, 283, 285, 286, 288, 290, 291, 292, 294, 295, 299, 300, 301, 302, 303, 304, 305, 308, 310, 311, 314, 354, 355, 356, 361, 373, 374], "nasbas": 12, "own": [12, 18, 21, 22, 34, 37, 41, 50, 53, 70, 71, 116, 120, 121, 126, 130, 151, 156, 157, 160, 165, 167, 186, 187, 220, 233, 240, 245, 248, 250, 252, 253, 256, 265, 267, 273, 274, 275, 276, 277, 279, 282, 354, 355, 367, 368], "just": [12, 13, 14, 31, 32, 42, 46, 52, 53, 66, 67, 68, 116, 121, 126, 130, 131, 134, 135, 139, 145, 146, 148, 150, 153, 154, 156, 157, 159, 165, 169, 179, 185, 186, 187, 192, 195, 203, 204, 206, 207, 210, 217, 222, 226, 230, 233, 235, 237, 240, 241, 244, 245, 246, 248, 249, 251, 252, 253, 254, 259, 272, 273, 276, 277, 279, 285, 288, 290, 296, 308, 309, 310, 311, 315, 327, 329, 354, 362, 367, 368, 375, 378], "nas_registri": 12, "well": [12, 13, 22, 46, 49, 66, 67, 68, 120, 121, 126, 134, 154, 155, 158, 159, 165, 172, 184, 186, 190, 191, 197, 198, 206, 208, 209, 216, 221, 230, 232, 233, 238, 241, 242, 244, 246, 249, 250, 252, 253, 264, 265, 267, 281, 285, 288, 290, 295, 296, 298, 300, 305, 308, 309, 310, 311, 313, 316, 319, 320, 329, 330, 333, 355, 362], "wai": [12, 18, 21, 22, 37, 42, 44, 46, 53, 73, 121, 126, 134, 135, 139, 140, 153, 154, 156, 159, 165, 167, 169, 183, 185, 186, 191, 195, 196, 208, 217, 228, 233, 240, 241, 244, 245, 246, 248, 249, 251, 252, 273, 275, 281, 282, 284, 285, 288, 295, 305, 329, 362, 370, 371], "__init__": [12, 13, 15, 16, 22, 37, 41, 53, 59, 72, 156, 159, 165, 187, 233, 285, 286, 288, 315, 319, 327, 329, 330, 333, 359, 360, 361], "search_spac": 12, "none": [12, 13, 15, 16, 22, 37, 46, 51, 52, 53, 158, 159, 165, 171, 182, 228, 233, 246, 248, 251, 285, 288, 296, 308, 309, 311, 312, 315, 327, 329, 330, 333, 355, 388], "model_build": 12, "initi": [12, 13, 16, 21, 22, 32, 37, 38, 44, 53, 116, 117, 159, 193, 206, 207, 220, 227, 233, 240, 241, 245, 248, 249, 250, 252, 253, 264, 272, 281, 285, 288, 308, 309, 311, 312, 318, 323, 328, 356, 357, 360, 361], "select_model_arch": 12, "propos": [12, 15, 24, 38, 44, 126, 159, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 208, 210, 211, 212, 213, 214, 215, 216, 218, 221, 222, 224, 225, 226, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 241, 250, 258, 269, 287, 289], "next": [12, 18, 38, 53, 126, 158, 165, 167, 169, 186, 192, 200, 211, 212, 218, 226, 230, 233, 236, 237, 240, 241, 242, 246, 250, 251, 252, 262], "res_save_path": 12, "estim": [12, 13, 14, 53, 121, 126, 148, 150, 264, 285, 288, 356], "pragma": 12, "depend": [12, 20, 30, 32, 53, 118, 121, 126, 127, 128, 129, 130, 140, 155, 157, 158, 159, 186, 198, 199, 202, 211, 222, 225, 228, 233, 234, 239, 241, 242, 247, 250, 251, 252, 264, 269, 276, 285, 286, 288, 297, 317, 325, 329, 330, 333], "load_search_result": 12, "load": [12, 13, 21, 46, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 126, 130, 136, 137, 140, 155, 157, 159, 164, 165, 177, 180, 184, 187, 190, 206, 207, 213, 240, 244, 245, 248, 250, 251, 253, 262, 272, 273, 275, 276, 284, 285, 288, 314, 319, 321, 359, 361, 368, 377, 381], "exist": [12, 16, 32, 37, 44, 53, 56, 120, 155, 156, 158, 159, 162, 184, 186, 191, 195, 196, 199, 206, 213, 240, 241, 248, 249, 251, 264, 269, 272, 273, 284, 285, 288, 323, 372], "dump_search_result": 12, "find_best_model_arch": 12, "pareto": 12, "front": 12, "setter": [12, 168], "callabl": [12, 187], "leverag": [12, 24, 32, 42, 46, 56, 73, 157, 162, 167, 168, 193, 200, 203, 204, 207, 208, 211, 212, 215, 222, 223, 236, 248, 249, 250, 254, 256, 267, 269, 279, 282, 319, 370], "grid": 12, "random": [12, 28, 52, 66, 131, 134, 135, 139, 153, 159, 241, 250, 260, 281, 285, 288, 354, 355, 362, 367, 388], "bayesian": [12, 36], "given": [12, 21, 44, 52, 101, 121, 126, 156, 157, 160, 165, 168, 169, 184, 185, 189, 195, 196, 200, 206, 212, 232, 233, 240, 241, 245, 246, 248, 250, 251, 252, 263, 272, 275, 277, 280, 281, 285, 359], "evalu": [12, 13, 14, 15, 16, 21, 22, 24, 32, 33, 34, 37, 38, 40, 41, 44, 46, 50, 51, 53, 58, 59, 60, 62, 63, 64, 66, 67, 68, 72, 117, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 157, 159, 162, 165, 168, 176, 184, 186, 187, 191, 195, 196, 203, 205, 208, 209, 213, 214, 216, 217, 227, 234, 238, 244, 249, 252, 253, 254, 256, 258, 261, 262, 263, 264, 275, 277, 285, 288, 290, 293, 296, 298, 303, 308, 309, 310, 311, 313, 315, 321, 327, 328, 329, 330, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 363, 364, 365, 366, 367, 370, 374, 378], "potenti": [12, 159, 186, 200, 234, 240, 248, 251, 272, 285, 288], "after": [12, 13, 14, 16, 18, 19, 21, 22, 24, 34, 37, 40, 41, 42, 44, 46, 47, 50, 51, 52, 53, 62, 63, 66, 67, 68, 70, 71, 121, 123, 126, 130, 131, 134, 135, 139, 145, 146, 147, 148, 150, 152, 153, 155, 156, 158, 159, 186, 207, 210, 218, 230, 233, 241, 249, 250, 251, 252, 253, 264, 273, 274, 275, 276, 281, 285, 288, 293, 315, 320, 323, 327, 329, 354, 356, 357, 359, 360, 361, 362, 367, 368, 377, 378, 381], "sever": [12, 13, 18, 24, 34, 38, 44, 52, 121, 123, 126, 130, 155, 156, 157, 158, 165, 167, 181, 183, 184, 185, 186, 187, 211, 212, 213, 215, 218, 221, 231, 233, 241, 246, 249, 250, 251, 252, 253, 263, 264, 271, 292, 295, 296, 301, 305, 308, 309, 310, 311, 312, 377, 381], "procedur": [12, 116, 159, 194, 244, 285, 288, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "lie": 12, "through": [12, 13, 16, 31, 33, 34, 35, 37, 41, 42, 50, 56, 116, 154, 155, 156, 159, 165, 169, 176, 186, 188, 203, 218, 220, 222, 224, 241, 246, 248, 249, 250, 252, 253, 254, 275, 281, 282, 285, 288, 332, 371], "basic_na": 12, "basicna": 12, "super": [12, 13, 14, 41, 159, 169, 240, 285, 288], "predictor": [12, 319], "predict": [12, 13, 16, 24, 37, 51, 52, 59, 60, 72, 117, 121, 122, 126, 130, 157, 158, 159, 162, 165, 167, 168, 171, 186, 190, 192, 200, 201, 202, 206, 210, 211, 212, 218, 221, 222, 226, 231, 233, 236, 237, 241, 242, 244, 246, 247, 248, 249, 250, 253, 260, 272, 275, 281, 285, 288, 319, 328, 354, 355], "4x": [12, 13, 46], "than": [12, 13, 14, 16, 22, 33, 37, 41, 42, 44, 46, 50, 52, 121, 122, 126, 130, 133, 136, 140, 155, 156, 157, 159, 160, 161, 164, 165, 167, 168, 169, 182, 186, 188, 190, 192, 194, 197, 199, 200, 203, 204, 206, 211, 212, 215, 219, 221, 227, 231, 233, 234, 236, 238, 239, 240, 241, 242, 244, 247, 248, 249, 250, 251, 252, 253, 256, 258, 264, 270, 272, 273, 274, 275, 277, 279, 281, 285, 288, 290, 297, 319, 328, 332, 354, 362], "typic": [12, 16, 25, 44, 66, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 156, 186, 190, 241, 244, 354, 355], "figur": [12, 44, 69, 70, 71, 126, 156, 159, 241, 263, 273, 281, 285, 288, 377, 378, 381], "first": [12, 13, 14, 15, 18, 22, 32, 35, 38, 46, 47, 50, 51, 53, 60, 66, 67, 68, 116, 120, 121, 124, 126, 131, 134, 135, 145, 146, 147, 148, 150, 153, 155, 156, 157, 158, 159, 160, 165, 167, 169, 176, 184, 186, 187, 191, 193, 194, 200, 201, 202, 203, 209, 210, 215, 216, 218, 219, 220, 221, 225, 228, 232, 233, 235, 238, 240, 241, 246, 248, 250, 251, 252, 253, 262, 264, 269, 273, 276, 281, 283, 285, 286, 288, 316, 317, 319, 354, 356, 357, 362, 368, 378, 379, 382], "phase": [12, 44, 46, 47, 53, 204, 249, 355], "small": [12, 14, 18, 53, 56, 126, 130, 156, 159, 168, 186, 188, 204, 205, 206, 212, 216, 229, 240, 241, 244, 247, 250, 264, 269, 270, 275, 276, 285, 288, 290, 292, 301, 337, 338, 351], "sub": [12, 19, 159, 165, 185, 186, 187, 239, 285, 288, 354, 355], "randomli": [12, 52, 53, 117, 126, 159, 167, 190, 206, 220, 233, 241, 250, 251, 253, 267, 272, 281, 285, 288, 314, 366], "measur": [12, 15, 16, 19, 24, 32, 37, 40, 48, 51, 53, 56, 57, 62, 63, 160, 195, 196, 198, 204, 224, 230, 251, 264, 328, 368], "provid": [12, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 31, 34, 35, 38, 39, 46, 51, 54, 58, 60, 62, 63, 66, 67, 68, 70, 71, 120, 121, 123, 126, 131, 134, 135, 139, 145, 146, 147, 148, 153, 154, 155, 156, 157, 158, 159, 164, 168, 169, 172, 173, 177, 180, 181, 185, 186, 187, 191, 195, 196, 200, 208, 213, 224, 227, 233, 241, 242, 244, 245, 246, 248, 249, 250, 251, 253, 254, 258, 260, 264, 272, 275, 277, 279, 282, 284, 285, 288, 290, 293, 295, 296, 298, 302, 305, 308, 309, 310, 311, 312, 313, 314, 315, 316, 319, 320, 327, 339, 340, 342, 343, 344, 346, 347, 348, 349, 350, 354, 355, 359, 360, 361, 367, 370, 372, 378], "inner": [12, 161, 281], "loop": [12, 14, 50, 53, 157, 167, 176, 186, 233, 240, 244, 248, 251], "multi": [12, 21, 22, 34, 41, 44, 56, 132, 159, 162, 168, 184, 186, 188, 190, 195, 196, 213, 218, 232, 236, 237, 238, 241, 247, 250, 272, 273, 275, 277, 285, 288, 292, 301, 314, 337, 338, 351], "evolutionari": 12, "extens": [12, 15, 27, 34, 38, 39, 45, 53, 69, 131, 134, 135, 139, 155, 157, 158, 168, 186, 193, 213, 216, 220, 233, 236, 239, 249, 273, 297, 355, 374, 375, 379, 382], "cycl": [12, 21, 159, 285, 288], "continu": [12, 16, 44, 126, 154, 156, 159, 186, 191, 208, 250, 251, 273, 285, 288], "until": [12, 32, 53, 123, 148, 150, 159, 246, 251, 252, 273, 285, 288, 290, 327], "conclud": [12, 156], "count": [12, 13, 22, 121, 197, 233, 247, 250, 252, 264, 269], "create_acc_predictor": 12, "create_macs_predictor": 12, "create_latency_predictor": 12, "latenc": [12, 31, 32, 50, 53, 66, 68, 69, 70, 71, 123, 186, 214, 221, 323, 357], "mobilenetv3": [12, 130, 131], "static": [13, 14, 15, 34, 53, 54, 56, 158, 219, 224, 256, 310, 320, 370, 373, 374, 375, 378], "involv": [13, 154, 155, 156, 165, 167, 190, 233, 244, 250], "float": [13, 14, 17, 22, 28, 37, 46, 52, 68, 116, 126, 158, 159, 187, 214, 233, 235, 249, 285, 288, 384], "int": [13, 22, 37, 44, 52, 79, 126, 158, 165, 179, 215, 246, 248, 250, 295, 305], "feed": [13, 24, 165, 221, 232, 233, 241, 242, 246, 247, 248, 252, 362], "batch": [13, 14, 16, 18, 21, 24, 32, 44, 48, 52, 54, 62, 63, 72, 121, 126, 135, 138, 144, 148, 150, 160, 165, 167, 181, 182, 185, 186, 187, 190, 220, 224, 230, 233, 241, 242, 246, 248, 249, 253, 256, 258, 260, 261, 262, 267, 275, 277, 281, 295, 296, 305, 306, 308, 309, 311, 312, 315, 316, 319, 323, 325, 326, 328, 334, 356, 357, 359, 360, 361, 366, 388], "comput": [13, 14, 25, 27, 37, 38, 44, 46, 53, 70, 71, 117, 121, 126, 130, 133, 155, 157, 160, 161, 167, 168, 182, 185, 186, 188, 193, 199, 200, 201, 202, 204, 206, 210, 212, 231, 234, 241, 244, 246, 249, 250, 252, 262, 263, 264, 273, 274, 295, 305, 314, 319, 361, 370, 378], "done": [13, 14, 24, 40, 44, 46, 59, 66, 67, 68, 116, 121, 123, 126, 130, 131, 134, 135, 139, 142, 143, 145, 146, 148, 150, 153, 156, 157, 158, 159, 160, 165, 167, 169, 186, 187, 206, 217, 230, 232, 233, 234, 240, 241, 248, 249, 250, 251, 252, 273, 281, 285, 286, 288, 315, 319, 327, 329, 356, 357, 359, 360, 361, 362, 368], "observ": [13, 28, 50, 51, 53, 156, 199, 200, 211, 212, 231, 241, 251], "point": [13, 14, 17, 27, 28, 37, 46, 52, 53, 73, 117, 118, 120, 126, 155, 156, 159, 169, 186, 188, 192, 195, 196, 209, 214, 233, 246, 249, 251, 252, 269, 272, 273, 280, 285, 288, 317, 319, 323], "time": [13, 14, 26, 30, 41, 44, 45, 46, 50, 51, 52, 53, 69, 70, 71, 117, 123, 126, 130, 131, 133, 134, 135, 139, 145, 146, 147, 148, 150, 154, 155, 156, 157, 159, 160, 165, 167, 168, 169, 186, 188, 193, 197, 208, 214, 215, 217, 220, 226, 228, 233, 234, 235, 237, 238, 239, 240, 241, 242, 244, 246, 248, 250, 251, 252, 255, 264, 272, 273, 275, 276, 277, 285, 288, 314, 315, 318, 319, 323, 327, 328, 334, 356, 357, 359, 360, 361, 362, 373, 375, 377, 381, 388], "would": [13, 20, 32, 38, 46, 117, 120, 121, 126, 136, 155, 156, 158, 159, 165, 171, 182, 186, 197, 213, 228, 240, 241, 244, 246, 248, 249, 250, 251, 252, 253, 254, 255, 262, 272, 275, 276, 282, 283, 285, 288, 319, 362], "simpli": [13, 26, 39, 116, 121, 123, 126, 155, 159, 160, 165, 167, 244, 249, 251, 252, 253, 264, 269, 273, 285, 286, 288, 293, 319, 370, 373], "divid": [13, 53, 140, 228, 241, 252, 281, 319], "rang": [13, 14, 15, 22, 24, 26, 28, 44, 46, 52, 120, 140, 148, 150, 157, 158, 162, 165, 167, 186, 190, 192, 201, 202, 204, 205, 211, 216, 227, 233, 238, 244, 249, 250, 253, 275, 288, 295, 305, 329, 359, 362], "256": [13, 19, 21, 22, 26, 52, 53, 54, 66, 130, 131, 134, 135, 136, 139, 140, 144, 145, 146, 147, 156, 241, 247, 252, 273, 310, 383], "sophist": 13, "addit": [13, 18, 24, 32, 49, 121, 126, 130, 155, 157, 158, 159, 160, 161, 167, 168, 169, 183, 185, 186, 187, 191, 192, 202, 206, 210, 215, 220, 233, 241, 246, 247, 248, 250, 252, 254, 258, 269, 271, 273, 276, 279, 290, 298, 308, 309, 310, 311, 316, 319, 362, 378], "step": [13, 14, 18, 20, 24, 25, 26, 38, 44, 47, 50, 51, 53, 116, 121, 122, 124, 126, 155, 158, 165, 168, 169, 171, 186, 187, 208, 226, 233, 237, 241, 244, 246, 248, 251, 252, 253, 254, 264, 273, 277, 281, 282, 295, 305, 319, 363, 379, 382, 386, 388], "allow": [13, 14, 18, 19, 24, 26, 28, 32, 37, 38, 53, 58, 60, 62, 63, 66, 120, 130, 131, 134, 135, 139, 140, 153, 154, 155, 156, 157, 159, 160, 165, 185, 186, 200, 211, 212, 213, 227, 228, 233, 240, 241, 244, 245, 248, 249, 250, 251, 252, 253, 272, 273, 277, 281, 285, 288, 314, 316, 354, 355, 362, 367], "u": [13, 121, 122, 135, 144, 154, 155, 156, 158, 159, 160, 165, 169, 202, 204, 246, 249, 251, 252, 253, 264, 280, 285, 288, 295, 296, 305, 308, 309, 311, 370], "instead": [13, 15, 120, 121, 126, 155, 156, 157, 159, 160, 165, 168, 186, 187, 196, 197, 202, 206, 220, 226, 228, 231, 233, 237, 240, 241, 244, 246, 248, 249, 250, 251, 267, 285, 288, 371, 373], "back": [13, 126, 155, 156, 157, 168, 185, 187, 209, 240, 241, 246, 248, 252, 258, 272, 279, 280, 314], "everi": [13, 15, 44, 53, 123, 126, 145, 146, 155, 156, 157, 158, 159, 160, 167, 168, 187, 217, 228, 230, 231, 232, 233, 240, 250, 251, 252, 269, 273, 275, 280, 285, 288, 373, 377, 381], "pre": [13, 22, 24, 32, 38, 44, 45, 46, 51, 53, 54, 136, 153, 156, 157, 159, 160, 161, 162, 164, 165, 168, 186, 190, 192, 193, 194, 199, 200, 201, 202, 203, 204, 206, 207, 208, 211, 212, 215, 218, 220, 221, 222, 223, 224, 225, 226, 227, 232, 233, 235, 237, 239, 241, 247, 250, 252, 253, 256, 258, 262, 264, 269, 273, 275, 276, 281, 284, 285, 288, 291, 292, 294, 299, 300, 301, 304, 318, 319, 362], "notabl": [13, 191, 234], "modif": [13, 15, 21, 121, 126, 130, 156, 165, 192, 219, 245, 248, 264, 273, 277, 319, 373], "floatfunct": 13, "quantstub": [13, 131, 134, 135, 139, 142, 143, 145, 148, 153, 327, 329], "dequantstub": [13, 131, 134, 135, 139, 142, 143, 145, 148, 153, 327, 329], "begin": [13, 24, 44, 53, 156, 158, 159, 165, 167, 185, 228, 240, 241, 249, 250, 251, 253, 285, 288, 295, 305], "end": [13, 14, 15, 24, 31, 32, 35, 41, 44, 51, 52, 53, 56, 70, 71, 72, 103, 120, 122, 126, 148, 150, 155, 157, 158, 159, 165, 167, 169, 193, 203, 205, 214, 228, 233, 241, 242, 247, 249, 250, 251, 252, 253, 254, 262, 265, 285, 288, 295, 305, 351, 361, 378], "relu6": [13, 15], "relu": [13, 15, 51, 131, 134, 135, 139, 145, 148, 153, 327, 329], "_make_divis": 13, "v": [13, 32, 56, 70, 71, 121, 126, 138, 148, 155, 157, 167, 168, 201, 202, 222, 231, 234, 239, 251, 275, 277, 279, 288, 298, 313, 314, 317, 323, 334], "divisor": 13, "min_valu": 13, "taken": [13, 126, 191, 244, 328, 359], "origin": [13, 15, 22, 32, 44, 46, 52, 67, 68, 126, 130, 140, 155, 156, 157, 164, 165, 167, 185, 186, 188, 190, 192, 193, 194, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 218, 219, 220, 221, 222, 223, 225, 228, 230, 232, 233, 234, 236, 238, 239, 245, 246, 247, 249, 250, 251, 262, 263, 264, 267, 269, 271, 275, 279, 280, 281, 290, 291, 294, 296, 298, 299, 302, 304, 306, 308, 309, 310, 311, 313, 316, 321, 323, 329, 330, 333, 362, 373], "repo": [13, 22, 29, 55, 58, 60, 62, 63, 116, 136, 155, 157, 159, 169, 186, 219, 224, 240, 251, 254, 261, 271, 273, 283, 284, 285, 288, 329, 330, 332, 333, 354, 355, 377, 379, 381, 382], "ensur": [13, 18, 26, 28, 46, 52, 72, 76, 93, 95, 120, 121, 123, 126, 159, 160, 165, 186, 213, 228, 249, 251, 252, 285, 286, 288, 293, 329, 330, 332, 333], "layer": [13, 21, 25, 34, 44, 49, 53, 128, 145, 146, 159, 162, 167, 168, 186, 187, 188, 192, 193, 197, 201, 202, 206, 210, 214, 216, 217, 218, 219, 220, 224, 228, 231, 232, 241, 247, 249, 250, 251, 252, 253, 263, 264, 269, 273, 285, 288, 293, 295, 305, 328, 354], "channel": [13, 15, 31, 34, 35, 44, 52, 54, 56, 120, 122, 140, 154, 157, 169, 187, 209, 370, 375, 388], "number": [13, 14, 18, 22, 26, 28, 37, 44, 46, 50, 52, 53, 56, 62, 63, 66, 68, 71, 121, 122, 126, 140, 155, 157, 159, 165, 167, 168, 186, 187, 188, 195, 196, 205, 215, 217, 224, 228, 233, 241, 244, 245, 246, 248, 249, 250, 251, 252, 253, 263, 269, 272, 275, 281, 285, 288, 292, 296, 301, 309, 311, 316, 318, 319, 328, 329, 330, 333, 359, 361, 388], "divis": [13, 250], "seen": [13, 15, 121, 156, 233, 240, 246, 250, 252, 275, 281], "blob": [13, 77, 326, 360, 361, 374], "master": [13, 126, 130, 159, 169, 209, 251, 269, 273, 285, 288, 292, 301, 317, 326, 332, 360, 361, 363, 365], "research": [13, 36, 126, 130, 133, 140, 157, 158, 159, 162, 169, 191, 195, 196, 198, 202, 203, 205, 206, 208, 213, 227, 241, 245, 248, 254, 271, 273, 285, 288, 319, 354, 367], "slim": [13, 39, 56, 57, 60, 130, 140, 354, 355, 367], "mobilenet": [13, 50, 54, 56, 68, 72, 130, 133, 145, 146, 336, 342, 353, 362], "param": [13, 15, 39, 53, 67, 130, 138, 186, 251, 253, 261, 288, 388], "new_v": 13, "max": [13, 17, 18, 46, 52, 53, 140, 244, 246, 247, 274, 279, 295, 305, 356, 359, 362, 388], "round": [13, 14, 17, 28, 46, 248, 250, 337], "down": [13, 156, 159, 167, 222, 244, 249, 251, 252, 269, 285, 288, 300, 378], "go": [13, 52, 116, 155, 156, 157, 158, 159, 165, 167, 169, 186, 219, 233, 240, 241, 246, 285, 288, 328, 332, 379, 382, 387], "convbnrelu": 13, "sequenti": [13, 42, 53, 130, 157, 162, 168, 210, 233, 239, 241], "in_plan": 13, "out_plan": 13, "kernel_s": 13, "stride": [13, 52, 231, 244], "group": [13, 34, 44, 51, 52, 53, 54, 56, 157, 165, 168, 188, 219, 231, 233, 241, 248, 250, 251, 252, 253, 295, 305, 306, 388], "pad": [13, 22, 52, 130, 162, 165, 167, 168, 178, 188, 192, 200, 203, 211, 212, 216, 219, 221, 224, 231, 232, 233, 234, 248, 249, 250, 253, 274, 316], "bia": [13, 51, 121, 159, 240, 253, 273, 285, 288], "fals": [13, 14, 15, 16, 21, 22, 37, 41, 46, 51, 52, 53, 63, 72, 130, 140, 147, 153, 159, 160, 165, 186, 187, 193, 194, 219, 233, 246, 250, 251, 253, 254, 262, 285, 287, 288, 295, 296, 305, 309, 311, 312, 315, 323, 325, 326, 327, 333, 334, 359, 377, 381, 388], "batchnorm2d": 13, "momentum": [13, 34, 44, 56, 121, 140, 295, 305, 314], "inplac": [13, 14], "invertedresidu": 13, "inp": 13, "oup": 13, "expand_ratio": 13, "assert": [13, 41, 156, 159, 190, 224, 251, 285, 288, 333, 334], "hidden_dim": [13, 248], "use_res_connect": 13, "pw": 13, "extend": [13, 59, 72, 167, 186, 203, 220, 233, 236, 245], "dw": 13, "linear": [13, 24, 140, 159, 186, 187, 206, 241, 247, 285, 288, 295, 305, 329], "conv": [13, 15, 130, 131, 134, 135, 139, 145, 148, 153, 295, 305, 327, 328, 368], "add": [13, 15, 18, 20, 22, 26, 32, 37, 40, 41, 50, 51, 53, 58, 61, 62, 63, 116, 123, 126, 130, 131, 134, 135, 139, 140, 142, 143, 145, 146, 148, 153, 155, 158, 165, 167, 168, 186, 187, 193, 233, 241, 244, 245, 246, 247, 250, 251, 254, 255, 261, 270, 271, 272, 274, 277, 286, 312, 316, 319, 323, 326, 327, 328, 329, 332, 334, 337, 338, 351, 354, 356, 357, 359, 360, 361, 362, 367, 368, 379, 382], "skip_add": 13, "forward": [13, 14, 46, 51, 156, 159, 160, 165, 187, 190, 195, 215, 217, 220, 221, 228, 232, 233, 244, 247, 249, 253, 272, 275, 285, 288], "x": [13, 24, 26, 39, 44, 46, 51, 52, 69, 71, 76, 93, 95, 126, 130, 133, 158, 165, 167, 168, 186, 194, 219, 220, 228, 233, 241, 244, 251, 252, 318, 324, 328, 354, 355, 362, 363, 367], "els": [13, 15, 51, 121, 156, 165, 169, 224, 233, 287, 295, 296, 305, 308, 309, 311, 312, 315, 333, 356, 373], "num_class": [13, 140, 367], "1000": [13, 32, 53, 140, 156, 165, 186, 187, 215, 219, 228, 251, 273, 275, 295, 354, 357], "width_mult": 13, "inverted_residual_set": 13, "round_nearest": 13, "width": [13, 26, 46, 52, 58, 60, 62, 63, 72, 140, 215, 316, 319, 328, 354, 355, 388], "multipli": [13, 28, 319], "adjust": [13, 14, 46, 155, 156, 159, 165, 186, 241, 251, 276, 284, 285, 288, 292, 301], "each": [13, 14, 15, 16, 18, 21, 22, 24, 28, 41, 42, 44, 50, 51, 52, 53, 72, 117, 119, 120, 121, 122, 123, 126, 140, 145, 146, 155, 156, 157, 158, 159, 160, 161, 165, 167, 168, 171, 180, 182, 184, 186, 189, 201, 202, 206, 210, 211, 215, 217, 218, 219, 224, 226, 228, 232, 233, 237, 240, 241, 244, 245, 246, 247, 248, 249, 250, 252, 259, 263, 264, 269, 272, 273, 275, 276, 281, 285, 286, 288, 292, 295, 301, 305, 316, 319, 328, 354, 378], "amount": [13, 126, 155, 156, 193, 200, 206, 208, 212, 218, 235, 269, 337, 338, 351], "structur": [13, 34, 44, 46, 51, 54, 56, 120, 123, 124, 126, 158, 159, 165, 171, 182, 185, 200, 221, 233, 285, 288, 316, 319, 321, 324], "multipl": [13, 16, 22, 42, 50, 53, 55, 56, 76, 93, 95, 120, 126, 156, 159, 162, 165, 181, 193, 197, 198, 205, 210, 216, 218, 219, 220, 225, 228, 233, 236, 240, 241, 242, 248, 250, 251, 252, 254, 262, 269, 272, 275, 276, 285, 288, 296, 309, 311, 316, 319], "turn": [13, 37, 123, 126, 142, 143, 156, 159, 165, 195, 196, 203, 224, 233, 275, 285, 288, 378], "off": [13, 47, 145, 146, 156, 165, 167, 186, 224, 238, 251], "block": [13, 34, 41, 44, 126, 130, 157, 167, 199, 210, 211, 241, 245, 247, 256, 269, 288, 319], "input_channel": 13, "32": [13, 16, 26, 33, 44, 48, 54, 58, 62, 63, 66, 67, 68, 70, 71, 72, 120, 126, 130, 140, 153, 160, 168, 233, 247, 249, 250, 253, 261, 264, 273, 274, 275, 277, 279, 281, 299, 300, 301, 302, 304, 305, 310, 312, 316, 328, 356, 388], "last_channel": 13, "1280": [13, 242, 247], "c": [13, 18, 22, 30, 31, 35, 116, 126, 130, 133, 155, 156, 157, 169, 186, 219, 240, 241, 249, 250, 251, 254, 261, 269, 271, 273, 274, 281, 317, 319, 320, 335, 362], "n": [13, 22, 24, 31, 44, 52, 130, 133, 155, 157, 159, 165, 167, 168, 203, 220, 226, 228, 231, 237, 241, 244, 251, 252, 253, 254, 275, 285, 288, 295, 305, 321, 357], "16": [13, 32, 44, 48, 54, 120, 130, 140, 165, 197, 215, 224, 236, 244, 247, 252, 253, 257, 258, 264, 269, 273, 275, 277, 293, 295, 305, 306, 308, 309, 311, 325, 328, 355, 357, 358, 367, 388], "24": [13, 31, 48, 53, 54, 130, 149, 167, 215, 247, 258, 273, 277, 357, 358, 388], "96": [13, 31, 54, 130, 140, 250, 277], "160": [13, 117, 130], "320": [13, 75, 130, 136, 328], "onli": [13, 15, 16, 19, 21, 26, 32, 35, 38, 51, 53, 58, 61, 62, 63, 65, 66, 67, 68, 72, 117, 119, 120, 121, 122, 123, 124, 126, 131, 134, 135, 136, 139, 140, 143, 145, 146, 147, 148, 150, 153, 155, 156, 158, 159, 160, 164, 165, 167, 169, 170, 171, 172, 173, 174, 175, 176, 179, 182, 184, 186, 187, 190, 191, 196, 199, 206, 210, 213, 214, 216, 217, 218, 219, 220, 227, 228, 233, 234, 236, 239, 240, 241, 242, 244, 246, 248, 249, 250, 252, 253, 254, 258, 261, 264, 269, 272, 273, 275, 276, 279, 281, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 314, 315, 319, 321, 327, 329, 330, 332, 333, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 373], "element": [13, 22, 34, 37, 44, 165, 167, 171, 182, 187, 241, 248, 253, 264, 295, 305, 316], "assum": [13, 15, 70, 71, 136, 138, 155, 164, 217, 241, 252, 253, 273, 276, 285, 288, 319, 321], "know": [13, 26, 49, 69, 118, 120, 121, 122, 123, 124, 126, 155, 156, 159, 168, 184, 204, 240, 241, 251, 252, 280, 281, 285, 288], "len": [13, 16, 22, 26, 44, 52, 59, 68, 72, 148, 165, 167, 187, 233, 250, 315, 329, 360, 361], "rais": [13, 44, 155, 230, 249, 251, 296, 309, 311], "valueerror": [13, 30, 156, 251, 296, 309, 311], "empti": [13, 165, 186, 241, 251, 273, 279, 371], "got": [13, 30, 32, 51, 156, 250, 276], "format": [13, 15, 16, 22, 24, 26, 37, 38, 39, 40, 46, 55, 58, 60, 62, 63, 120, 122, 123, 124, 126, 136, 148, 155, 156, 159, 162, 164, 165, 168, 206, 215, 219, 220, 223, 232, 233, 246, 249, 251, 253, 272, 273, 276, 279, 285, 288, 290, 296, 298, 306, 308, 309, 310, 311, 312, 313, 316, 324, 336, 339, 340, 342, 343, 344, 346, 347, 348, 349, 350, 354, 355, 357, 362, 370], "build": [13, 15, 18, 27, 35, 39, 53, 56, 70, 71, 116, 117, 118, 147, 157, 162, 165, 167, 168, 186, 187, 195, 196, 199, 201, 202, 204, 218, 230, 240, 241, 245, 246, 248, 250, 251, 272, 295, 297, 305, 308, 314, 317, 319, 320, 322, 359, 366, 377, 379, 381, 382], "invert": [13, 221], "residu": [13, 121, 159, 167, 228, 241, 285, 288], "output_channel": 13, "last": [13, 18, 38, 46, 53, 138, 140, 156, 159, 168, 169, 186, 209, 224, 241, 244, 246, 250, 251, 264, 285, 288, 328, 370, 375, 378], "classifi": [13, 22, 24, 130, 140, 153, 157, 162, 165, 167, 231, 241, 246, 248, 250, 261, 281, 295, 304, 305, 356], "dropout": [13, 159, 187, 247, 248, 273, 285, 288], "m": [13, 24, 32, 54, 69, 70, 71, 77, 79, 83, 93, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 122, 126, 130, 133, 147, 155, 156, 157, 159, 167, 168, 186, 195, 196, 211, 221, 229, 240, 246, 251, 252, 254, 258, 264, 269, 273, 274, 276, 285, 286, 288, 292, 295, 297, 301, 305, 314, 319, 323, 328, 357, 373, 379, 382, 386], "isinst": 13, "init": [13, 22, 37, 41, 130, 147, 159, 186, 285, 288, 293, 295, 305, 356], "kaiming_normal_": 13, "mode": [13, 15, 18, 19, 32, 34, 46, 47, 66, 68, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 130, 147, 148, 150, 153, 155, 159, 187, 246, 249, 251, 253, 272, 277, 285, 288, 296, 297, 309, 310, 311, 312, 316, 319, 323, 325, 326, 329, 330, 333, 334, 335, 336, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 356, 357, 359, 361, 364, 365, 366, 367, 377, 381, 384, 388], "fan_out": 13, "zeros_": 13, "elif": [13, 165], "ones_": 13, "normal_": 13, "01": [13, 15, 28, 50, 53, 54, 66, 67, 68, 72, 130, 131, 134, 135, 139, 140, 145, 146, 147, 148, 150, 153, 165, 186, 248, 253, 271, 290, 294, 296, 298, 300, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 360, 361, 362, 364, 367, 368, 388], "mean": [13, 14, 15, 16, 19, 21, 26, 28, 37, 44, 46, 52, 53, 66, 67, 68, 69, 117, 118, 126, 130, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 155, 159, 165, 171, 182, 186, 187, 199, 206, 216, 217, 228, 232, 233, 241, 244, 245, 246, 248, 249, 250, 251, 252, 253, 281, 285, 288, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 319, 320, 327, 329, 330, 333, 354, 355, 357, 361, 362, 367, 371, 383], "fuse": [13, 14, 15, 51, 131, 134, 135, 139, 145, 148, 153, 218, 248, 249, 327, 329], "bn": [13, 15, 54, 131, 134, 135, 139, 140, 145, 148, 153, 327], "prior": [13, 53, 126, 195, 196, 204, 216, 217, 233], "chang": [13, 20, 21, 26, 30, 37, 51, 52, 53, 118, 123, 130, 134, 135, 139, 155, 156, 157, 158, 159, 168, 169, 176, 179, 192, 202, 206, 210, 211, 228, 233, 240, 241, 248, 249, 251, 258, 264, 269, 270, 275, 283, 285, 286, 288, 308, 312, 319, 323, 326, 328, 329, 332, 334, 354, 355, 362, 367, 370, 377, 378, 381, 386, 387], "numer": [13, 14, 17, 31, 38, 45, 167, 249, 281], "fuse_model": [13, 14, 131, 135, 139, 145, 146, 148, 150, 327], "type": [13, 15, 18, 22, 27, 34, 38, 44, 46, 52, 56, 79, 120, 121, 123, 126, 140, 155, 156, 158, 159, 160, 165, 171, 182, 186, 217, 233, 240, 241, 245, 248, 249, 250, 251, 252, 260, 272, 285, 288, 295, 305, 306, 316, 318, 319, 327, 361], "fuse_modul": [13, 329], "true": [13, 14, 22, 26, 37, 41, 46, 47, 51, 52, 53, 67, 76, 93, 95, 121, 130, 136, 137, 145, 146, 147, 153, 158, 159, 160, 165, 167, 171, 182, 186, 190, 193, 216, 219, 220, 224, 233, 240, 244, 246, 248, 249, 250, 251, 253, 262, 275, 285, 288, 308, 309, 311, 312, 314, 315, 320, 323, 325, 326, 329, 330, 333, 334, 337, 338, 351, 354, 370, 371, 372, 388], "idx": [13, 16, 22, 165, 233, 315, 319], "str": [13, 22, 37, 51, 52, 140, 158, 233, 251], "averagemet": 13, "store": [13, 16, 33, 72, 76, 93, 95, 120, 122, 123, 124, 126, 159, 165, 167, 227, 228, 241, 245, 249, 250, 253, 269, 272, 285, 288, 316, 319, 324, 387], "averag": [13, 24, 37, 41, 44, 53, 126, 165, 213, 217, 220, 233, 238, 241, 244, 253, 264, 281, 314], "fmt": 13, "reset": [13, 37, 59, 72, 123, 251, 362], "val": [13, 41, 58, 66, 68, 106, 126, 131, 134, 135, 138, 139, 142, 143, 145, 146, 147, 148, 150, 165, 233, 272, 273, 277, 354, 355, 362, 367], "avg": [13, 14, 46], "sum": [13, 24, 59, 72, 158, 228, 233, 244, 275, 281, 298, 313], "updat": [13, 16, 18, 21, 37, 43, 44, 53, 59, 72, 107, 108, 109, 111, 112, 113, 126, 130, 140, 141, 144, 147, 156, 159, 165, 169, 227, 240, 248, 251, 253, 259, 264, 273, 285, 288, 290, 293, 296, 298, 308, 309, 310, 311, 313, 319, 320, 328, 332, 353, 371, 378, 385, 386], "__str__": 13, "fmtstr": 13, "__dict__": [13, 140], "target": [13, 14, 21, 22, 24, 26, 38, 44, 51, 52, 66, 67, 68, 121, 122, 126, 131, 134, 135, 138, 139, 145, 146, 147, 148, 150, 155, 158, 159, 167, 209, 219, 220, 232, 239, 241, 244, 249, 250, 264, 272, 273, 276, 285, 288, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 362, 367, 388], "topk": [13, 19, 21, 26, 37, 58, 60, 62, 63, 66, 72, 131, 134, 135, 139, 145, 146, 147, 148, 150, 187, 250, 269, 354, 355, 367, 388], "k": [13, 37, 44, 66, 131, 133, 134, 135, 139, 145, 146, 147, 148, 150, 153, 228, 231, 232, 241, 244, 250, 251, 272, 275, 298, 313, 354, 355], "top": [13, 37, 52, 54, 66, 130, 131, 133, 134, 135, 139, 145, 146, 147, 148, 150, 153, 157, 205, 233, 241, 245, 247, 248, 250, 251, 252, 253, 254, 259, 269, 281, 337, 354, 355], "specifi": [13, 18, 25, 26, 28, 37, 41, 46, 52, 53, 66, 67, 68, 119, 120, 121, 122, 123, 124, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 154, 155, 158, 160, 165, 169, 186, 187, 219, 240, 242, 244, 246, 248, 249, 251, 253, 272, 273, 276, 290, 291, 292, 294, 296, 298, 299, 300, 301, 304, 308, 309, 310, 311, 313, 315, 324, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 373, 383], "no_grad": [13, 194, 225, 244, 333, 370], "maxk": 13, "pred": [13, 37, 253], "eq": 13, "expand_a": 13, "re": [13, 32, 53, 155, 156, 157, 158, 159, 165, 169, 186, 200, 206, 210, 212, 233, 240, 241, 244, 248, 249, 250, 251, 256, 272, 275, 284, 285, 286, 288, 317, 362], "correct_k": 13, "keepdim": 13, "mul_": 13, "100": [13, 15, 21, 22, 26, 32, 33, 46, 52, 53, 54, 58, 60, 61, 66, 68, 72, 120, 130, 131, 134, 135, 139, 148, 156, 157, 165, 167, 168, 184, 187, 232, 235, 238, 241, 242, 244, 247, 248, 250, 253, 268, 273, 290, 295, 305, 306, 316, 328, 334, 337, 354, 355, 356, 357, 359, 360, 361, 362, 366, 367, 388], "criterion": [13, 14, 24, 32, 44, 46, 53, 148, 150, 295, 305, 354, 367, 388], "data_load": [13, 14, 15], "neval_batch": [13, 14], "top1": [13, 14, 46], "2f": [13, 14], "top5": [13, 14], "cnt": [13, 14, 24, 148, 150], "acc1": 13, "acc5": 13, "print": [13, 14, 18, 24, 26, 37, 53, 59, 69, 70, 71, 116, 117, 123, 126, 140, 143, 148, 150, 156, 159, 160, 165, 167, 169, 176, 193, 195, 219, 233, 242, 246, 248, 250, 251, 263, 285, 288, 315, 337, 351, 357], "load_model": [13, 66], "model_fil": [13, 117, 366], "state_dict": [13, 26, 51], "load_state_dict": 13, "cpu": [13, 14, 15, 20, 31, 34, 38, 43, 45, 47, 51, 55, 68, 70, 71, 118, 144, 145, 146, 147, 152, 153, 155, 159, 160, 165, 169, 186, 197, 224, 251, 272, 285, 288, 290, 292, 296, 298, 301, 308, 309, 310, 311, 313, 319, 327, 329, 330, 333, 355, 370], "print_size_of_model": 13, "temp": 13, "p": [13, 18, 120, 121, 137, 138, 140, 152, 153, 157, 168, 186, 191, 251, 252, 253, 264, 299, 314, 317, 319, 321, 357, 358], "mb": [13, 160, 219], "getsiz": 13, "1e6": 13, "num_calibration_batch": 13, "mymodel": [13, 155], "saved_model_dir": 13, "float_model_fil": 13, "start": [13, 35, 51, 52, 55, 59, 119, 120, 121, 124, 126, 157, 158, 159, 162, 164, 165, 186, 190, 193, 200, 219, 224, 231, 232, 233, 240, 241, 247, 249, 250, 251, 252, 264, 270, 272, 273, 282, 285, 288, 295, 305, 317, 384, 386, 388], "min": [13, 17, 18, 46, 52, 140, 157, 168, 205, 219, 244, 258, 277, 319, 328], "per": [13, 15, 16, 18, 32, 43, 47, 54, 68, 124, 126, 130, 144, 165, 227, 233, 238, 244, 248, 250, 253, 256, 264, 272, 273, 275, 314, 319, 328, 359, 361, 362, 388], "qconfig": [13, 14, 51, 296], "default_qconfig": [13, 296], "calibr": [13, 15, 16, 21, 33, 34, 46, 53, 58, 60, 64, 66, 67, 68, 72, 73, 118, 131, 134, 135, 139, 145, 146, 147, 148, 153, 290, 296, 298, 308, 309, 310, 311, 313, 315, 323, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 383], "fusion": [13, 15, 131, 134, 135, 139, 142, 143, 145, 148, 153, 193, 327, 329], "data_loader_test": [13, 14], "num_eval_batch": [13, 14], "d": [13, 14, 24, 33, 70, 71, 155, 156, 157, 161, 168, 169, 186, 228, 232, 241, 250, 251, 263, 271, 272, 273, 276, 279, 281, 299, 314, 315, 329, 360, 365], "eval_batch_s": [13, 14, 273, 356], "functool": 13, "partial": [13, 46, 247, 281], "minmaxobserv": 13, "reduce_rang": 13, "dtype": [13, 15, 21, 22, 51, 52, 53, 117, 138, 165, 248, 250, 296, 356, 357, 362, 370, 383, 388], "qint8": 13, "qscheme": 13, "per_tensor_symmetr": 13, "convrelu2d": 13, "activation_post_process": [13, 51], "min_val": 13, "max_val": 13, "quantizedconvrelu2d": 13, "scale": [13, 14, 17, 28, 46, 52, 73, 130, 136, 140, 157, 159, 161, 168, 186, 188, 194, 195, 196, 200, 203, 204, 206, 212, 215, 216, 217, 218, 220, 222, 223, 225, 226, 231, 232, 233, 237, 238, 241, 245, 249, 264, 271, 275, 285, 288, 300, 316, 328], "15583468973636627": 13, "zero_point": [13, 249], "quantizedconv2d": 13, "19358506798744202": 13, "74": [13, 31, 48, 54, 130, 140, 264, 277, 328], "631847": 13, "300": [13, 21, 130, 131, 133, 135, 145, 146, 147, 262, 290, 296, 298, 308, 309, 310, 311, 312, 313, 319, 326], "67": [13, 54, 130, 233, 264, 277, 300], "significantli": [13, 38, 44, 136, 186, 199, 201, 202, 209, 211, 218, 230, 238, 241, 277], "lower": [13, 17, 25, 44, 45, 46, 52, 72, 157, 168, 186, 188, 199, 210, 215, 219, 221, 229, 235, 241, 247, 273, 275, 318, 324], "62": [13, 48, 54, 130, 136, 221, 264], "same": [13, 15, 19, 21, 22, 24, 26, 43, 46, 51, 52, 53, 69, 70, 71, 119, 120, 121, 126, 130, 140, 155, 156, 157, 159, 164, 165, 167, 168, 184, 186, 188, 194, 197, 198, 206, 210, 217, 219, 220, 222, 224, 226, 227, 228, 230, 232, 237, 238, 240, 241, 242, 244, 246, 247, 248, 249, 250, 251, 252, 254, 256, 258, 262, 264, 267, 272, 273, 276, 277, 285, 288, 292, 293, 301, 308, 309, 311, 312, 316, 318, 319, 320, 324, 357, 358, 373, 377, 381], "nevertheless": [13, 14], "did": [13, 126, 156, 264, 273, 281], "reduc": [13, 15, 16, 21, 25, 38, 45, 46, 47, 53, 58, 60, 70, 71, 126, 131, 134, 135, 139, 156, 157, 167, 168, 186, 204, 210, 217, 222, 224, 228, 241, 249, 250, 251, 252, 269, 271, 273, 277, 319, 354, 355, 362, 367], "almost": [13, 159, 186, 215, 245, 252, 285, 288, 319], "decreas": [13, 250, 269, 271], "improv": [13, 16, 20, 32, 44, 46, 47, 53, 54, 69, 126, 130, 140, 148, 151, 155, 156, 157, 159, 168, 186, 188, 192, 195, 196, 197, 198, 199, 201, 202, 209, 210, 211, 213, 218, 220, 225, 228, 230, 233, 234, 236, 238, 241, 250, 251, 252, 258, 261, 269, 273, 275, 285, 288, 319, 370], "repeat": [13, 53, 165, 188, 247, 252, 253, 383], "exercis": [13, 156], "recommend": [13, 15, 16, 21, 44, 53, 56, 69, 70, 71, 121, 126, 139, 147, 158, 159, 160, 165, 186, 224, 228, 231, 232, 246, 247, 249, 253, 284, 285, 288, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 313, 319, 329, 330, 333, 334, 354, 355, 362, 363, 364, 365, 367, 378, 388], "x86": [13, 38, 130, 354], "basi": [13, 126, 250, 251], "histogram": [13, 27, 51, 145, 146, 254], "collect": [13, 46, 51, 53, 157, 165, 215, 233, 251, 272, 281, 303, 308, 309, 311, 312], "pick": [13, 121, 157, 168, 233, 240, 248, 251, 252, 379, 382], "paramet": [13, 14, 16, 18, 21, 22, 26, 28, 34, 37, 44, 46, 50, 52, 53, 64, 73, 76, 93, 95, 126, 130, 133, 148, 150, 156, 159, 160, 165, 167, 186, 187, 188, 195, 196, 197, 199, 200, 202, 204, 212, 218, 220, 221, 224, 227, 228, 233, 236, 241, 242, 245, 247, 249, 251, 253, 254, 257, 264, 272, 273, 277, 285, 288, 293, 295, 305, 319, 362, 378, 384, 388], "manner": [13, 24, 39], "per_channel_quantized_model": 13, "get_default_qconfig": 13, "fbgemm": [13, 14, 17, 118], "jit": [13, 51, 130, 159, 249, 285, 288, 334, 370, 375], "script": [13, 26, 34, 45, 57, 58, 60, 62, 63, 67, 68, 70, 71, 94, 96, 97, 99, 100, 103, 105, 116, 117, 118, 122, 126, 130, 135, 136, 144, 155, 157, 159, 161, 164, 168, 184, 186, 190, 200, 206, 211, 212, 224, 233, 240, 248, 249, 250, 251, 253, 254, 256, 257, 258, 262, 263, 264, 267, 268, 269, 272, 275, 278, 283, 285, 288, 293, 297, 303, 314, 315, 319, 324, 325, 334, 341, 345, 354, 355, 356, 357, 358, 360, 362, 363, 366, 367, 368, 370, 372, 375, 378], "scripted_quantized_model_fil": 13, "histogramobserv": 13, "perchannelminmaxobserv": 13, "per_channel_symmetr": 13, "76": [13, 31, 54, 130, 137, 140, 218, 258, 269, 274, 328], "increas": [13, 23, 34, 69, 70, 71, 126, 156, 162, 167, 186, 188, 228, 241, 250, 252, 271, 273, 370], "qat": [14, 25, 26, 27, 34, 40, 46, 56, 148, 150, 292, 300, 301, 312, 326, 352], "simul": [14, 275], "dure": [14, 27, 38, 39, 41, 42, 44, 46, 51, 56, 66, 67, 69, 121, 122, 123, 124, 126, 131, 134, 135, 140, 145, 146, 148, 150, 153, 154, 157, 159, 165, 167, 185, 186, 187, 204, 211, 214, 228, 233, 234, 241, 242, 246, 249, 251, 253, 256, 272, 275, 285, 288, 295, 300, 305, 306, 315, 319, 320, 327, 362, 368], "backward": [14, 16, 24, 26, 44, 46, 49, 148, 150, 160, 165, 187, 193, 233, 241, 253, 295, 305], "mimic": [14, 46, 250, 286], "still": [14, 46, 47, 126, 155, 156, 159, 186, 217, 227, 228, 232, 233, 235, 240, 241, 244, 246, 248, 249, 250, 251, 254, 256, 258, 269, 273, 279, 285, 288, 328], "thu": [14, 46, 70, 71, 126, 155, 156, 159, 167, 185, 186, 199, 218, 222, 231, 241, 249, 251, 252, 264, 269, 275, 285, 288, 316, 319, 359, 388], "made": [14, 15, 46, 49, 118, 140, 155, 156, 158, 159, 187, 201, 202, 231, 233, 236, 250, 251, 277, 285, 288, 312, 323, 326, 328, 334], "fact": [14, 46, 155, 162, 186, 245, 274, 341], "ultim": [14, 46], "yield": [14, 46, 53, 159, 167, 231, 233, 244, 250, 257, 258, 277, 285, 288, 315, 327, 329, 330, 333, 359, 362], "either": [14, 38, 42, 46, 120, 155, 156, 158, 159, 160, 165, 167, 176, 177, 180, 185, 186, 187, 198, 209, 220, 229, 240, 241, 245, 248, 250, 251, 253, 272, 273, 279, 280, 285, 286, 288, 373], "dynam": [14, 15, 21, 24, 27, 34, 45, 54, 56, 97, 98, 99, 100, 102, 104, 105, 157, 162, 168, 199, 213, 241, 249, 256, 263, 290, 298, 308, 309, 310, 311, 313, 370, 373, 374, 375, 378], "training_func_for_nc": [14, 148, 150], "epoch": [14, 16, 24, 26, 44, 67, 126, 127, 128, 129, 138, 148, 150, 165, 233, 241, 253, 256, 258, 273, 277, 293, 295, 305, 314, 328, 334, 356], "sgd": [14, 148, 150, 314], "lr": [14, 26, 67, 121, 127, 128, 129, 138, 144, 148, 150, 165, 186, 187, 233, 253, 318], "0001": [14, 119, 120, 122, 148, 150, 314, 364, 388], "nepoch": [14, 24, 148, 150], "train_load": [14, 26, 148, 150, 165], "zero_grad": [14, 24, 26, 44, 148, 150, 165, 233, 295, 305], "break": [14, 24, 26, 150, 156, 158, 159, 187, 233, 244, 251, 264, 285, 288, 290, 298, 308, 310, 313], "freez": [14, 44, 148, 150, 269, 354, 370], "disable_observ": [14, 148, 150], "norm": [14, 148, 150], "varianc": [14, 148, 150], "intrins": [14, 134, 135, 139, 148, 150, 153, 329], "freeze_bn_stat": [14, 148, 150], "get_default_qat_qconfig": 14, "final": [14, 16, 41, 44, 46, 49, 53, 126, 152, 153, 156, 159, 186, 210, 213, 216, 230, 238, 240, 241, 247, 248, 251, 253, 254, 273, 277, 285, 288, 290, 298, 308, 310, 313, 316, 354, 363, 371], "alreadi": [14, 15, 18, 22, 34, 116, 121, 123, 124, 126, 155, 156, 159, 160, 169, 186, 191, 194, 225, 233, 240, 246, 251, 253, 261, 264, 272, 285, 288, 310, 332, 356, 357, 379, 382], "hook": [14, 24, 44, 51, 360], "prepare_qat": 14, "high": [14, 22, 31, 35, 45, 53, 121, 123, 126, 130, 155, 157, 168, 184, 195, 196, 221, 224, 238, 241, 269, 276, 277], "accur": [14, 160, 162, 231, 273, 328], "switch": [14, 51, 130, 245, 248, 273, 276, 283, 370], "match": [14, 24, 28, 119, 121, 126, 130, 144, 156, 157, 159, 165, 186, 187, 190, 218, 230, 249, 269, 272, 276, 277, 285, 288, 306, 319], "zero": [14, 17, 44, 52, 53, 73, 233, 249, 264, 316, 328], "num_train_batch": 14, "train_one_epoch": 14, "qat_model": 14, "devic": [14, 15, 24, 44, 55, 133, 159, 160, 165, 168, 204, 221, 224, 231, 244, 253, 269, 275, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 315, 319, 325, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 371], "quantized_model": [14, 58, 60, 61, 62, 63, 65, 72, 145, 146, 315], "q_func": [14, 15, 16, 53, 148, 150], "eval_dataload": [14, 16, 21, 33, 53, 59, 66, 67, 68, 72, 145, 148, 150, 296, 309, 311, 329, 356, 362], "val_load": [14, 46, 148, 150], "timeout": [14, 15, 28, 50, 53, 66, 67, 68, 72, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 388], "constrain": [14, 66, 67, 68, 131, 134, 135, 145, 146, 148, 150, 153, 204, 249, 315, 327, 354, 362, 368], "71": [14, 31, 54, 133, 140, 145, 146, 258, 277], "close": [14, 120, 123, 126, 130, 159, 203, 241, 245, 249, 250, 273, 275, 277, 285, 288], "debug": [14, 18, 27, 53, 126, 156, 159, 160, 179, 377, 381], "analyz": [14, 44, 50, 51, 195, 196, 200, 248, 303], "limit": [14, 20, 24, 27, 44, 51, 131, 134, 135, 139, 142, 143, 145, 153, 156, 157, 168, 186, 187, 188, 195, 196, 198, 216, 217, 221, 222, 227, 232, 234, 235, 239, 240, 241, 244, 245, 256, 282, 296, 327, 329], "sinc": [14, 24, 28, 37, 42, 130, 156, 157, 159, 164, 165, 167, 169, 171, 182, 184, 186, 191, 210, 217, 219, 222, 233, 240, 241, 244, 246, 248, 251, 252, 272, 273, 275, 283, 285, 288, 306, 378], "actual": [14, 26, 126, 186, 233, 241, 285, 288, 362], "arithmet": [14, 214], "easili": [14, 15, 41, 44, 121, 126, 156, 157, 159, 162, 165, 179, 200, 228, 245, 248, 249, 251, 253, 254, 256, 267, 269, 279, 282, 285, 288, 319, 373], "relat": [14, 58, 60, 62, 63, 131, 134, 135, 139, 145, 146, 147, 148, 150, 155, 167, 168, 186, 233, 241, 245, 251, 254, 276, 315, 327, 329, 354, 355, 360, 361, 370], "onnx": [15, 16, 27, 29, 31, 34, 38, 39, 45, 46, 55, 117, 130, 168, 282, 375, 385], "runtim": [15, 16, 27, 28, 29, 31, 34, 46, 55, 249, 277, 357, 358, 375], "bridg": [15, 34, 250], "vanilla": [15, 34, 191, 234], "complet": [15, 18, 53, 54, 126, 140, 148, 157, 158, 159, 162, 186, 187, 220, 224, 241, 248, 250, 251, 253, 264, 284, 285, 286, 288, 327, 332, 354, 367], "subclass": [15, 53, 165, 171, 176, 182, 186, 251], "packag": [15, 16, 18, 30, 31, 35, 49, 53, 126, 130, 136, 137, 139, 168, 169, 184, 186, 251, 254, 272, 286, 290, 297, 298, 308, 309, 310, 311, 319, 320, 359], "adaptor_registri": 15, "abc": [15, 51, 53, 388], "abcadaptor": 15, "framework_specific_info": 15, "tune_cfg": 15, "postprocess": [15, 16, 19, 21, 51, 52, 72, 118, 122, 126, 273, 357], "query_fw_cap": [15, 53], "query_fused_pattern": 15, "awar": [15, 16, 25, 26, 27, 34, 38, 40, 42, 54, 56, 143, 148, 150, 156, 160, 183, 211, 269, 292, 295, 300, 301, 305], "he": [15, 136, 157, 168, 186, 201, 202, 233, 272, 314], "intersect": [15, 37], "graph": [15, 16, 22, 24, 26, 27, 33, 37, 39, 46, 47, 51, 59, 60, 67, 68, 249, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 370, 384], "decid": [15, 28, 49, 53, 66, 131, 134, 135, 139, 153, 156, 159, 160, 241, 285, 288, 319, 354, 355, 362, 367], "besid": [15, 20, 24, 42, 159, 224, 251, 273, 285, 288], "op": [15, 18, 32, 38, 46, 47, 49, 51, 53, 59, 131, 134, 135, 139, 142, 143, 145, 146, 148, 153, 323, 327, 329, 359, 361, 383, 388], "sequenc": [15, 22, 52, 130, 157, 158, 162, 167, 168, 171, 190, 191, 193, 199, 200, 203, 206, 207, 209, 210, 211, 212, 216, 217, 220, 224, 226, 227, 228, 231, 232, 233, 234, 237, 239, 242, 244, 246, 248, 249, 251, 253, 256, 264, 272, 275, 277, 281, 288, 359], "past": [15, 126, 156, 159, 187, 191, 200, 212, 251, 285, 288], "abov": [15, 19, 32, 44, 70, 71, 116, 118, 120, 121, 122, 123, 124, 126, 130, 145, 148, 152, 153, 156, 158, 159, 160, 165, 169, 186, 228, 233, 241, 244, 246, 249, 250, 251, 252, 253, 254, 258, 273, 276, 277, 285, 288, 320, 323, 334, 341, 357, 358, 383, 386], "hidden": [15, 44, 123, 161, 167, 171, 188, 206, 210, 218, 234, 241, 245, 247, 248, 250, 264, 273], "corner": [15, 52, 156, 215], "effect": [15, 44, 121, 126, 159, 162, 190, 197, 206, 207, 211, 215, 216, 232, 233, 236, 269, 282, 285, 288], "mainten": [15, 159, 285, 288], "difficult": [15, 156, 159, 285, 288], "correspond": [15, 16, 44, 46, 50, 53, 121, 122, 126, 159, 160, 165, 167, 179, 182, 185, 186, 215, 232, 233, 235, 240, 241, 246, 250, 251, 252, 267, 272, 273, 275, 276, 277, 280, 281, 285, 288, 295, 305, 328, 345], "abil": [15, 21, 159, 227, 244, 285, 288], "clear": [15, 37, 285, 288, 332], "fragment": [15, 186, 234], "field": [15, 16, 18, 19, 26, 28, 32, 53, 66, 67, 68, 121, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 161, 191, 233, 241, 249, 290, 296, 298, 308, 309, 310, 311, 313, 315, 319, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "enumer": [15, 26, 44, 51, 165, 233, 295, 305, 315, 330], "scenario": [15, 16, 18, 19, 24, 32, 44, 117], "doesn": [15, 19, 21, 26, 58, 60, 62, 63, 66, 69, 131, 134, 135, 139, 155, 156, 159, 190, 204, 206, 209, 217, 222, 230, 241, 251, 258, 273, 279, 285, 288, 354, 355, 367], "bf16": [15, 32, 38, 47, 53, 70, 71, 116, 375, 378, 388], "granular": [15, 34, 44, 53, 58, 273, 356, 357, 359, 360, 361, 371], "scheme": [15, 21, 53, 120, 121, 190, 191, 209, 213, 214, 230, 234], "semant": [15, 211, 218, 229, 233, 367], "pattern": [15, 22, 34, 42, 54, 56, 131, 134, 135, 139, 145, 148, 153, 154, 239, 251, 272, 292, 294, 295, 301, 304, 305, 327, 329], "common_precis": 15, "uint8": [15, 17, 22, 46, 52, 53], "valid_mixed_precis": 15, "common_op": 15, "matmul": [15, 217, 228, 295, 305, 356, 357], "concatv2": 15, "maxpool": 15, "avgpool": 15, "depthwiseconv2dn": 15, "todo": [15, 285], "common_cap": 15, "ref_2_4_int8": 15, "sym": [15, 53], "per_channel": [15, 53, 58, 356, 357, 359, 360, 361], "per_tensor": [15, 53], "minmax": [15, 53, 58, 354, 355, 362], "kl": [15, 53, 271, 306], "asym": [15, 53], "ref_2_4_uint8": 15, "common_pattern": 15, "demonstr": [15, 29, 31, 32, 40, 44, 51, 58, 59, 60, 61, 62, 63, 64, 65, 72, 118, 124, 136, 145, 146, 154, 155, 156, 157, 162, 165, 193, 197, 204, 206, 208, 211, 212, 216, 218, 220, 223, 231, 235, 236, 244, 272, 355, 370], "concept": [15, 16, 33, 50, 116, 168, 204, 218], "extern": [15, 18, 154, 187, 215, 249, 251, 272, 321], "biasadd": [15, 388], "addn": 15, "addv2": 15, "abstract": [15, 16, 33, 72, 157, 158, 159, 168, 184, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 245, 250, 262, 285, 287, 288, 328], "querybackendcap": 15, "tensorflowqueri": 15, "look": [15, 37, 41, 119, 120, 121, 126, 156, 158, 159, 160, 161, 165, 169, 182, 186, 232, 241, 248, 249, 252, 254, 264, 269, 272, 273, 281, 285, 288, 292, 301, 328], "microsoft": [15, 157, 168, 186, 201, 202, 233, 247, 290, 314], "mla": [15, 17], "kernel": [15, 43, 44, 53, 121, 126], "becom": [15, 72, 159, 187, 188, 204, 208, 241, 250, 252, 269, 285, 288], "integr": [15, 18, 66, 67, 68, 116, 118, 121, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 157, 159, 162, 168, 219, 239, 251, 270, 285, 288, 315, 327, 354], "explor": [15, 126, 157, 165, 168, 227, 232, 241, 246, 249, 269, 293, 357, 358], "attribut": [15, 16, 33, 38, 140, 159, 171, 182, 185, 200, 218, 224, 242, 248, 250, 253, 285, 288, 316, 388], "whether": [15, 22, 37, 52, 76, 93, 95, 121, 126, 156, 165, 168, 206, 233, 250, 251, 254, 272, 275, 281, 285], "qlinear": [15, 54, 375], "qdq": [15, 34, 46, 56, 76, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 100, 102, 104, 105, 107, 108, 109, 110, 114, 115], "integ": [15, 27, 46, 53, 120, 126, 158, 159, 165, 185, 187, 214, 233, 246, 248, 249, 251, 271, 285, 288, 292, 301], "qtype": 15, "choic": [15, 18, 22, 37, 121, 122, 123, 124, 126, 140, 159, 162, 179, 187, 195, 196, 210, 230, 241, 250, 251, 254, 259, 273, 285, 288], "float32": [15, 19, 22, 46, 52, 59, 72, 130, 138, 159, 248, 249, 285, 288, 388], "node": [15, 18, 26, 51, 70, 71, 126, 132, 144, 186, 264, 272, 275, 292, 301, 337, 338, 351], "exclud": [15, 251], "three": [15, 18, 21, 32, 35, 38, 42, 46, 47, 50, 51, 53, 120, 122, 123, 124, 126, 131, 134, 135, 139, 145, 146, 147, 153, 157, 158, 160, 164, 165, 168, 194, 213, 218, 219, 224, 227, 233, 241, 245, 246, 252, 263, 277, 288, 307, 315, 327, 328, 354, 355, 378], "onnxrt": [15, 97, 100, 105, 388], "mul": 15, "clip": [15, 187], "leakyrelu": 15, "gather": [15, 248, 272], "sigmoid": [15, 314, 368], "embedlayernorm": 15, "fusedconv": 15, "globalaveragepool": 15, "ref_1_6": 15, "key_1_6_0": 15, "graph_optim": [15, 32], "default_optim": 15, "graph_optimization_level": 15, "enable_extend": 15, "disable_al": 15, "enable_bas": 15, "enable_al": 15, "onnxrt_qlinearopsadaptor": 15, "dump_elapsed_tim": 15, "recov": [15, 25, 210, 271, 273], "q_config": 15, "inspect_tensor": 15, "op_list": [15, 51], "iteration_list": 15, "inspect_typ": 15, "save_to_disk": 15, "save_path": [15, 39, 267, 273], "quantization_cfg": 15, "set_tensor": 15, "tensor_dict": 15, "input_graph": [15, 354, 355, 360, 362, 363, 367], "fp32_baselin": 15, "diagnosis_help": 15, "fp32_model": [15, 21, 66, 146, 153, 315, 384], "int8_model": [15, 153], "fw": 15, "mandatori": [15, 28, 66, 67, 68, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 153, 159, 277, 285, 288, 290, 292, 296, 298, 301, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "onnxrt_qlinearop": [15, 66, 73], "accuracy_criterion": [15, 16, 28, 41, 50, 53, 64, 66, 67, 68, 72, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368], "rel": [15, 28, 50, 53, 54, 66, 67, 68, 72, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 165, 167, 198, 201, 202, 232, 233, 234, 238, 241, 249, 251, 273, 288, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 363, 367, 368, 388], "exit_polici": [15, 28, 50, 53, 66, 67, 68, 72, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 290, 296, 298, 308, 309, 310, 311, 313, 315, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 388], "max_trial": [15, 28, 53, 66, 131, 134, 135, 139, 153, 290, 296, 298, 308, 309, 310, 311, 313, 315, 354, 355, 356, 357, 359, 360, 361, 362, 367, 388], "post_training_static_qu": [15, 28, 53, 73, 290, 296, 311, 315], "op_wis": [15, 51, 53, 296, 356, 357, 362, 383], "calib_iter": 15, "op1": 15, "op2": 15, "op3": 15, "pars": [15, 52, 117, 157, 168, 198, 208, 225, 233, 272, 281, 383], "onnxquant": 15, "verifi": [15, 123, 126, 130, 135, 147, 156, 159, 215, 240, 285, 288], "wise": [15, 18, 21, 34, 44, 51, 53, 56, 58, 60, 131, 134, 135, 139, 140, 251, 295, 305, 354, 355, 362, 367, 383], "conv1": [15, 53], "conv2": [15, 53], "whole": [15, 18, 28, 46, 54, 56, 66, 68, 72, 117, 118, 126, 156, 159, 167, 199, 213, 227, 241, 247, 250, 251, 254, 258, 285, 288, 296, 297], "deploi": [16, 24, 53, 55, 59, 156, 167, 186, 221, 231, 288, 367], "recip": [16, 27, 53, 157, 168, 195, 196, 227], "memori": [16, 21, 25, 27, 38, 41, 44, 46, 53, 121, 126, 130, 160, 167, 186, 188, 199, 214, 217, 227, 228, 234, 241, 244, 249, 252, 255, 258, 269, 272, 273, 275, 319, 329, 330, 333, 370], "usag": [16, 18, 22, 26, 27, 29, 31, 32, 37, 40, 41, 52, 66, 67, 68, 70, 71, 96, 97, 100, 105, 131, 132, 134, 135, 139, 145, 146, 147, 148, 150, 153, 157, 160, 167, 168, 186, 193, 197, 198, 200, 211, 212, 230, 238, 242, 250, 251, 266, 278, 290, 298, 306, 308, 312, 313, 315, 323, 327, 329, 330, 333, 334, 354, 355, 356, 357, 358, 362, 363, 367, 368, 370], "intend": [16, 20, 123, 124, 126, 157, 158, 190, 220, 241], "cross": [16, 33, 53, 120, 124, 126, 156, 157, 159, 162, 168, 184, 193, 218, 232, 236, 238, 241, 244, 247, 253, 277, 285, 288, 314], "compat": [16, 26, 31, 39, 49, 59, 122, 124, 126, 130, 140, 159, 186, 193, 253, 269, 275, 285, 288, 320, 362, 379, 382], "locat": [16, 19, 26, 46, 49, 52, 53, 58, 60, 62, 63, 68, 117, 118, 120, 121, 122, 123, 126, 131, 134, 135, 139, 156, 158, 159, 165, 169, 186, 250, 251, 260, 277, 279, 285, 288, 319, 329, 330, 333, 345, 354, 355, 356, 357, 358, 360, 362, 363, 366, 367, 368, 371, 377, 381], "major": [16, 33, 46, 121, 159, 213, 285, 288], "those": [16, 24, 32, 33, 42, 44, 46, 53, 130, 154, 155, 156, 157, 159, 160, 167, 168, 169, 170, 171, 172, 173, 174, 175, 179, 182, 184, 186, 199, 215, 241, 242, 245, 246, 248, 249, 250, 251, 252, 256, 258, 259, 273, 274, 279, 281, 285, 288, 332, 354, 367], "case": [16, 18, 19, 21, 24, 26, 33, 37, 41, 44, 45, 46, 52, 56, 66, 67, 68, 72, 98, 119, 120, 121, 122, 123, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 155, 156, 157, 159, 160, 165, 167, 169, 186, 187, 189, 190, 194, 195, 196, 206, 213, 214, 228, 233, 240, 241, 242, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 262, 264, 270, 277, 279, 280, 281, 285, 286, 288, 290, 292, 296, 298, 301, 308, 309, 310, 311, 313, 315, 319, 327, 329, 330, 332, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 373], "whose": [16, 33, 44, 53, 159, 165, 251, 252, 253, 276, 285, 288], "style": [16, 20, 22, 33, 56, 130, 158, 159, 162, 168, 200, 215, 232, 241, 275, 285, 286, 288, 319, 321], "rather": [16, 33, 156, 157, 159, 165, 167, 168, 188, 192, 200, 203, 206, 211, 212, 221, 231, 233, 241, 244, 251, 256, 269, 270, 272, 285, 288, 332, 354], "refin": [16, 33, 79, 126, 251, 267], "__call__": [16, 21, 140, 158, 159, 185, 220, 246, 249, 250, 253, 285, 288], "properti": [16, 36, 43, 70, 71, 121, 126, 168, 249, 308, 388], "user_postprocess": 16, "eval_func": [16, 19, 21, 22, 26, 38, 46, 53, 58, 60, 62, 63, 66, 67, 68, 131, 134, 135, 139, 145, 153, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 359, 360, 361, 362, 367, 368], "templat": [16, 18, 53, 66, 67, 68, 121, 131, 134, 135, 142, 143, 145, 146, 147, 148, 150, 153, 155, 156, 157, 158, 159, 240, 275, 284, 286, 288, 315, 320, 327, 355], "understand": [16, 46, 51, 121, 156, 157, 159, 161, 162, 167, 168, 184, 187, 191, 192, 193, 197, 199, 204, 206, 208, 210, 211, 213, 215, 218, 222, 231, 232, 233, 236, 238, 239, 241, 248, 250, 264, 277, 281, 285, 288, 303, 331], "most": [16, 18, 38, 44, 46, 53, 66, 67, 68, 121, 123, 126, 130, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 155, 156, 157, 159, 167, 170, 171, 172, 173, 174, 175, 179, 183, 185, 186, 191, 198, 200, 204, 208, 211, 216, 217, 218, 222, 241, 242, 244, 246, 249, 250, 251, 252, 259, 273, 281, 285, 288, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 319, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "helloworld": [16, 22, 52, 72], "__getitem__": [16, 19, 21, 22, 59, 72, 165, 233, 319, 360, 361], "singl": [16, 22, 44, 72, 122, 126, 130, 133, 154, 157, 158, 159, 160, 165, 167, 168, 186, 187, 190, 202, 203, 210, 215, 229, 233, 241, 245, 246, 249, 251, 252, 256, 258, 262, 264, 272, 275, 277, 285, 288, 292, 295, 301, 305, 326], "tupl": [16, 22, 37, 44, 52, 76, 93, 95, 158, 165, 171, 182, 194, 218, 225, 228, 233, 248, 264, 316, 320], "collat": [16, 253], "custom_metr": [16, 33], "mini": [16, 54, 56, 72, 230, 295, 305, 306, 307], "calcul": [16, 22, 37, 41, 44, 46, 50, 53, 59, 73, 168, 214, 228, 249, 253, 272, 273, 308], "invok": [16, 72, 131, 134, 135, 139, 142, 143, 145, 153, 251, 329], "onc": [16, 18, 21, 45, 116, 123, 126, 130, 140, 155, 156, 158, 159, 164, 206, 228, 240, 241, 246, 248, 250, 251, 252, 256, 264, 269, 272, 279, 285, 286, 288, 314, 332], "scalar": [16, 37, 38, 46, 72, 120, 232], "higher_is_bett": [16, 37, 41, 72], "line": [16, 18, 26, 34, 51, 58, 61, 62, 63, 123, 124, 126, 130, 142, 143, 155, 156, 157, 159, 164, 165, 168, 169, 186, 187, 194, 203, 225, 249, 250, 251, 254, 256, 264, 272, 273, 274, 275, 276, 277, 280, 283, 285, 286, 288, 332, 337, 338, 351, 354, 361, 368, 370, 373, 374], "cal_dl": 16, "dir": [16, 22, 30, 33, 67, 118, 131, 134, 135, 136, 138, 139, 142, 143, 145, 146, 147, 148, 150, 153, 251, 257, 268, 290, 296, 298, 303, 308, 310, 317, 328, 335, 356, 359, 361], "kera": [16, 26, 39, 56, 57, 59, 71, 72, 140, 157, 165, 186, 245, 248, 253, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 375], "frozen": [16, 18, 39, 57, 70, 71, 253, 254, 359, 367], "checkpoint": [16, 39, 56, 57, 61, 126, 130, 157, 162, 168, 190, 193, 195, 196, 206, 207, 210, 212, 216, 220, 223, 231, 233, 236, 240, 241, 242, 245, 247, 249, 250, 258, 264, 269, 270, 272, 281, 286, 290, 296, 308, 310, 325, 354, 355, 356, 367], "gluon": [16, 39], "hybirdblock": 16, "instanti": [16, 42, 121, 159, 160, 165, 176, 183, 185, 186, 187, 189, 193, 245, 248, 249, 250, 253, 284, 285, 288], "custom": [16, 24, 27, 44, 50, 56, 57, 66, 67, 68, 72, 120, 121, 124, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 155, 156, 157, 158, 159, 160, 162, 168, 176, 186, 224, 233, 250, 251, 256, 267, 272, 279, 282, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 370, 388], "directli": [16, 37, 46, 51, 56, 121, 126, 130, 155, 156, 157, 159, 160, 167, 168, 186, 187, 189, 193, 199, 202, 210, 228, 240, 241, 244, 246, 248, 250, 251, 252, 263, 264, 269, 280, 285, 288, 355, 372], "execut": [16, 18, 24, 26, 27, 32, 38, 42, 44, 46, 54, 69, 70, 71, 76, 93, 95, 126, 127, 128, 129, 131, 132, 134, 135, 139, 142, 143, 145, 153, 159, 186, 240, 249, 251, 254, 262, 285, 288, 308, 327, 329, 357, 358, 371, 377, 378, 381, 387], "contain": [16, 21, 22, 24, 34, 37, 44, 51, 53, 117, 120, 121, 122, 123, 126, 130, 155, 159, 160, 165, 167, 168, 169, 171, 182, 184, 185, 186, 187, 206, 212, 218, 233, 240, 241, 248, 249, 250, 251, 253, 254, 259, 262, 264, 265, 269, 271, 272, 273, 276, 279, 285, 286, 288, 295, 305, 312, 314, 316, 317, 322, 323, 326, 334, 359, 366], "hyper": [16, 245, 257, 273, 277], "reserv": [16, 200], "special": [16, 31, 37, 41, 72, 158, 159, 165, 167, 168, 185, 186, 193, 220, 221, 241, 246, 248, 250, 251, 252, 258, 279, 285, 288], "had": [16, 187, 246, 251], "leav": [16, 120, 126, 186, 228, 250, 251, 378], "scaler": 16, "some": [16, 18, 28, 31, 35, 37, 41, 44, 46, 47, 51, 53, 120, 121, 126, 130, 142, 143, 145, 146, 155, 156, 157, 158, 159, 161, 167, 168, 169, 176, 186, 188, 190, 191, 195, 197, 199, 206, 212, 224, 233, 238, 240, 241, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 259, 273, 276, 277, 279, 280, 282, 285, 288, 303, 307, 308, 316, 319, 328, 354, 386], "effort": [16, 58, 121, 126, 159, 249, 285, 288], "on_epoch_begin": [16, 44], "on_step_begin": [16, 44, 295, 305], "batch_id": [16, 359], "on_step_end": [16, 44], "on_epoch_end": [16, 24, 44], "proof": [16, 204], "magnitud": [16, 34, 44, 54, 56, 249, 269, 275, 295, 303, 305, 337, 338, 351], "To": [16, 18, 20, 26, 38, 47, 49, 56, 69, 70, 71, 72, 86, 103, 110, 114, 115, 121, 123, 126, 130, 140, 155, 157, 158, 159, 160, 161, 164, 165, 167, 169, 179, 186, 187, 188, 203, 204, 210, 213, 215, 216, 217, 218, 220, 221, 232, 233, 239, 240, 241, 246, 248, 252, 253, 254, 256, 259, 262, 264, 267, 269, 272, 273, 275, 276, 277, 279, 283, 284, 285, 288, 292, 301, 321, 328, 341, 354, 355, 362, 372, 377, 379, 381, 382, 387], "b_dataload": [16, 19, 40, 356], "symmetr": [17, 46, 52, 217, 241], "asymmetr": [17, 46], "ab": [17, 46, 130, 161, 191, 220, 271, 272, 273, 302], "rmin": 17, "rmax": 17, "web": [18, 27, 51, 159, 212, 231, 241, 285, 288], "applic": [18, 45, 51, 52, 126, 155, 156, 159, 198, 207, 213, 215, 231, 241, 246, 250, 251, 269, 285, 288, 339, 340, 342, 343, 344, 346, 347, 348, 349, 350, 370], "easier": [18, 45, 126, 155, 157, 159, 160, 233, 240, 251, 285, 288, 377, 381], "gui": [18, 34, 35, 280], "conda": [18, 30, 31, 35, 49, 126, 130, 168, 187, 254, 293, 297, 317, 320, 325, 371, 378], "forg": [18, 30, 31, 35, 187, 254], "setup": [18, 31, 35, 117, 118, 130, 131, 135, 139, 140, 147, 156, 158, 159, 169, 179, 186, 187, 230, 232, 233, 240, 246, 251, 254, 276, 281, 283, 285, 288, 290, 293, 310, 317, 318, 321, 379, 382], "server": [18, 69, 117, 245], "command": [18, 26, 32, 57, 67, 69, 70, 71, 97, 100, 105, 110, 114, 115, 116, 121, 122, 123, 124, 126, 127, 128, 129, 132, 149, 155, 156, 157, 158, 159, 160, 164, 169, 186, 240, 246, 248, 249, 251, 254, 256, 259, 264, 269, 272, 273, 274, 275, 276, 277, 279, 280, 283, 284, 285, 286, 288, 292, 293, 297, 301, 320, 321, 323, 328, 329, 330, 333, 334, 354, 355, 373, 377, 381, 384, 386], "sign": [18, 46, 50], "tl": [18, 126], "certif": 18, "instruct": [18, 24, 27, 31, 35, 38, 45, 46, 58, 60, 62, 63, 68, 70, 71, 122, 124, 126, 130, 131, 134, 135, 142, 143, 145, 146, 147, 148, 150, 152, 153, 156, 159, 168, 186, 224, 246, 273, 276, 283, 285, 288, 297, 315, 317, 319, 320, 326, 327, 332, 335, 354, 355, 361, 362, 379, 382], "access": [18, 116, 122, 123, 130, 140, 156, 159, 161, 165, 171, 176, 182, 185, 186, 187, 216, 218, 227, 240, 241, 245, 250, 251, 253, 269, 272, 275, 280, 285, 288, 319, 345, 379, 382], "ui": [18, 251, 280], "13": [18, 31, 48, 54, 56, 129, 130, 140, 159, 226, 237, 238, 277, 285, 288, 318, 388], "5000": [18, 258, 388], "token": [18, 22, 37, 50, 52, 53, 116, 155, 157, 158, 162, 168, 171, 180, 182, 184, 190, 192, 193, 194, 195, 197, 200, 201, 202, 203, 204, 206, 209, 210, 211, 212, 213, 215, 216, 217, 219, 220, 221, 222, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 236, 237, 239, 240, 241, 242, 244, 245, 247, 249, 250, 251, 253, 254, 256, 258, 264, 267, 272, 273, 275, 281, 282, 286, 293, 296, 308, 309, 311, 312, 359], "338174d13706855fc6924cec7b3a8ae8": 18, "trust": [18, 156, 388], "browser": [18, 156, 158, 377, 381], "listen": [18, 195, 196], "port": [18, 126, 219, 273, 328], "firewal": 18, "8080": 18, "cert": 18, "kei": [18, 51, 121, 126, 165, 167, 171, 182, 186, 187, 200, 208, 212, 217, 224, 228, 230, 231, 233, 238, 241, 246, 248, 258, 270, 276, 290, 295, 298, 305, 308, 310, 313, 319], "path_to_cert": 18, "crt": 18, "path_to_private_kei": 18, "encrypt": 18, "insecur": 18, "connect": [18, 44, 50, 155, 159, 218, 231, 249, 269, 285, 288, 295, 305], "machin": [18, 31, 35, 45, 51, 138, 157, 167, 168, 184, 190, 193, 195, 196, 220, 236, 241, 247, 249, 251, 252, 371], "local": [18, 50, 69, 70, 71, 121, 140, 155, 156, 158, 159, 168, 169, 177, 180, 185, 186, 199, 202, 216, 217, 226, 237, 240, 241, 245, 248, 249, 251, 285, 288, 295, 305, 310, 315, 317, 320, 377, 381], "internet": [18, 22, 155], "expos": [18, 157, 168, 245], "forfeit": 18, "client": [18, 70, 71, 283], "threat": 18, "button": [18, 34, 155, 156, 159, 240, 285, 288, 378], "pop": [18, 165, 186], "choos": [18, 31, 34, 49, 53, 66, 70, 71, 120, 126, 131, 134, 135, 136, 145, 146, 147, 148, 150, 155, 156, 157, 159, 168, 233, 252, 253, 261, 270, 273, 285, 286, 288, 295, 305, 354, 355, 367], "second": [18, 28, 41, 53, 66, 67, 68, 70, 71, 120, 126, 131, 134, 135, 139, 153, 156, 157, 158, 159, 165, 167, 176, 184, 186, 193, 201, 202, 210, 219, 231, 233, 241, 246, 248, 249, 251, 252, 264, 274, 276, 277, 281, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 318, 323, 329, 330, 333, 334, 354, 355, 362, 367, 377, 381, 388], "possibl": [18, 28, 32, 42, 47, 53, 66, 117, 121, 126, 131, 134, 135, 139, 140, 145, 148, 153, 155, 156, 157, 159, 186, 204, 213, 228, 238, 245, 246, 250, 251, 252, 254, 264, 273, 275, 285, 288, 316, 319, 320, 327, 329, 332], "domain": [18, 44, 53, 56, 126, 156, 157, 168, 195, 196, 203, 205, 209, 212, 213, 227, 229, 241, 250, 385], "recognit": [18, 26, 51, 56, 58, 60, 62, 63, 79, 131, 134, 135, 139, 145, 146, 147, 148, 150, 157, 165, 168, 183, 194, 198, 213, 225, 235, 246, 248, 279, 336, 354, 355, 364, 367, 388], "finish": [18, 53, 70, 71, 124, 126, 152, 153, 159, 272, 273, 285, 286, 288, 378], "chosen": [18, 117, 140], "download": [18, 22, 31, 32, 35, 49, 55, 60, 66, 67, 68, 69, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 126, 131, 134, 135, 136, 139, 140, 142, 143, 145, 146, 147, 148, 150, 152, 153, 155, 157, 164, 165, 177, 180, 185, 211, 224, 245, 246, 248, 251, 260, 262, 263, 272, 273, 274, 276, 293, 297, 303, 315, 319, 321, 323, 325, 329, 330, 333, 334, 335, 336, 345, 354, 355, 361, 364, 367, 368, 388], "synthet": [18, 281], "collaps": 18, "plu": [18, 157, 186, 245, 248, 251, 273], "icon": [18, 156], "unfold": [18, 156], "On": [18, 46, 72, 126, 155, 157, 159, 209, 221, 236, 241, 245, 249, 250, 251, 252, 256, 261, 264, 267, 273, 285, 288], "left": [18, 52, 159, 188, 190, 192, 200, 203, 211, 212, 215, 221, 228, 231, 232, 233, 234, 241, 244, 248, 250, 251, 252, 281, 285, 288, 323, 334, 378], "side": [18, 22, 52, 156, 159, 219, 248, 285, 288, 378], "panel": [18, 379, 382], "navig": [18, 187, 328, 387], "previou": [18, 49, 51, 53, 120, 126, 156, 158, 159, 167, 168, 186, 194, 202, 211, 212, 214, 217, 218, 220, 222, 226, 228, 233, 235, 236, 237, 238, 241, 248, 251, 252, 253, 254, 264, 273, 277, 285, 288, 386], "trash": 18, "visibl": [18, 126, 154, 186, 202, 242, 250, 316], "cursor": 18, "prompt": [18, 26, 116, 241, 248, 250, 286], "confirm": [18, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 194], "revers": [18, 228, 241, 252], "bottom": [18, 123, 158], "There": [18, 24, 34, 37, 38, 70, 71, 73, 123, 126, 140, 155, 156, 159, 160, 161, 169, 183, 186, 189, 190, 220, 233, 241, 248, 251, 263, 264, 273, 285, 288, 354, 355, 368, 370], "even": [18, 44, 126, 158, 159, 169, 186, 187, 214, 249, 250, 251, 253, 261, 264, 269, 272, 274, 275, 285, 288, 319], "exit": [18, 28, 32, 38, 53, 66, 123, 131, 134, 135, 139, 153, 250, 290, 298, 308, 310, 313, 314, 320, 354, 355, 362, 367, 368], "yet": [18, 126, 156, 159, 167, 169, 176, 197, 241, 250, 251, 262, 276, 280, 285, 288, 379, 382], "pencil": 18, "light": [18, 25, 204, 239, 264, 273], "blue": [18, 120, 126, 276], "color": [18, 120, 122, 140], "That": [18, 21, 156, 159, 165, 186, 195, 219, 240, 241, 248, 251, 273, 285, 288, 319], "indic": [18, 19, 30, 51, 121, 155, 156, 158, 165, 167, 204, 217, 222, 230, 233, 241, 245, 246, 250, 259, 272], "befor": [18, 20, 21, 22, 24, 26, 30, 32, 41, 44, 46, 50, 51, 53, 55, 116, 119, 123, 126, 131, 134, 135, 139, 140, 142, 143, 145, 148, 153, 155, 156, 157, 158, 159, 160, 167, 169, 186, 187, 232, 241, 244, 246, 248, 251, 252, 256, 263, 264, 272, 273, 285, 288, 290, 298, 303, 308, 309, 310, 311, 316, 323, 327, 329, 359, 361, 379, 382], "row": [18, 44, 156, 233, 274, 328], "arrow": 18, "checkbox": [18, 116], "column": [18, 44, 165, 233, 272, 276, 277, 279, 300], "compar": [18, 21, 25, 32, 37, 46, 50, 51, 53, 56, 69, 70, 71, 121, 126, 130, 133, 145, 146, 156, 159, 188, 190, 198, 201, 202, 204, 206, 210, 214, 217, 222, 226, 227, 232, 233, 237, 239, 240, 244, 249, 264, 273, 281, 285, 288, 318, 328, 362], "chart": [18, 46, 50, 51], "core": [18, 36, 43, 48, 54, 62, 63, 117, 118, 155, 159, 160, 214, 248, 251, 254, 272, 277, 281, 285, 288, 322, 359, 361, 377, 381, 388], "ad": [18, 32, 38, 51, 72, 126, 130, 155, 157, 159, 160, 161, 165, 167, 180, 185, 186, 193, 204, 209, 220, 233, 240, 241, 246, 248, 250, 251, 252, 267, 272, 281, 284, 285, 288, 323, 332, 334, 362, 373, 379, 382, 388], "fill": [18, 50, 52, 159, 168, 242, 248, 249, 250, 273, 284, 285, 286, 288], "link": [18, 22, 54, 56, 98, 102, 117, 118, 126, 136, 155, 156, 158, 159, 169, 200, 219, 240, 241, 254, 262, 264, 271, 272, 273, 274, 280, 285, 287, 288, 293, 297, 315, 317, 318, 323, 337, 351, 354, 377, 381], "highlight": [18, 159, 165, 230, 282, 285, 288], "thread": [18, 21, 43, 126, 156, 251, 359, 361, 388], "form": [18, 24, 121, 162, 165, 181, 199, 215, 229, 232, 233, 241, 252, 281], "bar": [18, 70, 71, 155, 156], "offer": [18, 22, 157, 159, 183, 250, 252, 285, 288], "conveni": [18, 126, 165, 240, 253, 273, 275, 316], "easi": [18, 21, 45, 46, 50, 121, 122, 124, 126, 133, 156, 157, 159, 183, 184, 185, 216, 217, 240, 245, 248, 249, 250, 251, 252, 253, 270, 285, 288, 332, 355], "request": [18, 21, 46, 121, 126, 154, 159, 251, 255, 280, 282, 285, 288, 297, 388], "variat": [18, 121, 186], "mse": [18, 37, 49, 139, 290, 296, 298, 306, 309, 310, 311, 313, 329, 330, 333, 388], "summari": [18, 20, 43, 51, 121, 126, 155, 156, 157, 159, 168, 183, 187, 193, 210, 224, 244, 247, 248, 251, 253, 256, 262, 273, 276, 285, 287, 288, 320, 379, 382], "present": [18, 45, 69, 120, 121, 123, 157, 159, 188, 194, 203, 210, 217, 218, 220, 223, 225, 226, 230, 232, 233, 237, 238, 247, 248, 250, 252, 253, 254, 269, 285, 288, 319, 328, 359], "assign": [18, 26, 38, 126, 159, 165, 185, 186, 190, 209, 219, 220, 224, 226, 228, 237, 251, 285, 288, 292, 301], "inspect": [18, 49, 51, 158, 176, 186], "yellow": [18, 251], "warn": [18, 179, 224, 246, 251, 273], "remind": [18, 159, 285, 288], "dialog": [18, 162, 203], "organ": [18, 157, 159, 165, 168, 231, 240, 254, 256, 280, 285, 288], "cryptographi": 18, "flask": 18, "socketio": 18, "alwai": [19, 37, 44, 119, 121, 122, 140, 155, 156, 157, 158, 159, 160, 168, 186, 232, 244, 245, 249, 251, 252, 273, 285, 288, 328], "map": [19, 22, 26, 37, 44, 46, 58, 60, 62, 63, 66, 68, 107, 108, 109, 110, 111, 112, 113, 120, 121, 126, 131, 134, 135, 136, 139, 165, 185, 199, 232, 241, 249, 250, 273, 295, 305, 314, 324, 328, 354, 355, 362, 367, 377, 381], "f1": [19, 26, 37, 50, 54, 58, 60, 62, 63, 66, 67, 131, 134, 135, 139, 192, 221, 238, 253, 258, 264, 269, 272, 277, 290, 295, 296, 298, 300, 305, 308, 309, 310, 311, 312, 313, 327, 354, 355, 367], "imagefold": [19, 21, 22, 26, 131, 134, 135, 139, 145, 146, 147, 383], "root": [19, 21, 22, 26, 37, 53, 60, 72, 131, 134, 135, 139, 145, 146, 147, 155, 158, 160, 249, 251, 323, 332, 345, 354, 355, 357, 367, 383, 388], "resiz": [19, 21, 22, 52, 53, 58, 60, 131, 134, 135, 139, 140, 145, 146, 147, 180, 316], "centercrop": [19, 21, 52, 53, 131, 134, 135, 139, 145, 146, 147], "totensor": [19, 21, 52, 131, 134, 135, 139, 145, 146, 147, 383], "normal": [19, 21, 41, 52, 121, 130, 131, 134, 135, 139, 140, 145, 146, 147, 157, 159, 169, 178, 186, 194, 214, 215, 228, 251, 253, 275, 285, 288, 319, 383], "485": [19, 21, 54, 131, 134, 135, 139, 140, 145, 146, 147, 383], "456": [19, 21, 130, 131, 134, 135, 139, 140, 145, 146, 147, 383, 388], "406": [19, 21, 131, 134, 135, 139, 140, 145, 146, 147, 383], "std": [19, 21, 52, 130, 131, 134, 135, 139, 145, 146, 147, 320, 383], "229": [19, 21, 131, 134, 135, 139, 140, 145, 146, 147, 383], "225": [19, 21, 131, 134, 135, 139, 140, 145, 146, 147, 323, 383], "cores_per_inst": [19, 21, 32, 62, 63, 131, 134, 135, 139, 145, 146, 147, 354, 355, 356, 357, 367, 384, 388], "num_of_inst": [19, 21, 32, 62, 63, 131, 134, 135, 139, 145, 146, 147, 354, 355, 356, 357, 367], "flexibl": [19, 24, 44, 249, 250], "enough": [19, 46, 126, 155, 156, 159, 167, 241, 285, 288], "__iter__": [19, 21, 315, 327, 329, 330, 333, 359, 362], "postprocess_cl": 19, "metric_cl": 19, "benchmarkconf": 19, "lpot": [19, 32, 45, 49, 72], "pylint": 20, "flake8": [20, 155], "autopep8": 20, "clean": [20, 158, 159, 232, 235, 242, 247, 285, 288, 317, 320, 334, 335], "unit": [20, 126, 214, 220, 252], "motiv": [20, 155, 159, 216, 217, 285, 288], "explan": [20, 154, 272], "regress": [20, 159, 218, 232, 239, 241, 261, 278, 285, 288], "bring": [20, 46, 120, 123, 124, 130, 378], "submit": [20, 159, 251, 285, 288, 332], "page": [20, 133, 155, 157, 158, 159, 162, 165, 169, 170, 171, 172, 173, 174, 175, 182, 186, 197, 203, 212, 230, 236, 240, 241, 242, 248, 250, 252, 263, 269, 272, 279, 284, 285, 288, 332], "reach": [20, 44, 53, 155, 241, 246, 252, 256, 258, 264, 269, 279, 295, 305], "safe": [20, 126, 240, 246, 249, 251, 273, 332], "collabor": 20, "adher": [20, 126, 331], "often": [21, 24, 42, 44, 120, 122, 126, 156, 159, 167, 188, 230, 239, 241, 246, 248, 250, 251, 252, 273, 285, 288], "encount": [21, 155, 186, 320], "larg": [21, 24, 54, 56, 121, 126, 130, 140, 157, 159, 161, 165, 167, 168, 188, 190, 191, 192, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 211, 212, 214, 216, 218, 220, 222, 224, 225, 226, 227, 228, 231, 233, 237, 238, 239, 241, 242, 244, 245, 247, 249, 250, 251, 252, 253, 254, 261, 263, 264, 269, 270, 272, 273, 274, 275, 276, 281, 285, 288, 291, 293, 296, 299, 300, 309, 357, 358, 365], "consum": [21, 159, 251, 285, 288], "previous": [21, 160, 187, 200, 212, 230, 234, 242, 248, 249, 250, 252, 277], "constant": [21, 52, 76, 93, 95, 116, 157, 168, 223, 248, 249, 269, 288, 305], "lack": [21, 156, 159, 254, 285, 288], "faster": [21, 23, 45, 54, 56, 112, 126, 136, 155, 157, 159, 168, 169, 186, 197, 204, 214, 221, 228, 231, 234, 241, 244, 247, 249, 261, 264, 273, 274, 275, 285, 288, 328, 359, 362, 364], "dataloadermodul": 21, "hard": [21, 121, 156, 159, 165, 186, 285, 288], "anoth": [21, 24, 40, 52, 53, 120, 121, 156, 157, 158, 159, 162, 167, 184, 186, 233, 240, 241, 245, 246, 248, 249, 250, 251, 252, 262, 276, 277, 285, 288, 377, 381], "treat": [21, 72, 126, 159, 228, 244, 252, 285, 288], "third": [21, 148, 157, 158, 160, 186, 233, 315, 327], "eas": [21, 31, 35, 45, 72, 280], "advantag": [21, 133, 159, 200, 222, 249, 285, 288], "intern": [21, 157, 159, 167, 176, 245, 251, 261, 281, 285, 288, 314, 316, 319, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "hold": [21, 155, 185, 228, 249, 276, 316], "fetch": [21, 155, 159, 250, 262, 285, 288], "index": [21, 37, 59, 72, 158, 165, 185, 187, 227, 229, 233, 246, 248, 250, 264, 272, 288, 316, 328, 360, 361], "__len__": [21, 22, 59, 72, 165, 233, 359, 360, 361], "life": 21, "give": [21, 53, 121, 122, 126, 154, 156, 159, 165, 186, 195, 196, 240, 241, 244, 245, 246, 248, 250, 251, 252, 256, 267, 285, 288, 317, 354, 355], "compos": [21, 52, 140, 264, 288], "togeth": [21, 24, 31, 35, 51, 52, 157, 165, 167, 168, 184, 199, 224, 233, 241, 247, 248, 250, 252, 294, 302, 304, 372], "serial": [21, 159, 272, 285, 288], "launch": [21, 38, 116, 117, 126, 156, 186, 253, 254, 258, 264, 270, 273, 274, 277, 286, 292, 301, 319, 366], "__next__": 21, "constraint": [21, 50, 53, 58, 60, 131, 134, 135, 139, 244, 354, 355, 356, 357, 359, 360, 361, 362, 367], "sampling_s": [21, 53, 58, 60, 72, 131, 134, 135, 139, 145, 146, 147, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 383, 388], "mani": [21, 31, 35, 53, 58, 60, 116, 120, 121, 126, 130, 131, 134, 135, 139, 156, 157, 158, 159, 160, 165, 186, 189, 195, 201, 202, 208, 212, 214, 219, 220, 223, 230, 231, 232, 233, 236, 241, 246, 247, 250, 251, 267, 281, 285, 288, 319, 354, 355, 362, 367, 383], "randomresizedcrop": [21, 52, 131, 134, 135, 139, 145, 146, 147, 383], "randomhorizontalflip": [21, 52, 131, 134, 135, 139, 145, 146, 147, 383], "calib_data": [21, 67, 339, 340, 342, 343, 346, 347, 350], "mx": [21, 68], "imagerecordit": 21, "path_imgrec": 21, "label_width": 21, "preprocess_thread": 21, "data_nthread": 21, "data_shap": [21, 68], "label_nam": 21, "rand_crop": 21, "rand_mirror": 21, "shuffl": [21, 46, 165, 190, 251, 253, 327], "shuffle_dataset": 21, "shuffle_chunk_se": 21, "shuffle_se": 21, "data_layer_typ": 21, "ctx": [21, 68], "combine_mean_std": 21, "industri": [22, 37, 249], "mnist": [22, 26, 56, 70, 71, 341], "filter": [22, 34, 44, 51, 53, 56, 157, 168, 209, 210, 238, 241, 250, 251, 274, 279, 281, 388], "directori": [22, 26, 30, 51, 66, 67, 68, 116, 123, 126, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 153, 156, 158, 159, 165, 169, 177, 180, 185, 186, 187, 248, 250, 253, 260, 263, 272, 273, 276, 285, 288, 290, 293, 296, 298, 303, 308, 309, 310, 311, 313, 315, 321, 324, 327, 329, 330, 332, 333, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 377, 379, 381, 382, 386, 387], "bool": [22, 37, 52, 320], "subset": [22, 126, 197, 206, 235, 354, 355, 388], "condit": [22, 36, 52, 53, 157, 168, 190, 192, 200, 224, 227, 241, 244, 251, 278], "put": [22, 24, 44, 152, 153, 156, 158, 162, 165, 167, 186, 187, 216, 232, 241, 251, 253, 262, 264, 275, 286, 362, 368], "again": [22, 32, 47, 126, 159, 160, 169, 186, 228, 233, 246, 250, 251, 252, 276, 285, 288, 320], "npz": [22, 126], "manual": [22, 69, 121, 131, 134, 135, 139, 142, 143, 145, 148, 153, 155, 251, 319, 320, 327, 329, 370, 374, 378], "ensp": [22, 37, 52], "fashionmnist": [22, 345], "idx1": 22, "ubyt": 22, "gz": [22, 60, 114, 115, 119, 120, 122, 123, 126, 165, 272, 273, 298, 329, 330, 333, 335, 354, 355, 360, 362, 364, 367, 368, 379, 382], "idx3": 22, "t10k": 22, "cifar10": [22, 351, 388], "extract": [22, 122, 124, 126, 140, 157, 159, 161, 162, 165, 168, 178, 183, 187, 197, 203, 215, 224, 227, 241, 246, 247, 248, 262, 264, 272, 273, 279, 281, 285, 288, 321, 323, 327, 334], "toronto": [22, 192, 211, 264], "edu": [22, 118, 165, 184, 299], "kriz": 22, "cifar": [22, 54], "tar": [22, 60, 114, 115, 127, 128, 129, 165, 262, 273, 274, 298, 335, 354, 355, 360, 362, 364, 367, 368, 379, 382], "cifar100": 22, "imagerecord": [22, 26, 58, 60, 62, 63, 72, 354, 355, 388], "arrang": [22, 44], "000": [22, 140, 157, 162, 169, 184, 215, 219, 252, 262, 268, 281], "001": [22, 26, 144, 159, 186, 285, 288], "099": 22, "class_1": 22, "png": [22, 69, 116, 126, 215, 324], "xxy": 22, "xxz": 22, "class_n": 22, "123": [22, 52, 62, 63, 133, 354, 355, 388], "nsdf3": 22, "asd932_": 22, "categori": [22, 68, 183, 241, 242, 275], "folder": [22, 51, 70, 119, 120, 121, 122, 123, 124, 126, 131, 134, 135, 136, 139, 140, 142, 143, 145, 146, 147, 148, 150, 155, 157, 158, 159, 165, 169, 233, 240, 248, 251, 254, 259, 262, 263, 264, 265, 269, 271, 273, 279, 284, 285, 286, 288, 307, 315, 319, 320, 322, 323, 335, 357, 358, 360, 367, 368, 373, 377, 381], "imagenetraw": 22, "data_path": [22, 68, 74, 75, 78, 79, 80, 83, 84, 85, 90, 92, 99, 101, 102, 103, 104, 106, 107, 108, 111, 112, 113, 262], "image_list": [22, 316], "img1": 22, "jpg": [22, 140, 321, 328], "img2": 22, "imgx": 22, "val_map": 22, "cocorecord": 22, "num_cor": [22, 254], "28": [22, 31, 32, 48, 54, 64, 140, 274, 328, 356, 359, 361, 364, 388], "interleav": [22, 156], "parallel": [22, 44, 126, 155, 156, 165, 167, 186, 233, 236, 292, 301, 359, 361], "tfrecord": [22, 365, 367], "gt": [22, 52, 274], "cocoraw": 22, "img_dir": 22, "anno_dir": [22, 323], "val2017": [22, 83, 315, 319, 323, 324], "annot": [22, 37, 83, 126, 184, 215, 233, 241, 275, 277, 279, 315, 319, 323, 324], "instances_val2017": [22, 83, 323, 324], "json": [22, 39, 52, 70, 71, 83, 101, 117, 119, 120, 122, 123, 126, 152, 153, 159, 164, 165, 186, 240, 264, 269, 272, 273, 276, 277, 285, 288, 293, 297, 307, 321, 323, 324, 335, 356, 357, 358, 388], "coconpi": [22, 323], "npy_dir": [22, 323], "npy": [22, 263, 323], "total": [22, 52, 126, 156, 158, 159, 165, 184, 233, 242, 249, 250, 252, 253, 258, 264, 269, 275, 277, 285, 286, 288, 318, 328, 359, 361], "dimens": [22, 24, 44, 52, 159, 167, 228, 229, 233, 241, 248, 249, 264, 275, 285, 288, 316], "128": [22, 46, 52, 54, 67, 97, 100, 105, 138, 139, 160, 247, 253, 254, 258, 260, 261, 273, 277, 279, 294, 295, 296, 297, 299, 301, 302, 304, 305, 308, 309, 311, 312, 356, 359], "lt": [22, 43, 56, 361], "127": [22, 46, 54, 246], "length": [22, 37, 46, 52, 76, 93, 95, 126, 157, 160, 165, 167, 168, 203, 210, 216, 217, 228, 234, 239, 241, 246, 247, 248, 250, 256, 267, 271, 273, 274, 279, 281, 332, 356, 359], "float16": [22, 116], "int32": [22, 250, 388], "int64": [22, 388], "ignor": [22, 121, 165, 167, 244, 246, 248, 251, 273, 293], "stand_norm": 22, "dummy_v2": [22, 61, 64, 388], "input_shap": [22, 61, 64, 355, 388], "label_shap": [22, 61, 388], "eg": [22, 68, 355], "style_transf": [22, 368], "content_fold": [22, 368], "style_fold": [22, 368], "crop_ratio": 22, "resize_shap": 22, "image_format": 22, "content": [22, 120, 156, 186, 187, 200, 201, 202, 203, 251, 280, 281, 282, 283, 368, 383], "crop": [22, 52, 123, 130, 133, 136, 138, 140, 316], "ratio": [22, 31, 44, 48, 52, 54, 126, 140, 256, 269, 281, 295, 305, 306, 316, 319], "transfer": [22, 24, 25, 56, 140, 157, 159, 168, 191, 204, 206, 211, 221, 223, 232, 233, 238, 241, 264, 269, 285, 288, 355], "task": [22, 24, 34, 37, 67, 79, 93, 98, 102, 104, 117, 118, 119, 120, 122, 123, 124, 126, 133, 140, 156, 157, 159, 162, 165, 167, 168, 184, 186, 188, 189, 190, 191, 192, 193, 194, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 245, 247, 249, 251, 252, 253, 261, 262, 264, 267, 269, 272, 273, 275, 276, 277, 279, 281, 282, 284, 285, 288, 293, 295, 303, 305, 313, 314, 356, 357, 358, 359, 360, 361], "holder": 22, "tfrecorddataset": [22, 53], "filenam": [22, 119, 120, 158, 249], "bert": [22, 24, 28, 37, 44, 52, 54, 56, 67, 97, 98, 99, 100, 104, 105, 139, 157, 159, 160, 161, 162, 165, 167, 168, 169, 182, 188, 189, 190, 191, 193, 194, 197, 198, 199, 201, 202, 204, 206, 208, 210, 211, 213, 221, 222, 229, 230, 231, 233, 236, 238, 239, 244, 246, 247, 248, 249, 250, 252, 253, 254, 255, 257, 260, 261, 264, 267, 268, 269, 270, 277, 279, 281, 285, 286, 288, 290, 291, 292, 294, 295, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 313, 358, 359, 373], "label_fil": [22, 52, 357], "squad": [22, 31, 37, 52, 54, 56, 98, 101, 102, 104, 162, 168, 188, 190, 192, 201, 202, 221, 222, 226, 230, 234, 237, 247, 250, 253, 254, 264, 269, 282, 293, 296, 297, 308, 309, 310, 311, 329, 357, 358], "model_typ": [22, 97, 100, 105, 127, 129, 164, 260, 261, 263, 268, 269, 272, 278, 297, 327, 356], "sparse_dummy_v2": 22, "dense_shap": 22, "sparse_ratio": 22, "spars": [22, 44, 45, 56, 205, 269, 288, 292, 293, 294, 295, 301, 304, 305], "distilbert": [22, 54, 56, 99, 157, 162, 165, 168, 169, 247, 248, 250, 252, 275, 290, 291, 303, 308, 311], "xlnet": [22, 157, 168, 185, 206, 222, 247, 250, 252, 260, 278, 290, 308], "xlm": [22, 54, 56, 99, 157, 159, 168, 194, 225, 247, 250, 252, 264, 285, 288, 290, 308, 310], "tensordataset": 22, "huggingfac": [22, 56, 94, 97, 100, 105, 116, 154, 156, 157, 158, 159, 165, 167, 168, 169, 177, 180, 185, 186, 206, 233, 240, 247, 250, 254, 262, 269, 271, 273, 274, 276, 283, 284, 285, 286, 288, 290, 291, 292, 294, 295, 297, 298, 299, 300, 301, 304, 305, 310, 313, 373, 374], "glue": [22, 37, 67, 96, 97, 99, 100, 105, 152, 153, 161, 168, 188, 190, 192, 199, 204, 206, 214, 221, 222, 230, 231, 238, 241, 250, 253, 254, 261, 263, 264, 267, 277, 282, 296, 300, 303, 312, 329, 374], "data_dir": [22, 96, 97, 99, 100, 105, 116, 156, 251, 257, 260, 261, 268, 269, 272, 273, 274, 303, 356], "model_name_or_path": [22, 97, 98, 99, 100, 105, 156, 186, 254, 256, 257, 258, 260, 261, 267, 268, 269, 270, 272, 273, 276, 277, 278, 279, 290, 291, 292, 294, 295, 296, 297, 299, 300, 301, 302, 304, 305, 308, 309, 310, 311, 312, 373, 374], "max_seq_length": [22, 52, 97, 100, 105, 184, 254, 257, 258, 260, 261, 277, 292, 294, 295, 296, 297, 299, 301, 308, 309, 310, 311, 312, 356, 359], "do_lower_cas": [22, 52, 97, 100, 105, 261, 269, 297], "dynamic_length": 22, "shortcut": [22, 248], "maximum": [22, 46, 52, 165, 224, 244, 246, 248, 281, 295, 305, 359], "longer": [22, 52, 156, 159, 165, 167, 186, 188, 216, 217, 233, 234, 247, 251, 273, 279, 285, 288], "truncat": [22, 52, 120, 165, 167, 168, 224, 233, 248, 253, 273], "shorter": [22, 52, 186, 210, 250, 273, 274], "lowercas": [22, 252, 281, 285], "mrpc": [22, 31, 37, 54, 56, 96, 97, 99, 100, 105, 184, 247, 250, 253, 261, 263, 264, 277, 290, 296, 308, 309, 310, 311, 312, 356, 373], "qqp": [22, 37, 54, 184, 261, 263, 264, 269, 277, 310], "qnli": [22, 31, 37, 54, 184, 261, 263, 264, 277, 310], "rte": [22, 31, 37, 54, 184, 261, 263, 264, 277, 309, 310], "st": [22, 31, 37, 261, 264, 277, 310], "b": [22, 31, 37, 130, 139, 140, 155, 159, 162, 165, 241, 246, 250, 252, 254, 261, 271, 273, 274, 277, 279, 285, 288, 310, 354], "cola": [22, 31, 37, 54, 184, 261, 264, 277, 310], "mnli": [22, 37, 54, 184, 201, 202, 231, 247, 254, 260, 261, 263, 264, 269, 275, 277, 310], "wnli": [22, 37, 54, 184, 264, 277, 290, 308, 310], "mobilebert": [22, 24, 54, 56, 105, 168], "roberta": [22, 54, 56, 99, 157, 162, 168, 190, 193, 194, 197, 198, 201, 202, 206, 214, 216, 217, 222, 231, 247, 250, 252, 257, 260, 263, 264, 267, 275, 286, 288, 290, 299, 301, 308, 310], "uncas": [22, 52, 54, 56, 97, 99, 100, 152, 153, 157, 160, 162, 164, 165, 167, 182, 187, 193, 204, 242, 247, 248, 249, 250, 252, 253, 254, 258, 261, 264, 268, 269, 275, 277, 279, 291, 292, 294, 296, 297, 299, 300, 301, 302, 304, 308, 311, 357, 358, 361], "yaml_fil": [22, 26, 37, 41], "collate_fn": [22, 327, 356, 360, 361], "aid": [23, 156], "deploy": [23, 370], "infrastructur": 23, "smaller": [24, 44, 52, 155, 157, 159, 168, 186, 188, 195, 197, 204, 206, 219, 221, 241, 244, 250, 252, 264, 279, 285, 288, 291, 299, 359], "less": [24, 44, 126, 155, 156, 168, 186, 199, 204, 206, 235, 241, 244, 249, 250, 264, 269, 290, 319], "expens": [24, 53, 230, 231, 273], "power": [24, 43, 183, 192, 200, 203, 211, 212, 214, 224, 227, 232, 235, 241, 249, 250, 378], "mobil": [24, 54, 56, 133, 140, 168, 221, 231], "workflow": [24, 31, 35, 38, 51, 55, 165, 168, 251, 280, 283, 379, 382], "produc": [24, 194, 206, 250, 251, 273, 274], "logit": [24, 117, 171, 182, 186, 187, 233, 250, 253, 273, 306, 354, 355], "softmax": [24, 122, 126, 158, 201, 202, 214, 234, 241, 248, 250, 275, 356, 388], "l": [24, 51, 53, 70, 71, 123, 130, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 152, 153, 220, 228, 241, 251, 252, 276, 279, 335, 357, 358], "kd": 24, "z": [24, 126, 241, 330], "where": [24, 28, 44, 51, 53, 76, 93, 95, 120, 121, 122, 123, 124, 126, 156, 157, 159, 165, 167, 168, 169, 186, 190, 201, 202, 205, 206, 215, 216, 220, 227, 228, 232, 240, 241, 244, 246, 248, 249, 250, 251, 252, 261, 262, 271, 272, 273, 275, 276, 277, 278, 284, 285, 288, 292, 301, 316, 319, 359, 361, 367, 377, 381], "distanc": [24, 204, 228], "g": [24, 32, 44, 49, 53, 133, 156, 159, 160, 167, 169, 178, 185, 186, 187, 193, 214, 222, 232, 236, 241, 248, 250, 251, 252, 260, 271, 272, 281, 285, 288, 320, 370, 373], "euclidean": 24, "kullback": 24, "leibler": 24, "diverg": [24, 286, 306], "term": [24, 36, 37, 41, 42, 53, 154, 162, 165, 168, 195, 196, 203, 205, 228, 234, 241, 253, 269, 271], "patient": [24, 126], "compact": [24, 44, 151, 221, 249, 371], "agnost": [24, 211, 221, 253], "resourc": [24, 31, 44, 156, 168, 184, 190, 221, 238, 251, 261, 263, 264, 269, 277, 335], "summar": [24, 157, 159, 162, 167, 168, 190, 191, 193, 207, 216, 224, 226, 232, 233, 237, 241, 246, 247, 248, 254, 285, 288, 290, 298], "1x1": [24, 295, 305], "convolut": [24, 44, 45, 121, 126, 130, 133, 151, 157, 168, 199, 202, 210, 231, 241], "etc": [24, 34, 50, 121, 123, 126, 130, 155, 157, 158, 159, 160, 185, 200, 215, 222, 246, 248, 251, 260, 275, 280, 285, 288, 295, 305, 307, 316, 385], "ia": 24, "stage": [24, 51, 159, 186, 219, 240, 252, 285, 288, 292, 301, 326, 334], "attach": [24, 155, 156, 252], "shallow": 24, "depth": [24, 47, 130, 159, 251, 285, 288], "deepest": 24, "convent": [24, 120, 133, 228], "deeper": [24, 156, 159, 210, 285, 288], "lead": [24, 38, 44, 154, 159, 186, 188, 238, 249, 251, 252, 258, 272, 273, 276, 285, 288, 319], "much": [24, 28, 32, 44, 52, 120, 121, 122, 126, 130, 156, 159, 186, 187, 188, 210, 228, 230, 233, 240, 241, 244, 251, 252, 253, 273, 275, 279, 285, 288, 319, 378], "architectur": [24, 31, 35, 44, 45, 55, 126, 130, 133, 159, 160, 167, 168, 169, 184, 188, 189, 190, 192, 194, 195, 197, 201, 202, 203, 206, 207, 210, 211, 227, 230, 231, 232, 233, 234, 237, 241, 245, 247, 248, 250, 251, 254, 264, 269, 272, 277, 285, 286, 288, 359, 361], "paper": [24, 44, 126, 130, 133, 136, 140, 155, 157, 158, 159, 168, 184, 186, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 244, 250, 256, 261, 263, 264, 267, 269, 270, 271, 273, 281, 285, 287, 288, 292, 300, 301, 314, 328, 359], "10004": [24, 34, 38, 42], "Will": [24, 34, 328], "10006": 24, "student_model": 24, "teacher_model": [24, 127, 128, 129], "distillationconf": 24, "insid": [24, 44, 76, 93, 95, 117, 156, 167, 169, 186, 220, 240, 241, 251, 259, 277, 283, 284, 356, 357], "on_train_begin": [24, 295, 305], "on_after_compute_loss": 24, "student_output": 24, "student_loss": 24, "blendcnn": [24, 54, 56], "train_func": [24, 26, 44], "loss_sum": 24, "iter_bar": 24, "tqdm": [24, 156, 176, 244, 288], "train_dataload": [24, 44, 233, 295, 305], "desc": [24, 44, 68], "teacher_logit": 24, "input_id": [24, 44, 158, 159, 160, 165, 167, 185, 187, 190, 193, 194, 215, 216, 217, 220, 225, 228, 232, 233, 242, 244, 246, 248, 250, 253, 264, 285, 288], "segment_id": 24, "input_mask": 24, "pytorchknowledgedistillationloss": 24, "promis": [25, 31, 44, 200, 245, 269], "footprint": [25, 41, 44, 53, 157, 168, 186, 188, 199, 214, 241, 250, 269], "huge": [25, 156, 186, 208, 221, 241, 251, 273], "bit": [25, 38, 45, 46, 126, 140, 156, 159, 186, 210, 233, 241, 244, 248, 249, 250, 269, 285, 288], "heavi": [25, 221, 251], "booster": 25, "degrad": [25, 188], "retrain": [25, 140, 157, 168], "incorpor": [25, 53, 121, 215, 220, 221, 245], "novel": [25, 159, 190, 191, 199, 201, 202, 214, 218, 222, 226, 231, 234, 237, 241, 247, 275, 285, 288, 370, 378], "pipelin": [25, 42, 56, 70, 71, 120, 121, 124, 126, 130, 157, 161, 162, 168, 169, 203, 241, 245, 249, 250, 251, 275, 282, 292, 301, 319], "builtin": [26, 58, 60, 273], "write": [26, 33, 50, 51, 72, 73, 145, 155, 156, 157, 159, 165, 168, 186, 211, 212, 231, 264, 278, 280, 281, 285, 288, 319, 324, 370], "program": [26, 32, 38, 121, 156, 159, 186, 249, 251, 285, 288, 332, 363, 370], "real": [26, 45, 46, 126, 133, 169, 215, 232], "addition": [26, 53, 159, 184, 187, 213, 227, 233, 240, 281, 285, 288, 316], "eager": [26, 34, 46, 47, 51, 54, 56, 131, 134, 135, 139, 142, 143, 145, 148, 152, 153, 159, 285, 288, 290, 293, 298, 303, 308, 310, 313, 327, 329, 334, 335], "enable_eager_execut": 26, "yaml_file_path": 26, "pre_process": 26, "evaluation_result": 26, "evaluation_time_cost": 26, "partit": [26, 186], "distributedsampl": 26, "train_sampl": 26, "util": [26, 27, 44, 46, 58, 60, 64, 120, 122, 126, 140, 145, 146, 159, 165, 168, 187, 193, 214, 233, 249, 276, 285, 286, 288, 308, 309, 311, 312, 315, 319, 327, 355, 360, 370], "train_dataset": [26, 165, 233, 253, 296, 308, 309, 311], "num_replica": 26, "hvd": 26, "rank": [26, 186, 209, 239, 272, 292, 301], "train_kwarg": 26, "sampler": [26, 273], "adadelta": 26, "distributedoptim": 26, "named_paramet": [26, 253], "broadcast": [26, 52], "broadcast_paramet": 26, "root_rank": 26, "broadcast_optimizer_st": 26, "set_epoch": 26, "batch_idx": 26, "nll_loss": 26, "log_interv": 26, "0f": 26, "tloss": 26, "6f": 26, "item": [26, 50, 66, 67, 68, 73, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 153, 156, 158, 165, 233, 248, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 383], "dry_run": 26, "test_func": [26, 67, 68], "host": [26, 70, 71, 126, 132, 138, 149, 157, 169, 184, 186, 211, 212, 251, 256, 267, 279, 314, 317, 337, 338, 351, 385], "np": [26, 52, 59, 72, 132, 138, 144, 149, 165, 233, 251, 330, 337, 338, 351, 357], "num_of_process": [26, 132, 149, 337, 338, 351], "h": [26, 52, 68, 126, 130, 132, 133, 140, 149, 241, 252, 275, 316, 328, 337, 338, 351, 357, 358, 362, 368], "002": [26, 140, 160], "ssh": 26, "readm": [26, 159, 160, 166, 190, 191, 224, 240, 243, 250, 254, 259, 276, 280, 283, 284, 285, 288, 290, 291, 294, 296, 298, 299, 302, 304, 308, 309, 310, 311, 313, 321, 329, 330, 333, 335, 354, 363, 387], "md": [26, 27, 158, 159, 160, 163, 166, 190, 191, 224, 240, 243, 250, 273, 276, 280, 283, 284, 285, 288, 319, 321], "exactli": [26, 119, 120, 126, 159, 165, 186, 246, 252, 285, 286, 288], "resnet50_v1": [26, 32, 93, 354], "resizecropimagenet": [26, 52, 62, 63, 354, 355, 388], "height": [26, 44, 52, 58, 60, 62, 63, 72, 140, 215, 316, 319, 328, 354, 355, 388], "realiz": [26, 37, 41, 47, 50, 156, 211], "tow": 26, "situat": [26, 126, 156, 186, 250, 251], "node1": 26, "node2": 26, "TO": [26, 66, 68, 120, 141, 153, 353, 354, 355, 367], "your_node1_nam": 26, "your_node2_nam": 26, "resnet50_fp32_pretrained_model": [26, 32, 354], "nc_resnet50_v1": [26, 66, 354], "materi": 27, "ux": [27, 384, 385], "system": [27, 44, 123, 126, 130, 133, 157, 160, 179, 186, 203, 205, 209, 214, 231, 251, 260, 265, 273, 280, 283, 303, 322, 371], "simplifi": [27, 70, 71, 247, 293, 319, 370, 378, 383], "explain": [27, 155, 156, 157, 159, 160, 161, 229, 233, 241, 249, 251, 264, 269, 285, 288, 308], "kit": 27, "instal": [27, 30, 43, 55, 57, 118, 120, 121, 122, 124, 127, 128, 129, 130, 132, 141, 144, 151, 155, 156, 159, 164, 168, 176, 187, 211, 233, 240, 247, 251, 254, 259, 262, 264, 266, 269, 271, 273, 277, 283, 284, 285, 286, 288, 297, 303, 306, 314, 320, 321, 325, 370, 379, 382], "app": [27, 117, 158, 162, 169, 387], "bfp16": 27, "platform": [27, 31, 32, 34, 45, 46, 50, 54, 157, 162, 169, 176, 184, 186, 231, 251, 370], "model_convers": 27, "purpos": [27, 38, 53, 156, 157, 159, 167, 168, 204, 227, 233, 246, 250, 251, 269, 285, 288, 319], "factor": [28, 43, 54, 121, 126, 128, 130, 162, 228, 232, 238, 239, 241, 244, 256, 264], "oppos": [28, 126], "entail": [28, 184, 211, 213, 233, 260, 275, 277, 281], "signal": [28, 235, 269], "preserv": [28, 140, 200, 204, 264, 280], "nlp": [28, 44, 46, 56, 152, 153, 157, 159, 161, 162, 167, 168, 191, 193, 194, 198, 201, 202, 204, 206, 208, 215, 219, 221, 223, 225, 227, 231, 232, 241, 244, 245, 247, 249, 250, 254, 272, 273, 274, 283, 285, 288, 290, 291, 292, 293, 294, 298, 299, 300, 301, 302, 303, 304, 308, 312, 313, 356, 357, 358, 360, 373], "onnxrt_integerop": [28, 66, 73], "post_training_dynamic_qu": [28, 73, 298, 308, 309, 310, 313], "absolut": [28, 37, 43, 44, 46, 53, 64, 66, 69, 70, 71, 131, 134, 135, 139, 153, 155, 156, 159, 167, 188, 192, 197, 200, 203, 205, 211, 212, 218, 221, 231, 233, 236, 258, 285, 288, 323, 354, 355, 362, 367, 388], "earli": [28, 46, 53, 66, 67, 68, 131, 134, 135, 139, 148, 153, 176, 186, 269, 280, 290, 296, 298, 308, 309, 310, 311, 312, 313, 329, 330, 333, 354, 355, 362, 367], "stop": [28, 53, 66, 67, 68, 131, 134, 135, 139, 148, 153, 176, 186, 190, 246, 250, 252, 272, 273, 290, 296, 298, 308, 309, 310, 311, 312, 313, 329, 330, 333, 354, 355, 362, 367], "random_se": [28, 50, 53, 66, 67, 68, 72, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 388], "9527": [28, 50, 53, 66, 67, 68, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 388], "determinist": [28, 53, 66, 131, 134, 135, 139, 153, 159, 251, 269, 285, 288, 354, 355, 362, 367], "wide": [29, 38, 46, 56, 156, 157, 169, 186, 192, 201, 202, 204, 205, 208, 210, 211, 223, 227, 238, 249, 253, 269, 295, 305, 308, 365], "varieti": [29, 53, 121, 156, 210, 215, 216, 217, 222, 223, 232, 238, 249, 251, 253], "numpi": [30, 52, 164, 165, 178, 248, 250, 251, 330], "ndarrai": [30, 52], "incompat": [30, 126, 186, 320], "88": [30, 31, 48, 50, 54, 130, 136, 140, 151, 201, 202, 258, 261, 264, 269, 277, 306], "header": [30, 277], "80": [30, 31, 48, 51, 54, 130, 136, 137, 140, 151, 155, 192, 219, 234, 257, 258, 261, 269, 281, 306, 332], "pyobject": 30, "reinstal": [30, 155], "pycocotool": [30, 35, 317], "cach": [30, 46, 138, 157, 168, 187, 245, 248, 251], "importerror": 30, "libgl": 30, "share": [30, 53, 156, 157, 162, 168, 202, 208, 209, 241, 248, 264, 269, 273, 275, 276, 279, 283, 295, 305], "apt": [30, 31, 35, 240, 371, 378], "yum": [30, 31, 35], "opencv": [30, 317, 364, 378], "conflict": [30, 120, 186], "pend": 30, "long": [30, 52, 126, 156, 157, 158, 159, 162, 167, 168, 186, 193, 203, 211, 216, 217, 228, 229, 233, 234, 241, 248, 250, 252, 273, 285, 288, 354, 367], "sqlalchemi": [30, 35], "27": [30, 31, 35, 54, 67, 70, 71, 137, 140, 215, 388], "alemb": [30, 35, 386], "consolid": [31, 35, 272], "latest": [31, 35, 45, 49, 98, 99, 130, 156, 169, 186, 254, 264, 269, 277, 386], "place": [31, 35, 51, 121, 186, 248, 250, 307, 345], "along": [31, 35, 126, 130, 157, 159, 171, 182, 208, 241, 249, 251, 254, 265, 285, 288], "streamlin": [31, 35], "scienc": [31, 35, 126, 271, 275], "anaconda": [31, 35, 130, 140, 187, 254, 320], "suit": [31, 35, 51, 125, 155, 159, 191, 251, 262, 285, 288, 323, 326, 332, 334], "prerequisit": [31, 124, 126], "satisfi": [31, 35, 155, 159, 251, 273, 285, 288], "success": [31, 35, 126, 159, 198, 210, 221, 222, 251, 285, 288, 388], "virtual": [31, 70, 71, 126, 155, 157, 169, 240, 254], "nc": [31, 50, 53, 59, 145, 146, 147, 315, 326, 355], "hello": [31, 59, 157, 171, 182, 240, 246, 251, 264], "world": [31, 59, 144, 155, 157, 197, 215, 227, 251, 252, 275, 276], "processor": [31, 32, 38, 43, 45, 46, 47, 48, 54, 70, 71, 168, 214], "lakecoop": 31, "lakeskylakeic": 31, "3ubuntu": 31, "18": [31, 54, 130, 209, 224, 234, 241, 247, 250, 273, 306, 367, 388], "63": [31, 54, 130, 140, 200, 264, 323, 388], "73": [31, 54, 130, 133, 140, 145, 146, 264], "83": [31, 48, 50, 54, 130, 136, 151, 192, 201, 202, 258, 261, 264, 269, 277, 300], "15": [31, 32, 54, 55, 160, 184, 228, 241, 247, 252, 258, 261, 269, 277, 281, 288, 305, 319, 355, 367, 388], "up1": [31, 55], "up2": [31, 55], "up3": [31, 55], "ipex": [31, 34, 46, 54, 56, 147, 297, 325, 333, 374, 375], "gain": [31, 42, 45, 159, 190, 206, 211, 216, 230, 236, 238, 242, 285, 288, 378], "variou": [31, 34, 121, 156, 158, 165, 185, 186, 187, 199, 221, 233, 239, 241, 249, 250, 251, 259, 274, 370], "baselin": [31, 50, 51, 66, 67, 68, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 151, 194, 202, 203, 209, 213, 214, 220, 227, 290, 296, 298, 306, 308, 309, 310, 311, 313, 315, 323, 327, 329, 330, 333, 334, 337, 338, 351, 354, 355, 362, 367], "realtim": 31, "resnet50v1": 31, "70": [31, 48, 54, 56, 133, 140, 215, 264, 269, 275, 277, 294, 304], "26": [31, 48, 54, 130, 137, 160, 247, 268, 273, 274, 277, 388], "23x": [31, 54], "resnet101": [31, 54, 56, 61, 140, 141, 144, 145, 146, 147, 148, 150, 151, 343, 355, 362, 364, 388], "77": [31, 48, 54, 130, 140, 221, 264, 269], "40": [31, 43, 54, 128, 133, 136, 156, 179, 204, 212, 250, 252, 264, 277, 318, 388], "05": [31, 32, 37, 54, 70, 71, 120, 136, 138, 159, 160, 285, 288, 290, 323], "42x": [31, 48, 261], "inception_v1": [31, 60, 85, 354], "69": [31, 54, 140, 233, 264, 275, 281], "57": [31, 48, 54, 264, 269, 277, 328, 388], "88x": [31, 54], "inception_v2": [31, 354], "00": [31, 48, 54, 130, 136, 388], "14": [31, 48, 54, 130, 136, 137, 228, 247, 285, 288, 318, 388], "96x": 31, "inception_v3": [31, 51, 145, 146, 340, 354, 388], "65": [31, 48, 54, 130, 136, 137, 269, 274, 277, 305], "36x": [31, 54], "inception_v4": [31, 354, 388], "37": [31, 48, 54, 130, 136, 318, 328, 388], "59x": [31, 48, 54], "inception_resnet_v2": [31, 339, 354], "97x": 31, "mobilenetv1": [31, 110, 336, 388], "ssd_resnet50_v1": [31, 388], "coco": [31, 37, 61, 83, 107, 108, 109, 110, 111, 112, 113, 114, 115, 247, 314, 315, 317, 323, 325, 326, 362, 364], "90": [31, 48, 54, 56, 130, 136, 137, 140, 201, 202, 221, 250, 258, 261, 264, 269, 277, 292, 300, 301, 306, 316], "38": [31, 48, 54, 69, 136, 137, 157, 160, 236, 388], "mask_rcnn_inception_v2": [31, 388], "29": [31, 54, 130, 140, 160, 190, 277, 388], "66x": [31, 54], "vgg16": [31, 54, 56, 140, 348, 354], "72": [31, 54, 130, 133, 136, 137, 140, 145, 146, 215, 264, 269], "75x": [31, 54], "vgg19": [31, 54, 56, 140, 349, 354], "97": [31, 48, 54, 130, 136, 137, 204, 264, 323], "79x": 31, "75": [31, 54, 130, 136, 140, 264, 269, 388], "23": [31, 48, 54, 70, 71, 191, 250, 264, 275, 277, 329, 330, 333, 388], "63x": 31, "resnext101_32x8d": [31, 54, 56], "79": [31, 51, 54, 130, 136, 140, 215, 221, 264, 269, 305], "31": [31, 54, 133, 137, 197, 288, 318, 388], "61x": [31, 54], "0a0": [31, 318], "24aac32": 31, "bert_base_mrpc": [31, 356], "19": [31, 48, 54, 130, 136, 140, 159, 167, 205, 228, 244, 264, 285, 288, 297, 323, 355, 388], "98x": [31, 54], "bert_base_cola": 31, "59": [31, 48, 54, 130, 137, 157, 264, 269, 281, 328], "06": [31, 54, 136, 140, 151, 160, 277, 388], "58": [31, 48, 54, 140, 160, 261, 264, 277, 300], "84": [31, 48, 54, 130, 136, 137, 140, 258, 261, 264, 269, 277, 300], "19x": [31, 54], "bert_base_st": 31, "89": [31, 48, 54, 130, 140, 202, 258, 261, 264, 269, 300], "28x": [31, 54], "bert_base_sst": 31, "sst": [31, 54, 56, 99, 248, 261, 263, 264, 277, 308, 310, 311], "91": [31, 54, 130, 136, 140, 201, 202, 258, 261, 264, 269, 277, 300, 334], "51": [31, 54, 136, 258, 264, 288, 328], "86": [31, 48, 54, 130, 192, 199, 201, 202, 241, 258, 261, 264, 269, 300], "30x": [31, 54, 206], "bert_base_rt": 31, "68": [31, 48, 52, 54, 62, 63, 136, 140, 258, 354, 355, 388], "52": [31, 54, 70, 71, 136, 258, 264, 388], "15x": [31, 54], "bert_large_mrpc": 31, "87": [31, 48, 54, 130, 233, 264, 277, 281, 300, 306], "33": [31, 48, 54, 130, 136, 137, 197, 264, 300, 318, 388], "99": [31, 32, 48, 54, 130, 137, 157, 234, 264, 271, 288], "73x": [31, 54], "bert_large_squad": [31, 357, 358], "92": [31, 48, 54, 130, 140, 258, 261, 264, 277, 300, 334], "85": [31, 50, 54, 130, 151, 258, 261, 264, 269, 277], "93": [31, 48, 54, 130, 140, 192, 215, 244, 258, 261], "21": [31, 54, 130, 136, 140, 234, 264, 273, 274, 277, 281, 367, 374, 388], "01x": [31, 54], "bert_large_qnli": 31, "82": [31, 48, 54, 130, 136, 140, 151, 264, 269], "69x": [31, 54], "primarili": [32, 220, 251], "similar": [32, 53, 156, 159, 167, 188, 191, 199, 202, 209, 211, 214, 219, 221, 224, 228, 231, 233, 240, 241, 246, 247, 248, 251, 252, 254, 264, 273, 275, 278, 285, 288, 316, 319, 328, 383], "subexpress": 32, "elimin": 32, "bfloat16": [32, 38, 47, 366, 370], "word": [32, 37, 54, 56, 155, 156, 157, 159, 165, 167, 185, 186, 200, 201, 202, 208, 212, 213, 215, 225, 234, 241, 246, 247, 248, 250, 252, 254, 258, 264, 281, 285, 288, 296, 297], "explicitli": [32, 33, 186, 226, 237, 241, 276], "op_to_stor": 32, "optimized_model": [32, 384, 388], "cpx": 32, "clx": [32, 70, 71], "force_bf16": 32, "cmd": [32, 59, 60, 130, 155, 273, 293, 362], "executable_nc_wrapp": 32, "prefix": [32, 51, 68, 126, 130, 155, 158, 167, 219, 220, 224, 232, 241, 250, 373], "consequ": [32, 38, 154, 195, 245, 252], "later": [32, 51, 156, 159, 186, 248, 250, 285, 288, 365], "fallback": [32, 38, 47, 53], "graph_optimization_conf": 32, "throughput": [32, 66, 68, 69, 70, 71, 123, 296, 357], "resnet50_measur": 32, "8280": 32, "2021": [32, 61, 354, 364, 388], "165": 32, "139": [32, 323], "567": [32, 54], "sec": [32, 54, 296, 309, 311, 323, 357], "output_graph": [32, 354, 355, 363, 367], "fp32_optimized_model": 32, "3x": [32, 186, 221, 231, 247], "325": 32, "56": [32, 48, 54, 136, 140, 264, 274, 277, 281, 300], "41": [32, 54, 136, 137, 151, 277, 318, 388], "068": [32, 130], "992": [32, 140], "q_dataload": [33, 53, 145], "na": [34, 130], "gpu": [34, 44, 46, 55, 117, 121, 124, 130, 155, 156, 159, 160, 188, 197, 206, 214, 219, 224, 240, 241, 252, 253, 254, 256, 258, 262, 264, 272, 273, 274, 275, 277, 285, 288, 292, 293, 301, 318, 328, 355], "broad": [34, 374], "snippet": [34, 155, 231, 249, 281, 362], "upload": [34, 126, 157, 159, 168, 251, 275, 285, 288, 365, 379, 382], "dispatch": 34, "fx": [34, 45, 46, 47, 54, 56, 146, 150, 296, 309, 310, 311, 312, 315, 323, 326, 330, 333, 374, 375], "qlinearop": [34, 46, 56, 76, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 107, 108, 109, 110, 114, 115], "qintegerop": [34, 46], "unstructur": [34, 44, 54, 56, 292, 294, 301, 304], "lock": [34, 42, 44, 56, 292, 294, 301, 304], "snip": [34, 44, 54, 56, 295, 305], "gradient": [34, 44, 54, 56, 161, 162, 168, 187, 216, 233, 244, 253, 254, 273, 302, 303], "sensit": [34, 44, 56, 156, 228, 241, 290, 295, 302, 303, 305, 361], "lasso": [34, 44, 56, 306], "intermedi": [34, 44, 46, 159, 167, 233, 241, 247, 281, 285, 288, 295, 305], "plan": [34, 38, 121, 158, 190, 226, 237, 241, 246, 250], "frequent": [35, 250, 252], "ask": [35, 155, 156, 159, 167, 233, 248, 250, 273, 284, 285, 288], "esri": 35, "apach": [36, 55, 117, 281], "softwar": [36, 38, 43, 45, 49, 147, 155, 156, 297], "copyright": 36, "notic": [36, 156, 159, 167, 169, 251, 252, 285, 288, 356], "subject": [36, 156, 245, 384], "mit": [36, 70, 71, 250, 319], "accompani": [36, 164, 187, 213, 252], "wish": [36, 121, 123, 126, 158, 165, 253, 286, 295, 305], "bibtex": [36, 319], "entri": [36, 120, 126, 156, 157, 167, 168, 186, 273, 276, 319], "misc": [36, 250, 261, 273, 281, 319], "author": [36, 133, 136, 157, 158, 159, 162, 167, 190, 191, 195, 196, 197, 202, 217, 220, 224, 226, 228, 233, 237, 245, 255, 259, 261, 263, 264, 265, 267, 269, 270, 271, 272, 273, 275, 280, 281, 285, 286, 287, 288, 319, 328], "feng": [36, 157, 168, 199, 241], "tian": 36, "chuanqi": 36, "wang": [36, 133], "guom": 36, "zhang": [36, 136, 157, 168, 203, 224, 226, 237, 241], "penghui": 36, "cheng": [36, 319], "pengxin": 36, "yuan": 36, "haihao": 36, "shen": 36, "jiong": 36, "gong": [36, 157, 168, 226, 237, 241], "titl": [36, 133, 136, 155, 157, 240, 261, 263, 264, 269, 272, 273, 281, 319, 328], "howpublish": [36, 319], "url": [36, 133, 136, 140, 147, 156, 157, 240, 251, 263, 297, 319, 364, 388], "year": [36, 133, 136, 157, 209, 213, 215, 246, 250, 261, 263, 264, 269, 273, 276, 281, 319, 321, 328], "2020": [36, 126, 136, 157, 160, 191, 194, 195, 196, 225, 226, 237, 261, 263, 264, 269, 273, 281, 288], "logo": [36, 43], "atom": 36, "phi": 36, "pentium": 36, "vtune": 36, "corpor": [36, 43, 165], "subsidiari": [36, 43], "brand": [36, 43, 285], "claim": [36, 43], "popularli": 37, "mae": 37, "compare_label": 37, "error": [37, 53, 70, 71, 156, 159, 179, 186, 240, 249, 251, 285, 288, 319, 355, 388], "rmse": [37, 53], "squar": [37, 53, 241, 359, 361], "problem": [37, 38, 121, 126, 155, 156, 157, 159, 165, 169, 186, 188, 222, 227, 232, 234, 241, 251, 252, 275, 279, 285, 288], "anno_path": 37, "iou_thr": [37, 327], "map_point": 37, "label_map": 37, "union": 37, "decis": [37, 126, 154, 176, 186, 227, 251], "bound": [37, 52, 215, 218, 316, 319, 328], "string": [37, 52, 126, 130, 155, 156, 158, 159, 165, 185, 190, 233, 245, 246, 248, 250, 251, 252, 285, 288, 388], "95": [37, 54, 130, 140, 204, 215, 250, 261, 262, 264, 269, 271, 300], "standard": [37, 52, 53, 126, 164, 165, 167, 185, 186, 190, 195, 210, 213, 216, 217, 228, 232, 241, 245, 248, 253, 269, 270, 275, 286, 383], "threshold": [37, 261, 263, 269, 388], "101": [37, 54, 56, 136, 145, 146, 147, 148, 150, 167, 193, 223, 241, 246, 248, 318, 328, 346, 355], "interpol": [37, 52, 126, 130], "ap": [37, 130, 315, 318, 321, 327], "area": [37, 52, 156, 186, 195, 196], "pr": [37, 155, 157, 158, 159, 251, 274, 276, 284, 285, 288, 379, 382], "curv": [37, 240], "target_boxes_num": 37, "str_label": 37, "int_label": 37, "image_id": [37, 315, 362], "inturn": 37, "id": [37, 50, 53, 120, 122, 124, 126, 158, 159, 165, 185, 220, 228, 233, 238, 242, 246, 247, 248, 250, 252, 276, 277, 279, 285, 288, 318, 384, 388], "cocomap": [37, 362], "vocmap": 37, "cocomapv2": 37, "output_index_map": 37, "num_detect": [37, 114, 115, 362, 388], "bleu": [37, 209, 220, 236, 273, 276, 298, 313, 360, 361], "approxim": [37, 126, 214, 228, 244, 249], "piec": [37, 159, 176, 277, 285, 288], "decod": [37, 52, 157, 159, 162, 168, 185, 190, 191, 193, 201, 202, 209, 210, 216, 219, 220, 224, 226, 232, 235, 237, 239, 241, 245, 246, 247, 249, 250, 252, 273, 282, 285, 288, 334], "By": [37, 39, 72, 116, 140, 155, 159, 160, 176, 186, 193, 232, 241, 244, 246, 248, 249, 251, 264, 269, 272, 275, 285, 288, 332, 377, 378, 381], "ngram": [37, 202, 226, 237], "breviti": [37, 126], "penalti": [37, 269], "beam": [37, 224], "squadf1": [37, 357], "categor": [37, 250], "multiclass": [37, 162], "multilabel": 37, "multi_metr": 37, "equal": [37, 155, 228, 241, 244, 295, 297, 305], "num": [37, 120, 130, 138, 144, 328, 356, 388], "newmetr": 37, "reflect": [37, 43, 52, 72, 156, 164, 186, 233, 308], "recent": [38, 155, 156, 165, 192, 193, 197, 199, 201, 202, 213, 214, 215, 221, 223, 225, 230, 233, 236, 241, 249, 254, 259, 264, 277, 361], "growth": 38, "complex": [38, 126, 156, 159, 167, 183, 217, 228, 252, 253, 275, 285, 288], "capabl": [38, 46, 53, 153, 157, 200, 204, 211, 212, 218, 233, 239, 241, 249, 254, 269, 277, 329], "googl": [38, 45, 100, 130, 155, 156, 157, 158, 159, 164, 168, 193, 201, 202, 206, 215, 219, 224, 228, 230, 233, 247, 250, 254, 273, 274, 279, 285, 288, 289, 354, 355], "fp16": [38, 46, 156, 160, 186, 224, 254, 272, 273, 274, 275, 277], "ieee": [38, 314], "half": [38, 201, 202, 251, 256, 273], "sixteen": [38, 161], "bandwidth": 38, "3rd": [38, 45, 46, 47, 136], "gen": [38, 45, 47, 130, 131, 250], "codenam": 38, "boost": [38, 45, 56, 70, 71, 136, 191, 258, 275], "avx512": [38, 46, 69, 70, 71], "vcvtne2ps2bf16": 38, "vcvtneps2bf16": 38, "vdpbf16p": 38, "dot": [38, 46, 228, 244, 252], "pair": [38, 72, 159, 162, 165, 168, 184, 200, 209, 211, 212, 218, 219, 229, 233, 247, 276, 277, 281, 285, 288, 303, 341], "forc": [38, 47, 220, 232, 246, 250, 251, 252, 264, 272], "mixedprecis": 38, "drop": [38, 44, 54, 120, 216, 217, 241, 288, 295, 305, 378], "user_defined_funct": 38, "converted_model": 38, "output_path": [38, 94, 388], "avx512_bf16": 38, "encapsul": [39, 66, 67, 68, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 183, 272, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368], "persist": 39, "workspac": [39, 59, 314, 384], "gap": [39, 157, 168, 224, 241], "brought": [39, 46, 120], "graphdef": [39, 114, 115], "tf1": 39, "tf2": [39, 157, 168, 253, 364], "h5": [39, 240, 339, 340, 342, 343, 344, 346, 347, 348, 349, 350], "pt": [39, 45, 47, 145, 146, 152, 153, 157, 171, 182, 190, 193, 195, 213, 217, 219, 220, 224, 228, 232, 233, 244, 246, 248, 249, 250, 253, 273, 281, 288, 292, 293, 294, 301, 304, 315, 323, 329, 330, 333, 334], "onnx_ml_pb2": 39, "modelproto": 39, "hybridblock": 39, "0000": [39, 119, 120, 122], "inc_model": 39, "input_model": [39, 51, 66, 68, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 153, 290, 297, 308, 310, 312, 323, 325, 326, 329, 330, 333, 334, 336, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 361, 362, 364, 365, 367, 368, 384, 388], "saved_result": [39, 312, 323, 326, 334, 335], "tflite": [40, 77, 104, 130], "modelconvers": 40, "destin": [40, 122, 124], "saved_model": [40, 59, 263, 368], "models": [41, 53], "multi_object": [41, 388], "peak": [41, 160, 167, 275], "durat": [41, 50, 251, 388], "start_tim": 41, "_result_list": 41, "customobj": 41, "simultan": [42, 226, 237, 241, 292, 301, 370], "arbitrari": [42, 56, 126, 160, 316], "meaning": [42, 126, 159, 252, 285, 288], "benefit": [42, 44, 126, 155, 156, 169, 186, 269], "Of": [42, 156, 186, 233, 251, 253, 276], "cours": [42, 123, 156, 186, 233, 251, 253], "schedul": [42, 121, 165, 168, 224, 250, 251, 253, 295, 305, 319], "prune_conf": [42, 142, 143], "post_training_quantization_conf": 42, "opt_model": [42, 142, 143], "quantization_aware_training_conf": 42, "configurationintel": 43, "platinum": [43, 48, 54], "8380": [43, 48, 54], "manufactur": [43, 269], "m50cyp2sbstd": 43, "bio": 43, "se5c6200": 43, "86b": 43, "0022": 43, "d64": 43, "2105220049": 43, "microcod": 43, "0xd0002b1": 43, "30ghz": 43, "frequenc": [43, 138, 252, 295, 305], "3ghz": 43, "socket": [43, 48, 54, 359, 361], "turbo": 43, "perf": 43, "balanc": [43, 221, 233, 281], "256gb": 43, "16x16gb": 43, "ddr4": 43, "3200mt": 43, "nic": 43, "ethernet": 43, "10g": 43, "x550t": 43, "drive": [43, 123, 274, 279], "1x": [43, 318, 319], "intel_ssdsc2kw01": 43, "953": 43, "9g": 43, "ct1000mx500ssd1": 43, "931": 43, "5g": 43, "vari": [43, 54, 126, 160, 186, 213, 247, 249], "publicli": [43, 126, 193, 195, 196, 201, 202, 203, 236, 238, 281], "servic": [43, 156, 250, 387], "compil": [43, 126, 147, 159, 165, 186, 249, 253, 277, 285, 288, 319], "degre": [43, 250], "mark": [43, 241, 251, 328], "trademark": 43, "briefli": 44, "least": [44, 53, 76, 93, 95, 123, 126, 157, 159, 167, 179, 186, 187, 224, 228, 244, 245, 249, 251, 252, 285, 288], "maxim": [44, 53, 69, 126, 156, 239, 250, 252, 256], "state": [44, 126, 157, 160, 161, 165, 168, 171, 176, 186, 188, 190, 191, 192, 193, 194, 198, 205, 208, 210, 211, 214, 215, 216, 217, 218, 222, 223, 224, 225, 226, 227, 228, 230, 232, 233, 234, 235, 236, 237, 239, 241, 245, 247, 248, 250, 264, 269, 273, 282, 319, 371], "art": [44, 126, 157, 168, 188, 190, 191, 192, 193, 194, 198, 205, 208, 211, 214, 215, 216, 217, 218, 222, 223, 225, 226, 227, 228, 230, 232, 233, 234, 235, 236, 237, 239, 241, 245, 269, 273, 282, 319], "increasingli": 44, "plai": [44, 45, 121, 126, 157, 169, 233, 261, 262, 281], "crucial": [44, 159, 228, 231, 264, 285, 288], "role": [44, 121, 206], "rule": [44, 156, 159, 248, 252, 285, 288, 319, 370], "salient": 44, "nonzero": 44, "irregular": 44, "anywher": 44, "2in4": [44, 56], "amper": 44, "delet": [44, 123, 169, 240, 241, 251, 286], "due": [44, 46, 51, 121, 126, 159, 165, 188, 216, 217, 231, 233, 239, 285, 288], "restrict": [44, 50, 277], "howev": [44, 120, 126, 155, 156, 158, 159, 165, 167, 186, 188, 190, 195, 199, 206, 213, 214, 221, 222, 227, 231, 233, 239, 241, 244, 246, 249, 251, 252, 269, 275, 285, 288], "abl": [44, 46, 121, 126, 155, 156, 159, 161, 169, 186, 187, 190, 197, 210, 238, 240, 241, 246, 248, 251, 252, 262, 269, 272, 285, 288, 319, 332], "contigu": [44, 241, 330], "gemm": [44, 293, 295, 305], "ic": [44, 45], "oc": [44, 219], "kh": 44, "kw": [44, 219], "examin": [44, 210], "lowest": [44, 252], "head": [44, 56, 130, 158, 159, 161, 165, 167, 171, 180, 199, 206, 233, 241, 245, 247, 248, 249, 250, 253, 264, 272, 275, 281, 285, 288], "fastform": 44, "regular": [44, 123, 126, 157, 220, 240, 241, 245, 252, 254, 269, 295, 305, 383], "dens": [44, 54, 157, 159, 168, 205, 227, 229, 241, 269, 285, 288, 295, 305], "mask": [44, 54, 56, 126, 136, 157, 158, 162, 165, 168, 183, 185, 192, 201, 202, 206, 208, 213, 217, 218, 221, 222, 224, 231, 232, 233, 235, 236, 238, 239, 241, 242, 244, 245, 247, 248, 249, 253, 254, 258, 264, 281, 282, 296, 297, 314, 315, 362], "formula": [44, 249], "w": [44, 52, 130, 136, 157, 162, 168, 214, 217, 231, 251, 254, 269, 274, 316, 325, 328], "caus": [44, 118, 126, 159, 187, 212, 251, 252, 264, 267, 285, 288], "gradual": [44, 210], "on_before_optimizer_step": [44, 295, 305], "pruning_func": 44, "num_train_epoch": [44, 97, 100, 105, 156, 165, 186, 253, 254, 257, 258, 261, 268, 269, 273, 277, 291, 292, 294, 295, 299, 300, 301, 302, 304, 305, 310, 312, 356], "pbar": 44, "progressbar": [44, 251], "n_total": 44, "attention_mask": [44, 165, 167, 185, 233, 246, 248, 253], "token_type_id": [44, 167, 190, 204, 217, 222, 230, 233, 246, 288], "n_gpu": [44, 251], "gradient_accumulation_step": [44, 116, 186, 257, 258, 268, 273], "clip_grad_norm_": [44, 187], "max_grad_norm": [44, 186, 187], "rate": [44, 46, 121, 165, 186, 187, 230, 248, 253, 273, 281, 306, 319, 356], "cv": 44, "chines": [45, 242, 247, 252, 264, 267], "grain": [45, 126, 249], "aug": [45, 364], "purif": 45, "sacrif": [45, 238], "jun": 45, "partner": [45, 195, 196, 249], "democrat": [45, 186], "apr": [45, 195, 196], "ecosystem": [45, 140], "mar": 45, "workload": [45, 282, 384], "feb": 45, "sigopt": 45, "jan": [45, 70, 71, 226, 237, 388], "tutori": [45, 55, 66, 67, 68, 69, 110, 114, 115, 124, 131, 134, 135, 136, 138, 139, 145, 146, 147, 148, 150, 153, 157, 162, 165, 168, 240, 246, 248, 252, 290, 298, 308, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368], "bilibili": 45, "dec": [45, 224, 241, 388], "ml": [45, 168, 176, 186], "doubl": [45, 156, 158, 167, 187, 246], "mlperf": [45, 56, 104, 118, 314, 323, 324, 326, 329, 330, 333, 334, 361, 366], "3d": [45, 54, 56, 118, 120, 121, 122], "digit": [45, 119, 120, 219], "reconstruct": [45, 206, 220, 241], "abound": 45, "cern": 45, "gan": [45, 241], "3dgan": 45, "4th": 45, "iml": 45, "workshop": [45, 264], "highli": [45, 126, 186, 210, 231, 253, 264], "intelcaff": 45, "veri": [46, 53, 120, 121, 122, 126, 130, 155, 156, 157, 159, 160, 165, 186, 191, 197, 198, 200, 208, 209, 212, 216, 228, 238, 240, 241, 246, 248, 249, 250, 251, 252, 254, 264, 273, 282, 285, 288, 319], "invent": 46, "int4": 46, "mainli": [46, 161, 174, 193], "miss": [46, 159, 249, 251, 274, 285, 288], "cost": [46, 157, 159, 168, 188, 199, 210, 233, 241, 258, 285, 288], "theoret": 46, "affin": 46, "math": [46, 250, 251, 290, 359], "equat": 46, "zeropoint": 46, "255": [46, 59, 72, 140], "overflow": [46, 187], "solv": [46, 49, 153, 155, 156, 159, 235, 245, 250, 251, 252, 272, 285, 288, 329], "belong": [46, 120, 121, 156, 204, 215, 217, 222, 230, 250, 285, 288], "unseen": 46, "dump": [46, 51, 53, 237, 264], "peopl": [46, 154, 155, 156, 159, 161, 240, 250, 285, 288], "emul": [46, 186, 251], "uniqu": [46, 119, 120, 121, 140, 156, 228, 232, 251, 252], "parti": [46, 136, 186], "pain": 46, "lossi": [46, 324], "queri": [46, 101, 156, 199, 217, 228, 233, 241, 258, 272, 281, 295, 305], "philosophi": [46, 159, 168, 285, 288, 362], "fulli": [46, 53, 126, 155, 159, 165, 186, 231, 239, 240, 244, 251, 265, 269, 285, 288], "respons": [46, 120, 123, 156, 157, 168, 203, 224, 248, 384, 388], "val_dataset": [46, 68, 165], "val_dataload": [46, 295, 305], "num_work": [46, 68, 327], "worker": [46, 135, 251, 272], "ping_memori": 46, "use_bf16": [47, 116], "enhanc": [47, 117, 118, 157, 168, 201, 202, 370], "datatyp": [47, 53, 384], "bf16_op": 47, "cast": [47, 52], "bf16convert": 47, "matter": [47, 156, 159, 233, 285, 288], "wrapper": [47, 183, 186, 215, 230, 247, 251], "bf16wrapper": 47, "retrac": 47, "bert_large_squad_stat": 48, "78": [48, 52, 54, 62, 63, 130, 136, 140, 261, 264, 269, 277, 295, 300, 305, 354, 355, 388], "49": [48, 54, 136, 264, 274, 277, 300], "08": [48, 52, 54, 130, 140, 160, 234, 277, 388], "48": [48, 54, 130, 136, 233, 247, 273, 277, 300, 328, 388], "64x": 48, "bert_base_mrpc_stat": 48, "35": [48, 54, 56, 128, 130, 137, 157, 160, 264, 277, 318, 328, 388], "09": [48, 54, 130, 140, 160, 388], "497": 48, "151": [48, 54], "29x": [48, 54], "bert_base_nli_mean_tokens_stsb_stat": 48, "55": [48, 54, 136, 233, 277, 328], "546": [48, 130], "60x": 48, "bert_base_sparse_mrpc_stat": 48, "551": 48, "153": [48, 54], "bert_mini_mrpc_stat": 48, "6962": 48, "3252": 48, "14x": [48, 54], "bert_mini_sst2_stat": 48, "6850": 48, "3218": 48, "98": [48, 54, 130, 264, 295, 305, 388], "13x": [48, 54], "distilbert_base_uncased_sst2_stat": 48, "25": [48, 54, 130, 136, 137, 140, 160, 220, 241, 247, 264, 274, 320, 388], "1086": 48, "306": [48, 130], "54x": [48, 54], "distilbert_base_uncased_mrpc_stat": 48, "07": [48, 54, 70, 71, 136, 140, 215, 273, 277, 300, 388], "1091": 48, "303": 48, "distilbert_base_uncased_emotion_stat": 48, "94": [48, 52, 54, 62, 63, 130, 140, 215, 250, 261, 264, 354, 355, 388], "1081": 48, "53x": [48, 54], "minilm_l6_h384_uncased_sst2_stat": 48, "2594": 48, "1083": 48, "39x": 48, "roberta_base_mrpc_stat": 48, "508": [48, 130, 133, 140], "31x": [48, 54], "distilroberta_base_wnli_stat": 48, "34": [48, 54, 130, 137, 156, 236, 250, 258, 277, 305, 318], "1097": [48, 160], "22": [48, 54, 140, 218, 258, 277, 318, 320, 328, 359, 388], "315": [48, 130], "47x": [48, 54], "paraphrase_xlm_r_multilingual_v1_stsb_stat": 48, "66": [48, 54, 130, 140, 264, 277], "552": [48, 130], "44": [48, 54, 130, 136, 274, 328, 388], "finbert_financial_phrasebank_stat": 48, "999": [48, 186], "292": [48, 130, 140], "site": [49, 169], "assist": 49, "comparison": [49, 51, 159, 213, 230, 264, 273, 275, 285, 288, 300, 319], "impact": [49, 53, 69, 154, 230, 244, 251], "old": [49, 130, 159, 168, 233, 246, 250, 256, 258, 276, 285, 288, 328], "renam": [49, 165, 283], "sed": 49, "your_script": 49, "backbon": [50, 314, 318, 328], "interact": [50, 117, 154, 159, 215, 285, 288], "mechan": [50, 167, 187, 201, 202, 216, 217, 226, 227, 228, 234, 237, 241, 242, 250, 251, 256, 272, 288], "sigopt_api_token": [50, 53], "sigopt_project_id": [50, 53], "sigopt_experiment_id": 50, "login": [50, 116, 240, 254, 283, 321, 379, 382], "although": [50, 121, 199, 211, 241, 250], "certain": [50, 156, 159, 167, 186, 200, 241, 285, 288], "suffici": [50, 123, 126, 142, 143, 156, 159, 269, 285, 288, 332], "ordinari": 50, "capac": [50, 140, 156, 186, 210, 238, 250], "obtain": [50, 53, 122, 126, 140, 158, 192, 197, 213, 215, 233, 236, 241, 246, 252, 264, 269, 277, 279, 292, 301, 324], "sigopt_experiment_nam": [50, 53], "receiv": [50, 156, 186], "analysi": [50, 56, 145, 157, 161, 162, 169, 183, 184, 213, 239, 248, 249, 250, 260, 370], "draw": [50, 53, 155], "8266": 50, "8372": 50, "2132": [50, 159, 285, 288], "7495": 50, "8299": 50, "8294": 50, "0837": 50, "8291": 50, "4469": 50, "visual": [51, 53, 159, 215, 218, 285, 288], "discov": [51, 155, 250, 264, 275], "why": [51, 154, 155, 156, 159, 186, 240, 241, 248, 252, 267, 281, 285, 288], "valuabl": [51, 155], "instrument": [51, 250], "writer": 51, "pseudo": [51, 159, 285, 288], "_pre_eval_hook": 51, "_post_eval_hook": 51, "submodul": [51, 117, 147, 253, 288, 293], "whitelist": 51, "_recordingobserv": 51, "output_tensors_dict": 51, "current_it": 51, "export": [51, 76, 77, 93, 95, 96, 97, 98, 99, 100, 103, 105, 114, 115, 116, 117, 118, 123, 126, 140, 160, 164, 168, 186, 206, 257, 258, 260, 261, 264, 267, 273, 277, 279, 282, 297, 310, 319, 325, 354, 359, 361, 366, 367, 371], "get_tensor_valu": 51, "_observer_forward_hook": 51, "_add_observer_": 51, "child": [51, 157, 168, 212], "named_children": 51, "op_nam": 51, "leaf": 51, "add_modul": 51, "register_forward_hook": 51, "dump_tim": 51, "summarywrit": 51, "_acc": 51, "tune_": 51, "add_graph": 51, "get_observer_dict": 51, "observer_dict": 51, "strip": [51, 165, 356], "parent": [51, 121, 159, 168, 251, 285, 288, 324], "is_quant": 51, "add_histogram": 51, "merg": [51, 53, 122, 155, 156, 158, 159, 240, 251, 252, 273, 285, 286, 288, 379, 382], "shell": [51, 152, 155, 160, 169, 186], "bind_al": [51, 145, 146], "logdir_spec": [51, 145, 146], "tune_0_acc0": [51, 145, 146], "tune_1": 51, "tune_1_acc0": [51, 145, 146], "image_recognit": [51, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 354, 355], "run_tuning_dump_tensor": [51, 145, 146], "sh": [51, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 141, 144, 145, 146, 147, 151, 153, 224, 270, 273, 279, 283, 290, 293, 297, 298, 303, 306, 308, 310, 312, 313, 314, 315, 323, 325, 326, 327, 328, 329, 330, 333, 334, 335, 336, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368], "four": [51, 72, 120, 148, 158, 209, 214, 250, 273, 275, 279], "session": [51, 59, 117, 123, 203, 251, 362], "baseline_acc_0": 51, "776": [51, 130, 269], "tune_1_acc_0": 51, "095": 51, "runs_v3": 51, "inceptionv3": [51, 66, 140], "skip": [51, 53, 126, 155, 240, 249], "v0": 51, "cg": 51, "conv0": 51, "bash": [51, 66, 68, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 141, 147, 151, 186, 211, 251, 273, 279, 292, 293, 297, 301, 303, 312, 315, 323, 325, 326, 327, 328, 329, 330, 333, 334, 335, 336, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 365, 367, 368], "run_tun": [51, 66, 68, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 147, 153, 290, 297, 298, 308, 310, 312, 313, 315, 323, 325, 326, 329, 330, 333, 334, 335, 336, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 359, 361, 362, 364, 365, 367, 368], "topologi": [51, 66, 68, 103, 121, 126, 141, 144, 145, 146, 147, 151, 254, 290, 297, 298, 303, 308, 310, 313, 323, 326, 335, 353, 364], "dataset_loc": [51, 66, 68, 145, 146, 147, 151, 153, 290, 297, 308, 310, 323, 325, 326, 329, 330, 333, 334, 335, 356, 359, 361, 364, 365, 368], "inceptionv3_fp32_pretrained_model": [51, 354], "output_model": [51, 66, 68, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 141, 151, 153, 294, 302, 303, 304, 312, 315, 323, 326, 334, 335, 336, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 367, 368], "nc_inceptionv3": [51, 354], "inceptionv3_dump_tensor": 51, "poor": [51, 244], "tab": [51, 158, 159, 165, 272, 279, 285, 288, 332], "eightbit": 51, "requant": 51, "disappear": 51, "bilinear": [52, 58, 60, 130], "desir": [52, 126, 140, 155, 156, 186, 210, 219, 252, 273, 292, 301, 308], "nearest": 52, "bicub": [52, 130], "aspect": [52, 121, 140, 168, 200, 251, 316, 319], "deviat": [52, 273], "randomcrop": 52, "transform_list": 52, "cropres": 52, "y": [52, 69, 126, 157, 165, 168, 195, 196, 219, 220, 241, 328, 371], "boundari": 52, "horizont": [52, 156, 314], "flip": [52, 314, 316], "randomverticalflip": 52, "vertic": 52, "decodeimag": 52, "jpeg": [52, 324], "encod": [52, 121, 136, 138, 157, 158, 159, 162, 165, 167, 168, 185, 187, 190, 191, 192, 193, 194, 198, 201, 202, 205, 206, 211, 213, 216, 217, 218, 219, 220, 224, 225, 226, 229, 232, 233, 234, 237, 241, 242, 244, 245, 246, 250, 264, 269, 272, 273, 285, 288, 316], "encodejp": 52, "transpos": [52, 159, 285, 288, 316], "perm": 52, "permut": [52, 157, 168, 222, 239, 241], "resizewithratio": 52, "min_dim": 52, "max_dim": 52, "800": [52, 130, 140, 224, 234, 319], "1365": 52, "longest": [52, 224, 246], "exce": [52, 216, 230, 319], "arrai": [52, 59, 72, 120, 159, 165, 235, 248, 250, 285, 288, 330, 357], "croptoboundingbox": 52, "offset_height": 52, "offset_width": 52, "target_height": 52, "target_width": 52, "coordin": [52, 233, 316, 328], "toarrai": 52, "pil": [52, 140, 215, 316, 319], "rescal": [52, 140, 327], "alignimagechannel": [52, 388], "dim": [52, 126, 248, 250, 388], "deprec": [52, 126, 276, 379, 382], "parsedecodeimagenet": [52, 72], "proto": 52, "random_crop": 52, "resize_sid": 52, "random_flip_left_right": 52, "mean_valu": [52, 62, 63, 354, 355, 388], "116": [52, 62, 63, 354, 355, 388], "103": [52, 62, 63, 234, 247, 264, 354, 355, 388], "017": 52, "quantizedinput": 52, "labelshift": 52, "label_shift": 52, "shift": [52, 232, 250, 273], "bilinearimagenet": [52, 58, 60, 62, 63, 72], "central_fract": 52, "875": [52, 130, 140], "fraction": [52, 126, 167, 251], "squadv1": [52, 98], "n_best_siz": 52, "max_query_length": [52, 184], "max_answer_length": 52, "doc_strid": [52, 184, 258, 294, 295, 297], "vocab_fil": [52, 356, 357, 358, 360, 361], "vocabulari": [52, 158, 162, 164, 165, 167, 180, 185, 187, 189, 202, 209, 240, 245, 247, 248, 250, 252, 264, 281], "nbest_predict": 52, "384": [52, 130, 160, 258, 292, 294, 295, 297], "wordpiec": [52, 165, 167, 247, 281], "chunk": [52, 216, 228, 241, 244, 252], "topilimag": 52, "padding_mod": 52, "border": 52, "pixel": [52, 120, 140, 221, 231, 314], "edg": [52, 157, 169, 204, 214, 269, 388], "colorjitt": 52, "bright": [52, 276], "contrast": [52, 211, 216, 217, 235, 241, 252, 269], "satur": 52, "hue": 52, "jitter": 52, "tondarrai": 52, "logic": [53, 72, 159, 214, 217, 233, 241, 272, 273, 281, 283, 285, 288], "max_trail": [53, 388], "scale_propagation_max_pool": 53, "scale_propagation_concat": 53, "first_conv_or_matmul_quant": 53, "2000": [53, 159, 186, 248, 273, 285, 288], "tf_record": [53, 357, 358], "model_wis": [53, 58, 354, 355, 356, 357, 359, 360, 361, 362], "pool1": 53, "guarante": [53, 94, 126, 269], "performance_onli": [53, 359], "tri": [53, 130, 156, 197, 206], "sort": [53, 154, 228, 251, 279], "accordingli": [53, 126, 156, 242], "increment": 53, "classic": [53, 157, 161, 241, 244], "black": [53, 155, 159, 285, 288], "come": [53, 116, 118, 122, 124, 130, 155, 156, 165, 168, 186, 240, 241, 248, 249, 251, 308, 312, 323, 326, 334, 354], "discret": [53, 156], "compli": [53, 159, 285, 288], "gaussian": 53, "posterior": 53, "focu": [53, 156, 159, 193, 215, 241, 249, 252, 253, 285, 288], "short": [53, 126, 155, 156, 158, 167, 193, 234, 247, 250, 273, 287], "never": [53, 126, 130, 156, 159, 220, 252, 275, 285, 288], "loglevel": 53, "messag": [53, 155, 156, 231, 251, 320, 362, 368, 384, 386, 388], "endlessli": 53, "idea": [53, 130, 155, 159, 186, 224, 239, 241, 250, 285, 288], "primari": 53, "smbo": 53, "trial": [53, 159, 285, 288, 388], "hyperparamet": [53, 126, 169, 230, 233, 252], "appl": [53, 250], "surrog": 53, "entropi": [53, 244, 253, 263, 314], "quantil": 53, "x1": [53, 215, 316, 319], "x2": [53, 316, 319], "densiti": 53, "parzen": 53, "minimum": [53, 159, 251, 273, 285, 288], "greatest": [53, 155, 252, 272], "hour": [53, 124, 169, 197, 235, 251, 256, 262, 273, 274], "dai": [53, 157, 168, 169, 206, 208, 231, 234, 239, 241, 250, 251, 272, 276, 281, 329, 330, 333], "travers": 53, "perspect": [53, 199, 241], "tunestrategi": 53, "strategy_registri": 53, "abctunestrategi": 53, "next_tune_cfg": 53, "till": 53, "ye": [54, 136, 155], "dlrm": [54, 56, 329, 330, 333], "rnn": [54, 56, 167, 234, 241, 281], "unet": [54, 56, 117, 118, 121], "performancethroughput": 54, "efficientnet": [54, 56, 131, 336, 364], "03": [54, 136, 140, 271, 288, 293, 388], "43": [54, 130, 136, 160, 277, 323, 328, 388], "32x": 54, "cnn": [54, 56, 66, 70, 71, 127, 133, 136, 153, 162, 190, 210, 226, 237, 247, 250, 254, 262, 272, 274, 276, 314], "incept": [54, 56, 66, 130, 338, 339, 340, 362, 364], "53": [54, 136, 137, 140, 233, 244, 264, 274, 277, 281, 306, 318, 328, 388], "57x": [54, 261], "savedmodel": [54, 56, 336, 339, 340, 342, 343, 344, 346, 347, 348, 349, 350], "46": [54, 136, 140, 264, 274, 388], "54": [54, 130, 136, 218, 234, 258, 264, 277, 388], "61": [54, 137, 261], "58x": 54, "39": [54, 130, 136, 250, 306, 318, 388], "11x": 54, "51x": 54, "06x": 54, "25x": 54, "163": [54, 140], "133": 54, "22x": 54, "111": [54, 323], "20x": 54, "v3": [54, 56, 66, 130, 136, 168, 194, 240, 254, 281, 283, 327, 338, 340, 355, 364], "02": [54, 127, 128, 129, 165, 215, 288, 295, 359, 388], "43x": 54, "v4": [54, 56, 157, 168, 169, 194, 355, 364, 374], "33x": 54, "ckpt": [54, 56, 60, 164, 273, 288, 354, 355, 356, 367, 368, 385], "44x": 54, "374": [54, 126, 140], "226": 54, "47": [54, 136, 264, 274], "41x": 54, "fashion": [54, 56, 70, 232, 241, 281, 345], "359": 54, "244": [54, 130], "172": [54, 130], "76x": 54, "112": [54, 246, 370], "35x": 54, "26x": 54, "56x": 54, "93x": 54, "178": [54, 130], "156": [54, 130], "18x": 54, "albert": [54, 56, 99, 157, 162, 168, 185, 231, 247, 252, 256, 261, 290, 308, 374], "barthez": [54, 157, 168, 247, 310], "81": [54, 130, 136, 137, 140, 258, 264, 269], "82x": 54, "203": 54, "216": 54, "102": [54, 130, 167, 193, 242, 246, 247, 248, 388], "10x": [54, 212, 273], "sst2": [54, 56, 99, 184, 250, 277, 299, 300, 301, 302, 304, 305, 308, 309, 311, 359, 374], "218": 54, "stsb": [54, 184, 277], "49x": 54, "70x": 54, "50x": 54, "40x": 54, "3878": 54, "3717": 54, "04x": 54, "camembert": [54, 56, 99, 157, 168, 185, 191, 230, 247, 310], "188": [54, 130, 140], "91x": 54, "ctrl": [54, 157, 168, 187, 247, 250, 278, 290, 308, 314], "deberta": [54, 157, 168, 247, 286, 310], "124": [54, 130], "81x": 54, "347": [54, 215], "382": 54, "198": [54, 130, 328], "flaubert": [54, 157, 168, 191, 247, 252, 310], "561": 54, "370": [54, 130], "52x": 54, "hubert": [54, 56], "409": 54, "181": 54, "longform": [54, 157, 162, 168, 216, 247, 288, 310], "mbart": [54, 156, 157, 162, 168, 247, 273, 274, 276, 290, 308], "16x": 54, "639": [54, 219, 283], "490": 54, "lvwerra": [54, 56], "pegasu": [54, 56, 157, 168, 247, 274, 288, 290, 298], "samsum": [54, 56, 298], "peleenet": [54, 56, 134, 383], "419": 54, "316": [54, 274], "resnet18": [54, 56, 66, 140, 141, 144, 151], "686": [54, 130], "332": [54, 130], "07x": 54, "611": 54, "333": 54, "83x": 54, "327": 54, "162": [54, 130], "175": 54, "197": [54, 269, 273], "99x": 54, "se_resnext50_32x4d": [54, 56, 140], "308": [54, 130], "144": 54, "squeezebert": [54, 157, 168, 247, 310], "186": 54, "155": [54, 167, 246], "78x": 54, "transfo": [54, 164, 187, 247, 250, 290, 308], "xl": [54, 130, 157, 168, 187, 212, 239, 247, 250, 252, 278, 290, 308], "37x": 54, "wave2vec2": 54, "60": [54, 136, 204, 250, 258, 264, 273, 300, 316, 388], "21x": 54, "114": [54, 130], "yolo": [54, 327, 328, 364, 388], "690": [54, 318], "330": 54, "09x": 54, "614": [54, 130], "334": 54, "84x": 54, "410": 54, "168": 54, "finetun": [54, 56, 98, 99, 140, 152, 153, 157, 162, 168, 216, 217, 220, 231, 233, 234, 239, 241, 247, 248, 250, 258, 264, 269, 276, 295, 296, 297, 298, 305, 308, 310, 311], "resnext101_32x16d_wsl": [54, 56, 147], "1189": 54, "680": 54, "677": 54, "381": 54, "alexnet": [54, 56, 70, 71, 140, 355, 374], "960": [54, 130], "469": 54, "17": [54, 130, 136, 137, 140, 165, 242, 247, 277, 279, 388], "05x": 54, "962": 54, "466": [54, 130], "arcfac": [54, 56], "235": 54, "130": [54, 250], "294": [54, 130, 140], "125": [54, 269, 388], "34x": 54, "604": [54, 130], "80x": 54, "caffenet": [54, 56], "1501": 54, "536": [54, 130], "1493": 54, "533": 54, "1372": 54, "541": 54, "480": [54, 130], "1250": 54, "753": 54, "1130": 54, "748": [54, 130], "emot": [54, 56], "ferplu": [54, 56], "336": 54, "65x": 54, "fcn": [54, 56], "googlenet": [54, 56, 364], "740": [54, 140], "587": 54, "770": [54, 130], "824": 54, "601": 54, "819": 54, "597": 54, "45x": 54, "613": 54, "506": 54, "2454": 54, "1543": 54, "2164": 54, "1564": 54, "38x": 54, "2147": 54, "1046": 54, "1877": 54, "1054": 54, "mobilenetv2": [54, 66, 87, 128, 336], "zoo": [54, 56, 66, 67, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 101, 102, 106, 107, 108, 109, 110, 111, 112, 113, 139, 140, 290, 296, 298, 308, 309, 310, 311, 313, 325, 329, 330, 333, 345, 356, 357, 358, 359, 360, 361, 364, 365, 366, 368], "2751": 54, "1797": 54, "2656": 54, "1835": 54, "7615": 54, "7646": 54, "764": [54, 130], "901": 54, "434": [54, 130, 140], "141": 54, "7614": [54, 148], "575": 54, "952": [54, 130], "433": 54, "7226": 54, "7229": 54, "761": 54, "432": [54, 140], "615": 54, "722": [54, 130], "032": 54, "894": 54, "885": 54, "454": [54, 130, 140], "95x": 54, "603": 54, "455": 54, "644": 54, "636": [54, 130, 140, 323], "254": [54, 130], "791": 54, "shufflenet": [54, 56, 133], "2298": 54, "1480": 54, "55x": 54, "1951": 54, "1490": 54, "squeezenet": [54, 56], "2588": 54, "1605": 54, "2566": [54, 159, 285, 288], "1936": 54, "725": 54, "570": 54, "27x": 54, "666": 54, "539": 54, "641": 54, "519": 54, "633": 54, "492": [54, 130], "542": [54, 130], "401": 54, "68x": 54, "tini": [54, 56, 230, 249, 251, 277], "yolov3": [54, 56, 363], "648": [54, 130], "518": [54, 140], "221": 54, "319": 54, "307": 54, "yolov4": [54, 56, 111], "zfnet": [54, 56], "459": 54, "261": 54, "460": [54, 130], "264": [54, 130, 140], "74x": 54, "441": 54, "337": 54, "272": [54, 130], "211": 54, "152": [54, 56, 130, 140, 328, 355], "423": 54, "180": [54, 130], "311": 54, "taskdataset": 54, "accuracyspars": 54, "ratiospars": 54, "commentsbalanc": 54, "unbalanc": 54, "classificationimagenet": 54, "76top": 54, "13top": 54, "magnitudepost": 54, "magnitudequant": 54, "answeringsquad": 54, "34f1": 54, "2x1": [54, 56], "lassounbalanc": 54, "classificationmnli": 54, "mm": [54, 269], "lockbalanc": 54, "classificationsst": 54, "32accuraci": 54, "sensitivitybalanc": 54, "classificationqqp": 54, "classificationqnli": 54, "54accuraci": 54, "em": [54, 272], "87f1": 54, "4x1": [54, 56, 295, 305], "momentumunbalanc": 54, "momentumbalanc": 54, "classificationmrpc": 54, "52f1": 54, "61accuraci": 54, "7965": 54, "wideresnet40": [54, 56, 128], "9522": 54, "8178": 54, "0213": 54, "5494": 54, "7153": 54, "5540": 54, "0046": 54, "vgg": [54, 56, 91, 129, 355], "7022": 54, "7415": 54, "7025": 54, "0003": [54, 120], "6739": 54, "7399": 54, "6845": 54, "0106": 54, "7034": 54, "8382": 54, "bilstm": [54, 56, 299], "8314": 54, "9403": 54, "9048": 54, "0734": 54, "7323": 54, "8256": 54, "8084": 54, "8814": 54, "7442": 54, "8371": 54, "0119": 54, "0115": [54, 159, 285, 288], "tinybert": [54, 56], "8018": 54, "8044": 54, "8363": 54, "8411": [54, 277], "8025": 54, "8074": 54, "0007": [54, 364], "0030": [54, 159, 285, 288], "8626": 54, "8213": 54, "9091": 54, "8782": 54, "8684": 54, "8259": 54, "0058": 54, "distilroberta": [54, 56, 157, 168, 247, 264, 299], "6057": 54, "6455": 54, "6187": 54, "0130": 54, "c6i": 54, "2xlarg": 54, "c6a": 54, "c6g": 54, "a100cuda": 54, "except": [54, 130, 155, 160, 186, 191, 198, 241, 250, 251, 277, 290, 292, 301], "mkl": [55, 378], "nativ": [55, 168, 186, 233, 250, 273], "upstream": [55, 159, 285, 288], "opt": [55, 130, 327, 373], "tabl": [56, 130, 133, 157, 162, 168, 233, 246, 251, 252, 258, 269, 274, 279, 281, 328, 385], "example1": [56, 57, 58], "example2": [56, 57, 59], "example3": [56, 57, 60], "example4": [56, 57, 61], "example5": [56, 57, 62], "example6": [56, 57, 63], "example7": [56, 57, 64], "flavor": [56, 57, 64, 185], "example8": [56, 57, 65], "pure": [56, 57, 65, 185, 269], "recogn": [56, 70, 71, 120, 122, 233], "handwrit": [56, 71], "densenet121": [56, 140, 354], "densenet161": [56, 140, 354], "densenet169": [56, 140, 354], "b0": [56, 130, 131, 336, 364], "xception": [56, 350], "natur": [56, 126, 154, 157, 167, 168, 184, 188, 190, 191, 192, 193, 197, 198, 199, 200, 201, 202, 204, 206, 208, 211, 212, 213, 214, 221, 222, 225, 231, 232, 233, 236, 239, 241, 248, 250, 260, 269, 273, 275, 303], "vit": 56, "densenet201": [56, 140, 353], "resnest50": [56, 136, 138], "speech": [56, 157, 168, 178, 194, 198, 225, 235, 246, 279, 335], "wav2vec2": [56, 157, 168], "t5": [56, 156, 157, 159, 162, 167, 168, 185, 186, 187, 202, 223, 247, 250, 252, 276, 285, 288, 290, 313], "helsinki": [56, 219, 247, 273, 274, 283], "opu": [56, 157, 168, 219, 247, 273, 274], "mt": [56, 159, 219, 247, 274, 285, 288], "en": [56, 156, 186, 202, 209, 211, 219, 220, 241, 242, 247, 251, 273, 274, 276, 277, 281, 290, 313, 360, 361], "ro": [56, 156, 186, 219, 220, 241, 247, 273, 274, 276, 290, 313, 354, 355], "pruneofa": [56, 292, 301], "densenet": [56, 133], "integerop": 56, "gpt2": [56, 157, 159, 164, 168, 171, 202, 203, 244, 246, 247, 250, 252, 256, 264, 278, 285, 288, 290, 308], "lm": [56, 249, 261, 281, 282], "wikitext": [56, 103, 234, 244, 247, 256, 264, 267, 290], "bidaf": 56, "minilm": [56, 99, 299], "l12": [56, 99], "h384": [56, 99, 299], "l6": [56, 99], "spanbert": [56, 98], "multilingu": [56, 98, 157, 168, 191, 198, 213, 220, 223, 225, 236, 238, 241, 242, 247, 248, 264, 273, 277, 279], "duc": 56, "ultra": 56, "enter": [57, 251, 293, 359, 378], "pretrain": [57, 76, 93, 95, 102, 104, 120, 123, 124, 131, 142, 143, 144, 145, 146, 147, 148, 149, 150, 157, 162, 164, 167, 168, 169, 177, 180, 185, 188, 189, 190, 191, 192, 193, 197, 198, 201, 202, 204, 206, 207, 208, 210, 211, 212, 215, 216, 217, 218, 219, 220, 224, 226, 227, 230, 232, 236, 237, 238, 239, 240, 241, 245, 246, 250, 252, 253, 258, 261, 264, 269, 273, 282, 307, 325, 335, 354, 355, 359, 364, 365, 367, 370, 374], "resampl": [58, 60, 121], "224x224": [58, 60], "And": [58, 116, 156, 159, 187, 219, 240, 246, 251, 262, 267, 269, 276, 285, 288, 354, 356, 371], "tf_imagenet": 58, "quick": [59, 126, 156, 164, 168, 187, 244, 246, 273, 275, 277], "work_dir": 59, "train_imag": [59, 72], "train_label": [59, 72, 165], "test_imag": [59, 72], "test_label": [59, 72, 165], "fashion_mnist": [59, 72], "load_data": [59, 72], "astyp": [59, 72, 233], "mymetr": [59, 72], "pred_list": [59, 72], "label_list": [59, 72, 250], "argmax": [59, 72, 250, 253, 388], "axi": [59, 72, 121, 248, 250, 330], "correct_num": [59, 72], "hello_world": [59, 72], "as_default": [59, 362], "sess": 59, "import_graph_def": [59, 362], "graph_def": [59, 362], "styled_imag": 59, "feed_dict": [59, 359], "inception_v1_2016_08_28": [60, 354, 355], "xvf": [60, 114, 115, 262, 354, 355, 362, 367], "last_batch": [60, 62, 63], "discard": [60, 62, 63], "openvinotoolkit": [61, 354, 364], "open_model_zoo": [61, 354, 364], "checkout": [61, 118, 147, 155, 159, 251, 254, 285, 288, 314, 354, 364], "rfcn": [61, 364], "output_dir": [61, 67, 97, 100, 105, 116, 156, 165, 186, 253, 254, 256, 257, 258, 260, 261, 263, 267, 268, 269, 272, 273, 275, 276, 277, 279, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 301, 304, 305, 308, 309, 310, 311, 312, 313, 315, 354, 355, 356, 357, 358, 364, 368, 373, 374], "rfcn_resnet101_coco_2018_01_28": 61, "write_graph": [63, 360], "graph_or_graph_def": 63, "logdir": [63, 328], "as_text": 63, "frozen_graph": 64, "resnet152": 66, "prepare_dataset": [66, 68, 323, 334, 354, 355, 356, 357, 358, 362, 363], "q90": 66, "rec": [66, 138], "prepare_model": [66, 96, 97, 100, 105, 339, 340, 342, 343, 344, 346, 347, 348, 349, 350, 356, 357, 362, 368], "model_nam": [66, 73, 116, 140, 219, 224, 233, 248, 273, 274, 286, 354, 362, 364, 384], "model_path": [66, 94, 260, 362, 364, 368, 384, 388], "val_256_q90": 66, "nc_resnet18": 66, "nc_resnet152_v1": 66, "nc_squeezenet": 66, "nc_mobilenet1": 66, "nc_mobilenetv2_1": 66, "nc_inception_v3": [66, 355], "run_benchmark": [66, 68, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 147, 153, 160, 297, 312, 323, 325, 326, 329, 330, 333, 334, 335, 336, 339, 340, 342, 343, 344, 345, 346, 347, 348, 349, 350, 359, 361, 364, 365, 368], "q": [66, 67, 68, 131, 134, 135, 139, 146, 147, 148, 150, 153, 205, 231, 241, 251, 267, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368], "func": [66, 67, 68, 131, 134, 135, 139, 146, 147, 148, 150, 153, 158, 290, 296, 298, 308, 309, 310, 311, 313, 315, 326, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368], "itself": [66, 67, 68, 126, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 155, 157, 159, 167, 218, 233, 241, 245, 248, 251, 264, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 373], "simplic": [66, 131, 134, 135, 136, 139, 145, 146, 147, 148, 150, 153, 186, 315, 327, 354], "pytorch_ipex": [66, 131, 134, 135, 139, 147, 333, 354, 355, 362, 367], "toler": [66, 67, 68, 131, 134, 135, 139, 145, 146, 147, 148, 150, 159, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313, 315, 327, 329, 330, 331, 333, 354, 355, 362, 367], "symbol_fil": 66, "param_fil": 66, "logger": [66, 156, 159, 179, 285, 288, 290, 296, 298, 308, 309, 310, 311, 313], "gluonnlp": 67, "finetune_classifi": 67, "finetune_squad": 67, "2e": [67, 97, 100, 105, 254, 261, 277, 299, 302, 304, 306, 312, 356], "task_nam": [67, 96, 97, 99, 100, 105, 254, 257, 260, 261, 277, 299, 300, 301, 302, 304, 305, 308, 309, 310, 311, 312, 356, 373, 374], "warmup_ratio": 67, "adam": [67, 157, 165, 168, 186, 187, 223, 232, 251, 253, 281], "3e": [67, 186, 253, 258, 269, 273, 293, 306], "bert_model": [67, 102, 104, 164, 279, 312, 357, 358], "bert_12_768_12": 67, "only_infer": 67, "model_paramet": 67, "model_bert_mrpc_4": 67, "round_to": 67, "test_batch_s": 67, "only_predict": 67, "At": [67, 68, 70, 71, 156, 157, 159, 161, 169, 251, 252, 273, 285, 288, 328], "dev": [67, 101, 126, 152, 153, 155, 159, 165, 221, 251, 261, 264, 269, 272, 277, 279, 285, 286, 288, 293, 297, 334, 335, 357, 358, 377, 381, 387], "hybrid": [67, 252], "static_alloc": 67, "static_shap": 67, "segment": [67, 118, 119, 120, 121, 122, 124, 126, 165, 167, 204, 217, 222, 225, 230, 233, 234, 241, 244, 281, 314, 319, 367], "dev_data": 67, "dev_data_list": 67, "metric_nm": 67, "metric_v": 67, "loader_dev": 67, "voc2007": 68, "unchang": 68, "coco2017": [68, 107, 108, 111, 112, 113, 315, 323], "home": [68, 123, 138, 140, 169, 323, 371, 388], "dataset_nam": [68, 186, 256, 258, 267, 270, 276, 279, 290, 291, 292, 294, 295, 296, 297, 315], "nc_ssd_resnet50_voc": 68, "nc_ssd_mobilenet1": 68, "0_voc": 68, "nc_ssd_resnet50_coco": 68, "0_coco": 68, "model_prefix": 68, "nc_ssd_model": 68, "vocmapmetr": 68, "cocoev": 68, "val_metr": 68, "get_dataset": 68, "val_data": 68, "get_dataload": 68, "obvious": [69, 70, 71], "screen": [69, 70, 71], "lscpu": 69, "avx512_vnni": 69, "set_env": 69, "env_intel_tf": 69, "bin": [69, 70, 71, 79, 155, 159, 164, 186, 240, 266, 273, 285, 288, 297, 307, 320], "fp": [69, 70, 71, 126, 133, 328], "378": [69, 130], "35371907536023": 69, "x113": 69, "26080122625": 69, "190600580098675": 69, "y7": 69, "58170614437181": 69, "qt": 69, "qpa": 69, "xcb": 69, "xkeyboard": 69, "fp32_int8_absolut": [69, 70, 71], "throughput_times1": 69, "942381018341494": 69, "latency_tim": [69, 70, 71], "46036736467385464": 69, "fp32_int8_tim": [69, 70, 71], "lost": [69, 123], "newer": [70, 71, 186], "big": [70, 71, 156, 159, 186, 241, 248, 252, 276, 285, 288], "blocker": [70, 71], "demo": [70, 71, 127, 128, 129, 132, 149, 159, 215, 253, 265, 275, 278, 285, 288, 317], "train_mnist": 70, "alexnet_mnist_fp32_mod": 70, "pth": [70, 127, 128, 129, 140, 144, 315, 325], "inc_quantize_model": [70, 71], "mnistmodel": [70, 71], "pthyaml": 70, "alexnet_mnist_int8_mod": 70, "profiling_inc": [70, 71], "pthalexnet_mnist_int8_mod": 70, "json8": [70, 71], "compare_perf": [70, 71], "stdout": [70, 71, 263], "stderrlog": [70, 71], "filefp32_int8_absolut": [70, 71], "pngfp32_int8_tim": [70, 71], "But": [70, 71, 126, 156, 159, 186, 251, 267, 275, 276, 285, 288, 319], "2nd": [70, 71, 277], "vector": [70, 71, 159, 201, 202, 205, 210, 218, 220, 227, 228, 241, 285, 288], "freeli": [70, 71, 120], "articl": [70, 71, 136, 159, 193, 220, 234, 241, 250, 262, 269, 273, 275, 281, 285, 288, 328], "familiar": [70, 71, 159, 241, 253, 285, 288], "termin": [70, 71, 123, 126, 155, 240, 377, 378, 381], "env": [70, 71, 116, 130, 155, 159, 169, 251, 255, 285, 288, 293, 297, 317, 325], "devcloud_setup_env": [70, 71], "ipynb": [70, 71, 160, 266, 319], "icx": [70, 71, 147], "spr": [70, 71, 297, 325, 359], "qsub": [70, 71], "run_in_intel_devcloud": [70, 71], "pwd": [70, 71, 273, 367], "ppn": [70, 71], "28029": [70, 71], "qsvr": [70, 71], "nda": [70, 71], "aidevcloud": [70, 71], "bad": [70, 71, 159, 250, 251, 285, 288], "uid": [70, 71], "msg": [70, 71, 251], "ruserok": [70, 71], "uxxxxx": [70, 71], "s001": [70, 71], "n054": [70, 71], "qstat": [70, 71], "fault": [70, 71], "o28029": [70, 71], "e28029": [70, 71], "tail": [70, 71], "latr": [70, 71], "awk": [70, 71], "o1842253": [70, 71], "572": [70, 71], "4982883964987": [70, 71], "3030": [70, 71], "70552731285": [70, 71], "8339174329018104": [70, 71], "128233714979522": [70, 71], "9799": [70, 71], "9796": [70, 71], "throughput_tim": [70, 71], "293824608282245": [70, 71], "7509864932092611": [70, 71], "accuracy_tim": [70, 71], "9996938463108482": [70, 71], "thank": [70, 71, 140, 155, 156, 239, 254], "1842253": [70, 71], "date": [70, 71, 156, 160, 276, 285, 319], "pm": [70, 71], "pst": [70, 71], "copi": [70, 71, 121, 126, 138, 155, 156, 158, 159, 251, 253, 273, 275, 285, 286, 288, 300, 366], "scp": [70, 71], "pip_set_env": [70, 71], "env_inc": [70, 71], "conda_set_env": [70, 71], "run_sampl": [70, 71], "chapter": [70, 71, 335], "keras_tf_train_mnist": 71, "fp32_frozen": 71, "pbyaml": 71, "alexnet_int8_model": 71, "pbalexnet_int8_model": 71, "mayb": [71, 126, 148, 150, 240, 285, 288, 327], "diagram": 72, "mismatch": [72, 159, 165, 184, 277, 285, 288], "correctli": [72, 159, 186, 224, 228, 233, 240, 241, 249, 251, 285, 288], "quantconf": 72, "mobilenet_v1": [72, 354], "simple_model": 72, "omit": [73, 119, 121, 126, 158], "onnxrt_qdqop": 73, "fer": 74, "yourself": [74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 122, 155, 156, 159, 245, 246, 253, 285, 288, 354], "body_analysi": [74, 75, 79], "emotion_ferplu": 74, "wider": [75, 210], "ultrafac": 75, "rfb": 75, "ilsvr2012": [76, 77, 78, 80, 81, 82, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95], "torchvis": [76, 95, 130, 145, 147, 148, 150, 293, 317, 370, 374], "mobilenet_v2": [76, 148, 342, 354], "randn": [76, 93, 95, 130], "being": [76, 93, 95, 126, 130, 140, 156, 157, 159, 167, 168, 197, 204, 217, 220, 228, 232, 233, 235, 241, 245, 246, 251, 252, 264, 271, 276, 285, 288], "export_param": [76, 93, 95], "opset_vers": [76, 93, 95], "do_constant_fold": [76, 93, 95], "fold": [76, 93, 95, 117, 118, 124, 126, 249, 366], "input_nam": [76, 93, 95], "output_nam": [76, 93, 95], "dynamic_ax": [76, 93, 95], "ax": [76, 93, 95, 121, 249], "mobilenet_v2_qdq": 76, "tf2onnx": [77, 93, 104, 114, 115], "mlcommon": [77, 118, 326, 361], "mobile_model": [77, 104], "v0_7": [77, 104], "mobilenet_edgetpu_224_1": 77, "0_float": 77, "opset": [77, 93, 104, 114, 115, 249], "mobilenet_v3": 77, "mobilenet_v3_qdq": 77, "bvlcalexnet": 78, "label_path": [78, 80, 83, 84, 85, 90, 92, 106], "alexnet_qdq": 78, "celeb": 79, "1m": [79, 130, 275], "arcfaceresnet100": 79, "faces_ms1m_112x112": 79, "nfold": 79, "nfolds_num": 79, "caffenet_qdq": 80, "121": 81, "efficientnet_qdq": 82, "2017": [83, 107, 108, 109, 110, 111, 112, 113, 114, 115, 136, 140, 165, 203, 248, 314, 319, 325], "object_detection_segment": [83, 106, 107, 108, 109, 110, 111, 112, 113], "fcn_rn50": 83, "fcn_rn50_qdq": 83, "inception_and_googlenet": [84, 85], "googlenet_qdq": 84, "inception_v1_qdq": 85, "mobilenetv2_qdq": 87, "resnet50_v1_5": [88, 93, 354, 388], "resnet50_v1_5_qdq": [88, 93], "shufflenetv2": 89, "shufflenetv2_qdq": 89, "squeezenet1": [90, 140], "squeezenet_qdq": 90, "vgg16_qdq": [91, 95], "512": [92, 116, 160, 165, 241, 244, 247, 248, 250, 258, 268, 274, 281, 288], "zfnet512": 92, "zfnet512_qdq": 92, "requires_grad": [93, 95, 140, 253, 327], "torch_out": [93, 95], "zenodo": [93, 117, 118, 323, 334, 354], "2535873": [93, 354], "nchw": [93, 323], "input_tensor": [93, 140, 354, 360, 362, 388], "softmax_tensor": [93, 354, 388], "resnet50_v1_5_mlperf": 93, "resnet50_v1_5_mlperf_qdq": 93, "convert_stable_diffusion_checkpoint_to_onnx": 94, "compvi": [94, 116], "workdir": [94, 388], "translat": [96, 97, 98, 99, 100, 102, 103, 104, 105, 154, 156, 157, 159, 162, 167, 168, 186, 190, 193, 209, 219, 220, 224, 232, 236, 241, 242, 247, 248, 252, 254, 285, 288, 290, 313, 361], "prepare_data": [96, 97, 99, 100, 105], "glue_dir": [96, 97, 99, 100, 105, 261], "glue_data": [96, 97, 99, 100, 105, 261], "input_dir": [96, 97, 100, 105], "bert_dynam": 96, "model_tun": [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 290, 308, 310], "bert_stat": 96, "bert_qdq": [96, 102], "out_dir": [97, 100, 105, 293], "run_glu": [97, 100, 105, 164, 184, 250, 254, 260, 277, 309, 310, 311, 312, 373, 374], "do_train": [97, 100, 105, 156, 186, 254, 256, 257, 258, 261, 267, 268, 269, 273, 276, 277, 279, 290, 296, 308, 309, 310, 311, 312], "do_ev": [97, 100, 105, 254, 256, 257, 258, 260, 261, 267, 268, 269, 276, 277, 279, 290, 292, 296, 297, 300, 302, 308, 309, 310, 311, 312, 373, 374], "per_gpu_eval_batch_s": [97, 100, 105, 257, 258, 261], "per_gpu_train_batch_s": [97, 100, 105, 258, 261, 269], "learning_r": [97, 100, 105, 116, 148, 165, 186, 253, 254, 257, 258, 261, 269, 273, 275, 277, 291, 292, 293, 294, 295, 299, 301, 302, 304, 305, 310, 312, 356], "save_step": [97, 100, 105, 258, 261, 277, 279, 312], "100000": [97, 100, 105], "language_transl": [97, 100, 105], "distilbert_qdq": 97, "identifi": [98, 99, 119, 120, 121, 124, 156, 160, 165, 167, 206, 219, 242, 250, 252, 286, 290], "co": [98, 99, 120, 126, 154, 157, 168, 200, 219, 240, 247, 273, 274, 276, 283, 290, 295, 297, 298, 305], "mrm8488": 98, "salti": 98, "qa_dynam": 98, "english": [99, 162, 184, 186, 191, 194, 198, 208, 209, 219, 220, 223, 232, 233, 236, 241, 242, 247, 248, 250, 258, 264, 269, 270, 272, 274, 276, 277, 279, 281, 308, 311, 359, 361], "alireza1044": 99, "philschmid": 99, "glue_dynam": 99, "mobilebert_qdq": [100, 104], "context": [101, 156, 157, 165, 167, 168, 192, 199, 200, 203, 205, 212, 217, 218, 220, 226, 234, 237, 239, 241, 242, 244, 246, 248, 250, 251, 252, 254, 256, 272, 281, 314], "paragraph": [101, 155, 165, 251], "machine_comprehens": [101, 102], "bidirectional_attention_flow": 101, "squad_v1": 101, "vocab": [102, 104, 164, 240, 241, 246, 247, 248, 251, 273, 293, 307, 356, 357, 358, 360, 361], "2018_10_18": [102, 104], "uncased_l": [102, 104, 152, 153, 164], "12_h": [102, 104, 152, 153, 164], "768_a": [102, 104, 152, 153, 164], "unzip": [102, 104, 117, 152, 153, 272, 299, 329, 330, 333, 357, 358, 366], "bertsquad": 102, "gpt2_lm_wikitext2": 103, "fatihcakir": 104, "mobilebert_float_384_20200602": 104, "mobilebert_squad": 104, "roberta_qdq": 105, "cityscap": 106, "leftimg8bit": 106, "gtfine": [106, 321], "rcnn": [107, 108, 112, 315, 362, 364], "fasterrcnn": [107, 140], "faster_rcnn": 107, "anno": [107, 108, 109, 110, 111, 112, 113, 362], "faster_rcnn_qdq": 107, "mask_rcnn": 108, "mask_rcnn_qdq": 108, "ssd_qdq": 109, "ssdmobilenet": [110, 114, 115], "ssd_mobilenet_v1_12": 110, "ssd_mobilenet_v1": [110, 114, 388], "ssd_mobilenet_v1_qdq": [110, 114], "tiny_yolov3": 111, "ssd_mobilenet_v1_coco_2018_01_28": [114, 362], "object_detect": [114, 115, 314, 315, 323, 325, 326, 327, 354, 362, 363], "frozen_inference_graph": [114, 115, 362], "fold_const": [114, 115], "image_tensor": [114, 115, 362, 388], "detection_box": [114, 115, 362, 388], "detection_scor": [114, 115, 362, 388], "detection_class": [114, 115, 362, 388], "ssd_mobilenet_v2_coco_2018_03_29": 115, "ssd_mobilenet_v2": 115, "ssd_mobilenet_v2_qdq": 115, "progress": [116, 126, 155, 159, 176, 186, 201, 202, 217, 228, 232, 252, 285, 288, 323, 328, 378, 384, 388], "taught": 116, "textual_invers": 116, "licens": [116, 126, 156, 250, 281, 335, 364], "ll": [116, 159, 165, 169, 186, 240, 244, 246, 251, 252, 285, 288, 319], "card": [116, 159, 203, 219, 251, 281, 283, 285, 288, 328], "tick": 116, "agre": [116, 159, 285, 288, 332], "hub": [116, 136, 137, 147, 157, 159, 160, 165, 168, 193, 195, 219, 233, 245, 248, 249, 251, 255, 256, 267, 275, 277, 279, 280, 281, 285, 288, 297, 336], "authent": 116, "cli": [116, 155, 164, 240, 283, 286, 387], "let": [116, 126, 155, 156, 159, 160, 165, 169, 182, 186, 187, 204, 233, 240, 241, 242, 244, 245, 248, 249, 251, 252, 253, 254, 275, 279, 280, 285, 286, 288, 373], "pictur": 116, "sd": [116, 273], "dicoo2": 116, "dicoo": 116, "textual_inversion_ipex": 116, "pretrained_model_name_or_path": 116, "train_data_dir": 116, "learnable_properti": 116, "placeholder_token": 116, "initializer_token": 116, "toi": 116, "resolut": [116, 121, 122, 124, 130], "train_batch_s": [116, 186, 273, 356], "max_train_step": 116, "3000": 116, "0e": 116, "scale_lr": 116, "lr_schedul": 116, "lr_warmup_step": 116, "dicoo_model": 116, "ccl": 116, "oneccl_bindings_for_pytorch_path": 116, "oneccl_bindings_for_pytorch": 116, "cwd": 116, "setvar": 116, "intel_extension_for_pytorch": [116, 147, 297], "throughput_mod": 116, "stablediffusionpipelin": 116, "model_id": [116, 219, 244, 388], "soon": [116, 122, 159, 285, 288], "pipe": [116, 251, 387], "from_pretrain": [116, 157, 159, 164, 165, 167, 169, 171, 182, 187, 189, 190, 193, 194, 195, 213, 219, 220, 224, 225, 233, 240, 242, 244, 245, 246, 248, 249, 250, 252, 253, 264, 269, 273, 275, 281, 285, 288, 308, 309, 311, 312], "torch_dtyp": 116, "cuda": [116, 131, 135, 138, 140, 159, 165, 186, 224, 244, 251, 253, 285, 288, 314, 318, 320, 325, 370], "love": [116, 155, 169, 250, 252, 253, 272, 276], "red": [116, 120, 126, 250, 272, 276], "dress": [116, 272], "hat": [116, 219], "snowli": 116, "brightli": 116, "night": [116, 155, 276], "brighli": 116, "num_inference_step": 116, "guidance_scal": 116, "generated_imag": 116, "dicoo_christma": 116, "nnunet": [117, 118, 120, 121, 122, 123, 124, 126], "brat": [117, 118], "2019": [117, 118, 190, 194, 197, 198, 201, 202, 208, 224, 230, 238, 241, 260, 264, 267, 273], "brain": [117, 118, 157, 168], "tumor": [117, 118, 126], "85300": [117, 118], "9141": [117, 118], "8679": [117, 118], "7770": [117, 118], "openvino": [117, 354, 364], "meant": [117, 165], "fastest": [117, 126], "download_data_dir": [117, 118], "miccai_brats_2019_data_train": [117, 118], "build_dock": 117, "launch_dock": 117, "preprocess_data": [117, 118], "ov": 117, "singlestream": 117, "multistream": 117, "har": 117, "consol": [117, 156, 186, 262], "log_fil": 117, "loadgen_log": 117, "output_dtyp": 117, "loadgen": [117, 118], "sut": [117, 334], "qsl": 117, "volum": [117, 126, 169, 272, 273], "voxel": [117, 121, 126], "forti": [117, 366], "cal": [117, 366], "sha": 118, "b7e8f0da170a421161410d18e5d2a05d75d6bccf": 118, "b38c69b345b2f60cd0d053039669e8f988b0c0af": 118, "diff": [118, 156], "layernorm": [118, 159, 249, 253, 285, 288], "whl": [118, 147, 152, 153, 293, 297, 354, 379, 382], "torch_stabl": [118, 152, 153, 293], "med": 118, "upenn": 118, "cbica": 118, "brats2019": 118, "download_pytorch_model": 118, "mkdir_postprocessed_data": 118, "preprocessed_data_dir": 118, "calib_preprocess": 118, "validation_fold_fil": 118, "brats_cal_images_list": 118, "recurs": [118, 147, 159, 251, 285, 288, 293], "absl": 118, "run_pytorch_nc_tun": 118, "model_dir": 118, "3d_fullr": [118, 122, 124, 126], "task043_brats2019": 118, "nnunettrainerv2__nnunetplansv2": [118, 126], "preprocessed_data": [118, 366], "mlperf_conf": 118, "fromnnunet": 118, "imagestr": [119, 120, 122, 123, 124], "modal": [119, 120, 122, 126, 157, 168, 218, 247], "task005": [119, 120], "prostat": [119, 120, 122, 126], "input_fold": [119, 126], "prostate_03_0000": [119, 123], "nii": [119, 120, 122, 123, 126], "prostate_03_0001": [119, 123], "prostate_05_0000": 119, "prostate_05_0001": 119, "prostate_08_0000": 119, "prostate_08_0001": 119, "t2": [119, 120, 122], "adc": [119, 120, 122], "task002": [119, 126], "heart": [119, 126], "imagest": [119, 120, 122, 123, 124], "la_001_0000": [119, 120, 123], "la_002_0000": [119, 120, 123], "la_006_0000": 119, "nnu": [120, 123, 124, 125], "interpret": [120, 121, 162, 246], "medic": [120, 122, 124, 126], "msd": [120, 126], "associ": [120, 126, 130, 133, 157, 164, 167, 245, 246, 248, 252, 263, 265, 273, 281], "nnunet_raw_data_bas": [120, 122, 123, 126, 366], "nnunet_raw_data": [120, 122, 123, 126], "task001_braintumour": 120, "task002_heart": [120, 123], "task003_liv": 120, "task004_hippocampu": 120, "task005_prost": [120, 122, 123], "labelstr": [120, 122, 123, 124], "postproces": 120, "ensembl": [120, 122, 126, 151, 209], "ground": [120, 126, 233, 272, 273, 275], "truth": [120, 126, 233, 272, 273, 275], "metadata": [120, 268, 273, 283], "nifti": [120, 122, 124], "consecut": [120, 126, 165, 241], "background": [120, 126, 140, 251], "especi": [120, 140, 156, 160, 210, 228, 249, 250, 252], "photo": 120, "green": [120, 126, 251, 276], "divers": [120, 126, 154, 184, 208, 211, 212, 213, 218, 227, 232], "ct": [120, 121, 126], "mri": [120, 121, 126], "suffix": [120, 219, 241, 249], "xxxx": [120, 126], "herebi": [120, 126, 160, 232], "braintumour": 120, "flair": 120, "t1w": 120, "t1gd": 120, "0002": 120, "t2w": 120, "brats_001_0000": 120, "brats_001_0001": 120, "brats_001_0002": 120, "brats_001_0003": 120, "brats_002_0000": 120, "brats_002_0001": 120, "brats_002_0002": 120, "brats_002_0003": 120, "brats_003_0000": 120, "brats_003_0001": 120, "brats_003_0002": 120, "brats_003_0003": 120, "brats_004_0000": 120, "brats_004_0001": 120, "brats_004_0002": 120, "brats_004_0003": 120, "brats_485_0000": 120, "brats_485_0001": 120, "brats_485_0002": 120, "brats_485_0003": 120, "brats_486_0000": 120, "brats_486_0001": 120, "brats_486_0002": 120, "brats_486_0003": 120, "brats_487_0000": 120, "brats_487_0001": 120, "brats_487_0002": 120, "brats_487_0003": 120, "brats_488_0000": 120, "brats_488_0001": 120, "brats_488_0002": 120, "brats_488_0003": 120, "brats_489_0000": 120, "brats_489_0001": 120, "brats_489_0002": 120, "brats_489_0003": 120, "brats_001": 120, "brats_002": 120, "brats_003": 120, "brats_004": 120, "la_003_0000": [120, 123], "la_004_0000": [120, 123], "la_003": [120, 123], "la_004": [120, 123], "geometri": 120, "ones": [120, 159, 165, 179, 186, 206, 210, 233, 241, 246, 250, 251, 273, 277, 279, 285, 288], "therebi": [120, 159, 244, 285, 288], "descript": [120, 126, 155, 157, 158, 159, 160, 162, 233, 255, 282, 285, 288, 332, 384, 388], "transit": 120, "peripher": [120, 122], "radboud": 120, "univers": [120, 157, 168, 233], "nijmegen": 120, "centr": [120, 208], "licenc": 120, "cc": [120, 133, 317], "BY": 120, "sa": 120, "relas": 120, "2018": [120, 133, 140, 197, 201, 202, 208, 230, 252, 273, 319, 328, 364], "tensorimages": 120, "4d": [120, 122, 124], "pz": 120, "tz": 120, "numtrain": 120, "numtest": 120, "prostate_16": 120, "prostate_04": 120, "prostate_08": 120, "prostate_22": 120, "prostate_30": 120, "clariti": [120, 154], "blank": [120, 165, 248, 270, 378], "confus": 120, "nnunet_convert_decathlon_task": [120, 122, 124], "folder_to_task_as_downloaded_from_msd": 120, "num_process": 120, "AS": 120, "task05": [120, 126], "overwrit": [120, 121, 126, 186, 251, 264, 377, 381], "output_task_id": 120, "empir": [121, 157, 165, 188, 192, 193, 210, 221, 238, 239], "thing": [121, 126, 155, 156, 159, 165, 169, 186, 248, 249, 251, 252, 263, 285, 288], "deriv": [121, 130, 185, 186, 187, 200, 209], "feel": [121, 156, 159, 169, 248, 250, 273, 274, 285, 286, 288, 319], "guidanc": [121, 156], "augment": [121, 130, 227, 241, 269, 327], "trainer": [121, 126, 157, 162, 168, 176, 187, 240, 245, 248, 254, 256, 267, 273, 275, 279, 284, 290, 296, 298, 308, 309, 310, 311, 313], "2d": [121, 122, 215, 241], "nnunettrainerv2": [121, 124, 126], "nnunettrainerv2cascadefullr": [121, 126], "overrid": [121, 130, 176, 179, 186, 250, 251, 273, 319], "quit": [121, 126, 130, 156, 159, 252, 264, 285, 288, 328], "subfold": [121, 122, 123, 124, 126, 254], "somewher": [121, 159, 186, 285, 288], "twice": [121, 264], "worri": [121, 122, 159, 211, 240, 274, 285, 288, 328], "kind": [121, 154, 156, 167, 218, 241, 246, 273], "network_train": 121, "loss_funct": 121, "data_augment": 121, "optimizer_and_lr": 121, "architectural_vari": 121, "nnunettrainerv2_bn": 121, "pynnunet": 121, "nnunettrainerv2_frn": 121, "nnunettrainerv2_gn": 121, "nnunettrainerv2_nonormalization_lr1en3": 121, "nonlinear": [121, 214], "nnunettrainerv2_relu": 121, "nnunettrainerv2_mish": 121, "nnunettrainerv2_3convperstag": 121, "nnunettrainerv2_resencunet": 121, "fingerprint": [121, 126], "dimension": [121, 159, 285, 288], "captur": [121, 126, 234], "intens": [121, 126, 227, 241, 272], "datset": 121, "datasetanalyz": 121, "nnunet_plan_and_preprocess": [121, 124, 126], "experimentplann": [121, 126], "experimentplanner2d": 121, "v21": [121, 126], "experimentplanner3d": [121, 126], "nnunettrain": [121, 126], "data_identifi": 121, "plans_fnam": 121, "planner": [121, 126], "nnunet_train": [121, 124, 126], "priorit": 121, "patch": [121, 126, 140, 147, 372], "prioritizi": 121, "definit": [121, 130, 159, 165, 186, 285, 288, 328, 384], "inspir": [121, 140, 154], "preprocessor": 121, "preprocessor_nam": 121, "genericpreprocessor": 121, "preprocessorfor2d": 121, "anisotrop": [121, 126], "fname": 121, "overwritten": [121, 140, 233, 286, 337, 351, 373], "explanatori": 121, "wrt": 121, "downsampl": [121, 126], "supervis": [121, 157, 167, 168, 188, 191, 220, 226, 232, 233, 235, 236, 237, 241, 264, 269, 281], "suppos": [121, 131, 134, 135, 139, 142, 143, 145, 153, 264, 267, 329], "dynamiccali": 121, "furthermor": [121, 126, 214, 215, 228, 239, 362, 363], "consumpt": [121, 188, 214], "disregard": [121, 164, 218], "unless": [121, 130, 156, 169, 240, 246, 251, 273], "unreason": 121, "vram": [121, 126, 167], "occupi": 121, "mostli": [121, 158, 251, 281], "cudnn": [121, 251, 317, 318], "imposs": [121, 156, 159, 249, 285, 288], "approch": 121, "straightforward": [121, 251, 252], "largest": [121, 224, 244, 247, 249], "dowmsampl": 121, "illustr": [121, 165, 300, 319], "fabiansunet": 121, "modular": [121, 126, 157, 245, 319], "experimentplanner3dfabiansresunet": 121, "approx": [121, 228], "decathlon": [122, 124, 126], "relev": [122, 124, 156, 159, 160, 189, 203, 241, 248, 272, 279, 281, 285, 288], "archiv": [122, 124, 262], "task05_prost": 122, "nnunet_download_pretrained_model": [122, 126], "rgb": [122, 140, 364], "case_0000": 122, "case_0001": 122, "whenev": [122, 156, 159, 254, 285, 288], "nnunet_print_pretrained_model_info": 122, "central": [122, 140, 179], "medicaldecathlon": 122, "ran": [122, 158, 159, 273, 285, 288], "medcial": 122, "exemplarili": 122, "nnunet_predict": [122, 126], "output_directori": 122, "littl": [122, 126, 156, 248, 250, 328], "output_directory_3d": 122, "save_npz": [122, 126], "output_directory_2d": 122, "tell": [122, 126, 155, 156, 159, 165, 186, 251, 262, 267, 284, 285, 288], "probabl": [122, 126, 159, 187, 240, 241, 244, 246, 248, 250, 252, 264, 275, 285, 288, 316, 319, 320], "nnunet_ensembl": [122, 126], "output_folder_ensembl": 122, "pp": [122, 126], "postprocessing_fil": [122, 126], "were": [122, 123, 126, 140, 154, 156, 159, 160, 186, 187, 200, 206, 209, 219, 224, 228, 236, 248, 250, 251, 252, 254, 256, 258, 273, 276, 280, 281, 285, 288, 318, 371], "results_fold": [122, 123, 126, 366], "ensemble_2d__nnunettrainerv2__nnunetplansv2": 122, "3d_fullres__nnunettrainerv2__nnunetplansv2": 122, "reli": [123, 155, 159, 167, 185, 186, 187, 199, 205, 209, 221, 231, 233, 236, 239, 241, 251, 252, 269, 285, 288], "care": [123, 124, 126, 159, 167, 187, 230, 232, 245, 248, 249, 250, 251, 253, 285, 286, 288], "rest": [123, 124, 164, 167, 186, 199, 241, 251, 252, 332], "tree": [123, 130, 209, 273, 276, 326, 332, 365], "prostate_00_0000": 123, "prostate_00_0001": 123, "prostate_00": 123, "prostate_01": 123, "sata": 123, "nvme": 123, "linux": [123, 126, 130, 155, 160, 378], "bashrc": 123, "me": [123, 272, 276, 281], "fabian": [123, 125, 126], "editor": [123, 133, 156], "al": [123, 157, 168, 194, 197, 208, 219, 223, 225, 230, 241, 250, 252, 258, 260, 314], "rare": [123, 165, 240, 252, 264, 273, 279], "touch": [123, 251], "nnunet_raw": 123, "nnunet_preprocess": [123, 366], "nnunet_trained_model": 123, "rememb": [123, 126, 156, 159, 186, 246, 251, 285, 288], "reload": [123, 187, 245, 253, 387], "properli": [123, 126, 167, 169, 246, 252, 317, 320], "echo": [123, 186, 240, 251, 371], "task04_hippocampu": 124, "modern": [124, 249], "altern": [125, 160, 165, 169, 186, 206, 240, 251, 253, 254, 273, 281], "believ": [125, 250], "superior": [125, 195, 196], "biomed": 126, "drastic": [126, 228, 275], "liver": 126, "challeng": [126, 159, 195, 196, 204, 211, 218, 219, 230, 283, 285, 288], "tomographi": 126, "scan": [126, 162, 215], "512x512x512": 126, "isotrop": 126, "quantit": 126, "hounsfield": 126, "cardiac": 126, "diagnosi": 126, "cine": 126, "10x320x320": 126, "qualit": [126, 251], "acdc": 126, "suffer": [126, 199, 221, 222, 239, 241], "slice": [126, 187, 248], "misalign": [126, 279], "heterogen": [126, 208], "plane": 126, "artifact": [126, 158, 254, 273, 387], "practic": [126, 140, 156, 159, 168, 186, 198, 205, 228, 232, 241, 244, 252, 284, 285, 288], "mind": [126, 155, 156, 159, 245, 285, 288, 316], "indirectli": 126, "displai": [126, 158, 176, 195, 196, 233, 262, 314, 328], "affect": [126, 154, 202, 224, 251, 252, 275], "recept": [126, 241], "influenc": [126, 241], "inher": 126, "deal": [126, 165, 167, 186, 248, 251, 252], "somain": 126, "condens": 126, "against": [126, 156, 159, 167, 251, 272, 285, 288], "evid": [126, 188], "inexperienc": 126, "intervent": 126, "roll": [126, 169], "isense": 126, "paul": [126, 161], "j\u00e4ger": 126, "simon": 126, "kohl": 126, "jen": [126, 157, 168, 220], "petersen": 126, "klau": 126, "maier": 126, "hein": 126, "arxiv": [126, 130, 136, 161, 162, 191, 216, 220, 250, 261, 269, 271, 272, 273, 281, 302, 319, 328], "preprint": [126, 136], "1904": [126, 130], "08128": 126, "cite": [126, 133, 157, 203, 261, 263, 264, 269, 319], "ecotrust": 126, "canada": 126, "markdown": [126, 158], "toc": 126, "gb": [126, 167, 200, 212, 224, 247, 318], "rtx": [126, 160, 167, 277], "2080ti": 126, "volta": [126, 277], "titan": [126, 160, 167, 277, 328], "v100": [126, 224, 258, 262, 273, 275, 277, 318], "tensorcor": 126, "ture": [126, 214, 277], "strongli": [126, 155, 159, 245, 285, 288], "apex": [126, 186, 187, 254, 273, 277], "slower": [126, 186, 240, 256, 273], "experienc": [126, 159], "nvcc": [126, 186, 320], "swap": [126, 241, 281], "cluster": [126, 156, 264, 272], "torch_cuda_arch_list": 126, "mic": 126, "dkfz": 126, "hiddenlay": 126, "plot": [126, 263, 268], "upgrad": [126, 156, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "nanohanno": 126, "bugfix": 126, "get_trace_graph": 126, "egg": 126, "nnunet_": 126, "identif": 126, "coars": 126, "taskxxx_mytask": 126, "verify_dataset_integr": 126, "taskxxx": 126, "mytask": 126, "pkl": [126, 273], "Their": [126, 276], "happen": [126, 155, 156, 159, 248, 250, 252, 276, 285, 288], "fly": [126, 156, 186, 228, 240, 269], "ram": [126, 155, 186, 251, 273], "trainer_class_nam": 126, "task_name_or_id": 126, "OR": 126, "crossvalidaton": 126, "3d_cascade_fullr": 126, "five": [126, 168, 212, 218, 229, 250, 264, 269], "beforehand": [126, 159, 249, 285, 288], "written": [126, 154, 155, 158, 159, 251, 262, 273, 281, 285, 288, 324], "mytasknam": 126, "__": [126, 158, 191, 209, 251, 287, 320], "task02_heart": 126, "fold_0": 126, "fold_1": 126, "fold_2": 126, "fold_3": 126, "fold_4": 126, "model_best": [126, 127, 128, 129], "model_final_checkpoint": 126, "network_architectur": 126, "pdf": [126, 133, 215], "validation_raw": 126, "la_007": 126, "la_016": 126, "la_021": 126, "la_024": 126, "validation_arg": 126, "lowr": 126, "fullr": 126, "blueprint": 126, "Not": [126, 159, 246, 250, 251, 285, 288], "dice": 126, "foreground": 126, "salt": 126, "drawn": 126, "aggreg": [126, 233], "tp": 126, "fn": [126, 130, 165], "pretend": [126, 275], "proper": [126, 158, 190, 246], "watch": [126, 186, 250, 251, 377, 381], "NOT": [126, 139, 245, 290, 296, 298, 308, 309, 310, 311, 313, 329, 330, 333], "dataparallel": 126, "dp": 126, "ddp": [126, 251], "prefer": [126, 155, 159, 167, 285, 288], "variant": [126, 130, 136, 195, 196, 197, 199, 216, 223, 241, 250, 361], "cuda_visible_devic": [126, 160, 186, 251, 258], "nnunet_train_dp": 126, "nnunettrainerv2_dp": 126, "db": 126, "master_port": [126, 186, 264], "nproc_per_nod": [126, 156, 186, 254, 258, 264, 273, 274, 292, 301, 319], "run_training_ddp": 126, "nnunettrainerv2_ddp": 126, "someth": [126, 155, 156, 159, 169, 190, 195, 209, 217, 219, 220, 224, 226, 228, 232, 233, 237, 240, 248, 251, 252, 267, 273, 276, 288], "4321": 126, "sai": [126, 155, 167, 169, 186, 190, 220, 248, 250, 275, 373], "said": [126, 156, 157, 159, 186, 187, 245, 250, 285, 288], "nnunet_change_trainer_class": 126, "nnunet_find_best_configur": 126, "strict": [126, 159, 285, 288], "crash": 126, "flag": [126, 130, 155, 156, 186, 187, 240, 248, 250, 251, 254, 256, 267, 272, 277, 354, 356, 357, 360, 361, 387], "easiest": [126, 155, 159, 232, 248, 273, 285, 288, 319, 362], "output_fold": [126, 315], "alongsid": [126, 158, 159, 167, 184, 250, 285, 288], "disk": [126, 155, 159, 219, 224, 249, 251, 269, 273, 285, 288, 319], "folder1": 126, "folder2": 126, "nnunet_print_available_pretrained_model": 126, "task029_lit": 126, "task029": 126, "lit": 126, "abdomin": 126, "hippocampu": 126, "usabl": [126, 286], "abort": 126, "preprocessing_output_dir": 126, "taskxx_my_dataset": 126, "splits_fin": 126, "dictionari": [126, 157, 167, 171, 182, 185, 246, 248, 276], "patientid": 126, "pickl": [126, 264], "batchgener": 126, "robust": [126, 155, 261, 273], "happi": [126, 155, 156, 157, 159, 248, 264, 276, 284, 285, 286, 288], "contextu": [126, 206, 208, 272], "promise12": 126, "tbe": 126, "overfit": [126, 226, 237, 241], "whoever": 126, "recipi": 126, "11gb": 126, "slack": [126, 159, 285, 288], "exact": [126, 156, 159, 186, 187, 217, 251, 258, 272, 285, 288, 318], "3dunet": [126, 366], "attempt": [126, 251], "headroom": 126, "ref": [126, 267], "generic_unet": 126, "use_this_for_batch_size_computation_3d": 126, "32gb": 126, "remain": [126, 156, 167, 188, 204, 224, 227, 241, 242, 250, 251, 269, 281, 373], "substanti": [126, 192, 206], "goe": [126, 241, 246, 251, 267, 269], "void": 126, "thcudatensor_scatterfillkernel": 126, "tensorinfo": 126, "indextyp": 126, "unsign": 126, "4770": 126, "indexvalu": 126, "unexpect": [126, 188, 249, 276], "foregound": 126, "wrong": [126, 156, 159, 267, 285, 288], "median": 126, "128x128x128": 126, "enforc": [126, 250, 273], "creation": [126, 281, 283, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "how_much_of_a_patient_must_the_network_see_at_stage0": 126, "train_without_distil": [127, 128, 129], "student_typ": [127, 129, 264], "teacher_typ": [127, 129, 264], "widen": 128, "wideresnet": 128, "temperatur": [129, 233, 275, 291, 292, 299, 301], "loss_weight": [129, 152, 153, 291, 292, 299, 301], "mixnet": 130, "genefficientnet": 130, "layout": [130, 157, 168, 215], "newli": [130, 242, 247, 273], "rand": [130, 316, 370], "favour": 130, "lite": [130, 157, 168, 188, 241], "5m": [130, 137, 228], "110d": 130, "140": [130, 200, 388], "8m": 130, "120d": 130, "tpu": [130, 162, 186, 188, 251, 256, 267, 275, 281, 288, 354, 364], "scratch": [130, 153, 159, 165, 220, 228, 247, 248, 253, 256, 258, 272, 282, 285, 288], "impl": [130, 328], "fix_group_fanout": 130, "initialize_weight_goog": 130, "l2": [130, 233], "b7": [130, 364], "noisystud": 130, "b8": 130, "randaug": 130, "advprop": 130, "edgetpu": 130, "andrew": 130, "lavin": 130, "b2": 130, "b3": 130, "rwightman": 130, "torchscript": [130, 160, 168, 187], "mixedconv2d": 130, "moduledict": 130, "1911": 130, "09665": 130, "spec": 130, "aa": 130, "ra": [130, 167], "minimalist": 130, "mine": [130, 273], "biggest": [130, 241], "mem": [130, 318], "swish": 130, "mish": 130, "autograd": [130, 140], "autgrad": 130, "factori": [130, 355], "helper": [130, 251, 254, 319], "condconv": 130, "b5": [130, 364], "algo": 130, "my": [130, 155, 156, 159, 171, 182, 186, 195, 241, 251, 264, 271, 276, 285, 288, 328, 388], "pool": [130, 210, 241], "entrypoint": 130, "chamnet": 130, "04252": 130, "1905": [130, 161], "11946": 130, "googleblog": 130, "04971": 130, "1907": 130, "09595": 130, "mnasnet": 130, "b1": 130, "a1": 130, "excit": [130, 169], "1807": 130, "11626": 130, "02244": 130, "fbnet": 130, "1812": 130, "03443": 130, "02877": 130, "repositori": [130, 155, 156, 157, 158, 164, 168, 169, 177, 180, 185, 202, 233, 240, 247, 249, 251, 262, 281, 286, 314, 359, 369, 379, 382], "caffe2": [130, 318, 319], "ve": [130, 157, 159, 165, 168, 190, 233, 240, 275, 332, 362], "prec": 130, "err": [130, 156, 251], "madd": 130, "efficientnet_b3": 130, "866": 130, "134": 130, "836": 130, "164": [130, 133], "tbd": [130, 141, 151, 353], "672": [130, 140], "328": 130, "904": 130, "mixnet_xl": 130, "074": [130, 160], "926": [130, 140], "282": 130, "718": 130, "efficientnet_b2": 130, "612": 130, "388": 130, "318": 130, "682": 130, "288": [130, 197], "476": [130, 269], "524": [130, 133, 140], "936": 130, "064": [130, 160], "712": 130, "166": 130, "834": 130, "1003": 130, "260": 130, "890": 130, "mixnet_l": 130, "976": 130, "024": 130, "184": 130, "816": 130, "efficientnet_b1": 130, "692": 130, "086": [130, 140], "914": 130, "694": 130, "240": [130, 133], "882": 130, "efficientnet_": 130, "066": [130, 140], "934": 130, "efficientnet_b0": 130, "698": 130, "302": 130, "532": 130, "468": 130, "390": 130, "mobilenetv2_120d": 130, "706": [130, 388], "502": [130, 320], "498": [130, 140], "mixnet_m": 130, "744": 130, "418": 130, "582": 130, "353": 130, "mobilenetv2_140": 130, "990": 130, "010": 130, "mixnet_": 130, "988": 130, "012": 130, "794": 130, "206": 130, "mobilenetv3_large_100": 130, "766": [130, 140], "234": [130, 140, 159, 285, 288, 388], "458": 130, "mobilenetv3_rw": 130, "634": 130, "366": 130, "708": 130, "219": 130, "mnasnet_a1": 130, "448": [130, 140], "396": [130, 140], "312": 130, "fbnetc_100": 130, "876": 130, "386": [130, 140], "385": 130, "mobilenetv2_110d": 130, "052": 130, "948": 130, "820": 130, "mnasnet_b1": 130, "658": [130, 140], "342": 130, "886": [130, 140], "spnasnet_100": 130, "084": 130, "916": 130, "818": [130, 140], "182": [130, 140, 246], "mobilenetv2_100": 130, "978": 130, "022": [130, 160], "016": 130, "984": 130, "pretti": [130, 187, 240, 328], "equival": [130, 159, 167, 186, 244, 251, 252, 253, 273, 275, 285, 288], "tf_efficientnet_b5": 130, "img": [130, 327], "pct": 130, "ie": 130, "tf_efficientnet_b8_ap": 130, "954": 130, "tf_efficientnet_l2_n": 130, "tfp": 130, "352": 130, "652": 130, "348": 130, "961": [130, 318], "tf_efficientnet_l2_ns_475": 130, "475": 130, "828": 130, "566": [130, 140, 318], "tf_efficientnet_b7_n": 130, "844": 130, "600": [130, 315], "840": 130, "094": 130, "906": 130, "tf_efficientnet_b6_n": 130, "452": [130, 140], "548": [130, 140], "118": [130, 260], "528": 130, "444": 130, "556": 130, "880": 130, "120": 130, "tf_efficientnet_b5_n": 130, "746": [130, 140], "088": [130, 160], "912": 130, "752": [130, 140], "248": 130, "436": 130, "564": 130, "728": 130, "tf_efficientnet_b8": 130, "616": 130, "394": 130, "606": 130, "630": 130, "610": 130, "368": 130, "632": 130, "tf_efficientnet_b4_n": 130, "298": [130, 219, 323], "702": 130, "504": 130, "496": 130, "380": 130, "838": 130, "470": 130, "530": 130, "922": 130, "tf_efficientnet_b7_ap": 130, "154": 130, "846": 130, "756": 130, "252": [130, 140], "949": 130, "tf_efficientnet_b7": 130, "940": 130, "060": 130, "214": 130, "786": 130, "932": 130, "208": 130, "792": 130, "tf_efficientnet_b6_ap": 130, "138": [130, 167, 246], "862": 130, "942": 130, "760": 130, "tf_efficientnet_b5_ap": 130, "276": 130, "724": 130, "tf_efficientnet_b6": 130, "860": 130, "852": 130, "148": 130, "110": [130, 133, 140], "tf_efficientnet_b3_n": 130, "054": [130, 160], "946": 130, "918": 130, "082": 130, "048": 130, "910": 130, "090": 130, "822": [130, 140], "812": 130, "tf_efficientnet_b4_ap": 130, "278": 130, "376": 130, "624": [130, 140], "tf_efficientnet_b4": 130, "700": [130, 324], "tf_efficientnet_b2_n": 130, "268": 130, "732": 130, "620": [130, 140, 318], "tf_efficientnet_b3_ap": 130, "662": [130, 140], "338": 130, "tf_efficientnet_b3": 130, "364": 130, "576": 130, "424": 130, "tf_efficientnet_lite4": 130, "472": 130, "668": 130, "tf_efficientnet_b1_n": 130, "514": 130, "486": 130, "676": 130, "324": 130, "738": 130, "262": 130, "tf_efficientnet_el": 130, "534": 130, "190": 130, "810": 130, "tf_efficientnet_b2_ap": 130, "580": 130, "040": 130, "028": [130, 140, 318], "972": [130, 269], "tf_efficientnet_b2": 130, "974": 130, "026": [130, 140], "908": 130, "092": 130, "tf_efficientnet_lite3": 130, "734": 130, "266": [130, 140], "tf_efficientnet_b1_ap": 130, "622": 130, "tf_efficientnet_cc_b1_8": 130, "464": 130, "tf_efficientnet_b1": 130, "450": [130, 234], "550": 130, "tf_efficientnet_em": 130, "958": 130, "042": 130, "tf_efficientnet_b0_n": 130, "806": 130, "194": [130, 140], "tf_mixnet_l": 130, "212": 130, "788": 130, "826": 130, "174": 130, "802": 130, "230": 130, "004": [130, 160], "996": 130, "742": 130, "258": [130, 140], "tf_efficientnet_cc_b0_8": 130, "314": 130, "790": 130, "210": 130, "656": 130, "344": 130, "tf_efficientnet_cc_b0_4": 130, "304": [130, 140, 388], "696": 130, "tf_efficientnet_": 130, "750": [130, 279], "tf_efficientnet_lite2": 130, "544": [130, 318], "540": 130, "tf_efficientnet_b0_ap": 130, "736": [130, 140], "400": [130, 140, 215, 269], "tf_efficientnet_b0": 130, "478": [130, 252], "522": 130, "tf_mixnet_m": 130, "072": [130, 269], "928": 130, "950": 130, "050": 130, "848": 130, "228": 130, "772": 130, "tf_efficientnet_lite1": 130, "236": [130, 140], "326": 130, "674": 130, "638": 130, "362": 130, "232": 130, "768": [130, 247, 249, 264], "tf_mixnet_": 130, "tf_mobilenetv3_large_100": 130, "710": 130, "290": 130, "516": 130, "484": 130, "tf_efficientnet_lite0": 130, "842": 130, "158": 130, "170": [130, 140, 167, 246, 316], "830": 130, "tf_mobilenetv3_large_075": 130, "730": 130, "270": [130, 138], "442": 130, "558": 130, "tf_mobilenetv3_large_minimal_100": 130, "678": 130, "322": 130, "tf_mobilenetv3_small_100": 130, "tf_mobilenetv3_small_075": 130, "142": [130, 140], "858": [130, 140], "136": [130, 133, 140, 246], "864": 130, "tf_mobilenetv3_small_minimal_100": 130, "898": 130, "window": [130, 156, 158, 159, 216, 217, 241, 244, 250, 251, 285, 288], "myself": [130, 276], "cudatoolkit": [130, 186, 320], "geffnet": [130, 131], "create_model": 130, "drop_rat": 130, "drop_connect_r": 130, "as_sequenti": 130, "onnx_export": 130, "mobilenetv3_100": 130, "onnx_optim": 130, "onnx_to_caff": 130, "c2": 130, "caffe2_valid": 130, "_export": 130, "set_export": 130, "rw": 131, "onnxrt_integ": [131, 134, 135, 139, 354, 355, 362, 367], "onnxrt_qlinear": [131, 134, 135, 139, 354, 355, 362, 367], "unlimit": [131, 134, 135, 139, 145, 146, 147, 148, 150, 315, 327], "builder": [131, 155], "conf_efficientnet_b0": 131, "horovod": [132, 337, 338, 351], "horovodrun": [132, 138, 144, 149, 337, 338, 351], "great": [133, 155, 156, 159, 161, 165, 183, 215, 221, 228, 241, 250, 251, 285, 288, 370], "pele": 133, "neurip": [133, 264], "incollect": 133, "nips2018_7466": 133, "robert": [133, 157, 168, 213, 223, 232], "j": [133, 134, 139, 157, 168, 191, 197, 224, 228, 232, 241, 325, 330], "li": [133, 136, 157, 168, 215, 220, 232, 241, 272], "xiang": [133, 157, 168, 203], "ling": 133, "charl": 133, "booktitl": [133, 157, 263, 264], "bengio": 133, "wallach": 133, "larochel": 133, "grauman": 133, "cesa": 133, "bianchi": 133, "garnett": 133, "1963": 133, "1972": 133, "curran": 133, "nip": 133, "7466": 133, "flop": [133, 210], "tx2": 133, "569": 133, "condensenet": 133, "274m": 133, "0m": 133, "5x": [133, 186, 221, 273], "621": 133, "245": 133, "what_you_w": 135, "splat": 135, "downstream": [136, 159, 165, 188, 198, 199, 201, 202, 206, 208, 214, 215, 216, 217, 221, 224, 227, 232, 241, 242, 250, 272, 281, 282, 285, 288, 292, 301], "deeplabv3": [136, 364], "zhanghang1989": [136, 137], "269": [136, 138], "416": [136, 328, 363], "caff": [136, 354], "extra": [136, 220, 247, 251, 256, 267, 273, 274, 279, 319], "ablat": [136, 218], "studi": [136, 161, 170, 171, 172, 173, 174, 175, 193, 204, 211, 218, 221, 230, 232, 236, 245, 251], "force_reload": [136, 137], "detectron2": 136, "fork": [136, 156, 159, 251, 273, 283, 285, 288, 332, 379, 382], "trick": [136, 158, 186, 240, 252], "dcn": 136, "mutli": 136, "dev2019": 136, "pq": 136, "gluoncv": [136, 138], "pixacc": 136, "miou": [136, 367], "deeplab": 136, "mapillari": 136, "recordio": 136, "prepare_imagenet": 136, "slightli": [136, 159, 186, 214, 220, 233, 251, 252, 256, 258, 273, 285, 288], "wors": [136, 244, 273], "hang": [136, 157, 168, 208, 241, 276], "chongruo": 136, "wu": [136, 157, 168, 205, 212], "zhongyu": 136, "yi": 136, "zhu": 136, "zhi": 136, "haibin": 136, "lin": [136, 263], "yue": [136, 219], "sun": [136, 157, 168, 203, 221], "tong": 136, "jona": 136, "muller": [136, 157, 168, 198], "manmatha": 136, "mu": 136, "alex": [136, 140], "smola": 136, "zhang2020resnest": 136, "alexand": [136, 157, 269, 273, 319], "journal": [136, 273, 328], "2004": [136, 281], "08955": 136, "gflop": 137, "resnest": 137, "1s1x64d": 137, "3m": [137, 247, 281], "2s1x64d": 137, "4s1x64d": 137, "9m": [137, 281], "1s2x40d": 137, "2s2x40d": 137, "4s2x40d": 137, "4m": 137, "1s4x24d": 137, "7m": 137, "fast_2s1x64d": 137, "resnest50_fast_2s1x64d": 137, "cu100": 138, "horovod_gpu_allreduc": 138, "nccl": [138, 318], "mpi4pi": 138, "unfortun": [138, 195, 275], "ramdisk": 138, "sudo": [138, 186, 240, 328, 371], "mkdir": [138, 152, 153, 165, 272, 273, 297, 314, 315, 319, 321], "mount": 138, "tmpf": 138, "200g": 138, "cp": [138, 273, 321], "hostfil": 138, "warmup": [138, 165, 187, 253, 281, 356, 359, 361, 388], "gamma": [138, 271], "wd": 138, "smooth": [138, 264, 275, 314], "mixup": 138, "params_": 138, "interv": 138, "auto_aug": 138, "se": [139, 140, 219], "resnext": 139, "pretrainedmodel": [139, 140, 159, 168, 250, 285, 288], "resnext50": [139, 140], "32x4d": [139, 140], "imagenet_ev": [139, 140], "senet": 139, "convnet": 140, "travi": 140, "parinov": 140, "senet154": 140, "cafferesnet101": 140, "veronika": 140, "yurchuk": 140, "anastasiia": 140, "ross": [140, 319], "wightman": 140, "standlei": 140, "transformimag": 140, "pretrained_set": 140, "pull": [140, 159, 169, 255, 280, 282, 285, 288], "durand": 140, "caden": 140, "valset": 140, "dualpathnet68": 140, "dualpathnet92": 140, "dualpathnet98": 140, "dualpathnet107": 140, "dualpathnet113": 140, "fbresnet152": 140, "resnext101": [140, 145, 146, 147, 148, 150], "64x4d": 140, "vgg11": 140, "vgg13": 140, "resnext101_32x4d": 140, "resnext101_64x4d": 140, "squeezenet1_0": 140, "squeezenet1_1": 140, "vgg11_bn": 140, "vgg13_bn": 140, "vgg16_bn": 140, "vgg19_bn": 140, "nasnetalarg": 140, "nasnetamobil": 140, "se_resnet50": 140, "se_resnet101": 140, "se_resnet152": 140, "se_resnext101_32x4d": 140, "pnasnet5larg": 140, "lip6": 140, "fr": [140, 219, 242], "a1897284": 140, "331": 140, "1001": [140, 354], "torch_hom": 140, "load_img": 140, "loadimag": 140, "ex": [140, 155, 187], "tobgr": 140, "torange255": 140, "tf_img": 140, "path_img": 140, "cat": [140, 186, 219, 250, 273, 279, 371], "input_img": 140, "3x400x225": 140, "3x299x299": 140, "unsqueez": [140, 182, 253, 264], "1x3x299x299": 140, "output_logit": 140, "1x1000": 140, "bewar": 140, "output_featur": 140, "1x14x14x2048": 140, "imagenet_logit": 140, "tiger": 140, "imagenet_2012": 140, "693": 140, "062": 140, "dualpathnet107_5k": 140, "684": 140, "torch7": 140, "dualpathnet131": 140, "574": 140, "dualpathnet92_5k": 140, "488": 140, "resnext50_32x4d": 140, "076": 140, "500": [140, 156, 162, 165, 186, 253, 273, 276, 281, 304, 323, 356, 357, 359, 360, 361, 365], "956": 140, "888": 140, "428": 140, "560": 140, "798": 140, "438": 140, "594": 140, "dualpathnet68b_5k": 140, "034": [140, 318], "590": 140, "900": [140, 294], "980": 140, "868": 140, "774": 140, "646": 140, "080": 140, "554": [140, 318], "562": 140, "608": [140, 328], "354": 140, "494": 140, "274": 140, "970": 140, "108": 140, "378x378": 140, "kaimingh": 140, "xiong": [140, 157, 168, 200], "yuanjun": 140, "resnext101_62x4d": 140, "chen": [140, 157, 168, 188, 199, 201, 202, 203, 205, 220, 226, 230, 237, 241], "yunpeng": [140, 157, 168, 199, 241], "hi": [140, 233, 250], "crope": 140, "dpn68": 140, "dpn98": 140, "dpn131": 140, "dpn68b": 140, "5k": [140, 274], "dpn92": 140, "dpn107": 140, "imagenet5k": 140, "imagenet1k": 140, "jie": 140, "hu": [140, 250], "cuhk": 140, "multimedia": 140, "299": [140, 355], "bgr": 140, "substrat": 140, "input_224": 140, "2048": [140, 247], "input_448": 140, "bellow": 140, "dim_feat": 140, "in_featur": [140, 159, 285, 288], "nb_class": 140, "th": [140, 250], "fbresnet": 140, "resnet152_dump": 140, "lua": 140, "resnet152_load": 140, "clcarwin": 140, "contributor": [140, 155, 159, 281, 285, 288], "run_distil": [141, 151, 353], "torchvision_model": [142, 143, 145, 146, 147, 148, 150], "optimization_pipelin": [142, 143], "prune_and_ptq": 142, "ptq_conf": 142, "qat_during_prun": 143, "qat_conf": 143, "pruner": 144, "model_fin": 144, "32x8d": [145, 146, 148, 150, 318], "main_dump_tensor": 145, "nc_model": [145, 146, 147, 315], "path_to_save_configure_fil": [145, 146, 147, 315], "join": [145, 146, 167, 233, 240, 244, 315], "best_configur": [145, 146, 315], "best_model_weight": [145, 146, 315], "imagenet_ptq": [145, 146, 147], "didn": [145, 148, 171, 182, 250, 251, 273], "tune_2_acc0": [145, 146], "acc0": [145, 146], "tune_2": [145, 146], "your_dataload": [146, 315], "gcc9": 147, "sync": [147, 293], "1279c5824f1bcb61cd8990f4148abcadf3f214a4": 147, "resnet18_ipex": 147, "resnet50_ipex": 147, "32x16d": 147, "resnext101_32x16d_wsl_ipex": 147, "conf_ipex": [147, 333], "himself": [148, 150], "imagenet_qat": [148, 150], "quant_aware_train": [148, 150], "end_epoch": 148, "crossentropyloss": 148, "reduct": [148, 188, 210], "prev_loss": 148, "loss_increase_tim": 148, "patienc": [148, 155, 268], "curr_loss": 148, "val_loader_earlystop": 148, "main_buildin": [148, 149], "conf_buildin": [148, 149], "config_fil": [148, 150, 319, 359, 361], "7613": 148, "functionet": 148, "omp_num_thread": 149, "use_cpu": 151, "weiaicunzai": 151, "Be": [151, 157, 159, 245, 285, 288], "classifier1": 151, "classifier2": 151, "classifier3": 151, "classifier4": 151, "mv": [152, 153, 273], "dev_id": [152, 153], "tsv": [152, 153, 233, 272], "blend": [153, 195, 196], "model_config": 153, "bert_dataload": 153, "loader": [153, 315, 327, 329, 330, 333], "data_it": 153, "nc_yaml": 153, "leader": 154, "invis": 154, "healthi": 154, "opinion": [154, 159, 245, 273, 285, 288], "feedback": [154, 155, 157, 280], "apolog": 154, "mistak": [154, 155, 159, 251, 285, 288], "overal": [154, 156, 249, 251, 252], "email": [154, 159, 240, 285, 288], "moder": 154, "promptli": 154, "fairli": [154, 248, 273], "privaci": 154, "violat": 154, "unprofession": 154, "around": [154, 162, 169, 183, 186, 230, 240, 245, 247, 262, 268, 276, 281], "apologi": 154, "unsolicit": 154, "period": [154, 203], "seriou": 154, "sustain": 154, "aggress": 154, "disparag": 154, "mozilla": 154, "ladder": 154, "everybodi": [155, 159, 285, 288], "immens": 155, "spread": [155, 286], "blog": [155, 156, 159, 165, 186, 202, 204, 228, 229, 244, 249, 250, 265, 271, 285, 288], "shout": 155, "star": 155, "whichev": 155, "outstand": 155, "reliabl": 155, "notifi": [155, 159, 285, 288], "realli": [155, 156, 159, 161, 250, 264, 285, 288], "appreci": [155, 224], "traceback": [155, 156, 251], "src": [155, 156, 159, 160, 164, 187, 219, 247, 251, 283, 285, 286, 288], "transformers_cli": 155, "willing": 155, "frustrat": 155, "hear": 155, "think": [155, 156, 250, 251, 272, 276], "screenshot": [155, 284], "advis": [155, 159, 188, 192, 200, 203, 211, 212, 216, 221, 231, 233, 246, 285, 288], "nobodi": [155, 156], "unsur": 155, "profici": 155, "enjoi": [155, 159, 285, 288, 373], "book": [155, 192, 200, 211, 241, 264, 335], "pro": [155, 239], "remot": [155, 159, 240, 251, 285, 288], "uninstal": [155, 251], "pytest": [155, 159, 285, 286, 288], "overload": 155, "dist": [155, 251, 379, 382, 387], "loadfil": [155, 251], "isort": [155, 159, 285, 288], "qualiti": [155, 156, 159, 184, 285, 286, 288], "ci": [155, 158, 168, 169], "verif": [155, 159, 285, 288], "fixup": [155, 286], "modified_fil": 155, "regularli": 155, "rebas": [155, 159, 285, 288], "push": [155, 159, 192, 193, 236, 251, 280, 282, 285, 288], "too": [155, 156, 159, 164, 169, 186, 187, 195, 240, 241, 251, 256, 276, 285, 288, 290], "webpag": [155, 159, 165, 250, 285, 288, 328], "ok": 155, "mention": [155, 158, 165, 241, 242, 248, 250, 251, 252, 254, 277, 285, 288, 320], "consult": [155, 160, 275], "wip": [155, 159, 285, 288], "duplic": [155, 159, 285, 288], "differenti": [155, 227], "readi": [155, 159, 165, 253, 285, 288, 305, 310], "coverag": [155, 251], "modeltest": [155, 285], "all_model_class": 155, "mymodelwithlmhead": 155, "slow": [155, 168, 187, 273, 275, 288], "run_slow": [155, 159, 251, 285, 288], "test_my_new_model": 155, "test_tokenization_": 155, "your_model_nam": 155, "circleci": [155, 158, 251], "docstr": [155, 159, 187, 190, 285, 288], "nice": [155, 159, 165, 250, 285, 288], "sphinx": [155, 158], "modeling_ctrl": 155, "xdist": [155, 251], "san": 155, "gigabyt": 155, "likewis": 155, "run_custom_token": 155, "runner": [155, 251], "unittest": [155, 251], "crlf": 155, "lf": [155, 240, 283], "autocrlf": 155, "msys2": 155, "msys64": 155, "menu": [155, 156], "pacman": 155, "syu": 155, "usr": [155, 186, 320], "powershel": 155, "ping": [155, 159, 285, 288], "unnessari": 155, "notif": [155, 156], "squash": 155, "encourag": [156, 226, 237, 241, 248, 264, 281], "misunderstand": 156, "importantli": [156, 159, 210, 218, 244, 285, 288], "formul": [156, 227, 239], "chanc": [156, 159, 285, 288], "understood": [156, 159], "venu": 156, "difficulti": [156, 233, 239], "discuss": [156, 159, 186, 190, 195, 196, 244, 251, 253, 285, 288], "crystal": 156, "proce": [156, 186, 244], "particular": [156, 159, 164, 165, 185, 200, 231, 245, 250, 251, 269, 285, 288], "bertmodel": [156, 160, 167, 168, 187, 189, 207, 230, 245, 249, 288], "rl": 156, "bertformaskedlm": [156, 167, 168, 187], "chatbotmodel": 156, "embed": [156, 159, 167, 180, 187, 188, 192, 197, 200, 203, 205, 206, 209, 211, 212, 218, 219, 220, 221, 224, 228, 230, 231, 232, 233, 234, 241, 245, 247, 249, 252, 269, 272, 285, 288, 295, 305], "matrix": [156, 159, 188, 202, 228, 241, 249, 252, 285, 288], "t5model": [156, 168], "de": [156, 157, 168, 197, 198, 205, 209, 219, 220, 249, 251, 276, 277, 360, 361], "everyth": [156, 158, 159, 168, 186, 251, 253, 269, 285, 286, 288, 373], "hint": 156, "repli": 156, "someon": [156, 159, 197, 285, 288], "quot": 156, "remaind": [156, 250], "commonli": [156, 276], "shortli": [156, 250], "stackexchang": 156, "went": 156, "dependency_versions_check": 156, "file_util": [156, 159, 170, 285, 288], "is_tokenizers_avail": 156, "modulenotfounderror": 156, "stack": [156, 241, 244, 251], "favorit": [156, 162, 186, 240, 255, 258, 276, 279], "noth": [156, 169, 276], "outsid": [156, 250], "filesystem": [156, 251], "tmp": [156, 251, 254, 256, 257, 258, 267, 276, 277, 279, 354, 362], "wrong_path": 156, "filenotfounderror": 156, "errno": 156, "unrel": 156, "hit": [156, 186, 267, 272], "satisfactori": 156, "shoe": 156, "anyth": [156, 158, 165, 176, 229, 251, 273], "mental": 156, "intuit": [156, 210, 228, 244, 252], "distributeddataparallel": 156, "disentangl": [156, 157, 168, 201, 202], "local_rank": [156, 186], "enclos": 156, "tripl": [156, 204], "backtick": [156, 158], "backslash": 156, "seq2seq": [156, 159, 162, 167, 186, 190, 191, 195, 224, 227, 241, 250, 251, 262, 272, 273, 276, 285, 288], "finetune_train": [156, 276], "sshleifer": [156, 273, 274], "wmt_en_ro": [156, 251, 273, 290], "overwrite_output_dir": [156, 186, 276, 277, 296, 308, 309, 311, 312], "n_train": 156, "per_device_train_batch_s": [156, 165, 186, 253, 254, 257, 258, 275, 276, 277, 294, 295, 299, 302, 304, 305, 310, 312], "freeze_emb": [156, 273], "src_lang": [156, 220], "en_xx": [156, 220, 276], "tgt_lang": [156, 220], "ro_ro": [156, 220, 276], "sharded_ddp": [156, 186], "scroll": 156, "immedi": [156, 157, 377, 381], "pertin": 156, "pastebin": 156, "benefici": [156, 215], "tend": 156, "expir": 156, "reader": [156, 241], "anymor": [156, 159, 187, 248, 285, 288], "luxuri": 156, "couldn": 156, "dispair": 156, "perhap": 156, "colab": [156, 159, 168, 253, 254, 275, 285, 288], "notebook": [156, 159, 160, 168, 215, 216, 233, 243, 251, 253, 254, 265, 269, 275, 285, 288, 306, 317], "upper": [156, 215], "lengthi": 156, "albeit": 156, "older": [156, 186], "revis": [156, 162, 233, 240, 308, 309, 311, 312, 386], "highest": [156, 197], "retest": [156, 251], "hf": 156, "suppli": [156, 167, 186, 187, 189, 246], "gave": 156, "direct": [156, 162, 179, 198, 209, 212, 220, 234, 239, 240, 244, 250, 251, 387], "triag": 156, "doubt": 156, "surpris": 156, "prevent": [156, 186, 200, 212, 226, 237, 241, 249, 251], "expertis": 156, "coher": [156, 188, 200, 211, 212, 234, 250, 264], "typo": 156, "aren": [156, 186, 209, 251], "seem": 156, "sift": 156, "dozen": [156, 157, 186, 232, 253], "discontinu": 156, "bullet": 156, "outcom": 156, "readabl": [156, 159, 248, 251, 285, 288], "bartmodel": [156, 168, 195, 209], "stand": [156, 159, 186, 192, 252, 264, 285, 288], "comprehens": [156, 157, 168, 184, 188, 190, 210, 213, 241], "ital": 156, "bold": 156, "referenc": 156, "latter": [156, 186, 251, 359, 360, 361, 362, 368], "9257": 156, "issuecom": 156, "749945162": 156, "poster": 156, "somewhat": [156, 233], "friendli": [156, 159, 285, 288], "advic": [156, 159, 285, 288], "satisfact": 156, "elucid": 156, "hesit": [156, 158, 159, 267, 285, 288], "thousand": [157, 159, 216, 217, 224, 234, 285, 288], "Its": [157, 209, 237, 250], "cut": [157, 250, 273, 279, 379, 382], "standalon": [157, 286, 288], "seamless": [157, 195, 196, 280], "entiti": [157, 168, 183, 194, 198, 213, 225, 246, 248, 279, 281], "electra": [157, 159, 162, 168, 247, 252, 285, 288], "gpt": [157, 159, 161, 162, 168, 169, 187, 190, 193, 203, 206, 212, 230, 247, 250, 252, 271, 278, 281, 285, 288], "bart": [157, 159, 162, 167, 168, 187, 191, 219, 220, 247, 250, 251, 272, 273, 274, 285, 288, 290, 308], "versu": [157, 202, 248], "neg": [157, 165, 248, 250, 251, 271], "alloc": 157, "sentiment": [157, 162, 165, 169, 183, 213, 239, 248, 250, 253, 359], "9978193640708923": 157, "confid": [157, 159, 250, 275, 285, 288], "question_answer": 157, "5135612454720828": 157, "sentenc": [157, 162, 165, 167, 168, 184, 185, 188, 190, 192, 193, 200, 208, 210, 217, 218, 219, 222, 224, 228, 230, 232, 241, 242, 247, 248, 250, 252, 264, 267, 279, 281, 303, 359], "autotoken": [157, 168, 193, 194, 213, 225, 240, 246, 248, 250, 275], "automodel": [157, 168, 194, 213, 225, 240, 248, 250], "return_tensor": [157, 171, 182, 190, 193, 195, 213, 217, 219, 220, 224, 228, 232, 233, 244, 246, 248, 250, 253, 281], "tfautomodel": [157, 168, 194, 225, 248], "fourth": [157, 241], "fifth": 157, "nlu": [157, 167, 168, 184, 192, 197, 213, 221, 231, 233, 248, 250], "nlg": [157, 167, 168, 248, 250], "barrier": [157, 168, 364], "practition": [157, 168, 193, 245], "carbon": [157, 168, 250, 284], "lifetim": [157, 168], "seamlessli": [157, 168, 169, 253], "independ": [157, 159, 167, 185, 233, 241, 244, 252, 275, 285, 288], "toolbox": [157, 245], "refactor": [157, 159, 285, 288], "strive": [157, 169], "unfamiliar": [157, 169], "flax": [157, 168, 169, 270], "bleed": [157, 169], "wait": [157, 251, 276, 377, 381], "toyota": [157, 168], "technolog": [157, 168], "institut": [157, 168], "chicago": [157, 168], "zhenzhong": [157, 168, 188, 241], "lan": [157, 168, 188, 195, 196, 241, 271], "mingda": [157, 168, 188], "sebastian": [157, 168, 188, 227, 241], "goodman": [157, 168, 188], "kevin": [157, 161, 168, 188, 241], "gimpel": [157, 168, 188], "piyush": [157, 168, 188], "sharma": [157, 168, 188], "radu": [157, 168, 188], "soricut": [157, 168, 188], "facebook": [157, 168, 190, 195, 196, 198, 201, 202, 209, 220, 238, 247, 272, 273, 274, 276, 331, 332], "denois": [157, 168, 190, 220, 232, 239, 241], "mike": [157, 168, 190, 220, 227, 230, 241], "lewi": [157, 168, 190, 205, 220, 227, 230, 241, 250], "yinhan": [157, 168, 190, 195, 196, 220, 230, 241], "liu": [157, 168, 190, 194, 195, 196, 197, 201, 202, 203, 207, 220, 221, 222, 224, 226, 230, 232, 237, 241, 262, 271], "naman": [157, 168, 190, 195, 196, 220, 227, 230, 238, 241], "goyal": [157, 168, 190, 195, 196, 220, 227, 230, 238, 241, 250], "marjan": [157, 168, 190, 220, 241], "ghazvininejad": [157, 168, 190, 220, 241], "abdelrahman": [157, 168, 190, 235], "moham": [157, 168, 190, 235], "omer": [157, 161, 168, 190, 230], "levi": [157, 161, 168, 190, 230], "stoyanov": [157, 168, 190, 230, 238], "luke": [157, 168, 190, 220, 230, 238, 241], "zettlemoy": [157, 168, 190, 220, 230, 238, 241], "\u00e9cole": [157, 168], "polytechniqu": [157, 168], "skill": [157, 159, 168, 191, 195, 196, 285, 288], "french": [157, 168, 191, 198, 208, 219, 220, 241, 242, 247, 248], "moussa": [157, 168, 191], "kamal": [157, 168, 191], "eddin": [157, 168, 191], "antoin": [157, 168, 191], "tixier": [157, 168, 191], "michali": [157, 168, 191], "vazirgianni": [157, 168, 191], "bidirect": [157, 168, 190, 192, 210, 218, 221, 231, 239, 241, 256, 281], "jacob": [157, 168, 192, 241], "devlin": [157, 168, 192, 194, 197, 208, 230, 241], "ming": [157, 168, 192, 215, 226, 237, 241], "wei": [157, 168, 192, 215, 232, 261], "kenton": [157, 168, 192], "lee": [157, 168, 192, 232, 263], "kristina": [157, 168, 192], "toutanova": [157, 168, 192], "sascha": [157, 168, 193, 207], "roth": [157, 168, 193, 207], "shashi": [157, 168, 193, 207], "narayan": [157, 168, 193, 207], "aliaksei": [157, 168, 193, 207], "severyn": [157, 168, 193, 207], "blenderbot": [157, 168], "chatbot": [157, 162, 168, 195, 196], "stephen": [157, 168, 195, 196], "roller": [157, 168, 195, 196], "emili": [157, 168, 195, 196], "dinan": [157, 168, 195, 196], "da": [157, 161, 168, 195, 196, 219, 232], "ju": [157, 168, 195, 196], "mari": [157, 168, 195, 196, 250], "williamson": [157, 168, 195, 196], "jing": [157, 168, 195, 196], "xu": [157, 168, 195, 196, 215, 222, 261, 273], "myle": [157, 168, 195, 196, 209, 230, 238], "ott": [157, 168, 195, 196, 209, 230, 238], "kurt": [157, 168, 195, 196, 214, 231], "shuster": [157, 168, 195, 196], "eric": [157, 168, 195, 196, 271], "smith": [157, 168, 195, 196], "boureau": [157, 168, 195, 196], "jason": [157, 168, 195, 196, 271], "weston": [157, 168, 195, 196], "blenderbotsmal": [157, 162, 168, 195], "bort": [157, 168], "alexa": [157, 168], "subarchitectur": [157, 168, 197], "adrian": [157, 168, 197, 270], "wynter": [157, 168, 197], "daniel": [157, 168, 197], "perri": [157, 168, 197], "inria": [157, 168], "sorbonn": [157, 168], "tasti": [157, 168, 198], "loui": [157, 168, 198], "martin": [157, 168, 198, 233, 281], "benjamin": [157, 168, 198], "pedro": [157, 168, 198], "javier": [157, 168, 198], "ortiz": [157, 168, 198], "su\u00e1rez": [157, 168, 198], "yoann": [157, 168, 198], "dupont": [157, 168, 198], "laurent": [157, 168, 198], "romari": [157, 168, 198], "\u00e9ric": [157, 168, 198], "villemont": [157, 168, 198], "la": [157, 168, 198, 219], "clergeri": [157, 168, 198], "djam\u00e9": [157, 168, 198], "seddah": [157, 168, 198], "beno\u00eet": [157, 168, 198], "sagot": [157, 168, 198], "convbert": [157, 168], "yitutech": [157, 168], "span": [157, 162, 168, 185, 190, 199, 203, 232, 239, 241, 256, 279], "zihang": [157, 168, 199, 234, 239, 241], "jiang": [157, 168, 199, 241], "weihao": [157, 168, 199, 241], "yu": [157, 168, 199, 221, 226, 237, 241, 263], "daquan": [157, 168, 199, 241], "zhou": [157, 168, 199, 215, 221, 226, 232, 235, 237, 241, 261], "jiashi": [157, 168, 199, 241], "shuicheng": [157, 168, 199, 241], "yan": [157, 168, 199, 222, 226, 237, 241], "salesforc": [157, 168, 233, 247], "nitish": [157, 168, 200, 241], "shirish": [157, 168, 200, 241], "keskar": [157, 168, 200, 241], "bryan": [157, 168, 200], "mccann": [157, 168, 200], "lav": [157, 168, 200], "varshnei": [157, 168, 200], "caim": [157, 168, 200], "richard": [157, 168, 200], "socher": [157, 168, 200], "pengcheng": [157, 168, 201, 202], "xiaodong": [157, 168, 201, 202], "jianfeng": [157, 168, 201, 202, 203, 222], "gao": [157, 168, 201, 202, 203], "weizhu": [157, 168, 201, 202], "dialogpt": [157, 162, 168, 247, 290], "yizh": [157, 168, 203], "siqi": [157, 168, 203], "michel": [157, 161, 168, 203], "gallei": [157, 168, 203], "yen": [157, 168, 203], "chun": [157, 168, 203], "chri": [157, 168, 203], "brockett": [157, 168, 203], "jingj": [157, 168, 203], "bill": [157, 168, 203], "dolan": [157, 168, 203], "cheaper": [157, 168, 169, 204, 241, 264, 359], "lighter": [157, 168, 204, 241, 264, 359], "victor": [157, 168, 241, 264, 269, 273], "sanh": [157, 168, 241, 264, 269, 273], "lysandr": [157, 159, 168, 264, 273, 285, 288], "debut": [157, 168, 264, 273], "thoma": [157, 159, 168, 233, 264, 269, 273, 281, 285, 288], "wolf": [157, 168, 264, 269, 273], "distilgpt2": [157, 162, 168, 247, 264], "distilmbert": [157, 168, 264], "german": [157, 168, 209, 232, 236, 241, 242, 247, 248, 250, 264, 276, 361], "dpr": [157, 168, 227, 272], "passag": [157, 165, 168, 205, 227, 241], "retriev": [157, 159, 161, 168, 187, 189, 205, 227, 233, 250, 285, 288, 364], "vladimir": [157, 168, 205, 227, 241], "karpukhin": [157, 168, 205, 227, 241], "barla": [157, 168, 205], "o\u011fuz": [157, 168, 205], "sewon": [157, 168, 205], "patrick": [157, 162, 168, 205, 227, 241, 273, 288], "ledel": [157, 168, 205], "sergei": [157, 168, 205, 209, 220, 241], "edunov": [157, 168, 205, 209, 220, 241], "danqi": [157, 168, 205, 230], "wen": [157, 168, 205, 227, 241], "tau": [157, 168, 205, 227, 241], "yih": [157, 168, 205, 227, 241], "stanford": [157, 165, 168, 184, 233, 299, 359], "discrimin": [157, 168, 191, 206, 211, 241], "clark": [157, 161, 168, 241], "minh": [157, 168], "thang": [157, 168], "luong": [157, 168], "quoc": [157, 168, 194, 225, 234, 239], "le": [157, 168, 208, 220, 234, 239, 241, 273], "christoph": [157, 161, 168, 250], "man": [157, 161, 168, 250], "cnr": [157, 168, 208], "unsupervis": [157, 168, 193, 200, 208, 212, 232, 236, 238, 241], "lo\u00efc": [157, 168], "vial": [157, 168], "jibril": [157, 168], "frej": [157, 168], "vincent": [157, 168], "segonn": [157, 168], "maximin": [157, 168], "coavoux": [157, 168], "lecouteux": [157, 168], "alexandr": [157, 168], "allauzen": [157, 168], "crabb\u00e9": [157, 168], "besaci": [157, 168], "didier": [157, 168], "schwab": [157, 168], "funnel": [157, 168, 247, 290, 308], "cmu": [157, 168], "redund": [157, 168, 199, 210, 241], "guokun": [157, 168], "lai": [157, 160, 168], "yime": [157, 168, 221, 234, 239], "yang": [157, 168, 207, 208, 221, 234, 239, 241, 262, 319], "openai": [157, 168, 203, 247, 250, 264], "alec": [157, 168, 211, 212, 241], "radford": [157, 168, 208, 211, 212, 241], "karthik": [157, 168, 211], "narasimhan": [157, 168, 211], "tim": [157, 168, 211, 227, 241, 273], "saliman": [157, 168, 211], "ilya": [157, 168, 211, 212], "sutskev": [157, 168, 211, 212], "multitask": [157, 168, 212, 241], "learner": [157, 168, 212, 241], "jeffrei": [157, 168, 212], "rewon": [157, 168, 212], "david": [157, 168, 212, 270], "luan": [157, 168, 212], "dario": [157, 168, 212], "amodei": [157, 168, 212], "layoutlm": [157, 162, 168, 247, 310], "asia": [157, 168], "yiheng": [157, 168, 215], "minghao": [157, 168, 215], "lei": [157, 168, 215], "cui": [157, 168, 215], "shaohan": [157, 168, 215], "huang": [157, 168, 215, 258], "furu": [157, 168, 215, 261], "led": [157, 162, 168, 230], "allenai": [157, 162, 168, 247], "iz": [157, 162, 168, 216, 217, 241], "beltagi": [157, 162, 168, 216, 217, 241], "matthew": [157, 168, 216, 217, 277], "peter": [157, 162, 168, 208, 216, 217, 224, 232, 241, 270, 285], "arman": [157, 168, 216, 217], "cohan": [157, 168, 216, 217], "lxmert": [157, 168, 247], "unc": [157, 168], "chapel": [157, 168], "hill": [157, 168], "hao": [157, 168, 218], "tan": [157, 168, 218, 222], "mohit": [157, 168, 218], "bansal": [157, 168, 218], "marianmt": [157, 168, 247, 290, 313], "j\u00f6rg": [157, 168, 219], "tiedemann": [157, 168, 219], "marian": [157, 168, 219, 241, 252, 274, 283], "jiatao": [157, 168, 220, 241], "gu": [157, 168, 220, 241], "xian": [157, 168, 220, 241], "yuqe": [157, 168, 220], "tang": [157, 168, 220, 263], "chau": [157, 168, 220], "tran": [157, 168, 220], "peng": [157, 168, 220], "vishrav": [157, 168, 220, 238], "chaudhari": [157, 168, 220, 238], "angela": [157, 168, 220], "fan": [157, 168, 220, 250, 276], "mpnet": [157, 168], "kaitao": [157, 168, 222], "song": [157, 168, 221, 222, 270], "tao": [157, 168, 222, 261], "qin": [157, 168, 222], "lu": [157, 168, 222], "tie": [157, 168, 222], "mt5": [157, 168], "massiv": [157, 168, 223, 241, 252], "lint": [157, 168, 223, 241, 332], "xue": [157, 168, 223, 241], "noah": [157, 168, 223, 299], "mihir": [157, 168, 223], "kale": [157, 168, 223], "rami": [157, 168, 223], "rfou": [157, 168, 223], "aditya": [157, 168, 223], "siddhant": [157, 168, 223], "barua": [157, 168, 223], "colin": [157, 168, 223, 232, 241], "raffel": [157, 168, 223, 232, 241], "jingq": [157, 168, 224, 241], "yao": [157, 168, 214, 224, 241], "zhao": [157, 168, 224, 241], "mohammad": [157, 168, 224, 241], "saleh": [157, 168, 224, 241], "prophetnet": [157, 168], "gram": [157, 168, 226, 237, 241], "weizhen": [157, 168, 226, 237, 241], "qi": [157, 168, 226, 237, 241], "yeyun": [157, 168, 226, 237, 241], "dayiheng": [157, 168, 226, 237, 241], "nan": [157, 168, 226, 233, 237, 241], "duan": [157, 168, 226, 237, 241], "jiusheng": [157, 168, 226, 237, 241], "ruofei": [157, 168, 226, 237, 241], "reform": [157, 162, 167, 168, 247, 250, 282, 290], "nikita": [157, 168, 228, 241], "kitaev": [157, 168, 228, 241], "\u0142ukasz": [157, 168, 228], "kaiser": [157, 168, 228, 270], "anselm": [157, 168, 228], "levskaya": [157, 168, 228], "robustli": [157, 168, 230, 241], "jingfei": [157, 168, 230], "du": [157, 168, 230], "mandar": [157, 168, 230], "joshi": [157, 168, 230], "veselin": [157, 168, 230, 238], "teach": [157, 159, 168, 231], "forrest": [157, 168, 231], "iandola": [157, 168, 231], "shaw": [157, 168, 231, 258], "ravi": [157, 168, 231], "krishna": [157, 168, 231], "keutzer": [157, 168, 214, 231], "noam": [157, 168, 232], "shazeer": [157, 168, 232], "katherin": [157, 168, 232], "sharan": [157, 168, 232], "narang": [157, 168, 232], "michael": [157, 162, 168, 209, 214, 232, 235], "matena": [157, 168, 232], "yanqi": [157, 168, 232], "tapa": [157, 162, 168], "weakli": [157, 168, 233, 281], "jonathan": [157, 168, 233, 281], "herzig": [157, 168, 233, 281], "pawe\u0142": [157, 168, 233, 281], "krzysztof": [157, 168, 233, 270, 281], "nowak": [157, 168, 233, 281], "m\u00fcller": [157, 168, 233, 281], "francesco": [157, 168, 233, 281], "piccinno": [157, 168, 233, 281], "julian": [157, 168, 233, 261, 281], "eisenschlo": [157, 168, 233, 281], "beyond": [157, 168, 234, 241], "zhilin": [157, 168, 234, 239, 241], "jaim": [157, 168, 234, 239], "carbonel": [157, 168, 234, 239], "ruslan": [157, 168, 234, 239], "salakhutdinov": [157, 168, 234, 239], "wav2vec": [157, 168, 235], "alexei": [157, 168, 209, 235, 250], "baevski": [157, 168, 209, 235], "henri": [157, 168, 235], "auli": [157, 168, 209, 235], "lingual": [157, 168, 184, 236, 237, 238, 241, 277], "guillaum": [157, 168, 236, 238, 241], "lampl": [157, 168, 236, 241], "alexi": [157, 168, 236, 238, 241], "conneau": [157, 168, 194, 225, 236, 238, 241], "kartikai": [157, 168, 238], "khandelw": [157, 161, 168, 238], "wenzek": [157, 168, 238], "francisco": [157, 168, 238, 319], "guzm\u00e1n": [157, 168, 238], "edouard": [157, 168, 238], "grave": [157, 168, 238], "autoregress": [157, 167, 168, 207, 239, 244, 256, 281], "migrat": [157, 168, 240, 280], "inproceed": [157, 263, 264], "etal": [157, 263], "julien": [157, 240, 264, 273], "chaumond": [157, 264, 273], "clement": [157, 273], "delangu": [157, 273], "anthoni": [157, 273], "moi": [157, 273], "pierric": [157, 273], "cistac": [157, 273], "rault": [157, 273], "r\u00e9mi": [157, 273], "louf": [157, 273], "morgan": [157, 273], "funtowicz": [157, 273], "joe": [157, 273], "davison": [157, 273], "sam": [157, 273], "shleifer": [157, 273], "von": [157, 162, 255, 273], "platen": [157, 162, 255, 273], "clara": [157, 273], "ma": [157, 213, 273], "yacin": [157, 273], "jernit": [157, 273], "canwen": [157, 261, 273], "teven": [157, 273], "scao": [157, 273], "sylvain": [157, 273], "gugger": [157, 273], "mariama": [157, 273], "drame": [157, 273], "quentin": [157, 273], "lhoest": [157, 273], "rush": [157, 269, 273], "proceed": [157, 263], "confer": [157, 203, 314], "month": [157, 168, 187, 263], "linguist": [157, 263], "aclweb": [157, 263], "anthologi": [157, 263], "emnlp": 157, "theme": 158, "sphinx_rtd_them": 158, "recommonmark": 158, "restructur": 158, "_build": 158, "rebuild": [158, 377, 381], "restructuredtext": 158, "rst": [158, 159, 285, 286, 288], "expand": [158, 162, 249, 251, 368], "build_doc": 158, "sourceforg": 158, "unlik": [158, 186, 191, 192, 238], "beginn": 158, "model_doc": [158, 159, 285, 286, 288], "tip": [158, 159, 188, 192, 193, 197, 198, 199, 200, 203, 204, 206, 210, 211, 212, 215, 216, 217, 218, 221, 222, 230, 231, 232, 233, 234, 235, 236, 238, 239, 240, 264, 275, 285, 287, 288], "xxxconfig": 158, "autoclass": [158, 189], "xxxtoken": 158, "build_inputs_with_special_token": 158, "get_special_tokens_mask": 158, "create_token_type_ids_from_sequ": 158, "save_vocabulari": 158, "surround": [158, 241, 256], "obj": [158, 251], "xxxclass": 158, "meth": 158, "underscor": 158, "loc": [158, 250], "indent": [158, 332], "showcas": [158, 159, 162, 211, 212, 250, 264, 269, 285, 288], "far": [158, 193, 227, 250, 251, 252, 269], "longtensor": 158, "sequence_length": [158, 160, 167, 242], "alberttoken": [158, 168, 187], "pretrainedtoken": [158, 168, 174, 246], "glossari": [158, 162, 168], "imagin": 158, "signatur": 158, "my_funct": 158, "semicolon": 158, "doctest": 158, "stai": 158, "compris": [158, 185, 192, 211, 215, 233], "floattensor": [158, 327], "bertconfig": [158, 160, 168, 245, 249], "masked_lm_label": [158, 187, 217], "prediction_scor": 158, "vocab_s": [158, 264, 288], "ideal": [159, 285, 288], "empow": [159, 285, 288], "sound": 159, "insight": [159, 232, 285, 288], "principl": [159, 252, 285, 288], "resembl": [159, 275, 285], "fundament": 159, "composit": [159, 228, 241, 252, 285, 288], "favor": [159, 187, 244, 285, 288], "modeling_": [159, 285, 286, 288], "henc": [159, 210, 227, 248, 251, 285, 288, 362], "possibli": [159, 285, 288, 316], "tweak": [159, 230, 241, 248, 262, 277, 285, 288], "pretrainedconfig": [159, 168, 285, 288], "exemplari": [159, 252, 285, 288], "brandnewbertmodel": [159, 285, 288], "brandnewbertpretrainedmodel": [159, 285, 288], "save_pretrain": [159, 187, 240, 245, 248, 253, 273, 285, 288], "deseri": [159, 285, 288], "modeling_brand_new_bert": [159, 285, 288], "brandnewbertformaskedlm": [159, 285, 288], "brandnewbertconfig": [159, 285, 288], "brandi": [159, 285, 288], "brand_new_bert": [159, 285, 288], "pytorch_model": [159, 164, 240, 253, 273, 285, 288, 297], "wmt19": [159, 209, 251, 285, 288], "sta": [159, 251, 285, 288], "reinvent": [159, 285, 288], "wheel": [159, 285, 288], "rg": [159, 285, 288], "friend": [159, 195, 285, 288], "fsmt": [159, 168, 187, 251, 285, 288], "scientif": [159, 208, 250, 285, 288], "spend": [159, 285, 288], "stuck": [159, 285, 288], "skeleton": [159, 285, 288], "job": [159, 189, 248, 251, 285, 288], "troubl": [159, 285, 288], "sentencepiec": [159, 185, 202, 285, 288], "gotten": [159, 285, 288], "venv": [159, 266, 285, 288], "org_that_created_brand_new_bert_org": 159, "researchi": [159, 285, 288], "reimplement": [159, 285, 288], "shoulder": [159, 285, 288], "giant": [159, 285, 288], "rewrit": [159, 251, 285, 288], "beauti": [159, 285, 288], "encodermodel": [159, 285, 288], "decodermodel": [159, 285, 288], "statement": [159, 169, 250, 281, 285, 288, 320], "debugg": [159, 251, 285, 288], "ipdb": [159, 285, 288], "pycharm": [159, 285, 288], "costli": [159, 228, 285, 288], "cell": [159, 186, 233, 240, 281, 285, 288, 378], "jupit": [159, 275, 285, 288], "obviou": [159, 285, 288], "disadvantag": [159, 252, 285, 288], "jupyth": [159, 285, 288], "Such": [159, 213, 250, 251, 252, 272, 285, 288, 323], "pseudocod": [159, 285], "load_pretrained_checkpoint": [159, 285, 288], "original_output": [159, 285, 288], "decompos": [159, 244, 252, 285, 288], "testabl": [159, 285, 288], "breakpoint": [159, 273, 285, 288], "worth": [159, 252, 285, 288], "road": [159, 285, 288], "rope": [159, 285, 288], "occur": [159, 200, 212, 215, 250, 252, 281, 285, 288], "meshtensorflow": [159, 285, 288], "1465": [159, 285, 288], "6501": [159, 285, 288], "1993": [159, 285, 288], "1451": [159, 285, 288], "3430": [159, 285, 288], "6024": [159, 285, 288], "4417": [159, 285, 288], "5920": [159, 285, 288], "3450": [159, 285, 288], "3062": [159, 285, 288], "6182": [159, 285, 288], "7132": [159, 285, 288], "5009": [159, 285, 288], "7122": [159, 285, 288], "4548": [159, 285, 288], "3662": [159, 285, 288], "6091": [159, 285, 288], "7648": [159, 285, 288], "5613": [159, 285, 288], "6332": [159, 285, 288], "4324": [159, 285, 288], "3792": [159, 285, 288], "7372": [159, 285, 288], "9288": [159, 285, 288], "5416": [159, 285, 288], "6345": [159, 285, 288], "4180": [159, 285, 288], "3564": [159, 285, 288], "6992": [159, 285, 288], "9191": [159, 285, 288], "5334": [159, 285, 288], "6403": [159, 285, 288], "4271": [159, 285, 288], "3339": [159, 285, 288], "6533": [159, 285, 288], "8694": [159, 285, 288], "coupl": [159, 160, 187, 251, 285, 288], "1e": [159, 186, 187, 253, 269, 273, 285, 288, 291, 292, 294, 295, 299, 301, 305], "nearli": [159, 206, 224, 285, 288], "certainli": [159, 285, 288], "jax": [159, 270, 285, 288], "smallest": [159, 264, 285, 288], "sens": [159, 208, 241, 273, 285, 288], "autoregressive_sampl": [159, 285, 288], "set_se": [159, 251, 285, 288], "amaz": [159, 285, 288], "cookiecutt": [159, 284, 285, 288], "carefulli": [159, 221, 230, 285, 288], "add_brand_new_bert": 159, "draft": [159, 285, 288, 379, 382], "forget": [159, 187, 240, 248, 284, 285, 286, 288], "configuration_brand_new_bert": 159, "unclean": [159, 285, 288], "simplemodel": [159, 285, 288], "layer_norm": [159, 285, 288], "out_featur": [159, 285, 288], "ep": [159, 186, 285, 288], "elementwise_affin": [159, 285, 288], "0818": [159, 248, 285, 288], "2207": [159, 285, 288], "0749": [159, 285, 288], "0045": [159, 285, 288], "1569": [159, 285, 288], "1598": [159, 285, 288], "0212": [159, 285, 288], "2077": [159, 285, 288], "2157": [159, 285, 288], "1044": [159, 285, 288], "0201": [159, 285, 288], "0990": [159, 285, 288], "2482": [159, 285, 288], "3116": [159, 285, 288], "2509": [159, 285, 288], "2866": [159, 285, 288], "2190": [159, 285, 288], "2166": [159, 285, 288], "1107": [159, 285, 288], "1999": [159, 250, 285, 288], "3119": [159, 285, 288], "1559": [159, 285, 288], "0993": [159, 285, 288], "1776": [159, 285, 288], "1950": [159, 285, 288], "1023": [159, 285, 288], "0447": [159, 285, 288], "0888": [159, 285, 288], "1092": [159, 285, 288], "2281": [159, 285, 288], "0336": [159, 285, 288], "1817": [159, 285, 288], "2096": [159, 285, 288], "1415": [159, 285, 288], "1876": [159, 285, 288], "2467": [159, 285, 288], "2208": [159, 285, 288], "2352": [159, 285, 288], "1426": [159, 285, 288], "2636": [159, 285, 288], "2889": [159, 285, 288], "2061": [159, 285, 288], "2849": [159, 285, 288], "0465": [159, 285, 288], "2577": [159, 285, 288], "0402": [159, 285, 288], "1502": [159, 285, 288], "2465": [159, 285, 288], "0693": [159, 285, 288], "0530": [159, 285, 288], "1859": [159, 285, 288], "0604": [159, 285, 288], "1680": [159, 285, 288], "1733": [159, 285, 288, 323], "2407": [159, 285, 288], "1721": [159, 285, 288], "1484": [159, 285, 288], "0358": [159, 285, 288], "0633": [159, 285, 288], "0721": [159, 285, 288], "0090": [159, 285, 288], "2707": [159, 285, 288], "1173": [159, 285, 288], "1561": [159, 285, 288], "2945": [159, 285, 288], "0595": [159, 285, 288], "1996": [159, 248, 285, 288], "2988": [159, 285, 288], "0802": [159, 285, 288], "0407": [159, 285, 288], "1829": [159, 285, 288], "1568": [159, 285, 288], "1164": [159, 285, 288], "2228": [159, 285, 288], "0403": [159, 285, 288], "0428": [159, 285, 288], "1339": [159, 285, 288], "0047": [159, 285, 288], "1967": [159, 285, 288], "2923": [159, 285, 288], "0333": [159, 285, 288], "0536": [159, 285, 288], "1492": [159, 285, 288], "1616": [159, 285, 288], "1057": [159, 285, 288], "2807": [159, 285, 288], "2710": [159, 285, 288], "1586": [159, 285, 288], "0739": [159, 285, 288], "2220": [159, 285, 288], "2358": [159, 285, 288], "layer_nam": [159, 285, 288], "pretrained_weight": [159, 285, 288, 328], "array_of_dense_lay": [159, 285, 288], "model_point": [159, 285, 288], "getattr": [159, 285, 288], "from_numpi": [159, 285, 288], "pointer": [159, 285, 288], "incorrect": [159, 285, 288], "analog": [159, 285, 288], "last_hidden_st": [159, 264, 285, 288], "throw": [159, 246, 285, 288, 355], "disappoint": [159, 285, 288], "forgotten": [159, 285, 288], "ti": [159, 228, 234, 277, 285, 288], "offset": [159, 165, 250, 285, 288], "allclos": [159, 285, 288], "atol": [159, 285, 288], "congratul": [159, 285, 288], "cakewalk": [159, 285, 288], "test_modeling_brand_new_bert": 159, "essenti": [159, 228, 251, 285, 288], "earlier": [159, 186, 251, 252, 285, 288], "brandnewbertmodelintegrationtest": 159, "sv": [159, 219, 251, 285, 288], "brandnewbertmodeltest": 159, "extrem": [159, 231, 285, 288], "acquir": [159, 285, 288, 370], "input_str": [159, 285, 288], "charact": [159, 165, 185, 216, 217, 219, 241, 244, 247, 251, 252, 267, 279, 285, 288, 332], "2872": [159, 285, 288], "brandnewberttoken": 159, "forgot": [159, 285, 288], "concis": [159, 285, 288], "oneself": [159, 285, 288], "lastli": [159, 165, 218, 248, 275, 285, 288], "awesom": [159, 240, 285, 288], "stream": [159, 222, 226, 237, 241, 252, 285, 288, 300], "eventu": [159, 165, 285, 288], "credit": [159, 285, 288], "hundr": [159, 221, 224, 231, 238, 285, 288], "proud": [159, 285, 288], "prefix_link": [160, 161, 164, 184, 190, 191, 224, 242, 250, 251], "pytorchbenchmark": 160, "tensorflowbenchmark": 160, "flexibli": 160, "pytorchbenchmarkargu": 160, "tensorflowbenchmarkargu": 160, "benchmark_args_util": 160, "benchmark_arg": 160, "benchmark_args_tf": 160, "run_benchmark_tf": 160, "seq": [160, 356, 359], "006": 160, "018": 160, "1227": 160, "1281": 160, "1307": 160, "1539": 160, "transformers_vers": 160, "use_torchscript": 160, "framework_vers": 160, "python_vers": 160, "x86_64": 160, "64bit": 160, "371351": 160, "use_multiprocess": 160, "only_pretrain_model": 160, "cpu_ram_mb": 160, "32088": 160, "use_gpu": 160, "num_gpu": [160, 186], "gpu_ram_mb": 160, "24217": 160, "gpu_power_watt": 160, "280": 160, "gpu_performance_st": 160, "use_tpu": 160, "005": 160, "008": [160, 318], "105": 160, "1330": [160, 246], "1770": 160, "use_xla": [160, 277], "617317": 160, "save_to_csv": 160, "hid": 160, "config_bas": 160, "config_384_hid": 160, "hidden_s": [160, 167, 228, 249, 288], "config_6_lai": 160, "num_hidden_lay": [160, 249, 288], "011": 160, "003": 160, "009": 160, "044": 160, "1277": 160, "1005": [160, 248], "1027": 160, "1035": 160, "1255": 160, "1101": 160, "1127": 160, "1359": 160, "143267": 160, "106": [160, 277], "007": 160, "0011": 160, "1540": 160, "487125": 160, "no_multi_process": 160, "heavili": [160, 199, 241], "xla": [160, 254, 277], "blogpost": [160, 264], "ever": [160, 251, 276], "grow": [161, 168, 187, 251, 275], "concern": [161, 242, 250], "rediscov": 161, "ian": 161, "tennei": 161, "dipanjan": 161, "elli": 161, "pavlick": 161, "05950": 161, "graham": 161, "neubig": 161, "10650": 161, "urvashi": 161, "1906": 161, "04341": 161, "research_project": [161, 256, 272], "run_bertologi": 161, "regroup": 162, "flashcard": 162, "learnt": 162, "anki": 162, "retent": 162, "introductori": [162, 269], "video": 162, "darigov": 162, "amp": [162, 186, 187, 273, 277, 318, 370, 375], "muhammad": 162, "harri": 162, "suraj": [162, 276], "patil": [162, 276], "lightn": [162, 219, 251, 375], "nathan": [162, 209], "fastai": 162, "blurr": 162, "wayd": 162, "gilliam": 162, "anyon": [162, 240, 303], "tweet": [162, 194, 284], "bori": 162, "dayma": 162, "bias": [162, 204, 270], "qa": [162, 165, 205, 227, 272], "triviaqa": [162, 216, 217], "lorenzo": 162, "ampil": 162, "abhishek": 162, "kumar": 162, "mishra": 162, "track": [162, 249, 328, 332], "wandb": [162, 176, 254, 270, 273], "bucket": [162, 169, 202, 228, 251], "benesti": 162, "bi": [162, 198, 239, 250], "sci": 162, "scibert": 162, "cord": 162, "tanmai": 162, "thakur": 162, "captum": 162, "eliza": 162, "szczechla": 162, "philipp": 162, "schmid": 162, "dhaval": 162, "taunk": 162, "nadir": 162, "el": 162, "manouzi": 162, "pascal": [162, 254, 277, 319, 367], "zoleko": 162, "bayerl": 162, "dailymail": [162, 226, 237, 276], "warm": [162, 193, 253], "encoderdecodermodel": [162, 168, 193], "bbc": 162, "xsum": [162, 224, 274, 276], "sqa": [162, 233], "tapasforquestionansw": [162, 168], "niel": 162, "rogg": 162, "tabfact": [162, 233], "tapasforsequenceclassif": [162, 168], "seq2seqtrain": [162, 168], "hindi": [162, 220], "vasudev": [162, 288], "gupta": 162, "funsd": [162, 215], "layoutlmfortokenclassif": [162, 168], "aakash": 162, "tripathi": 162, "8k": 162, "pubm": 162, "rvl": [162, 215], "cdip": [162, 215], "layoutlmforsequenceclassif": [162, 168], "convert_bert_original_tf_checkpoint_to_pytorch": 164, "bert_config": [164, 288, 356], "tour": [164, 168, 246, 273], "bert_base_dir": 164, "tf_checkpoint": 164, "pytorch_dump_output": 164, "convert_albert_original_tf_checkpoint_to_pytorch": 164, "albert_config": 164, "albert_base_dir": 164, "albert_bas": 164, "openai_gpt_checkpoint_folder_path": 164, "openai_gpt_config": 164, "finetuning_task_nam": 164, "openai_gpt_finetuned_task": 164, "openai_gpt2_checkpoint_path": 164, "openai_gpt2_config": 164, "openai_gpt2_finetuned_task": 164, "transfo_xl_checkpoint_folder_path": 164, "transfo_xl": 164, "transfo_xl_config": 164, "transfo_xl_finetuned_task": 164, "transfo_xl_checkpoint_path": 164, "transfo_xl_config_path": 164, "xlnet_finetuned_task": 164, "xlm_checkpoint_path": 164, "xml_config": 164, "xml_finetuned_task": 164, "t5_model": 164, "t5_config": 164, "brief": 165, "tftrainer": [165, 168, 187, 240, 245, 248, 253, 254], "load_dataset": [165, 244, 359], "movi": [165, 233, 241, 268, 281], "amaa": 165, "aclimdb_v1": 165, "xf": 165, "po": [165, 186, 246, 279, 282], "pathlib": [165, 251], "read_imdb_split": 165, "split_dir": 165, "label_dir": 165, "text_fil": 165, "iterdir": 165, "read_text": 165, "train_text": 165, "aclimdb": 165, "test_text": 165, "taint": 165, "sklearn": [165, 253, 330], "model_select": 165, "train_test_split": 165, "val_text": 165, "val_label": 165, "test_siz": 165, "alright": [165, 285, 288], "tackl": [165, 272], "distilberttokenizerfast": [165, 168], "train_encod": 165, "val_encod": 165, "test_encod": 165, "from_tensor_slic": 165, "constructor": 165, "imdbdataset": 165, "test_dataset": [165, 253], "trainingargu": [165, 168, 176, 253, 254, 275], "tftrainingargu": [165, 168, 253], "distilbertforsequenceclassif": [165, 168, 240, 248], "training_arg": [165, 186, 253, 290, 296, 298, 308, 309, 310, 311, 313], "per_device_eval_batch_s": [165, 253, 258, 276, 277, 295, 296, 308, 309, 311, 312], "warmup_step": [165, 186, 253, 269, 273, 275, 359, 361], "weight_decai": [165, 186, 253, 294, 295, 304, 305], "strength": [165, 253], "decai": [165, 181, 187, 253, 314], "logging_dir": [165, 253, 258], "logging_step": [165, 258, 261, 277], "eval_dataset": [165, 253, 290, 296, 308, 309, 310, 311], "tfdistilbertforsequenceclassif": [165, 168, 240, 248], "scope": [165, 186, 355], "adamw": [165, 168, 186, 233, 253], "is_avail": [165, 224, 251], "5e": [165, 233, 257, 277, 281, 292, 293, 295, 304, 305, 310], "compute_loss": [165, 186], "wnut": [165, 279], "wnut_17": 165, "corpu": [165, 184, 191, 192, 200, 208, 211, 212, 226, 232, 237, 241, 244, 246, 247, 250, 252, 264, 275, 281, 359], "noisi": [165, 209], "wnut17train": 165, "conll": [165, 250, 254, 264, 279], "token_doc": 165, "token_tag": 165, "read_wnut": 165, "file_path": [165, 264], "raw_text": 165, "raw_doc": 165, "tag_doc": 165, "week": [165, 240, 250], "train_tag": 165, "val_tag": 165, "moment": [165, 224, 251, 258, 273], "unique_tag": 165, "tag2id": 165, "id2tag": 165, "is_split_into_word": [165, 187, 246], "return_offsets_map": 165, "arriv": 165, "obstacl": 165, "subtoken": [165, 279], "offset_map": 165, "cl": [165, 167, 186, 193, 246, 247, 249, 250, 251, 261, 269, 273, 275, 281, 328], "encode_tag": 165, "encoded_label": 165, "doc_label": 165, "doc_offset": 165, "doc_enc_label": 165, "arr_offset": 165, "tolist": [165, 248, 250, 327], "wnutdataset": 165, "distilbertfortokenclassif": [165, 168], "num_label": [165, 248, 253], "tfdistilbertfortokenclassif": [165, 168], "squad_v2": [165, 258], "rajpurkar": [165, 293, 357, 358], "apart": [165, 176], "read_squad": 165, "rb": 165, "squad_dict": 165, "train_context": 165, "train_quest": 165, "train_answ": 165, "val_context": 165, "val_quest": 165, "val_answ": 165, "subsequ": [165, 193, 244, 260, 370], "add_end_idx": 165, "gold_text": 165, "start_idx": 165, "answer_start": [165, 250], "end_idx": 165, "answer_end": [165, 250], "gold": [165, 184, 233, 272], "char_to_token": 165, "add_token_posit": 165, "start_posit": 165, "end_posit": 165, "model_max_length": [165, 187, 224], "inputs_dict": 165, "labels_dict": 165, "squaddataset": 165, "distilbertforquestionansw": [165, 168], "tfdistilbertforquestionansw": [165, 168], "minor": [165, 219], "lambda": 165, "ce": 165, "sparsecategoricalcrossentropi": [165, 253], "from_logit": [165, 253], "return_dict": 165, "esperanto": [165, 253], "150": [165, 250, 316], "column_nam": 165, "rename_column_": 165, "set_format": 165, "tensorshap": 165, "thorough": [165, 206], "autoencod": [167, 168, 207, 239], "mlm": [167, 192, 206, 208, 213, 221, 222, 231, 233, 236, 241, 242, 247, 256, 264, 267, 281], "clm": [167, 200, 203, 211, 212, 221, 231, 233, 236, 241, 242, 247, 256, 290], "causal": [167, 200, 203, 211, 212, 221, 231, 233, 234, 236, 241, 242, 244, 247, 282], "hide": [167, 241], "timestep": [167, 241], "corrupt": [167, 206, 239, 241, 281], "multimod": [167, 168, 268], "talk": [167, 195, 196, 285, 288], "wikipedia": [167, 192, 200, 227, 233, 237, 241, 242, 247, 258, 264, 270, 272, 281], "recurr": [167, 234, 241, 281], "attend": [167, 217, 218, 228, 234, 250], "subword": [167, 246], "punctuat": [167, 246, 248, 252], "bear": [167, 264], "underli": [167, 185, 187, 206, 249], "berttoken": [167, 168, 182, 187, 193, 245, 249, 252, 253, 279], "24gb": 167, "tokenized_sequ": 167, "wasn": 167, "hash": [167, 228, 240, 241, 273], "rust": [167, 185], "encoded_sequ": 167, "18696": [167, 246], "1942": [167, 246], "3190": [167, 246], "1144": [167, 246], "1572": [167, 246], "13745": [167, 246], "1104": [167, 246], "159": [167, 246], "9664": [167, 246], "2107": [167, 246], "decoded_sequ": 167, "sequence_a": 167, "sequence_b": 167, "encoded_sequence_a": 167, "encoded_sequence_b": 167, "padded_sequ": 167, "1188": 167, "1110": 167, "1603": 167, "4954": 167, "119": 167, "1897": 167, "1263": 167, "1135": 167, "1120": 167, "1655": 167, "2039": 167, "1190": 167, "1103": [167, 246], "nyc": 167, "encoded_dict": 167, "wherea": [167, 241], "xlnetmodel": [167, 168], "contrari": 167, "unawar": 167, "position_id": [167, 204], "max_position_embed": 167, "sinusoid": [167, 219, 224, 234], "bertforsequenceclassif": [167, 168, 182, 187, 253, 269], "bertfortokenclassif": [167, 168], "seq_length": 167, "bartforconditionalgener": [167, 168, 187, 195, 216, 219, 224, 273, 276], "mbartforconditionalgener": [167, 168, 273, 276], "tgt_seq_length": 167, "decoder_input_id": [167, 190, 193, 232], "bigger": [167, 186, 241, 328], "intermediate_s": [167, 249, 288], "mathemat": 167, "_0": 167, "_n": 167, "concat": [167, 250], "afterward": [167, 249, 286, 288], "trade": [167, 186, 238], "emploi": [167, 217, 244], "apply_chunking_to_forward": 167, "chunk_siz": 167, "interoper": [168, 250, 253], "fairseq": [168, 190, 209, 273], "rag": [168, 272], "retribert": 168, "xlmprophetnet": 168, "hood": 168, "technic": [168, 249], "byte": [168, 211, 230, 241, 249], "bpe": [168, 185, 209, 219, 230, 241, 246], "imdb": [168, 253], "nut": 168, "emerg": [168, 232, 250, 279], "bertologi": 168, "perplex": [168, 234, 256, 264, 290], "ppl": 168, "callback": [168, 186, 187], "trainercallback": 168, "trainerst": 168, "trainercontrol": 168, "moduleutilsmixin": 168, "tfpretrainedmodel": 168, "tfmodelutilsmixin": 168, "flaxpretrainedmodel": 168, "adafactor": [168, 224], "adamweightdecai": 168, "modeloutput": [168, 171], "basemodeloutput": 168, "basemodeloutputwithpool": 168, "basemodeloutputwithcrossattent": 168, "basemodeloutputwithpoolingandcrossattent": 168, "basemodeloutputwithpast": 168, "basemodeloutputwithpastandcrossattent": 168, "seq2seqmodeloutput": 168, "causallmoutput": 168, "causallmoutputwithcrossattent": 168, "causallmoutputwithpast": 168, "maskedlmoutput": 168, "seq2seqlmoutput": 168, "nextsentencepredictoroutput": 168, "sequenceclassifieroutput": 168, "seq2seqsequenceclassifieroutput": 168, "multiplechoicemodeloutput": 168, "tokenclassifieroutput": 168, "questionansweringmodeloutput": 168, "seq2seqquestionansweringmodeloutput": 168, "tfbasemodeloutput": 168, "tfbasemodeloutputwithpool": 168, "tfbasemodeloutputwithpast": 168, "tfseq2seqmodeloutput": 168, "tfcausallmoutput": 168, "tfcausallmoutputwithpast": 168, "tfmaskedlmoutput": 168, "tfseq2seqlmoutput": 168, "tfnextsentencepredictoroutput": 168, "tfsequenceclassifieroutput": 168, "tfseq2seqsequenceclassifieroutput": 168, "tfmultiplechoicemodeloutput": 168, "tftokenclassifieroutput": 168, "tfquestionansweringmodeloutput": 168, "tfseq2seqquestionansweringmodeloutput": 168, "xnli": [168, 236, 238, 242, 247, 254, 264], "pretrainedtokenizerfast": [168, 174], "batchencod": [168, 253], "seq2seqtrainingargu": 168, "extractor": 168, "pretrainedfeatureextractor": 168, "batchfeatur": 168, "albertconfig": 168, "alberttokenizerfast": 168, "albertmodel": 168, "albertforpretrain": [168, 187], "albertformaskedlm": [168, 187], "albertforsequenceclassif": 168, "albertformultiplechoic": 168, "albertfortokenclassif": 168, "albertforquestionansw": 168, "tfalbertmodel": 168, "tfalbertforpretrain": 168, "tfalbertformaskedlm": 168, "tfalbertforsequenceclassif": 168, "tfalbertformultiplechoic": 168, "tfalbertfortokenclassif": 168, "tfalbertforquestionansw": 168, "autoconfig": 168, "automodelforpretrain": 168, "automodelforcausallm": 168, "automodelformaskedlm": 168, "automodelforseq2seqlm": [168, 273], "automodelforsequenceclassif": [168, 248, 250, 275], "automodelformultiplechoic": 168, "automodelfornextsentencepredict": 168, "automodelfortokenclassif": [168, 250], "automodelforquestionansw": [168, 250], "automodelfortablequestionansw": 168, "tfautomodelforpretrain": 168, "tfautomodelforcausallm": 168, "tfautomodelformaskedlm": 168, "tfautomodelforseq2seqlm": 168, "tfautomodelforsequenceclassif": [168, 248, 250], "tfautomodelformultiplechoic": 168, "tfautomodelfortokenclassif": [168, 250], "tfautomodelforquestionansw": [168, 250], "flaxautomodel": 168, "bartconfig": 168, "barttoken": [168, 216], "barttokenizerfast": 168, "bartforsequenceclassif": 168, "bartforquestionansw": 168, "bartforcausallm": 168, "tfbartmodel": 168, "tfbartforconditionalgener": 168, "bartheztoken": 168, "bartheztokenizerfast": 168, "berttokenizerfast": 168, "bertforpretrain": [168, 187], "bertmodellmheadmodel": 168, "bertfornextsentencepredict": 168, "bertformultiplechoic": 168, "bertforquestionansw": [168, 269], "tfbertmodel": 168, "tfbertforpretrain": 168, "tfbertmodellmheadmodel": 168, "tfbertformaskedlm": 168, "tfbertfornextsentencepredict": 168, "tfbertforsequenceclassif": [168, 253], "tfbertformultiplechoic": 168, "tfbertfortokenclassif": 168, "tfbertforquestionansw": 168, "flaxbertmodel": 168, "flaxbertformaskedlm": 168, "bertweet": 168, "bertweettoken": 168, "bertgener": 168, "bertgenerationconfig": 168, "bertgenerationtoken": [168, 288], "bertgenerationencod": 168, "bertgenerationdecod": 168, "blenderbotconfig": 168, "blenderbottoken": 168, "blenderbotmodel": [168, 196], "blenderbotforconditionalgener": [168, 196], "blenderbotforcausallm": 168, "tfblenderbotmodel": 168, "tfblenderbotforconditionalgener": 168, "blenderbotsmallconfig": 168, "blenderbotsmalltoken": 168, "blenderbotsmallmodel": 168, "blenderbotsmallforconditionalgener": 168, "blenderbotsmallforcausallm": 168, "tfblenderbotsmallmodel": 168, "tfblenderbotsmallforconditionalgener": 168, "camembertconfig": 168, "camemberttoken": [168, 187], "camemberttokenizerfast": 168, "camembertmodel": 168, "camembertforcausallm": 168, "camembertformaskedlm": 168, "camembertforsequenceclassif": 168, "camembertformultiplechoic": 168, "camembertfortokenclassif": 168, "camembertforquestionansw": 168, "tfcamembertmodel": 168, "tfcamembertformaskedlm": 168, "tfcamembertforsequenceclassif": 168, "tfcamembertformultiplechoic": 168, "tfcamembertfortokenclassif": 168, "tfcamembertforquestionansw": 168, "convbertconfig": 168, "convberttoken": 168, "convberttokenizerfast": 168, "convbertmodel": 168, "convbertformaskedlm": 168, "convbertforsequenceclassif": 168, "convbertformultiplechoic": 168, "convbertfortokenclassif": 168, "convbertforquestionansw": 168, "tfconvbertmodel": 168, "tfconvbertformaskedlm": 168, "tfconvbertforsequenceclassif": 168, "tfconvbertformultiplechoic": 168, "tfconvbertfortokenclassif": 168, "tfconvbertforquestionansw": 168, "ctrlconfig": 168, "ctrltoken": 168, "ctrlmodel": 168, "ctrllmheadmodel": 168, "ctrlforsequenceclassif": 168, "tfctrlmodel": 168, "tfctrllmheadmodel": 168, "tfctrlforsequenceclassif": 168, "debertaconfig": 168, "debertatoken": 168, "debertamodel": 168, "debertapretrainedmodel": 168, "debertaformaskedlm": 168, "debertaforsequenceclassif": 168, "debertafortokenclassif": 168, "debertaforquestionansw": 168, "debertav2config": 168, "debertav2token": 168, "debertav2model": 168, "debertav2pretrainedmodel": 168, "debertav2formaskedlm": 168, "debertav2forsequenceclassif": 168, "debertav2fortokenclassif": 168, "debertav2forquestionansw": 168, "distilbertconfig": [168, 248], "distilberttoken": [168, 248, 264], "distilbertmodel": [168, 264], "distilbertformaskedlm": [168, 187], "distilbertformultiplechoic": 168, "tfdistilbertmodel": 168, "tfdistilbertformaskedlm": 168, "tfdistilbertformultiplechoic": 168, "dprconfig": 168, "dprcontextencodertoken": 168, "dprcontextencodertokenizerfast": 168, "dprquestionencodertoken": 168, "dprquestionencodertokenizerfast": 168, "dprreadertoken": 168, "dprreadertokenizerfast": 168, "dprcontextencod": 168, "dprquestionencod": 168, "dprreader": 168, "tfdprcontextencod": 168, "tfdprquestionencod": 168, "tfdprreader": 168, "electraconfig": 168, "electratoken": 168, "electratokenizerfast": 168, "electramodel": 168, "electraforpretrain": 168, "electraformaskedlm": [168, 187], "electraforsequenceclassif": 168, "electraformultiplechoic": 168, "electrafortokenclassif": 168, "electraforquestionansw": 168, "tfelectramodel": 168, "tfelectraforpretrain": 168, "tfelectraformaskedlm": 168, "tfelectraforsequenceclassif": 168, "tfelectraformultiplechoic": 168, "tfelectrafortokenclassif": 168, "tfelectraforquestionansw": 168, "encoderdecoderconfig": 168, "flaubertconfig": 168, "flauberttoken": 168, "flaubertmodel": 168, "flaubertwithlmheadmodel": 168, "flaubertforsequenceclassif": 168, "flaubertformultiplechoic": 168, "flaubertfortokenclassif": 168, "flaubertforquestionansweringsimpl": 168, "flaubertforquestionansw": 168, "tfflaubertmodel": 168, "tfflaubertwithlmheadmodel": 168, "tfflaubertforsequenceclassif": 168, "tfflaubertformultiplechoic": 168, "tfflaubertfortokenclassif": 168, "tfflaubertforquestionansweringsimpl": 168, "fsmtconfig": 168, "fsmttoken": 168, "fsmtmodel": 168, "fsmtforconditionalgener": [168, 273, 276], "funnelconfig": 168, "funneltoken": 168, "funneltokenizerfast": 168, "funnelbasemodel": 168, "funnelmodel": 168, "funnelmodelforpretrain": 168, "funnelformaskedlm": 168, "funnelforsequenceclassif": 168, "funnelformultiplechoic": 168, "funnelfortokenclassif": 168, "funnelforquestionansw": 168, "tffunnelbasemodel": 168, "tffunnelmodel": 168, "tffunnelmodelforpretrain": 168, "tffunnelformaskedlm": 168, "tffunnelforsequenceclassif": 168, "tffunnelformultiplechoic": 168, "tffunnelfortokenclassif": 168, "tffunnelforquestionansw": 168, "herbert": 168, "herberttoken": 168, "herberttokenizerfast": 168, "ibertconfig": 168, "ibertmodel": 168, "ibertformaskedlm": 168, "ibertforsequenceclassif": 168, "ibertformultiplechoic": 168, "ibertfortokenclassif": 168, "ibertforquestionansw": 168, "layoutlmconfig": 168, "layoutlmtoken": 168, "layoutlmtokenizerfast": 168, "layoutlmmodel": 168, "layoutlmformaskedlm": 168, "ledconfig": 168, "ledtoken": 168, "ledtokenizerfast": 168, "ledmodel": 168, "ledforconditionalgener": 168, "ledforsequenceclassif": 168, "ledforquestionansw": 168, "tfledmodel": 168, "tfledforconditionalgener": 168, "longformerconfig": 168, "longformertoken": 168, "longformertokenizerfast": 168, "longformermodel": [168, 216], "longformerformaskedlm": [168, 187], "longformerforsequenceclassif": 168, "longformerformultiplechoic": 168, "longformerfortokenclassif": 168, "longformerforquestionansw": 168, "tflongformermodel": 168, "tflongformerformaskedlm": 168, "tflongformerforquestionansw": 168, "tflongformerforsequenceclassif": 168, "tflongformerfortokenclassif": 168, "tflongformerformultiplechoic": 168, "lxmertconfig": 168, "lxmerttoken": 168, "lxmerttokenizerfast": 168, "lxmertmodel": 168, "lxmertforpretrain": 168, "lxmertforquestionansw": 168, "tflxmertmodel": 168, "tflxmertforpretrain": 168, "marianconfig": 168, "mariantoken": 168, "marianmodel": 168, "marianmtmodel": [168, 273, 276], "marianforcausallm": 168, "tfmarianmodel": 168, "tfmarianmtmodel": 168, "mbartconfig": 168, "mbarttoken": [168, 187], "mbarttokenizerfast": 168, "mbart50token": 168, "mbart50tokenizerfast": 168, "mbartmodel": 168, "mbartforquestionansw": 168, "mbartforsequenceclassif": 168, "mbartforcausallm": 168, "tfmbartmodel": 168, "tfmbartforconditionalgener": 168, "mobilebertconfig": 168, "mobileberttoken": 168, "mobileberttokenizerfast": 168, "mobilebertmodel": 168, "mobilebertforpretrain": 168, "mobilebertformaskedlm": [168, 187], "mobilebertfornextsentencepredict": 168, "mobilebertforsequenceclassif": 168, "mobilebertformultiplechoic": 168, "mobilebertfortokenclassif": 168, "mobilebertforquestionansw": 168, "tfmobilebertmodel": 168, "tfmobilebertforpretrain": 168, "tfmobilebertformaskedlm": 168, "tfmobilebertfornextsentencepredict": 168, "tfmobilebertforsequenceclassif": 168, "tfmobilebertformultiplechoic": 168, "tfmobilebertfortokenclassif": 168, "tfmobilebertforquestionansw": 168, "mpnetconfig": 168, "mpnettoken": 168, "mpnettokenizerfast": 168, "mpnetmodel": 168, "mpnetformaskedlm": 168, "mpnetforsequenceclassif": 168, "mpnetformultiplechoic": 168, "mpnetfortokenclassif": 168, "mpnetforquestionansw": 168, "tfmpnetmodel": 168, "tfmpnetformaskedlm": 168, "tfmpnetforsequenceclassif": 168, "tfmpnetformultiplechoic": 168, "tfmpnetfortokenclassif": 168, "tfmpnetforquestionansw": 168, "mt5config": 168, "mt5token": 168, "mt5tokenizerfast": 168, "mt5model": 168, "mt5forconditionalgener": 168, "mt5encodermodel": 168, "tfmt5model": 168, "tfmt5forconditionalgener": 168, "tfmt5encodermodel": 168, "openaigptconfig": 168, "openaigpttoken": 168, "openaigpttokenizerfast": 168, "openaigptmodel": 168, "openaigptlmheadmodel": 168, "openaigptdoubleheadsmodel": [168, 187], "openaigptforsequenceclassif": 168, "tfopenaigptmodel": 168, "tfopenaigptlmheadmodel": 168, "tfopenaigptdoubleheadsmodel": 168, "tfopenaigptforsequenceclassif": 168, "gpt2config": 168, "gpt2token": [168, 171], "gpt2tokenizerfast": [168, 244], "gpt2model": [168, 264], "gpt2lmheadmodel": [168, 171, 244], "gpt2doubleheadsmodel": [168, 187], "gpt2forsequenceclassif": 168, "tfgpt2model": 168, "tfgpt2lmheadmodel": 168, "tfgpt2doubleheadsmodel": 168, "tfgpt2forsequenceclassif": 168, "tfsequenceclassifieroutputwithpast": 168, "pegasusconfig": 168, "pegasustoken": [168, 187], "pegasustokenizerfast": 168, "pegasusmodel": 168, "pegasusforconditionalgener": [168, 273, 276], "pegasusforcausallm": 168, "tfpegasusmodel": 168, "tfpegasusforconditionalgener": 168, "phobert": 168, "phoberttoken": 168, "prophetnetconfig": 168, "prophetnettoken": 168, "prophetnetmodel": 168, "prophetnetencod": 168, "prophetnetdecod": 168, "prophetnetforconditionalgener": 168, "prophetnetforcausallm": 168, "ragconfig": 168, "ragtoken": 168, "ragretriev": 168, "ragmodel": 168, "ragsequenceforgener": [168, 272], "ragtokenforgener": [168, 272], "axial": [168, 241], "lsh": [168, 241], "reformerconfig": 168, "reformertoken": [168, 187], "reformertokenizerfast": 168, "reformermodel": 168, "reformermodelwithlmhead": 168, "reformerformaskedlm": 168, "reformerforsequenceclassif": 168, "reformerforquestionansw": 168, "retribertconfig": 168, "retriberttoken": 168, "retriberttokenizerfast": 168, "retribertmodel": 168, "robertaconfig": 168, "robertatoken": 168, "robertatokenizerfast": 168, "robertamodel": [168, 213, 264], "robertaforcausallm": 168, "robertaformaskedlm": [168, 187, 217], "robertaforsequenceclassif": 168, "robertaformultiplechoic": 168, "robertafortokenclassif": 168, "robertaforquestionansw": 168, "tfrobertamodel": 168, "tfrobertaformaskedlm": 168, "tfrobertaforsequenceclassif": 168, "tfrobertaformultiplechoic": 168, "tfrobertafortokenclassif": 168, "tfrobertaforquestionansw": 168, "flaxrobertamodel": 168, "squeezebertconfig": 168, "squeezeberttoken": 168, "squeezeberttokenizerfast": 168, "squeezebertmodel": 168, "squeezebertformaskedlm": 168, "squeezebertforsequenceclassif": 168, "squeezebertformultiplechoic": 168, "squeezebertfortokenclassif": 168, "squeezebertforquestionansw": 168, "t5config": 168, "t5token": [168, 187, 223], "t5tokenizerfast": [168, 223], "t5forconditionalgener": [168, 187, 273, 276], "t5encodermodel": 168, "tft5model": 168, "tft5forconditionalgener": 168, "tft5encodermodel": 168, "tapasconfig": 168, "tapastoken": [168, 281], "tapasmodel": [168, 281], "tapasformaskedlm": 168, "transfoxlconfig": 168, "transfoxltoken": 168, "transfoxl": 168, "transfoxlmodel": 168, "transfoxllmheadmodel": 168, "transfoxlforsequenceclassif": 168, "tftransfoxlmodel": 168, "tftransfoxllmheadmodel": 168, "tftransfoxlforsequenceclassif": 168, "wav2vec2config": 168, "wav2vec2ctctoken": 168, "wav2vec2featureextractor": 168, "wav2vec2processor": 168, "wav2vec2model": 168, "wav2vec2forctc": 168, "xlmconfig": 168, "xlmtoken": [168, 209, 242], "xlmmodel": 168, "xlmwithlmheadmodel": [168, 242], "xlmforsequenceclassif": 168, "xlmformultiplechoic": 168, "xlmfortokenclassif": 168, "xlmforquestionansweringsimpl": 168, "xlmforquestionansw": 168, "tfxlmmodel": 168, "tfxlmwithlmheadmodel": 168, "tfxlmforsequenceclassif": 168, "tfxlmformultiplechoic": 168, "tfxlmfortokenclassif": 168, "tfxlmforquestionansweringsimpl": 168, "xlmprophetnetconfig": 168, "xlmprophetnettoken": 168, "xlmprophetnetmodel": 168, "xlmprophetnetencod": 168, "xlmprophetnetdecod": 168, "xlmprophetnetforconditionalgener": 168, "xlmprophetnetforcausallm": 168, "xlmrobertaconfig": 168, "xlmrobertatoken": [168, 187], "xlmrobertatokenizerfast": 168, "xlmrobertamodel": 168, "xlmrobertaforcausallm": 168, "xlmrobertaformaskedlm": 168, "xlmrobertaforsequenceclassif": 168, "xlmrobertaformultiplechoic": 168, "xlmrobertafortokenclassif": 168, "xlmrobertaforquestionansw": 168, "tfxlmrobertamodel": 168, "tfxlmrobertaformaskedlm": 168, "tfxlmrobertaforsequenceclassif": 168, "tfxlmrobertaformultiplechoic": 168, "tfxlmrobertafortokenclassif": 168, "tfxlmrobertaforquestionansw": 168, "xlnetconfig": 168, "xlnettoken": [168, 187, 252], "xlnettokenizerfast": 168, "xlnetlmheadmodel": 168, "xlnetforsequenceclassif": 168, "xlnetformultiplechoic": 168, "xlnetfortokenclassif": 168, "xlnetforquestionansweringsimpl": 168, "xlnetforquestionansw": 168, "tfxlnetmodel": 168, "tfxlnetlmheadmodel": 168, "tfxlnetforsequenceclassif": 168, "tflnetformultiplechoic": 168, "tfxlnetfortokenclassif": 168, "tfxlnetforquestionansweringsimpl": 168, "pretrainedtokenizerbas": [168, 185], "specialtokensmixin": [168, 185], "enum": [168, 387], "namedtupl": 168, "logitsprocessor": 168, "beamsearch": 168, "9998704791069031": 169, "stuff": [169, 187], "hasn": [169, 233], "sooner": 169, "hate": [169, 248, 250], "constantli": 169, "magic": [169, 186, 248, 250], "anaconda3": [169, 320], "lib": [169, 317, 325, 371], "resid": [169, 186, 250, 251], "saw": [169, 246, 248, 252, 320], "cache_dir": [169, 308, 309, 311, 312], "transformers_cach": 169, "prioriti": [169, 186, 295, 305], "hf_home": 169, "xdg_cache_hom": 169, "predecessor": 169, "pytorch_transformers_cach": 169, "pytorch_pretrained_bert_cach": 169, "swift": 169, "coreml": 169, "distilgpt": [169, 212], "prototyp": [169, 250], "greedy_search": 171, "beam_search": 171, "beam_sampl": 171, "group_beam_search": 171, "dog": [171, 182, 232, 241, 264, 271], "cute": [171, 182, 232, 241, 264], "generation_output": 171, "return_dict_in_gener": 171, "output_scor": 171, "greedysearchdecoderonlyoutput": 171, "hidden_st": [171, 182], "output_hidden_st": [171, 182, 248], "output_attent": [171, 182, 187, 248], "mixin": 174, "defaultflowcallback": 176, "printercallback": 176, "progresscallback": 176, "deactiv": [176, 246], "tensorboardcallback": [176, 187], "tensorboardx": 176, "wandbcallback": 176, "cometcallback": 176, "comet_ml": [176, 254], "mlflowcallback": 176, "mlflow": 176, "azuremlcallback": 176, "azureml": 176, "sdk": 176, "s3": [177, 180, 185, 297], "charg": [178, 185, 250], "audio": [178, 235, 335], "mel": 178, "spectrogram": 178, "verbos": [179, 246, 251, 351], "set_verbosity_info": [179, 251], "transformers_verbos": [179, 251], "myprogram": 179, "get_verbos": 179, "set_verbos": 179, "parenthesi": 179, "fatal": 179, "among": [180, 188, 201, 202, 222, 233, 241, 244, 252, 378], "tfmoduleutilsmixin": 180, "generationmixin": 180, "tfgenerationmixin": 180, "_lrschedul": 181, "accumul": [181, 253, 273], "dedic": [183, 186, 249, 251, 362, 363], "tradit": [184, 205, 210, 214, 216, 226, 237, 241, 247, 281, 371], "dataprocessor": 184, "inputexampl": [184, 279], "inputfeatur": 184, "mrpcprocessor": 184, "mnliprocessor": 184, "mnlimismatchedprocessor": 184, "sst2processor": 184, "stsbprocessor": 184, "qqpprocessor": 184, "qnliprocessor": 184, "rteprocessor": 184, "wnliprocessor": 184, "nli": [184, 260, 275], "crowd": [184, 277], "multinli": [184, 192, 277], "nyu": 184, "bowman": 184, "textual": [184, 211, 213, 277], "swahili": [184, 238, 277], "xnliprocessor": 184, "run_xnli": [184, 250, 277], "unanswer": 184, "squadv1processor": 184, "squadv2processor": 184, "squadprocessor": 184, "squadfeatur": 184, "aforement": [184, 186, 319], "tensorflow_dataset": [184, 253], "get_dev_exampl": 184, "squad_v2_data_dir": 184, "squad_v1_data_dir": 184, "squad_convert_examples_to_featur": 184, "is_train": [184, 315], "tfds_exampl": 184, "tfd": [184, 253], "get_examples_from_dataset": 184, "run_squad": [184, 250, 258], "xlmroberta": 185, "encode_plu": 185, "batch_encode_plu": 185, "behav": [185, 187, 248, 286], "mixed_precis": 186, "inject": 186, "get_train_dataload": [186, 298, 308, 313], "get_train_tfdataset": 186, "get_eval_dataload": [186, 290, 296, 309, 310, 311], "get_eval_tfdataset": 186, "get_test_dataload": 186, "get_test_tfdataset": 186, "create_optimizer_and_schedul": 186, "training_step": [186, 187], "prediction_step": 186, "run_model": [186, 187], "mytrain": 186, "my_custom_loss": 186, "dramat": 186, "trillion": 186, "samyam": 186, "rajbhandari": 186, "jeff": 186, "raslei": 186, "olatunji": 186, "ruwas": 186, "yuxiong": 186, "dealt": [186, 252], "unix": 186, "ld_library_path": 186, "whatev": [186, 251, 253], "despit": [186, 198, 215, 251, 275], "lib64": 186, "prepend": [186, 219, 232, 253, 272], "libcudart": 186, "realiti": [186, 275], "refus": 186, "gcc": [186, 317, 320, 323, 334], "complain": 186, "ln": [186, 315, 319, 321], "symlink": [186, 319, 377, 381], "succe": [186, 251], "unsuccess": 186, "shard": 186, "offload": 186, "number_of_gpus_you_hav": 186, "haven": [186, 332], "run_seq2seq": [186, 250, 276], "max_train_sampl": [186, 276], "wmt16": [186, 276], "dataset_config": [186, 270, 276], "translation_en_to_ro": [186, 276], "source_prefix": [186, 276], "romanian": [186, 220, 236, 241, 242, 247, 274, 276], "larger": [186, 196, 204, 206, 230, 241, 244, 251, 258, 273, 319], "zero_dp_2": 186, "zero_dp_3": 186, "cpu_offload": 186, "caveat": 186, "predict_with_gener": [186, 276], "fullyshardeddataparallel": 186, "billion": [186, 200, 212, 231, 234], "ds_config": 186, "your_program": 186, "everywher": [186, 276], "deepspeed_config": 186, "sake": [186, 275], "deleg": 186, "smart": 186, "zero_optim": 186, "allgather_partit": 186, "allgather_bucket_s": 186, "2e8": 186, "reduce_scatt": 186, "reduce_bucket_s": 186, "overlap_comm": 186, "contiguous_gradi": 186, "buffer": [186, 251], "localhost": [186, 328, 387, 388], "master_addr": [186, 264, 292, 301], "9994": 186, "runtimeerror": 186, "world_siz": [186, 264], "eot": 186, "loss_scal": 186, "loss_scale_window": 186, "hysteresi": 186, "min_loss_scal": 186, "zero_allow_untested_optim": 186, "beta": 186, "warmuplr": 186, "warmup_min_lr": 186, "warmup_max_lr": 186, "warmup_num_step": 186, "steps_per_print": 186, "wall_clock_breakdown": 186, "deepspeedexampl": 186, "lamb": 186, "5e8": 186, "adam_beta1": 186, "adam_beta2": 186, "adam_epsilon": 186, "lr_scheduler_typ": [186, 305], "constant_with_warmup": 186, "fp16_backend": 186, "chose": [186, 252], "shouldn": 186, "train_micro_batch_size_per_gpu": 186, "9gb": 186, "2byte": 186, "8gb": 186, "oom": [186, 272], "6gb": 186, "exclus": [186, 215], "onebitadam": 186, "thoroughli": 186, "isn": [186, 233], "lrrangetest": 186, "onecycl": 186, "warmupdecaylr": 186, "total_num_step": 186, "max_step": 186, "fp16_opt_level": [186, 273], "opt_level": 186, "o1": [186, 273], "subtl": 186, "gradient_clip": 186, "roughli": [187, 273, 319], "grouped_ent": 187, "use_fast": [187, 194], "lift": 187, "forese": 187, "harder": [187, 188, 252, 273], "intermediari": 187, "modeling_bert": 187, "bertlay": 187, "unpack": [187, 248, 303], "value0": 187, "value1": 187, "8604": 187, "lm_label": 187, "decoder_cached_st": 187, "past_key_valu": 187, "decoder_past_key_valu": 187, "max_len": [187, 273], "return_length": 187, "is_pretoken": 187, "tb_writer": 187, "prediction_loss_onli": 187, "data_col": [187, 253, 296, 308, 309, 311], "_log": 187, "_training_step": 187, "_prediction_loop": 187, "prediction_loop": 187, "is_local_mast": 187, "is_local_process_zero": 187, "is_world_mast": 187, "is_world_process_zero": 187, "_setup_wandb": 187, "setup_wandb": 187, "_run_model": 187, "trainerargu": 187, "evaluate_during_train": [187, 261], "evaluation_strategi": [187, 277, 312], "tie_weight": 187, "tie_words_embed": 187, "reset_length": 187, "reset_memory_length": 187, "fillmaskpipelin": 187, "top_k": [187, 250], "1010": 187, "1204": 187, "1195": 187, "inputs_id": 187, "ii": [187, 250], "save_directori": [187, 248], "add_token": [187, 224], "special_token_1": 187, "special_token_2": 187, "resize_token_embed": 187, "my_saved_model_directori": 187, "num_training_step": 187, "num_warmup_step": [187, 253, 294, 295, 304], "warmup_proport": 187, "warmup_linear": 187, "train_data": 187, "correct_bia": 187, "get_linear_schedule_with_warmup": [187, 253], "matric": [188, 201, 202, 217, 228, 241], "inter": [188, 251, 359, 361], "establish": [188, 205], "fewer": [188, 199, 210, 241, 249, 319], "guess": [189, 241], "disclaim": [190, 195, 209, 217, 220, 224, 226, 228, 232, 237, 281], "strang": [190, 195, 209, 217, 219, 220, 224, 226, 228, 232, 237, 279], "patrickvonplaten": [190, 219, 220, 224, 226, 237, 270, 272], "particularli": [190, 191, 206, 238, 246, 250, 275], "dialogu": [190, 195, 196, 203], "roug": [190, 224, 273, 274, 298, 313], "forum": [190, 273], "force_bos_token_to_be_gener": 190, "mask_token_id": [190, 250], "tok": [190, 273], "example_english_phras": [190, 220], "un": [190, 219, 220, 252], "chief": [190, 220], "syria": [190, 220], "generated_id": 190, "batch_decod": [190, 195, 220, 224], "skip_special_token": [190, 219, 220, 224, 250], "chemic": 190, "weapon": 190, "2010": [191, 250, 273, 281, 302], "12321": 191, "induct": [191, 204], "storm": 191, "countless": 191, "monolingu": [191, 220, 225, 236, 238, 247], "perturb": 191, "flue": [191, 208], "orangesum": 191, "mbarthez": [191, 247], "unlabel": [192, 208, 210, 211, 232, 235, 275], "jointli": [192, 215, 227, 235, 241, 281], "conceptu": [192, 235], "eleven": 192, "nsp": [192, 241], "revolution": 193, "efficaci": 193, "bert2bert": 193, "bo": [193, 220, 250], "eo": [193, 220, 232, 250], "bos_token_id": 193, "eos_token_id": [193, 220], "add_cross_attent": 193, "is_decod": 193, "add_special_token": [193, 246, 250], "sentence_fus": 193, "roberta2roberta_l": 193, "24_discofus": 193, "encoderdecod": 193, "dat": [194, 225], "nguyen": [194, 225], "thanh": 194, "vu": 194, "anh": [194, 225], "tuan": [194, 225], "et": [194, 197, 208, 225, 230, 241, 250, 252, 258, 260, 314], "strong": [194, 203, 205, 206, 218, 226, 233, 237, 238, 241, 242, 245, 250], "vinai": [194, 225], "sc": [194, 219], "presumpt": 194, "coronaviru": 194, "dhec": 194, "httpurl": 194, "cry": 194, "blender": [195, 196], "ingredi": [195, 196, 362], "expert": [195, 196], "conversationalist": [195, 196], "engag": [195, 196], "persona": [195, 196], "90m": [195, 196, 247], "7b": [195, 196], "4b": [195, 196], "human": [195, 196, 202, 203, 209, 224, 231, 272, 281], "engaging": [195, 196], "blenderbot_small_90m": 195, "mname": 195, "400m": [195, 224, 247], "utter": 195, "cool": [195, 248], "eat": 195, "carb": 195, "reply_id": 195, "lose": [195, 250, 252, 261], "healthier": 195, "breakthrough": 197, "parametr": [197, 227], "9x": 197, "agora": 197, "sadli": 197, "138gb": 198, "ubiquit": 198, "concaten": [198, 203, 232, 241, 247, 252, 256, 264, 330], "hope": [198, 248], "impress": [199, 241, 250], "equip": [199, 221, 241], "remark": [199, 241, 318], "convbertbas": [199, 241], "electrabas": [199, 241], "yitu": 199, "opensourc": 199, "unidirect": [200, 211, 212], "govern": [200, 248], "syntact": [200, 211, 212, 281], "run_gener": [200, 211, 212, 239, 242, 278], "reus": [200, 212, 228, 234, 245, 249, 288, 295, 305, 308, 309, 311, 312], "5b": [202, 247], "superglu": [202, 241], "submiss": [202, 209, 251], "surpass": 202, "128k": 202, "ngie": 202, "induc": [202, 269], "asid": 202, "postion": 202, "900m": [202, 247], "147m": [203, 247], "exchang": [203, 216, 247, 249], "reddit": [203, 241, 247], "tunabl": 203, "chain": 203, "2005": [203, 269, 272], "attain": [203, 223, 252], "facilit": [203, 232, 263, 370], "intellig": 203, "chat": 203, "bot": [203, 379, 382], "multiturn": 203, "frame": 203, "x_1": [203, 244], "x_n": 203, "cheap": [204, 264], "preval": 204, "budget": 204, "counterpart": [204, 249], "retain": [204, 269, 275], "cosin": [204, 228, 241], "sep_token": [204, 217, 222, 230], "though": [204, 241, 249, 250, 264, 269, 328], "candid": [205, 252, 275], "idf": 205, "bm25": 205, "facto": 205, "alon": [205, 228, 235, 252], "dual": 205, "lucen": 205, "plausibl": [206, 281], "mirella": [207, 262], "lapata": [207, 262], "nowadai": 208, "2015": [208, 252], "howard": 208, "ruder": 208, "2019b": 208, "jean": 208, "zai": 208, "supercomput": 208, "paraphras": [208, 250], "disambigu": 208, "protocol": 208, "stas00": [209, 273], "machinetransl": 209, "ng": [209, 387], "kyra": 209, "yee": 209, "russian": [209, 250], "bitext": 209, "rerank": 209, "campaign": 209, "upon": [209, 211, 245, 251], "wmt": [209, 236, 247, 250, 254, 274, 290, 313, 361], "exploit": 210, "abund": [210, 211], "overlook": [210, 230], "invest": 210, "quarter": 210, "upsampl": [210, 241], "funnelforpretrain": 210, "assess": 211, "corpora": [211, 213, 220, 222, 252], "scarc": 211, "adequ": 211, "craft": 211, "webapp": [211, 212], "ftfy": [211, 252], "spaci": [211, 252], "basictoken": 211, "million": [212, 221, 233, 247, 250, 281, 365], "medium": [212, 246, 247], "klej": 213, "polish": 213, "piotr": 213, "rybak": 213, "mroczkowski": 213, "janusz": 213, "tracz": 213, "ireneusz": 213, "gawlik": 213, "unlock": 213, "pace": 213, "allevi": [213, 233, 241], "leaderboard": 213, "adopt": [213, 222, 231, 331, 370], "commerc": 213, "allegro": 213, "promot": 213, "nine": [213, 250, 303], "encoded_input": [213, 246, 281], "kto": 213, "lepsz\u0105": 213, "sztuk\u0119": 213, "lepszi": 213, "rz\u0105d": 213, "jasn": 213, "sehoon": 214, "kim": 214, "amir": 214, "gholami": 214, "zhewei": 214, "mahonei": 214, "prohibit": [214, 228], "viabl": 214, "lightweight": [214, 253, 276], "gelu": 214, "preliminari": 214, "0x": 214, "t4": 214, "receipt": 215, "199": [215, 260], "sroie": 215, "626": 215, "widespread": 215, "manipul": [215, 227, 251], "neglect": [215, 222, 239], "vital": 215, "ocr": 215, "tesseract": 215, "x0": 215, "y0": 215, "y1": [215, 316, 319], "normalize_bbox": 215, "name_of_your_docu": 215, "unabl": [216, 217], "quadrat": [216, 217], "linearli": [216, 217, 253, 275], "text8": [216, 217, 234], "enwik8": [216, 217, 247], "wikihop": [216, 217], "alia": [216, 273, 375], "1024": [216, 242, 244, 247, 288, 357, 358, 371], "attention_window": [216, 217], "pad_to_multiple_of": 216, "global_attention_mask": [216, 217], "16384": [216, 247], "gradient_checkpoint": 216, "frac": [217, 228, 244], "succed": 217, "convention": 217, "bertselfattent": 217, "bottleneck": [217, 221, 228, 241], "mathcal": [217, 228, 252], "n_": [217, 228], "insignific": 217, "mlm_label": 217, "roi": 218, "mscoco": 218, "genom": 218, "vqa": [218, 247], "gqa": [218, 247], "relationship": [218, 244, 247], "endow": 218, "intra": [218, 359, 361], "generaliz": 218, "nlvr": 218, "prove": 218, "spacial": 218, "static_position_embed": 219, "layernorm_embed": 219, "normalize_embed": 219, "pad_token_id": [219, 224], "token_embed": [219, 224], "bulk": 219, "convert_marian_to_pytorch": 219, "tgt": [219, 247], "inconsist": [219, 320], "es_ar": 219, "code_": 219, "region": 219, "spanish": [219, 248, 264], "argentina": 219, "iso": [219, 283], "src_text": [219, 220, 224], "constitu": [219, 260], "roa": 219, "tatoeba": [219, 283], "fra": 219, "por": 219, "portugues": 219, "esp": 219, "supported_language_cod": 219, "zlm_latn": 219, "mfe": 219, "pap": 219, "ast": 219, "ind": 219, "glg": 219, "wln": 219, "spa": 219, "ron": 219, "ita": 219, "oci": 219, "est": 219, "phrase": 219, "anglai": 219, "que": 219, "nou": 219, "voulon": 219, "traduir": 219, "fran\u00e7ai": 219, "isto": 219, "deve": 219, "ir": [219, 249, 281], "para": 219, "portugu\u00ea": 219, "esto": 219, "espa\u00f1ol": 219, "hf_api": 219, "hfapi": 219, "model_list": 219, "modelid": 219, "startswith": 219, "old_style_multi_model": 219, "north_eu": 219, "romanc": 219, "scandinavia": 219, "zh": 219, "celtic": 219, "norwai": 219, "fi": 219, "fi_nb_no_nn_ru_sv_en": 219, "sami": 219, "group_memb": 219, "cmn": 219, "cn": 219, "ze_zh": 219, "zh_cn": 219, "zh_hk": 219, "zh_tw": 219, "zh_yue": 219, "zht": 219, "fr_be": 219, "fr_ca": 219, "fr_fr": 219, "frp": 219, "ca": 219, "rm": [219, 251, 314, 320], "lld": 219, "fur": 219, "lij": 219, "lmo": 219, "es_cl": 219, "es_co": 219, "es_cr": 219, "es_do": 219, "es_ec": 219, "es_": 219, "es_gt": 219, "es_hn": 219, "es_mx": 219, "es_ni": 219, "es_pa": 219, "es_p": 219, "es_pr": 219, "es_sv": 219, "es_ui": 219, "es_v": 219, "pt_br": 219, "pt_pt": 219, "gl": 219, "lad": 219, "mwl": 219, "it_it": 219, "nap": 219, "scn": 219, "vec": 219, "nl": 219, "fy": 219, "af": 219, "fo": 219, "nb": 219, "sma": 219, "smj": 219, "smn": 219, "sm": 219, "nb_no": 219, "nn_no": 219, "nog": 219, "no_nb": 219, "ga": 219, "cy": 219, "br": 219, "gd": 219, "gv": 219, "src_lang_cod": 220, "tgt_lang_cod": 220, "as_target_token": 220, "militari": [220, 271], "expected_translation_romanian": 220, "\u015feful": 220, "onu": 220, "declar\u0103": 220, "c\u0103": 220, "nu": 220, "exist\u0103": 220, "solu\u0163i": 220, "militar\u0103": 220, "\u00een": 220, "siria": 220, "decoder_start_token_id": 220, "translated_token": 220, "lang_code_to_id": 220, "2008": 220, "00401": 220, "cc25": [220, 241, 247, 273], "extended": 220, "strongest": 220, "bilingu": 220, "lang_cod": 220, "tgt_text": [220, 224], "model_input": 220, "forced_bos_token_id": 220, "arab": [220, 264], "article_hi": 220, "\u0938": 220, "\u092f": 220, "\u0915": 220, "\u0924": 220, "\u0930": 220, "\u0937": 220, "\u091f": 220, "\u092a": 220, "\u0930\u092e": 220, "\u0916": 220, "\u0915\u0939\u0928": 220, "\u0939": 220, "\u092e": 220, "\u0908": 220, "\u0928": 220, "\u0938\u092e": 220, "\u0927": 220, "\u0928\u0939": 220, "article_ar": 220, "\u0627\u0644\u0623\u0645\u064a\u0646": 220, "\u0627\u0644\u0639\u0627\u0645": 220, "\u0644\u0644\u0623\u0645\u0645": 220, "\u0627\u0644\u0645\u062a\u062d\u062f\u0629": 220, "\u064a\u0642\u0648\u0644": 220, "\u0625\u0646\u0647": 220, "\u0644\u0627": 220, "\u064a\u0648\u062c\u062f": 220, "\u062d\u0644": 220, "\u0639\u0633\u0643\u0631\u064a": 220, "\u0641\u064a": 220, "\u0633\u0648\u0631\u064a\u0627": 220, "mmt": [220, 247], "hi_in": 220, "encoded_hi": 220, "generated_token": 220, "fr_xx": 220, "chef": 220, "affirm": 220, "qu": 220, "il": 220, "pa": 220, "militair": 220, "ar_ar": 220, "encoded_ar": 220, "secretari": 220, "zhiqe": 221, "hongkun": 221, "xiaodan": 221, "renji": 221, "denni": 221, "thin": 221, "bert_larg": 221, "bert_bas": 221, "competit": [221, 231, 238], "gluescor": 221, "phone": 221, "plm": [222, 256], "discrep": [222, 239], "auxiliari": 222, "160gb": [222, 226, 237], "margin": [222, 227, 239, 241], "crawl": [223, 232, 233, 247], "intention": [224, 240, 241], "whenc": 224, "568m": [224, 247], "replic": [224, 230, 273], "finetune_pegasus_xsum": [224, 273], "num_beam": [224, 250, 273, 298, 313], "max_length": [224, 233, 244, 246, 248, 250, 253, 262, 279, 298, 302, 304, 305, 313], "length_penalti": [224, 250, 273], "convert_pegasus_tf_to_pytorch": 224, "pg": 224, "blackout": 224, "forecast": 224, "wind": 224, "amid": 224, "dry": 224, "risk": 224, "wildfir": 224, "shutoff": 224, "middai": 224, "tomorrow": 224, "torch_devic": [224, 251], "california": 224, "electr": 224, "vietnames": 225, "BE": 225, "t\u00f4i": 225, "l\u00e0": 225, "sinh_vi\u00ean": 225, "tr\u01b0\u1eddng": 225, "\u0111\u1ea1i_h\u1ecdc": 225, "c\u00f4ng_ngh\u1ec7": 225, "ahead": [226, 237], "correl": [226, 237, 241], "16gb": [226, 237, 258, 273, 277], "gigaword": [226, 237], "ethan": [227, 241], "perez": [227, 241], "aleksandara": [227, 241], "piktu": [227, 241], "fabio": [227, 241], "petroni": [227, 241], "heinrich": [227, 241], "k\u00fcttler": [227, 241], "rockt\u00e4schel": [227, 241], "riedel": [227, 241], "douw": [227, 241], "kiela": [227, 241], "factual": 227, "lag": 227, "behind": [227, 248], "proven": 227, "nonparametr": 227, "overcom": [227, 239, 296, 309, 311], "routin": 228, "llog": 228, "trax": 228, "ldot": 228, "max_embedding_s": 228, "x_": [228, 244, 249, 252], "500m": 228, "mod": [228, 384], "ge": [228, 261], "lfloor": 228, "rfloor": 228, "x_j": 228, "mathbb": 228, "1_": 228, "2_": 228, "49000": 228, "axial_pos_embds_dim": 228, "axial_pos_shap": 228, "angular": [228, 387], "num_bucket": 228, "premis": 228, "num_hash": 228, "lsh_chunk_length": 228, "themselv": [228, 233], "lsh_num_chunks_befor": 228, "neighbor": 228, "lsh_num_chunks_aft": 228, "local_chunk_length": 228, "local_num_chunks_befor": 228, "local_num_chunks_aft": 228, "64000": 228, "computation": [230, 231], "undertrain": 230, "ffn": 231, "proofread": 231, "opportun": 231, "myriad": 231, "busi": [231, 275], "smartphon": [231, 247], "todai": [231, 250, 252], "headless": [231, 247, 378], "rich": 232, "rise": 232, "methodologi": [232, 250], "landscap": 232, "systemat": 232, "coloss": [232, 247], "mixtur": [232, 250, 288], "appendix": 232, "sentinel": [232, 241], "extra_id_0": 232, "extra_id_1": 232, "extra_id_99": 232, "walk": [232, 254], "park": 232, "extra_id_2": 232, "hous": 232, "wonder": [232, 276], "hau": 232, "ist": [232, 250], "wunderbar": 232, "slight": [233, 241, 308], "tabular": 233, "wtq": 233, "wikisql": 233, "simpler": [233, 235], "weak": 233, "denot": 233, "parser": 233, "pose": 233, "joint": [233, 249, 250], "rival": 233, "wikitq": 233, "trivial": [233, 251, 275], "16k": [233, 275], "syrin": [233, 281], "krichen": [233, 281], "restart": 233, "reset_position_index_per_cel": 233, "no_reset": 233, "prev_label": 233, "actor": [233, 281], "cristiano": 233, "ronaldo": 233, "career": 233, "scatter": [233, 272], "necessarili": 233, "num_aggregation_label": 233, "average_logits_per_cel": 233, "select_one_column": 233, "brittl": 233, "bookkeep": 233, "table_fil": 233, "answer_coordin": 233, "answer_text": 233, "aggregation_label": 233, "float_answ": 233, "interestingli": 233, "perfect": 233, "numeric_valu": 233, "numeric_values_scal": 233, "panda": [233, 281, 283], "pd": [233, 281], "brad": [233, 281], "pitt": [233, 281], "leonardo": [233, 281], "di": [233, 271, 281], "caprio": [233, 281], "georg": [233, 281], "cloonei": [233, 281], "209": 233, "datafram": [233, 281], "from_dict": [233, 281], "tsv_path": 233, "your_path_to_the_tsv_fil": 233, "table_csv_path": 233, "your_path_to_a_directory_containing_all_csv_fil": 233, "tabledataset": 233, "iloc": 233, "read_csv": 233, "use_answer_as_supervis": 233, "answer_loss_cutoff": 233, "664694": 233, "cell_selection_prefer": 233, "207951": 233, "huber_loss_delta": 233, "121194": 233, "init_cell_selection_weights_to_zero": 233, "allow_empty_column_select": 233, "0352513": 233, "handi": [233, 251], "convert_logits_to_predict": 233, "predicted_answer_coordin": 233, "predicted_aggregation_indic": 233, "detach": [233, 330], "logits_aggreg": 233, "id2aggreg": 233, "aggregation_predictions_str": 233, "iat": 233, "cell_valu": 233, "predicted_agg": 233, "uni": 234, "sinuso\u00efd": 234, "disrupt": 234, "tempor": [234, 235], "bpc": [234, 244], "enwiki8": 234, "penn": 234, "treebank": [234, 359], "transcrib": 235, "semi": 235, "latent": 235, "librispeech": [235, 334, 335], "wer": 235, "ten": 235, "53k": 235, "feasibl": 235, "waveform": 235, "connectionist": 235, "ctc": 235, "tlm": [236, 241, 242, 247], "suitabl": [236, 290, 296, 298, 308, 309, 310, 311, 313], "lang": [236, 238, 242], "prohpetnet": 237, "wiki100": 237, "5tb": [238, 242], "commoncrawl": [238, 242, 247], "terabyt": [238, 329, 330, 333], "dub": 238, "mbert": [238, 242, 264, 277], "mlqa": 238, "ner": [238, 246, 248, 250, 254, 264, 282], "urdu": [238, 264], "dilut": 238, "ri": 238, "likelihood": [239, 244, 252, 256, 275], "con": 239, "perm_mask": 239, "target_map": 239, "paradigm": 240, "pin": [240, 267, 377, 381], "esperberto": 240, "live": 240, "credenti": 240, "usernam": [240, 280], "decent": [240, 249, 264], "change_config": 240, "pariti": 240, "tf_model": [240, 248], "from_pt": [240, 248], "pt_model": [240, 248], "from_tf": [240, 248, 253], "garbag": 240, "special_tokens_map": [240, 273], "tokenizer_config": [240, 273], "added_token": 240, "save_model": 240, "ethic": 240, "consider": [240, 244, 269, 275, 277], "meta": 240, "model_card": 240, "namespac": [240, 280], "password": [240, 317], "profil": 240, "gentl": 241, "fall": 241, "webtext": [241, 264], "outgo": 241, "karma": [241, 387], "pai": [241, 246, 306], "subtract": 241, "recomput": 241, "feedforward": 241, "percentag": [241, 323, 334, 388], "justifi": 241, "subunit": 241, "unicod": [241, 252], "fool": 241, "preselect": 241, "rotat": 241, "forabstract": 241, "gsg": 241, "marcin": 241, "junczi": 241, "dowmunt": 241, "forth": 241, "delimit": 241, "xglue": 241, "headlin": 241, "bitransform": 241, "qk": 241, "n_round": 241, "e1": 241, "e2": [241, 272, 387], "l_": 241, "d_": 241, "l1": [241, 269, 314], "mono": 242, "enfr": [242, 247], "enro": [242, 247], "xnli15": [242, 247], "lang2id": 242, "id2lang": 242, "language_id": 242, "reshap": [242, 326], "104": [242, 247, 264], "exponenti": 244, "x_0": 244, "x_t": 244, "exp": [244, 290, 295, 305], "sum_i": 244, "p_": 244, "theta": 244, "x_i": 244, "ith": 244, "preced": [244, 286], "thought": 244, "uniformli": 244, "fantast": 244, "weren": 244, "greater": [244, 252], "broken": 244, "tempt": 244, "suboptim": [244, 252], "disjoint": 244, "serv": [244, 245, 272, 275, 387], "slide": [244, 269], "repeatedli": 244, "closer": [244, 252, 285, 288], "decomposit": 244, "downsid": 244, "compromis": 244, "overlap": [244, 250], "n_posit": 244, "begin_loc": 244, "end_loc": 244, "trg_len": 244, "target_id": 244, "log_likelihood": 244, "jump": [244, 251], "seek": 245, "vice": [245, 253], "versa": [245, 253], "batch_sent": 246, "8667": 246, "146": 246, "1423": 246, "5650": 246, "1262": 246, "1304": 246, "1314": 246, "1141": 246, "1731": 246, "1385": 246, "1132": 246, "1128": 246, "1201": [246, 334], "return_input_id": 246, "return_token_type_id": 246, "batch_of_second_sent": 246, "1115": 246, "2947": 246, "1114": 246, "1148": 246, "1431": 246, "1129": 246, "12544": 246, "1248": 246, "1301": 246, "boolean": 246, "do_not_pad": 246, "only_first": 246, "only_second": 246, "longest_first": 246, "do_not_trunc": 246, "wouldn": [246, 272], "110m": 247, "336m": 247, "109m": 247, "335m": 247, "168m": 247, "179m": 247, "103m": 247, "deepset": 247, "dbmdz": [247, 250, 264], "tohoku": 247, "japanes": [247, 252], "111m": 247, "mecab": 247, "fugashi": 247, "ja": 247, "char": 247, "turkunlp": 247, "finnish": 247, "125m": [247, 264], "wietsedv": 247, "dutch": [247, 248], "117m": 247, "345m": 247, "774m": 247, "1600": 247, "1558m": 247, "wt103": 247, "257m": 247, "340m": 247, "355m": 247, "82m": [247, 264], "detector": [247, 326], "66m": [247, 264], "65m": [247, 264], "134m": [247, 264], "6b": [247, 299], "11m": 247, "17m": 247, "xlarg": 247, "58m": 247, "xxlarg": 247, "4096": 247, "223m": 247, "60m": 247, "c4": [247, 318], "220m": 247, "3072": [247, 249], "770m": 247, "3b": 247, "8b": 247, "11b": 247, "65536": 247, "270m": 247, "tb": 247, "550m": 247, "flaubert_small_cas": 247, "54m": 247, "flaubert_base_uncas": 247, "137m": 247, "flaubert_base_cas": 247, "138m": 247, "flaubert_large_cas": 247, "373m": 247, "406m": 247, "139m": 247, "moussakam": 247, "216m": 247, "561m": 247, "124m": [247, 264], "149m": 247, "crime": [247, 290], "punish": [247, 290], "fyodor": 247, "dostoyevski": 247, "74m": 247, "096": 247, "435m": 247, "610m": 247, "228m": 247, "couplet": 247, "visualgenom": 247, "130m": 247, "115m": 247, "3x2": 247, "177m": [247, 264], "161m": 247, "386m": 247, "358m": 247, "468m": 247, "440m": 247, "113m": 247, "343m": 247, "140m": 247, "750m": 247, "1536": 247, "51m": 247, "sop": 247, "reiniti": [247, 270], "dig": 248, "9997795224189758": 248, "9998": 248, "5309": 248, "neutral": 248, "nlptown": 248, "italian": 248, "beneath": 248, "2057": 248, "2024": 248, "2200": 248, "3407": 248, "2265": 248, "19081": 248, "3075": 248, "1012": 248, "pt_batch": 248, "tf_batch": 248, "3246": 248, "2123": 248, "1056": 248, "5223": 248, "2009": 248, "pt_output": 248, "tf_output": 248, "0833": 248, "3364": 248, "0418": 248, "grad_fn": 248, "addmmbackward": 248, "0832963": 248, "336414": 248, "08181786": 248, "04179301": 248, "pt_predict": 248, "tf_predict": 248, "2042994e": 248, "9977952e": 248, "3086340e": 248, "6913657e": 248, "2043e": 248, "9978e": 248, "3086e": 248, "6914e": 248, "softmaxbackward": 248, "dataclass": 248, "autocomplet": 248, "all_hidden_st": 248, "all_attent": 248, "scene": 248, "brows": 248, "n_head": 248, "ort": 249, "convert_graph_to_onnx": 249, "2gb": 249, "fastgelu": 249, "greatli": [249, 252], "y_": 249, "_point": 249, "deepen": 249, "upcom": 249, "serializ": 249, "optimiz": 249, "necess": 249, "impli": [249, 251], "unti": 249, "synchron": [249, 315], "propag": 249, "singleton": 249, "traced_bert": 249, "enc": 249, "jim": 249, "henson": 249, "puppet": 249, "tokenized_text": 249, "masked_index": 249, "indexed_token": 249, "convert_tokens_to_id": 249, "segments_id": 249, "tokens_tensor": 249, "segments_tensor": 249, "dummy_input": 249, "vocab_size_or_config_json_fil": 249, "32000": [249, 288], "num_attention_head": [249, 288], "traced_model": 249, "initialis": 249, "loaded_model": 249, "all_encoder_lay": 249, "pooled_output": [249, 288], "dunder": 249, "versatil": 250, "run_": [250, 264], "run_tf_glu": [250, 277], "run_tf_text_classif": [250, 277], "9991": 250, "9999": 250, "sequence_0": 250, "compani": 250, "york": 250, "citi": 250, "sequence_1": 250, "health": 250, "sequence_2": 250, "headquart": 250, "manhattan": 250, "not_paraphras": 250, "paraphrase_classification_logit": 250, "not_paraphrase_classification_logit": 250, "paraphrase_result": 250, "not_paraphrase_result": 250, "run_qa": [250, 258, 296, 297], "run_tf_squad": [250, 258], "6226": 250, "5053": 250, "147": 250, "161": 250, "answer_start_scor": 250, "start_logit": 250, "answer_end_scor": 250, "end_logit": 250, "convert_tokens_to_str": 250, "convert_ids_to_token": 250, "lysandrejik": 250, "lui": 250, "run_mlm": [250, 256], "pprint": 250, "mask_token": 250, "1792745739221573": 250, "3944": 250, "token_str": 250, "\u0121tool": 250, "11349421739578247": 250, "7208": 250, "\u0121framework": 250, "05243554711341858": 250, "5560": 250, "\u0121librari": 250, "03493533283472061": 250, "databas": [250, 251], "8503": 250, "\u0121databas": 250, "02860250137746334": 250, "17715": 250, "\u0121prototyp": 250, "automodelwithlmhead": 250, "mask_token_index": 250, "token_logit": 250, "mask_token_logit": 250, "top_5_token": 250, "tfautomodelwithlmhead": 250, "run_clm": [250, 256], "top_k_top_p_filt": 250, "dumbo": 250, "next_token_logit": 250, "filtered_next_token_logit": 250, "top_p": 250, "next_token": 250, "multinomi": 250, "num_sampl": [250, 271], "resulting_str": 250, "tf_top_k_top_p_filt": 250, "hopefulli": 250, "portion": [250, 264], "text_gener": 250, "am": 250, "do_sampl": 250, "generated_text": 250, "admit": 250, "market": 250, "stretch": 250, "overridden": 250, "aman": 250, "rusia": 250, "rusiaaman": 250, "padding_text": 250, "1991": 250, "tsar": 250, "nichola": 250, "famili": 250, "maria": 250, "voic": [250, 252], "young": 250, "son": 250, "tsarevich": 250, "nikolaevich": 250, "narrat": 250, "stori": [250, 262], "1883": 250, "western": 250, "siberia": 250, "grigori": 250, "rasputin": 250, "father": 250, "men": 250, "denounc": 250, "hors": 250, "thief": 250, "slap": 250, "him": [250, 276], "accus": 250, "chase": 250, "beaten": 250, "twenti": 250, "virgin": 250, "priest": 250, "famou": 250, "bishop": 250, "beg": 250, "bless": [250, 276], "eod": 250, "weather": 250, "prompt_length": 250, "clean_up_tokenization_spac": 250, "eop": 250, "organis": [250, 286], "2003": [250, 264, 279], "run_ner": [250, 279], "mi": 250, "miscellan": 250, "stefan": [250, 279], "9995632767677307": 250, "gging": 250, "9915938973426819": 250, "9982671737670898": 250, "9994403719902039": 250, "9994346499443054": 250, "9993270635604858": 250, "9993864893913269": 250, "9825621843338013": 250, "um": 250, "936983048915863": 250, "8987102508544922": 250, "9758241176605225": 250, "990249514579773": 250, "hack": 250, "conll03": 250, "daili": [250, 254, 262], "liana": 250, "barriento": 250, "she": 250, "marri": 250, "westchest": 250, "counti": 250, "divorc": 250, "her": 250, "husband": 250, "marriag": 250, "hitch": 250, "declar": 250, "bronx": 250, "crimin": 250, "court": 250, "prosecutor": 250, "immigr": 250, "scam": 250, "fridai": 250, "plead": 250, "guilti": 250, "suprem": 250, "attornei": 250, "wright": 250, "declin": 250, "arrest": 250, "theft": 250, "trespass": 250, "allegedli": 250, "sneak": 250, "subwai": 250, "annett": 250, "markowski": 250, "polic": 250, "spokeswoman": 250, "2002": [250, 279], "island": 250, "jersei": 250, "eight": 250, "approv": 250, "unclear": 250, "prosecut": 250, "district": 250, "offic": 250, "depart": 250, "homeland": 250, "seven": 250, "countri": 250, "egypt": 250, "turkei": 250, "georgia": 250, "pakistan": 250, "mali": 250, "eighth": 250, "rashid": 250, "rajput": 250, "deport": 250, "2006": [250, 261], "terror": 250, "convict": 250, "prison": 250, "min_length": [250, 262], "summary_text": 250, "early_stop": 250, "translation_en_to_d": [250, 276], "pari": 250, "translation_text": 250, "ein": 250, "technologieunternehmen": 250, "sitz": 250, "und": 250, "yml": 251, "ton": 251, "test_optim": 251, "test_log": 251, "subtest": 251, "optimizationtest": 251, "test_adam_w": 251, "keyword": [251, 285, 295, 305], "ada": 251, "unstag": 251, "looponfail": 251, "looponfailroot": 251, "cfg": [251, 315, 319, 328], "ini": 251, "tox": 251, "test_modeling_": [251, 285, 286], "test_model": 251, "isol": 251, "plugin": [251, 370], "onto": 251, "unpredict": 251, "undetect": 251, "replai": 251, "somehow": 251, "tear": 251, "uncov": 251, "flakefind": 251, "flake": 251, "finder": 251, "test_failing_test": 251, "presenc": 251, "573663": 251, "narrow": 251, "test_a": 251, "test_c": 251, "test_b": 251, "impos": 251, "pspec": 251, "instafail": 251, "require_torch": 251, "require_torch_gpu": 251, "require_torch_multi_gpu": 251, "require_torch_non_multi_gpu": 251, "require_torch_tpu": 251, "depict": 251, "test_example_with_multi_gpu": 251, "require_tf": 251, "test_tf_thing_with_tensorflow": 251, "test_example_slow_on_gpu": 251, "require_": 251, "parameter": 251, "test_integration_foo": 251, "testing_util": 251, "get_gpu_count": 251, "spawn": [251, 254, 319], "test_seq2seq_examples_multi_gpu": 251, "pl": [251, 273, 341], "test_finetune_train": 251, "execute_subprocess_async": 251, "sent": [251, 269], "junit": 251, "junitxml": 251, "xml": [251, 321], "white": [251, 276], "fixtur": 251, "neither": 251, "test_this1": 251, "testmathunittest": 251, "testcas": 251, "test_floor": 251, "assert_equ": 251, "floor": 251, "test_mytest": 251, "test_floor_0_neg": 251, "test_floor_1_integ": 251, "test_floor_2_large_fract": 251, "marker": 251, "test_this2": 251, "test_util": 251, "testcaseplu": 251, "accessor": 251, "test_file_path": 251, "__file__": 251, "test_file_dir": 251, "tests_dir": 251, "examples_dir": 251, "repo_root_dir": 251, "src_dir": 251, "stringifi": 251, "test_file_path_str": 251, "test_file_dir_str": 251, "tests_dir_str": 251, "examples_dir_str": 251, "repo_root_dir_str": 251, "src_dir_str": 251, "pathexampletest": 251, "test_something_involving_local_loc": 251, "test_data": [251, 290], "oboject": 251, "_str": 251, "test_something_involving_stringified_loc": 251, "tempfil": 251, "examplestest": 251, "test_whatev": 251, "tmp_dir": 251, "get_auto_remove_tmp_dir": 251, "monitor": [251, 254], "intact": 251, "subdir": 251, "nuke": 251, "altogeth": 251, "xfail": 251, "xpass": 251, "buggi": 251, "uncondition": 251, "test_feature_x": 251, "has_someth": 251, "unsupport": [251, 296], "getopt": 251, "allow_module_level": 251, "xyz": 251, "docutil": 251, "importorskip": 251, "minvers": 251, "skipif": 251, "sy": [251, 371], "version_info": 251, "win32": 251, "testclass": 251, "afford": [251, 300], "var": 251, "caught": 251, "rough": 251, "50mb": 251, "excruciatingli": 251, "incorrectli": 251, "overheard": 251, "outlier": 251, "slowest": 251, "capsi": 251, "accomplish": 251, "print_to_stdout": 251, "print_to_stderr": 251, "test_result_and_stdout": 251, "readouterr": 251, "raise_except": 251, "test_something_except": 251, "contextlib": 251, "redirect_stdout": 251, "stringio": 251, "getvalu": 251, "cleanup": 251, "buf": 251, "capturestdout": 251, "function_that_writes_to_stdout": 251, "secret": [251, 379, 382], "capturestderr": 251, "function_that_writes_to_stderr": 251, "capturestd": 251, "function_that_writes_to_stdout_and_stderr": 251, "capturelogg": 251, "get_logg": 251, "tokenization_bart": 251, "mockenv": 251, "hfargumentparsertest": 251, "test_env_overrid": 251, "env_level_str": 251, "getenv": 251, "pythonpath": [251, 367], "envexampletest": 251, "test_external_prog": 251, "get_env": 251, "rng": 251, "manual_se": 251, "manual_seed_al": 251, "userwarn": 251, "pdb": 251, "problemat": 251, "interfer": 251, "purposefulli": 251, "solid": 251, "travisci": 251, "workaround": 251, "euo": 251, "pipefail": 251, "suppress": 251, "this_command_will_fail": 251, "cmd_that_may_fail": 251, "vote": 251, "sensibl": 252, "explod": 252, "complic": [252, 273], "mose": 252, "loos": 252, "267": 252, "735": 252, "enorm": 252, "unsatisfactori": 252, "letter": 252, "annoyingli": 252, "annoi": 252, "ly": 252, "kept": [252, 319], "agglutin": 252, "turkish": 252, "arbitrarili": 252, "gp": 252, "er": 252, "sennrich": 252, "pretoken": 252, "pug": 252, "pun": 252, "bun": 252, "occurr": [252, 264, 388], "ug": 252, "mug": 252, "unk": 252, "emoji": 252, "clever": 252, "257": 252, "outlin": [252, 332], "korean": 252, "schuster": 252, "2012": [252, 367], "kudo": 252, "trim": 252, "substr": 252, "conjunct": [252, 256], "percent": 252, "exhibit": 252, "sum_": 252, "thai": 252, "detoken": 252, "quickstart": 253, "nuanc": 253, "hyperpamet": 253, "no_decai": 253, "optimizer_grouped_paramet": 253, "nd": 253, "text_batch": 253, "pixar": 253, "cross_entropi": 253, "num_train_step": 253, "base_model": 253, "glue_convert_examples_to_featur": 253, "steps_per_epoch": 253, "115": 253, "tight": 253, "my_mrpc_model": 253, "tfds_train_dataset": 253, "tfds_test_dataset": 253, "compute_metr": [253, 296, 308, 309, 311], "accuracy_scor": 253, "precision_recall_fscore_support": 253, "label_id": 253, "recal": [253, 327], "snapshot": 254, "swag": 254, "arc": 254, "number_of_gpu_you_hav": 254, "path_to_script": 254, "all_arguments_of_the_script": 254, "mnli_output": 254, "boilerpl": 254, "xla_spawn": 254, "num_tpu_you_hav": 254, "report_to": 254, "wandb_log_model": 254, "wandb_watch": 254, "wandb_project": [254, 273], "run_nam": 254, "partick": 255, "run_language_model": 256, "dataset_config_nam": [256, 267, 276, 290], "k80": 256, "train_fil": [256, 267, 269, 276, 277, 279], "path_to_train_fil": [256, 267, 279], "validation_fil": [256, 267, 276, 279], "path_to_validation_fil": [256, 267, 279], "converg": 256, "line_by_lin": 256, "pad_to_max_length": [256, 267, 291, 292, 300, 301], "mlm_wwm": 256, "plm_probabl": 256, "max_span_length": 256, "run_plm": 256, "run_swag": 257, "swag_bas": 257, "overwrite_output": 257, "eval_acc": 257, "8338998300509847": 257, "eval_loss": [257, 290], "44457291918821606": 257, "swag_dir": 257, "swag_data_dir": 257, "run_tf_multiple_choic": 257, "models_bert": 257, "tesla": [258, 262, 277], "debug_squad": 258, "exact_match": 258, "wwm_uncased_finetuned_squad": 258, "run_qa_beam_search": 258, "wwm_cased_finetuned_squad": 258, "squad_dir": 258, "version_2_with_neg": 258, "45884578997162": 258, "5974600601065": 258, "10570": 258, "hasans_exact": 258, "hasans_f1": 258, "59746006010651": 258, "hasans_tot": 258, "4177545691906": 258, "07154997729623": 258, "11873": 258, "73751686909581": 258, "05558584352873": 258, "5928": 258, "noans_exact": 258, "0874684608915": 258, "noans_f1": 258, "noans_tot": 258, "5945": 258, "bookscorpu": 258, "zhiheng": 258, "relative_squad": 258, "6802270577105": 258, "54772098174814": 258, "heurist": [260, 370], "han": 260, "mccoi": 260, "nafis": 260, "sadat": 260, "moosavi": 260, "hans_dir": 260, "run_han": 260, "heur": 260, "lexical_overlap": 260, "9702": 260, "9942": 260, "9962": 260, "0396": 260, "pabe": 261, "sacrific": 261, "run_glue_with_pabe": 261, "eval_all_checkpoint": 261, "comma": [261, 388], "regression_threshold": 261, "12m": 261, "108m": 261, "62x": 261, "18m": 261, "zhou2020bert": 261, "wangchunshu": 261, "mcaulei": 261, "ke": 261, "eprint": [261, 269, 273, 281], "04152": 261, "archiveprefix": [261, 269, 273, 281], "primaryclass": [261, 269, 273, 281], "nltk": [262, 271], "bertab": [262, 276], "kyunghyun": 262, "cho": 262, "uncompress": 262, "cnn_stori": 262, "tgz": [262, 273, 274], "dailymail_stori": 262, "run_summar": 262, "documents_dir": 262, "summaries_output_dir": 262, "summaries_path": 262, "no_cuda": [262, 275, 292, 296, 297, 301, 308, 309, 311], "beam_siz": 262, "alpha": [262, 306], "block_trigram": 262, "compute_roug": 262, "rouge_scor": 262, "utils_summar": 262, "path_to_data": 263, "plot_data_dir": 263, "analys": 263, "model_s": 263, "xin": 263, "ee": 263, "ji": 263, "raphael": 263, "jaejun": 263, "yaoliang": 263, "jimmi": 263, "58th": 263, "annual": 263, "jul": 263, "acl": 263, "204": 263, "2246": 263, "2251": 263, "victorsanh": [264, 269], "januari": 264, "decemb": 264, "novemb": 264, "octob": 264, "supersed": 264, "septemb": 264, "formal": 264, "macro": 264, "distilroberta1": 264, "ourselv": 264, "germev": 264, "2014": 264, "openwebtextcorpu": 264, "reproduct": 264, "sole": 264, "similarli": 264, "binar": 264, "binarized_data": 264, "tokenizer_typ": [264, 286], "tokenizer_nam": [264, 273, 297], "dump_fil": 264, "binarized_text": 264, "emphasi": 264, "token_count": 264, "data_fil": [264, 275], "token_counts_dump": 264, "30522": 264, "student_config": 264, "training_config": 264, "teacher_nam": 264, "alpha_c": 264, "alpha_mlm": 264, "alpha_co": 264, "alpha_clm": 264, "freeze_pos_emb": 264, "dump_path": 264, "serialization_dir": [264, 269], "my_first_train": 264, "node_rank": [264, 292, 301], "n_node": 264, "n_gpu_nod": 264, "an_open_port": 264, "pkill": 264, "nnode": [264, 292, 301], "extract_distilbert": 264, "student_pretrained_weight": 264, "sanh2019distilbert": 264, "emc": 264, "yjernit": 265, "virtualenv": 266, "req": 266, "run_mlm_wwm": 267, "wwm": [267, 357, 358], "ltp": 267, "\u6211\u559c\u6b22\u4f60": 267, "\u6211": 267, "\u559c": 267, "\u6b22": 267, "\u4f60": 267, "\u559c\u6b22": 267, "chine": 267, "clue": 267, "ltp_resourc": 267, "bert_resourc": 267, "run_chinese_ref": 267, "file_nam": 267, "path_to_train_or_eval_fil": 267, "path_to_ltp_token": 267, "path_to_bert_token": 267, "path_to_reference_fil": 267, "train_ref_fil": 267, "path_to_train_chinese_ref_fil": 267, "validation_ref_fil": 267, "path_to_validation_chinese_ref_fil": 267, "note1": 267, "note2": 267, "rune": 267, "wlhgtc": 267, "run_mmimdb": 268, "mmimdb": 268, "max_seq_len": 268, "num_image_emb": 268, "regim": 269, "basefin": 269, "remainingweight": 269, "l0": 269, "soft": [269, 275], "devem": 269, "145": 269, "964": 269, "367": 269, "devacc": 269, "369": 269, "879": 269, "887": 269, "286": 269, "889": [269, 318], "awai": 269, "invit": 269, "fun": [269, 276], "deck": 269, "340mb": 269, "11mb": 269, "floppi": 269, "null": [269, 388], "hypothet": 269, "q8bert": 269, "nois": 269, "prunebert": 269, "fineprun": 269, "pruned_bert": 269, "stabil": 269, "352d5472b0c1dec0f420d606d16747d851b4bda8": 269, "squad_data": 269, "masked_run_squad": 269, "predict_fil": [269, 297, 357, 358], "masked_bert": 269, "5400": 269, "mask_scores_learning_r": 269, "initial_threshold": 269, "final_threshold": 269, "initial_warmup": 269, "final_warmup": 269, "pruning_method": 269, "mask_init": 269, "mask_scal": 269, "sigmoied_threshold": 269, "final_lambda": 269, "dbg": 269, "coeffici": [269, 271], "counts_paramet": 269, "maskedbertforquestionansw": 269, "bertar": 269, "exhaust": 269, "announc": [269, 295, 305], "sanh2020mov": 269, "07683": 269, "tevenlescao": 270, "choromanski": 270, "valerii": 270, "likhosherstov": 270, "dohan": 270, "xingyou": 270, "andreea": 270, "gane": 270, "tama": 270, "sarlo": 270, "hawkin": 270, "jare": 270, "davi": 270, "afroz": 270, "mohiuddin": 270, "lukasz": 270, "belang": 270, "luci": 270, "colwel": 270, "weller": 270, "sanity_script": 270, "full_script": 270, "wandb_user_nam": 270, "viewer": 270, "sumanth": 271, "dathathri": 271, "andrea": 271, "madotto": 271, "janic": 271, "jane": 271, "hung": 271, "frank": 271, "piero": 271, "molino": 271, "yosinski": 271, "rosann": 271, "1912": 271, "02164": 271, "eng": [271, 283], "uber": 271, "torchtext": 271, "run_pplm": 271, "cond_text": 271, "potato": 271, "num_iter": [271, 295, 305], "stepsiz": 271, "window_length": 271, "kl_scale": 271, "gm_scale": 271, "colorama": 271, "intensifi": 271, "soften": 271, "uncontrol": 271, "repetit": 271, "gm": 271, "grad": 271, "xx": 271, "class_label": 271, "lhoestq": 272, "11401": 272, "finetune_rag": 272, "rag_sequ": 272, "question_encod": 272, "nq": 272, "consolidate_rag_checkpoint": 272, "generator_name_or_path": 272, "question_encoder_name_or_path": 272, "dest": 272, "rai": 272, "distributed_retriev": 272, "num_retrieval_work": 272, "eval_mod": 272, "end2end": 272, "evaluation_set": 272, "gold_data_path": 272, "contan": 272, "datapoint": 272, "constitut": 272, "sing": 272, "reba": 272, "sandi": 272, "spika": 272, "mcentir": 272, "album": 272, "shoot": 272, "moon": [272, 275], "biencod": 272, "fbaipublicfil": 272, "gzip": 272, "parse_dpr_relevance_data": 272, "wherev": 272, "src_path": 272, "eval_rag": 272, "predictions_path": 272, "retrieval_pr": 272, "rag_token": 272, "poutput": 272, "gold_data_mod": 272, "output_list": 272, "owner": 272, "footbal": 272, "club": 272, "xiu": 272, "yongg": 272, "xiuli": 272, "recalcul": 272, "gold_data": 272, "e2e_pr": 272, "n_doc": 272, "print_predict": 272, "use_custom_knowledge_dataset": 272, "use_own_knowledge_dataset": 272, "csv_path": 272, "my_csv": 272, "my_knowledge_dataset": 272, "index_nam": 272, "passages_path": 272, "index_path": 272, "my_knowledge_dataset_hnsw_index": 272, "faiss": 272, "contrib": 273, "cdn": [273, 274, 283, 297, 298], "xzvf": [273, 298], "xsum_dir": 273, "cnn_dm_v2": 273, "cnn_cln": 273, "cnn_dm": 273, "cnn_dir": 273, "enro_dir": 273, "wmt_en_d": 273, "eval_": 273, "leak": 273, "8403": 273, "freeze_encod": 273, "3hr": 273, "best_tfmr": 273, "do_predict": [273, 277], "evaluate_checkpoint": 273, "run_ev": [273, 274], "summ": 273, "13gb": 273, "cnndm": 273, "val_max_target_length": 273, "test_max_target_length": 273, "rerun": 273, "test_gener": 273, "max_target_length": 273, "logger_nam": 273, "hf_xsum": 273, "legacyseq2seqdataset": 273, "prepare_seq2seq_batch": 273, "seq2seqdataset": 273, "encoder_layerdrop": 273, "decoder_layerdrop": 273, "attention_dropout": 273, "xsum_result": 273, "starter": 273, "train_mbart_cc25_enro": 273, "enro_finetune_baselin": 273, "label_smooth": 273, "sortish_sampl": 273, "6h": 273, "romanian_postprocess": 273, "multigpu": 273, "git_log": 273, "val_avg_rouge2": 273, "1984": 273, "step_count": 273, "summarizationdistil": 273, "test_result": 273, "hparam": 273, "save_dir": [273, 274, 283], "convert_pl_checkpoint_to_hf": 273, "path_to_ckpt": 273, "randomly_initialized_hf_model_path": 273, "run_distributed_ev": [273, 274], "max_tokens_per_batch": 273, "sortish": 273, "save_len_fil": 273, "dynamic_bs_exampl": 273, "benchmark_dynamic_b": 273, "uneven": 273, "723": 273, "shrink": 273, "dm": [273, 274], "dbart": 273, "tradeoff": 273, "deval": 273, "proc": 273, "dd": 273, "dbart_12_3_xsum_ev": 273, "dbart_12_6_cnn_ev": 273, "dpx_cnn_eval": 273, "dpx_xsum_ev": 273, "make_stud": 273, "dbart_xsum_12_3": 273, "dpx_xsum_16_4": 273, "create_student_by_copying_alternating_lay": 273, "val_check_interv": 273, "n_val": 273, "eval_beam": 273, "distilbart_xsum_sft_12_3": 273, "train_distilbart_cnn": 273, "no_teach": 273, "dbart_xsum_12_3_pl": 273, "curl": [273, 274, 279, 283, 293], "bart_xsum_pl": [273, 274], "xvz": [273, 274], "pegasus_xsum": [273, 274], "all_pl": 273, "train_distilbart_xsum": 273, "13h": 273, "supervise_forward": 273, "normalize_hidden": 273, "shleifer2020pretrain": 273, "13002": 273, "wolf2019huggingfacest": 273, "1910": 273, "03771": 273, "took": 274, "rouge2": 274, "ft": 274, "282173": 274, "2016": 274, "sync_timeout": 274, "60000": 274, "max_source_length": 274, "type_path": 274, "pegasus_cnn_cnn_pl": 274, "sortishsampl": 274, "joeddav": 275, "distill_classifi": 275, "unlabeled_data": 275, "class_names_fil": 275, "class_nam": [275, 363], "teacher_name_or_path": 275, "student_name_or_path": 275, "distillbert": 275, "hypothesis_templ": 275, "hypothesi": 275, "sport": 275, "multi_class": 275, "contradict": 275, "smoother": 275, "teacher_batch_s": 275, "tech": [275, 319], "orbit": 275, "zero_shot_classifi": 275, "7035840153694153": 275, "18744826316833496": 275, "06027870625257492": 275, "04868902638554573": 275, "agnew": 275, "train_unlabel": 275, "newlin": 275, "textclassificationpipelin": 275, "distilled_classifi": 275, "return_all_scor": 275, "14899294078350067": 275, "03205857425928116": 275, "05943061783909798": 275, "7595179080963135": 275, "dirti": 275, "seet": 275, "secretli": 275, "held": 275, "legaci": 276, "jsonlin": 276, "tst": 276, "max_val_sampl": 276, "cnn_dailymail": 276, "text_column": 276, "summary_column": 276, "path_to_csv_or_jsonlines_fil": 276, "sit": 276, "bore": 276, "room": 276, "raini": 276, "sundai": 276, "afternoon": 276, "wast": 276, "rose": 276, "bloom": 276, "ski": 276, "dark": 276, "sacr": 276, "garden": 276, "flower": 276, "christma": 276, "cheer": 276, "children": 276, "snowflak": 276, "air": 276, "carol": 276, "olden": 276, "ancient": 276, "rhyme": 276, "dream": 276, "text_column_nam": 276, "summary_column_nam": 276, "source_lang": 276, "target_lang": 276, "nether": 276, "path_to_jsonlines_fil": 276, "dismiss": 276, "joke": 276, "al\u021bii": 276, "au": 276, "numit": 276, "glum\u0103": 276, "implos": 276, "iar": 276, "a\u0219teapt\u0103": 276, "implozia": 276, "wmt14": 276, "isntead": 277, "corr": 277, "spearman": 277, "toggl": 277, "use_amp": 277, "tlkh": 277, "8438": 277, "8281": 277, "8333": 277, "8568": 277, "8646": 277, "8359": 277, "8464": 277, "8385": 277, "1080": 277, "dev_fil": 277, "test_fil": 277, "label_column_id": 277, "train_languag": 277, "debug_xnli": 277, "7093812375249501": 277, "scrip": 279, "conll2003": 279, "outer": 279, "uc": 279, "1jjhbal535vvz2ap4v4r_rn1uehtdlk5p": 279, "tr": 279, "1zfrcqthdtar5pprjidtrvp7btxscubbm": 279, "1u9mb7knjhwqcwywemdrmutfoohofebth": 279, "x96": 279, "u200": 279, "x95": 279, "xad": 279, "x80": 279, "uniq": 279, "num_epoch": 279, "preciou": 280, "tapas_inter_masklm_base_reset": 281, "flatten": 281, "refut": 281, "counterfactu": 281, "tapas": 281, "infobox": 281, "wikit": 281, "authro": 281, "caption": 281, "gerald": 281, "ford": 281, "taller": 281, "presid": 281, "herzig2020tapa": 281, "02349": 281, "eisenschlos2020understand": 281, "00571": 281, "wrote": 282, "gitpython": 283, "language_cod": 283, "3b2": 283, "convert_marian_tatoeba_to_pytorch": 283, "heb": 283, "convert_model": 283, "tatoebaconvert": 283, "upload_model": 283, "tatoebacoderesolv": 283, "write_model_card": 283, "adding_a_new_example_script": 284, "brandnewbert": [285, 288], "mentor": [285, 288], "model_summari": [285, 288], "add_": 285, "configuration_": [285, 286], "forconditionalgener": [285, 287], "test_attention_output": 285, "modelintegrationtest": 285, "closest": 285, "modelnam": 286, "plain": 286, "uppercase_modelnam": 286, "lowercase_modelnam": 286, "camelcase_modelnam": 286, "modelhub": 286, "checkpoint_identifi": 286, "modeling_tf_": 286, "tokenization_": 286, "test_modeling_tf_": 286, "test_": 286, "checklist": 286, "generate_tensorflow_and_pytorch": 287, "is_encoder_decoder_model": [287, 288], "endif": 287, "yannic": 288, "kilcher": 288, "superfici": 288, "big_bird": 288, "bigbirdconfig": 288, "ckpt_path": 288, "bigbr_bas": 288, "ckpt_reader": 288, "newcheckpointread": 288, "set_weight": 288, "get_tensor": 288, "trainable_weight": 288, "bigbp_larg": 288, "00000": 288, "00001": 288, "add_big_bird": 288, "modeling_big_bird": 288, "configuration_big_bird": 288, "bigbirdmodel": 288, "discourag": 288, "bigbirdattent": 288, "bigbirdforconditionalgener": 288, "test_modeling_big_bird": 288, "bigbirdmodelintegrationtest": 288, "bigbirdmodeltest": 288, "mistaken": 288, "tokenizer_class": 288, "bird": 288, "bigbirdtokenizationtest": 288, "bigbird": 289, "huggingface_model": [290, 293, 296, 298, 303, 308, 309, 310, 311, 312, 313], "ptq_static": [290, 296, 310, 311], "run_clm_tun": 290, "ptq_dynam": [290, 298, 308, 309, 313, 334, 335], "topology_nam": [290, 298, 308, 310, 313], "billsum": [290, 298], "matrics": [290, 298, 308, 313], "mcc": [290, 296, 298, 308, 309, 310, 311, 313], "spearmanr": [290, 296, 298, 308, 309, 310, 311, 313], "eval_func_for_nc": [290, 298, 308, 310, 313], "eval_output": 290, "eval_samples_per_second": [290, 296, 309, 311], "clm_task_metrics_kei": 290, "csarron": [291, 292], "portal": [291, 292, 294, 299, 300, 301, 304], "run_qa_no_trainer_distil": 291, "teacher_model_name_or_path": [291, 292, 295, 299, 300, 301], "do_distil": [291, 292, 299, 300, 301], "run_teacher_logit": [291, 292], "5143": [291, 292, 294, 299, 301, 302, 304], "run_qa_no_trainer_pruneofa": 292, "do_prun": [292, 295, 301, 302, 305], "stage1_output_dir": [292, 301], "do_quant": [292, 300, 301], "stage2_output_dir": [292, 301], "best_model": [292, 301], "master_address": [292, 301], "num_processes_per_nod": [292, 301], "num_nod": [292, 301], "lanuch": [292, 301], "pip3": [293, 328, 378], "cu113": 293, "torchaudio": [293, 335], "group_lasso": 293, "pyyaml": 293, "squad1": 293, "settl": [293, 295, 305], "ngc": 293, "bert_pyt_ckpt_large_pretraining_amp_lamb": 293, "bert_large_pretrained_amp": 293, "lo": 293, "run_squad_spars": 293, "tf32": 293, "outdir": [293, 321], "prune_bert": 293, "init_checkpoint": [293, 356], "ckpt_8601": 293, "bert_prep_working_dir": 293, "bert_data": 293, "prune_config": 293, "run_qa_no_trainer_prun": 294, "nxm": [295, 305], "oneshot": [295, 305], "weight_compression_pytorch": [295, 305], "start_step": [295, 305], "end_step": [295, 305], "excluded_nam": [295, 305], "prune_layer_typ": [295, 305], "target_spars": [295, 305], "max_sparsity_ratio_per_lay": [295, 305], "extra_excluded_nam": [295, 305], "update_frequency_on_step": [295, 305], "prune_domain": [295, 305], "prune_typ": [295, 305], "snip_momentum": [295, 305], "pytorch_prun": [295, 305], "sparsity_decay_typ": [295, 305], "cube": [295, 305], "update_items_for_all_prun": [295, 305], "sparsity_warm_epoch": [295, 305], "total_iter": [295, 305], "on_after_optimizer_step": [295, 305], "run_qa_no_train": 295, "dense_finetuned_model": 295, "pruning_config": [295, 305], "bert_mini_2in4": 295, "distill_loss_weight": [295, 305], "bert_mini_4x1": 295, "cooldown_epoch": [295, 305], "pruned_squad_bert": 295, "prajjwal1": 295, "output_bert": 295, "7993": 295, "7662": 295, "7687": 295, "7617": 295, "7627": 295, "4795": [295, 305], "7645": 295, "7685": 295, "dataloader_drop_last": [296, 309, 311], "furtur": 296, "metric_nam": [296, 309, 311], "eval_f1": [296, 308, 309, 310, 311], "take_eval_step": [296, 309, 311], "save_metr": [296, 309, 311], "torchvison": 297, "jemalloc": [297, 325, 378], "tcmalloc": 297, "openmp": 297, "amx": [297, 325], "dnnl_max_cpu_isa": [297, 325], "avx512_core_amx": [297, 325], "savedresult": 297, "bert_large_ipex": 297, "verison": 297, "run_qa_1_10": 297, "bert_squad_model": 297, "amazonaw": 297, "int8_fp32": 297, "bert_large_1_10_ipex": 297, "distilbert_base_ipex": 297, "pegasus_data": 298, "model_arg": [298, 308, 309, 311, 312, 313], "metric_key_prefix": [298, 313], "task_metrics_kei": [298, 313], "eval_bleu": [298, 313], "eval_rouge1": [298, 313], "eval_rouge2": [298, 313], "eval_rougel": [298, 313], "eval_rougelsum": [298, 313], "textattack": [299, 301], "glove": 299, "50d": 299, "run_glue_no_trainer_distil": 299, "augmented_sst2_data": 299, "huawei": 299, "tinybert_general_4l_312d": 299, "blackbird": [299, 301], "nreimer": 299, "l3": 299, "howei": 299, "zeroqu": 300, "yoshitomo": 300, "matsubara": 300, "run_glue_no_train": [300, 305], "baseli": 300, "run_glue_no_trainer_pruneofa": 301, "head_conf": 302, "13382": 302, "run_glue_no_trainer_gradient_prun": 302, "run_prun": 303, "distilbert_sst": 303, "run_glue_no_trainer_prun": 304, "1700": 304, "baseline_mrpc": 305, "bert_mini_mrpc_2in4": 305, "baseline_sst2": 305, "bert_mini_sst2_2in4": 305, "mrpcbaselin": 305, "bert_mini_mrpc_4x1": 305, "sst2_baselin": 305, "bert_mini_sst2_4x1": 305, "tee": [305, 371], "sst2_orig": 305, "sst2_snip": 305, "8804": 305, "8619": 305, "8752": 305, "8610": 305, "8722": 305, "8562": 305, "8695": 305, "8815": 305, "8660": 305, "8761": 305, "8651": 305, "8692": 305, "8609": 305, "8693": 305, "nerual": 306, "comporessor": 306, "run_glue_prune_distil": 306, "run_glue_tun": [308, 312], "int8_model_dir": [308, 309, 311], "output_log": [308, 309, 311, 312], "save_for_huggingface_upstream": [308, 309, 311, 312], "load_huggingfac": [308, 309, 311, 312], "optimizedmodel": [308, 309, 311, 312], "model_revis": [308, 309, 311, 312], "use_auth_token": [308, 309, 311, 312], "ramp": [308, 309, 311, 312], "bert_task_acc_kei": [308, 310], "eval_accuraci": [308, 310], "game": 308, "theori": 308, "fulfil": 308, "shap": 308, "shapleyms": 308, "recommand": 310, "optimum": 310, "intergr": 310, "enbal": 312, "eval_step": 312, "greater_is_bett": 312, "load_best_model_at_end": 312, "save_strategi": 312, "metric_for_best_model": 312, "save_total_limit": 312, "install_cuda_dock": 314, "ipc": 314, "download_dataset": [314, 315, 325, 326, 359], "run_and_tim": 314, "kaim": 314, "iccv": 314, "377": 314, "339": 314, "118k": 314, "train2017": [315, 319], "download_weight": [315, 327, 328], "e2e_mask_rcnn_r_50_fpn_1x": [315, 319], "maskrcnn_dataload": 315, "data_loaders_v": 315, "make_data_load": 315, "is_distribut": 315, "data_loader_v": 315, "iou_typ": 315, "box_onli": 315, "retinanet_on": 315, "rpn_onli": 315, "expected_result": 315, "expected_results_sigma_tol": 315, "solver": [315, 319], "ims_per_batch": [315, 319], "is_calib": 315, "cal_dataload": 315, "maskrcnn_benchmark": [316, 317, 318, 319], "image_s": 316, "to_image_list": 316, "batched_imag": 316, "batched_images_32": 316, "size_divis": 316, "nx4": 316, "geometr": 316, "xyxi": [316, 319], "y2": [316, 319], "xywh": 316, "bounding_box": [316, 319], "flip_left_right": 316, "bbox_scal": 316, "bbox_flip": 316, "add_field": [316, 319], "bbox_subset": 316, "cocoapi": [317, 319], "yac": 317, "matplotlib": 317, "webcam": 317, "fresh": 317, "ipython": 317, "ninja": 317, "cython": 317, "cocodataset": [317, 319, 321, 323], "pythonapi": 317, "build_ext": 317, "facebookresearch": [317, 319, 320], "maco": 317, "macosx_deployment_target": 317, "clang": 317, "cxx": 317, "td": 317, "8888": 317, "dd2c487": 318, "sched": 318, "im": [318, 321], "hr": 318, "4036": 318, "17130": 318, "6358800": 318, "3530": 318, "12580": 318, "6358793": 318, "4591": 318, "143149": 318, "6358804": 318, "7007": 318, "209965": 318, "6358717": 318, "4520": 318, "17796": 318, "6358801": 318, "4536": 318, "12966": 318, "6358792": 318, "5665": 318, "15384": 318, "6358805": 318, "7562": 318, "21739": 318, "6358718": 318, "keypoint": [318, 319], "3771": 318, "10941": 318, "9981060": 318, "p100": 318, "647": 318, "799": 318, "rpn": 319, "mmdetect": 319, "model_zoo": 319, "500mb": 319, "e2e_mask_rcnn_r_101_fpn_1x_caffe2": 319, "heatmap": 319, "e2e_keypoint_rcnn_r_50_fpn_1x_caffe2": 319, "cocodemo": 319, "e2e_mask_rcnn_r_50_fpn_1x_caffe2": 319, "merge_from_fil": 319, "merge_from_list": 319, "coco_demo": 319, "min_image_s": 319, "confidence_threshold": 319, "run_on_opencv_imag": 319, "miniv": 319, "valminusminiv": 319, "path_to_coco_dataset": 319, "train2014": 319, "test2014": 319, "val2014": 319, "test2017": 319, "voc": [319, 367], "path_to_vocdevkit_dir": 319, "coco_2017_train": 319, "coco_2014_train": 319, "coco_2017_v": 319, "paths_catalog": 319, "path_to_maskrcnn_benchmark": 319, "train_net": 319, "drawback": 319, "8x": 319, "base_lr": 319, "0025": 319, "max_it": 319, "720000": 319, "480000": 319, "640000": 319, "ngpu": 319, "boxlist": 319, "mydataset": 319, "get_img_info": 319, "img_height": 319, "img_width": 319, "segmentation_mask": 319, "segmentationmask": 319, "trim_detectron_model": 319, "latex": 319, "massa2018mrcnn": 319, "massa": 319, "girshick": 319, "maskrnn": 319, "retinamask": 319, "fu": 319, "mykhailo": 319, "shvet": 319, "berg": 319, "1901": 319, "03353": 319, "type_trait": 320, "1558": 320, "_from": 320, "_to": 320, "struct": 320, "is_convert": 320, "constexpr": 320, "_tc": 320, "anonym": 320, "_element": 320, "_nonnestedtupl": 320, "_srctupl": 320, "cudapopcallconfigur": 320, "firstli": 320, "abi": 320, "inde": 320, "gnu": 320, "onlinedoc": 320, "libstdc": 320, "gist": 320, "goldsborough": 320, "d466f43e8ffc948ff92de7486c5216d6": 320, "recompil": 320, "rf": 320, "ap50": [321, 328], "ap75": 321, "apm": 321, "apl": 321, "segm": 321, "jpegimag": 321, "pascal_train": 321, "pascal_v": 321, "pascal_test": 321, "vocdevkit": 321, "instanceonly_gtfile_train": 321, "trainvaltest": 321, "gtfine_trainvaltest": 321, "mcordt": 321, "cityscapesscript": 321, "instances2dict_with_polygon": 321, "convert_cityscapes_to_coco": 321, "datadir": 321, "gcc5": [323, 334], "prepare_loadgen": [323, 334], "step1": 323, "step2": 323, "upscal": 323, "1200x1200": 323, "annotations_trainval2017": 323, "origin_dir": 323, "origin_dataset": [323, 334], "convert_dir": [323, 334], "convert_dataset": [323, 334], "3236545": 323, "ssd1200": [323, 325], "1200": 323, "6298": 323, "3103": 323, "3418": 323, "elaps": 323, "76469": 323, "763": 323, "7865": 323, "22288": 323, "4817": 323, "861": 323, "9649": 323, "878": 323, "480769": 323, "0617": 323, "649": 323, "5251": 323, "215259": 323, "5257": 323, "5329": 323, "upscale_coco": 324, "coco700": 324, "ssd_resnet34": 325, "download_model": 325, "preload": 325, "ld_preload": [325, 371], "libjemalloc": [325, 371], "malloc_conf": [325, 371], "oversize_threshold": [325, 371], "background_thread": [325, 371], "metadata_thp": [325, 371], "dirty_decay_m": [325, 371], "9000000000": [325, 371], "muzzy_decay_m": [325, 371], "iomp": 325, "libiomp5": [325, 371], "dataset_dir": [325, 359, 361], "pretained_model": 325, "ssd300": 326, "yolo_v3": 327, "get_coco_dataset": [327, 328], "weights_path": [327, 328], "yolo_dataload": 327, "xywh2xyxi": 327, "img_siz": [327, 328], "ap_class": 327, "valid_path": 327, "conf_thr": 327, "nms_thre": 327, "listdataset": 327, "multiscal": 327, "nc_dataload": 327, "eriklindernoren": 328, "iou": 328, "256x256": 328, "darknet": [328, 363], "1080ti": 328, "image_fold": 328, "gradient_accumul": 328, "model_def": 328, "data_config": 328, "n_cpu": 328, "checkpoint_interv": 328, "evaluation_interv": 328, "compute_map": 328, "multiscale_train": 328, "darknet53": 328, "7300": 328, "14658": 328, "grid_siz": 328, "554926": 328, "446884": 328, "427585": 328, "028157": 328, "044483": 328, "051159": 328, "040524": 328, "035687": 328, "046307": 328, "078980": 328, "066310": 328, "027984": 328, "133414": 328, "094540": 328, "037121": 328, "234448": 328, "165665": 328, "223495": 328, "039402": 328, "040198": 328, "041520": 328, "cls_acc": 328, "recall50": 328, "361111": 328, "384615": 328, "300000": 328, "recall75": 328, "222222": 328, "282051": 328, "520000": 328, "070175": 328, "conf_obj": 328, "599058": 328, "622685": 328, "651472": 328, "conf_noobj": 328, "003778": 328, "004039": 328, "004044": 328, "429395": 328, "eta": 328, "821929": 328, "6006": 328, "create_custom_model": 328, "label_idx": 328, "x_center": 328, "y_center": 328, "joseph": 328, "redmon": 328, "ali": 328, "farhadi": 328, "bunch": 328, "swell": 328, "retinanet": 328, "pjreddi": [328, 363], "pc": [329, 330, 333], "370g": [329, 330, 333], "criteo": [329, 330, 333, 365], "tb00_40m": [329, 330, 333], "90gb": [329, 330, 333], "dlrm_dataload": [329, 330, 333], "x_test": [329, 330, 333, 337, 351], "ls_o_test": [329, 330, 333], "ls_i_test": [329, 330, 333], "test_ld": [329, 333], "fuse_list": 329, "bot_l": 329, "top_l": 329, "test_dataload": 330, "is_contigu": 330, "roc_auc": 330, "roc_auc_scor": 330, "transpar": 332, "bounti": 332, "disclosur": 332, "102400": 333, "ipex_config_path": 333, "int8_configur": 333, "best_acc_test": 333, "best_auc_test": 333, "inference_onli": 333, "train_ld": 333, "speech_recognit": [334, 335], "download_dir": 334, "stage1": 334, "stage2": 334, "flac": 334, "wav": 334, "3662521": 334, "distributeddataparallel_1576581068": 334, "9962234": 334, "scriptmodul": 334, "5477": 334, "796": 334, "7552": 334, "5872": 334, "1202": 334, "2529": 334, "5894": 334, "3231": 334, "5195": 334, "1211": 334, "5965": 334, "6030": 334, "1218": 334, "2211": 334, "4812": 334, "1169": 334, "5080": 334, "torchaudio_model": 335, "speech_dataset": 335, "openslr": 335, "zxvf": [335, 360], "folder_in_arch": 335, "dataset_info": 335, "speaker": 335, "driver": [336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "itex": [336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "nc_savedmodel": 336, "run_experi": 337, "load_weight": 337, "checkpoint_filepath": 337, "top_5_accuraci": 337, "y_test": [337, 351], "vit_model": 337, "uncom": [337, 338, 351], "eval_data": [339, 340, 342, 343, 346, 347, 350], "tensorflow_model_optim": 341, "resnet50_fashion_mnist_train": 345, "lowprecisioninferencetool": [345, 368], "resnet50_fashion": 345, "resnetv2": [346, 347, 351], "resnetv2_101": 346, "resnetv2_50": 347, "resnetv2_model": 351, "resnet_v2": 352, "trained_qat_model": 352, "tensorflow_model": [354, 355, 362], "imagenet_prepar": [354, 355], "synset": [354, 355], "raw_dir": [354, 355], "img_raw": [354, 355], "berkeleyvis": 354, "caffe_ilsvrc12": 354, "intelai": [354, 361, 365], "export_inference_graph": 354, "alsologtostderr": 354, "output_fil": [354, 357, 358], "inception_v1_inf_graph": 354, "0up2": 354, "cp36": 354, "cp36m": 354, "manylinux2010": 354, "cp37": 354, "cp37m": 354, "cp35": 354, "cp35m": 354, "labels_offset": 354, "netron": 354, "inceptionv1": [354, 355], "reshape_1": [354, 355], "freeze_graph": 354, "input_checkpoint": 354, "input_binari": 354, "frozen_inception_v1": 354, "output_node_nam": 354, "nc_resnet50_v15": 354, "resnet101_fp32_pretrained_model": 354, "nc_resnet101": 354, "nc_mobilenetv1": 354, "frozen_mobilenet_v2": 354, "nc_mobilenetv2": 354, "nc_inceptionv1": 354, "frozen_inception_v2": 354, "nc_inceptionv2": 354, "inceptionv4_fp32_pretrained_model": 354, "nc_inceptionv4": 354, "frozen_inception_resnet_v2": 354, "nc_irv2": 354, "frozen_vgg16": 354, "nc_vgg16": 354, "frozen_vgg19": 354, "nc_vgg19": 354, "resnet_v2_50": 354, "frozen_resnet50v2_50": 354, "nc_resnetv2_50": 354, "resnet_v2_101": 354, "frozen_resnetv2_101": 354, "nc_resnetv2_101": 354, "resnet_v2_152": 354, "frozen_resnetv2_152": 354, "nc_resnetv2_152": 354, "nc_densenet121": 354, "nc_densenet161": 354, "nc_densenet169": 354, "nasnet_mobil": 354, "frozen_nasnet_mobil": 354, "nc_nasnet_mobil": 354, "nc_efficientnet": 354, "intelai_model": 354, "resnet50v1_5": 354, "eval_classifier_optimized_graph": [354, 367], "auto_tun": 354, "__main__": 354, "eval_image_": 354, "classifier_infer": 354, "q_graph": 354, "evaluate_opt_graph": 354, "tfslimnetsfactori": 355, "inception_v4_arg_scop": 355, "overfeat": 355, "nc_resnet_v1_50": 355, "nc_resnet_v1_101": 355, "nc_resnet_v1_152": 355, "nc_resnet_v2_50": 355, "nc_resnet_v2_101": 355, "nc_resnet_v2_152": 355, "nc_inception_v1": 355, "nc_inception_v2": 355, "nc_inception_v4": 355, "vgg_16": 355, "nc_vgg_16": 355, "vgg_19": 355, "nc_vgg_19": 355, "tf_util": [355, 360], "get_slim_graph": 355, "slim_graph": 355, "model_func": 355, "arg_scop": 355, "run_classifi": 356, "bert_config_fil": 356, "343": 356, "strip_iter": [356, 357], "input_fil": [356, 357, 361], "iteratorgetnext": [356, 357], "kmp_blocktim": [356, 371], "eval_fil": 356, "input_fn": 356, "estimator_input_fn": 356, "get_model_typ": 356, "frozen_pb": 356, "2019_05_30": [357, 358], "wwm_uncased_l": [357, 358], "24_h": [357, 358], "1024_a": [357, 358], "create_tf_record": [357, 358], "v1_8": [357, 362], "bert_large_checkpoint": 357, "freeze_estimator_to_pb": 357, "bert_fp32": [357, 358], "tune_squad": [357, 358], "unstack": 357, "squadv1posttransform": 357, "result_list": 357, "3f": 357, "v2_7_0": 358, "fp32_bert_squad": 358, "872": 359, "ww42": 359, "path_to_save_dataset": 359, "max_seq": 359, "num_int": [359, 361], "inter_thread": [359, 361], "num_intra": [359, 361], "intra_thread": [359, 361], "bracket": [359, 361, 388], "data_loc": 359, "num_batch": 359, "ceil": 359, "generate_dataload": 359, "create_feed_dict_and_label": 359, "distilbert_bas": 359, "v2_2_0": 360, "transformer_lt_official_fp32_pretrained_model": 360, "prepare_dataset_model": 360, "transformer_lt": 360, "fp32_graphdef": 360, "inputs_fil": 360, "newstest2014": [360, 361], "reference_fil": 360, "getitem": [360, 361], "ref_lin": 360, "tensor2tensor": 360, "strided_slice_19": 360, "32768": 361, "file_out": 361, "output_translation_fil": 361, "bleu_vari": 361, "uniform": 361, "input_token": 361, "strided_slice_15": 361, "fastrcnn": 362, "protobuf": 362, "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03": 362, "xvzf": [362, 368], "faster_rcnn_inception_v2_coco_2018_01_28": 362, "faster_rcnn_resnet101_coco_2018_01_28": 362, "faster_rcnn_resnet50_fp32_coco_pretrained_model": 362, "mask_rcnn_inception_v2_coco_2018_01_28": 362, "ssd_resnet34_fp32_1200x1200_pretrained_model": 362, "data_graph": 362, "input_imag": 362, "get_input": 362, "data_sess": 362, "coco_num_val_imag": 362, "get_graph_def": 362, "output_lay": 362, "infer_graph": 362, "output_tensor": 362, "get_tensor_by_nam": 362, "input_lay": 362, "tensorflow_itex": 362, "featureextractor": 362, "resnet_v1_50": 362, "bottom_up_block5": 362, "weightsharedconvolutionalboxpredictor_2": 362, "classpredictiontow": 362, "conv2d_0": 362, "meanwhil": 362, "accuracy_check": 362, "mystic123": 363, "githubusercont": 363, "convert_weights_pb": 363, "weights_fil": 363, "data_format": 363, "nhwc": 363, "infer_detect": 363, "yolov3_fp32": 363, "yolov3_tuned3": 363, "oob": 364, "i3d": 364, "plate": 364, "vehicl": 364, "0123": 364, "ava": 364, "kitti": 364, "lowpropos": 364, "640x640": 364, "retinanet50": 364, "20200711": 364, "coco17": 364, "300x300": 364, "bs1": 364, "model_topologi": 364, "output_model_path": 364, "wide_deep_large_d": 365, "kaggl": 365, "large_vers": 365, "calib": [365, 366], "preprocess_csv_tfrecord": 365, "inputcsv": 365, "datafil": 365, "calibrationcsv": 365, "outputfil": 365, "processed_data": 365, "wide_deep_fp32_pretrained_model": 365, "wnd_int8_opt": 365, "3dunetcnn": 366, "raw_data": 366, "run_accuraci": 366, "calibrationset": 366, "semantic_image_segment": 367, "download_and_convert_voc2012": 367, "deeplabv3_pascal_train_aug_2018_01_04": 367, "export_model": 367, "checkpoint_path": 367, "deeplabv3_pascal_train_aug": 367, "export_path": 367, "deeplab_export": 367, "model_vari": 367, "xception_65": 367, "logtostderr": 367, "eval_split": 367, "atrous_r": 367, "output_strid": 367, "decoder_output_strid": 367, "eval_crop_s": 367, "513": 367, "pascal_voc_seg": 367, "nc_deeplab": 367, "vocrecord": 367, "parsedecodevoc": 367, "arbitrary_style_transf": 368, "styliz": 368, "magenta": 368, "style_tun": 368, "style_images_path": 368, "style_imag": 368, "content_images_path": 368, "content_imag": 368, "style_input": 368, "content_input": 368, "conv3": 368, "autocast": 370, "my_model": 370, "memory_format": 370, "channels_last": 370, "jupyterlab": [370, 374, 377, 381], "bench": [370, 386], "superbench": 370, "bc": [371, 378], "numactl": [371, 378], "conda_prefix": 371, "kmp_affin": 371, "dnnl_primitive_cache_capac": 371, "cpufreq": 371, "scaling_governor": 371, "powersav": 371, "neural_cod": [372, 373, 374], "pytorch_jit_script": [372, 375], "pytorch_channels_last": [372, 375], "run_bench": 372, "patch_path": 372, "your_patch_path": 372, "sweep": 372, "sweep_object": 372, "bench_config": 372, "bench_featur": 372, "inlin": 373, "run_glue_optim": 373, "static_ipex": 373, "stock": 374, "auto_qu": 374, "pytorch_amp": 375, "optimize_for_infer": 375, "pytorch_jit_trac": 375, "pytorch_jit_script_ofi": 375, "pytorch_jit_trace_ofi": 375, "torchdynamo": 375, "pytorch_torchdynamo_jit_script": 375, "pytorch_torchdynamo_jit_trac": 375, "pytorch_torchdynamo_jit_script_ofi": 375, "pytorch_torchdynamo_jit_trace_ofi": 375, "pytorch_inc_bf16": 375, "pytorch_inc_static_quant_fx": 375, "pytorch_inc_static_quant_ipex": 375, "pytorch_inc_dynamic_qu": 375, "pytorch_ipex_fp32": 375, "pytorch_ipex_bf16": 375, "pytorch_ipex_int8_static_qu": 375, "pytorch_ipex_int8_dynamic_qu": 375, "blade": 375, "disc": 375, "pytorch_aliblad": 375, "pytorch_lightning_bf16_cpu": 375, "tensorflow_amp": 375, "keras_amp": 375, "onnx_inc_static_quant_qlinear": 375, "ext": [377, 379, 381, 382], "nodej": [377, 381], "jlpm": [377, 381], "yarn": [377, 381], "npm": [377, 378, 381], "lieu": [377, 381], "labextens": [377, 378, 381], "typescript": [377, 381], "refresh": [377, 381], "rebuilt": [377, 381], "pyproject": [379, 382], "toml": [379, 382], "twine": [379, 382], "sdist": [379, 382], "bdist_wheel": [379, 382], "frontend": [379, 382, 385], "admin_github_token": [379, 382], "pypi_token": [379, 382], "npm_token": [379, 382], "changelog": [379, 382], "pkg": [379, 382], "feedstock": [379, 382], "hatch": 382, "stemblock": 383, "f_cat": 383, "denseblock1": 383, "denselayer1": 383, "denselayer2": 383, "denselayer3": 383, "denseblock2": 383, "denselayer4": 383, "denseblock3": 383, "denselayer5": 383, "denselayer6": 383, "denselayer7": 383, "denselayer8": 383, "denseblock4": 383, "denselay": 383, "workspace_path": 384, "configuration_id": 384, "localdisk": 384, "benchmark_start": [384, 388], "benchmark_progress": 384, "execution_detail": 384, "input_model_benchmark": 384, "config_path": [384, 388], "benchmark_script": 384, "benchmark_model": [384, 388], "perf_throughput_input_model": 384, "optimized_model_benchmark": 384, "perf_throughput_optimized_model": 384, "benchmark_finish": [384, 388], "autogener": [385, 386], "prebuild": 385, "outdat": 386, "4200": 387, "guard": 387, "prod": 387, "protractor": 387, "x2611": 388, "input_nod": 388, "output_nod": 388, "x2610": 388, "input1": 388, "input2": 388, "project_id": 388, "project1": 388, "created_at": 388, "tue": 388, "gmt": 388, "modified_at": 388, "domain_flavour": 388, "supports_graph": 388, "supports_profil": 388, "fri": 388, "metric_param": 388, "dataset_id": 388, "dataset_typ": 388, "calibration_batch_s": 388, "calibration_sampling_s": 388, "precision_id": 388, "optimization_type_id": 388, "optimization_id": 388, "optimization_typ": 388, "log_path": 388, "execution_command": 388, "tune_model": 388, "my_optimization_1": 388, "my_optim": 388, "last_run_at": 388, "accuracy_benchmark_id": 388, "performance_benchmark_id": 388, "tuning_detail": 388, "accuracy_criterion_typ": 388, "accuracy_criterion_threshold": 388, "tuning_histori": 388, "minimal_accuraci": 388, "6999299999999999": 388, "baseline_accuraci": 388, "baseline_perform": 388, "57273483276367": 388, "last_tune_accuraci": 388, "last_tune_perform": 388, "251153230667114": 388, "best_tune_accuraci": 388, "best_tune_perform": 388, "699": 388, "758240222930908": 388, "679": 388, "93209171295166": 388, "257209062576294": 388, "67054533958435": 388, "697": 388, "60370635986328": 388, "95270": 388, "cocorecord_50": 388, "optimize_model": 388, "my_graph_optimization_1": 388, "my_graph_optim": 388, "my_optimization_2": 388, "my_first_optim": 388, "my_first_optimization_2": 388, "request_id": 388, "asd": 388, "exit_cod": 388, "websocket": 388, "optimization_start": 388, "size_input_model": 388, "accuracy_criterion_valu": 388, "optimization_finish": 388, "optimization3": 388, "dataset2": 388, "1231": 388, "pin_accuracy_benchmark": 388, "benchmark_id": 388, "pin_performance_benchmark": 388, "warmup_iter": 388, "number_of_inst": 388, "template_path": 388, "mon": 388, "412": 388, "num_thread": 388, "profiling_id": 388, "tbodi": 388, "node_nam": 388, "total_execution_tim": 388, "accelerator_execution_tim": 388, "cpu_execution_tim": 388, "op_run": 388, "op_defin": 388, "node_a": 388, "117": 388, "node_b": 388, "node_c": 388, "node_d": 388, "185": 388, "profile_model": 388, "profiling_start": 388, "profiling_finish": 388, "micro": 388, "faster_rcnn_inception_resnet_v2": 388, "faster_rcnn_resnet101": 388, "progress_step": 388, "create_example_project_start": 388, "create_example_project_progress": 388, "download_start": 388, "download_progress": 388, "download_finish": 388, "create_example_project_finish": 388, "example_finish": 388, "boundary_nod": 388, "boundary_nodes_start": 388, "boundary_nodes_finish": 388, "placehold": 388, "attribute_typ": 388, "node_typ": 388, "node_group_resnet_model": 388, "resnet_model": 388, "group_nod": 388, "tidx": 388, "output_typ": 388, "is_support": 388, "show_dataset_loc": 388}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"type": [0, 167, 388], "chang": [0, 33, 49, 121, 126, 187], "descript": [0, 281, 324], "expect": 0, "behavior": [0, 187], "potenti": [0, 273], "risk": 0, "how": [0, 21, 32, 40, 73, 120, 123, 126, 136, 155, 156, 159, 160, 187, 251, 264, 269, 280, 284, 285, 288, 296, 309, 310, 311, 324], "ha": [0, 187], "thi": [0, 155, 296, 309, 310, 311], "pr": 0, "been": [0, 187], "test": [0, 155, 251, 314, 328, 366, 387], "depend": [0, 116, 139, 187, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 313, 354, 362, 363, 365, 368], "intel": [1, 18, 34, 54, 55, 66, 67, 68, 69, 70, 71, 131, 134, 135, 139, 147, 153, 290, 296, 298, 308, 309, 310, 311, 313, 329, 330, 333, 336, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 371, 378, 388], "neural": [1, 9, 12, 18, 34, 44, 50, 55, 66, 67, 68, 70, 71, 131, 134, 135, 139, 146, 147, 148, 150, 153, 290, 296, 298, 308, 309, 310, 311, 312, 313, 315, 323, 326, 327, 329, 330, 333, 334, 338, 354, 355, 356, 357, 359, 360, 361, 362, 363, 367, 368, 369, 370, 372, 374, 378, 388], "compressor": [1, 9, 18, 34, 50, 55, 66, 67, 68, 70, 71, 131, 134, 135, 139, 146, 147, 148, 150, 153, 290, 296, 298, 308, 309, 310, 311, 312, 313, 315, 323, 326, 327, 329, 330, 333, 334, 338, 354, 355, 356, 357, 359, 360, 361, 362, 363, 367, 368, 369, 378, 388], "instal": [1, 18, 26, 31, 35, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 116, 126, 131, 134, 135, 136, 138, 139, 140, 142, 143, 145, 146, 147, 148, 149, 150, 152, 153, 157, 158, 169, 186, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 312, 313, 315, 317, 319, 323, 326, 327, 328, 329, 330, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 371, 377, 378, 381], "prerequisit": [1, 35, 59, 66, 67, 68, 117, 118, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 152, 153, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 312, 313, 315, 323, 326, 327, 329, 330, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "linux": [1, 31, 35, 317], "get": [1, 24, 27, 31, 37, 38, 41, 42, 44, 46, 59, 70, 71, 126, 168, 248, 251, 308, 309, 311, 312, 323, 326, 334, 363, 370, 378, 388], "start": [1, 18, 24, 27, 31, 37, 38, 41, 42, 44, 46, 70, 71, 155, 168, 248, 290, 291, 292, 294, 296, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 313, 370, 373, 378], "quantiz": [1, 8, 11, 14, 15, 16, 17, 25, 28, 46, 47, 54, 56, 59, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 249, 290, 296, 298, 300, 308, 309, 310, 311, 312, 313, 323, 334, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 374], "python": [1, 12, 37, 139, 249, 290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 313, 370, 372, 373, 379, 382], "api": [1, 3, 4, 12, 15, 16, 24, 33, 37, 38, 41, 42, 44, 140, 370, 372], "jupyterlab": [1, 378], "extens": [1, 54, 147, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 370, 377, 378, 381], "gui": [1, 387], "system": [1, 18, 31, 43], "requir": [1, 31, 151, 187, 270, 306, 317, 328, 337, 338, 359, 377, 381], "valid": [1, 31, 48, 54, 136, 140, 328, 363], "hardwar": [1, 31, 54, 70, 71, 318], "environ": [1, 31, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 123, 130, 144, 159, 251, 285, 288, 303, 314, 371], "support": [1, 15, 17, 20, 22, 24, 26, 34, 37, 38, 39, 41, 42, 44, 46, 52, 69, 117, 156, 273, 276, 296, 309, 310, 311, 374, 375, 388], "cpu": [1, 54, 69, 116, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 371], "base": [1, 9, 70, 71, 152, 153, 179, 241, 246, 258, 261, 271, 281, 297, 312, 359], "64": 1, "architectur": [1, 12, 13, 23, 34, 121, 157, 187, 273, 276], "compat": 1, "processor": [1, 184], "gpu": [1, 116, 126, 186, 251, 319, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "built": [1, 9, 22, 33, 37], "": [1, 130, 282, 388], "xe": 1, "onnx": [1, 17, 54, 56, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 249], "model": [1, 13, 18, 31, 39, 40, 48, 53, 54, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 122, 126, 130, 134, 136, 137, 138, 139, 140, 145, 146, 147, 152, 153, 155, 157, 158, 159, 160, 167, 168, 169, 180, 182, 187, 207, 219, 240, 241, 242, 244, 247, 248, 249, 250, 256, 258, 260, 267, 269, 271, 280, 281, 283, 285, 286, 287, 288, 290, 291, 293, 294, 296, 298, 299, 302, 304, 308, 309, 310, 311, 312, 313, 314, 315, 318, 319, 323, 325, 326, 328, 329, 330, 333, 334, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 374, 385, 388], "multipl": [1, 41, 54, 186, 257, 273], "vendor": 1, "through": [1, 54], "runtim": [1, 17, 54, 56, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "softwar": [1, 31, 318], "document": [1, 16, 27, 31, 140, 158, 272, 369], "select": [1, 378], "public": [1, 45, 314], "event": [1, 45], "addit": [1, 165, 253, 285, 288, 365, 368], "content": [1, 18, 126, 136, 168, 388], "hire": 1, "secur": [2, 18, 26], "polici": 2, "report": [2, 251], "vulner": 2, "refer": [3, 17, 48, 59, 136, 295, 305, 306], "benchmark": [5, 16, 18, 19, 66, 68, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 114, 115, 117, 151, 160, 255, 308, 309, 311, 312, 314, 319, 323, 326, 329, 330, 333, 334, 355, 356, 357, 358, 359, 361, 364, 367, 368, 384, 388], "object": [6, 41, 68, 136, 308], "prune": [7, 16, 44, 54, 56, 142, 143, 269, 292, 294, 301, 302, 303, 304, 306, 337, 338, 351], "build": [9, 30, 37, 158, 387], "inc": [9, 329, 330, 333], "contain": 9, "To": [9, 156, 251, 308, 309, 311, 312, 323, 326, 334], "pip": [9, 130, 140, 157, 169], "deploy": [9, 169, 186], "develop": [9, 18, 27, 31, 155, 377, 381, 387], "check": [9, 69, 70, 71, 240, 368], "contributor": [10, 20, 136, 154, 332], "coven": [10, 20, 154], "code": [10, 12, 20, 66, 67, 68, 70, 71, 131, 134, 135, 139, 145, 146, 147, 148, 150, 153, 154, 158, 248, 290, 295, 296, 298, 305, 306, 308, 309, 310, 311, 313, 315, 327, 329, 330, 331, 332, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 387], "conduct": [10, 20, 154, 331], "our": [10, 20, 151, 154], "pledg": [10, 20, 154], "standard": [10, 20, 154, 187, 249], "respons": [10, 20, 154], "scope": [10, 20, 154], "enforc": [10, 20, 154], "attribut": [10, 20, 154, 187, 314], "fx": 11, "overview": [11, 159, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 285, 287, 288], "usag": [11, 12, 13, 14, 51, 53, 72, 126, 130, 184, 195, 224, 233, 263, 275, 286, 295, 296, 305, 309, 310, 311, 374], "note": [11, 69, 144, 169, 186, 190, 195, 209, 219, 224, 254, 319, 324, 388], "detail": [11, 18, 117, 285, 288, 356, 357, 359, 360, 361, 362, 368, 388], "common": [11, 30], "problem": [11, 314], "dynam": [11, 12, 28, 46, 73, 96, 273, 323, 334], "static": [11, 46, 73, 96], "awar": [11, 14, 46, 312, 326], "train": [11, 14, 26, 46, 59, 66, 124, 126, 136, 138, 148, 217, 220, 228, 232, 251, 253, 254, 256, 258, 261, 264, 268, 273, 276, 277, 281, 312, 314, 318, 319, 323, 326, 328, 334, 337, 351, 354, 355, 364, 366, 367], "search": [12, 258], "introduct": [12, 15, 16, 18, 24, 25, 26, 32, 34, 37, 38, 39, 40, 41, 42, 44, 46, 50, 51, 53, 55, 58, 59, 60, 61, 62, 63, 64, 65, 69, 70, 71, 118, 252, 383], "na": 12, "basic": [12, 53, 240], "1": [12, 18, 26, 30, 33, 35, 54, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 152, 153, 154, 159, 187, 285, 288, 290, 293, 296, 298, 306, 308, 309, 310, 311, 312, 313, 314, 315, 317, 319, 323, 326, 327, 329, 330, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "yaml": [12, 19, 21, 25, 26, 58, 59, 60, 62, 63, 66, 67, 68, 131, 134, 135, 139, 146, 147, 148, 150, 153, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "2": [12, 18, 30, 33, 35, 54, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 152, 153, 154, 159, 164, 165, 187, 241, 244, 253, 256, 277, 285, 288, 290, 293, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 310, 311, 312, 314, 315, 317, 323, 326, 327, 329, 330, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "onli": [12, 142, 251, 317], "advanc": [12, 27, 168], "custom": [12, 18, 37, 41, 53, 59, 70, 71, 165, 172, 248, 276, 319, 328], "exampl": [12, 13, 14, 15, 19, 24, 25, 26, 29, 31, 32, 38, 39, 41, 42, 44, 46, 48, 51, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 72, 116, 122, 124, 126, 127, 128, 129, 131, 132, 134, 135, 139, 140, 146, 147, 148, 149, 150, 153, 184, 190, 191, 219, 224, 244, 254, 270, 271, 275, 277, 284, 290, 295, 298, 305, 306, 308, 312, 313, 315, 323, 326, 327, 328, 329, 330, 333, 334, 354, 355, 367, 374, 384, 388], "ptq": [13, 54, 142], "design": [13, 14, 23, 51, 53], "pytorch": [13, 17, 22, 37, 47, 51, 52, 54, 56, 70, 130, 131, 134, 135, 136, 137, 140, 146, 147, 148, 150, 153, 165, 172, 181, 187, 253, 273, 277, 290, 293, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 319, 327, 328], "mobilenetv2": [13, 148], "helper": [13, 168, 172], "function": [13, 26, 148, 172, 179, 314, 322], "adaptor": 15, "layer": [15, 24, 172, 234, 314], "work": [15, 46, 140, 159, 240, 285, 288], "flow": [15, 46], "summari": [15, 140, 241, 250, 252], "queri": 15, "background": [15, 70, 71], "unifi": 15, "config": [15, 19, 21, 41, 60, 66, 67, 68, 131, 134, 135, 139, 146, 147, 148, 150, 153, 287, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 320, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "ad": [15, 158, 319], "new": [15, 18, 53, 126, 130, 155, 158, 274, 284, 379, 382], "backend": 15, "capabl": 15, "implement": [15, 155, 190, 195, 209, 219, 224, 251, 292, 300, 301], "onnxrtadaptor": 15, "class": [15, 168, 183, 189, 328, 363], "pre": [15, 66, 246, 279, 323, 334, 354, 355, 364, 366, 367, 378], "optim": [15, 18, 32, 42, 181, 186, 187, 249, 314, 341, 375, 388], "set": [15, 117, 123, 136, 140, 321, 328, 366, 371], "tune": [15, 32, 46, 53, 66, 67, 68, 131, 134, 135, 146, 147, 148, 150, 152, 153, 165, 233, 253, 257, 258, 269, 270, 271, 277, 290, 291, 294, 296, 298, 299, 302, 304, 308, 309, 310, 311, 312, 313, 315, 323, 326, 327, 329, 330, 333, 334, 354, 355, 356, 357, 358, 359, 361, 364, 367, 368], "do": [15, 126, 155, 169, 370], "user": [16, 19, 21, 22, 25, 26, 33, 66, 67, 68, 131, 134, 135, 139, 146, 147, 148, 150, 153, 290, 298, 308, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368], "face": [16, 33, 75, 282], "experiment": [16, 251, 273, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "relat": [16, 53], "poc": 16, "default": [16, 32, 187], "matrix": [17, 24, 34, 37, 38, 39, 41, 42, 44, 46], "tensorflow": [17, 22, 37, 47, 51, 52, 54, 56, 71, 164, 165, 172, 181, 253, 257, 258, 277, 279, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "ipex": [17, 116], "mxnet": [17, 22, 37, 52, 54, 66, 67, 68, 138], "bench": [18, 372, 388], "tabl": [18, 126, 136, 254, 388], "option": [18, 26, 35, 159, 285, 288, 317, 373], "from": [18, 31, 35, 93, 126, 140, 169, 187, 319, 357, 388], "binari": [18, 31, 35], "sourc": [18, 31, 35, 158, 169, 251, 272], "home": 18, "screen": 18, "creat": [18, 21, 126, 285, 288, 321, 388], "project": [18, 259, 319, 388], "predefin": [18, 385], "displai": 18, "graph": [18, 32, 388], "list": [18, 22, 52, 251, 314, 388], "remov": [18, 187], "tab": 18, "wizard": 18, "edit": [18, 169, 388], "entri": [18, 281], "profil": [18, 388], "diagnosi": 18, "dataset": [18, 22, 33, 58, 60, 62, 63, 66, 67, 68, 96, 97, 98, 99, 100, 102, 103, 104, 105, 120, 124, 126, 131, 134, 135, 136, 139, 141, 142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 165, 273, 279, 293, 298, 303, 306, 314, 315, 319, 321, 323, 324, 325, 326, 327, 328, 329, 330, 333, 334, 335, 345, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 388], "inform": [18, 36, 59, 323, 334], "evalu": [19, 26, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 140, 175, 260, 272, 273, 276, 314, 360, 361, 362, 368], "file": [19, 21, 66, 67, 68, 70, 71, 131, 134, 135, 139, 146, 147, 148, 150, 153, 240, 251, 276, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "us": [19, 21, 32, 40, 59, 73, 116, 120, 121, 140, 157, 159, 165, 168, 187, 240, 246, 248, 249, 264, 272, 281, 285, 286, 288, 308, 319, 363], "specif": [19, 21, 22, 53, 158, 183, 188, 192, 205, 206, 210, 211, 212, 216, 217, 218, 221, 226, 227, 233, 234, 236, 239, 251, 325, 388], "dataload": [19, 21, 59, 60, 388], "run": [19, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 118, 126, 131, 134, 135, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 159, 169, 251, 254, 257, 277, 279, 285, 288, 292, 293, 297, 300, 301, 306, 312, 314, 315, 320, 323, 324, 325, 326, 327, 329, 330, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 367, 368, 387], "contribut": [20, 155, 274, 332, 377, 381], "guidelin": [20, 154], "pull": [20, 155, 158, 332], "request": [20, 155, 156, 158, 332, 384], "checklist": [20, 155], "templat": [20, 285, 295, 305], "onnxrt": [22, 37, 52], "workflow": [23, 240, 273], "distil": [24, 25, 54, 56, 127, 128, 129, 151, 152, 153, 264, 273, 275, 291, 299, 300, 306], "knowledg": [24, 54, 272, 273], "intermedi": 24, "self": [24, 151, 217, 228], "defin": [25, 26, 59, 158, 258, 328], "distribut": [26, 116, 132, 144, 149, 175, 251, 254, 258, 374], "infer": [26, 116, 117, 119, 121, 122, 126, 233, 249, 261, 269, 297, 319, 325, 328], "horovod": [26, 138], "pure": 26, "configur": [26, 43, 50, 53, 126, 144, 177, 186, 306, 314, 385], "option2": 26, "horovodrun": 26, "follow": [26, 323, 334], "ar": [26, 187, 251], "deep": [27, 69], "dive": 27, "topic": [27, 275], "frequent": 30, "ask": 30, "question": [30, 98, 165, 250, 265], "issu": [30, 49, 155, 156, 273, 332], "3": [30, 35, 58, 59, 60, 61, 62, 63, 64, 65, 67, 134, 142, 143, 145, 146, 147, 148, 150, 152, 153, 154, 159, 187, 293, 306, 312, 314, 323, 326, 327, 329, 330, 333, 334, 336, 337, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "ai": [31, 35, 70, 71], "kit": [31, 35], "window": [31, 35, 155], "fp32": [32, 58, 59, 60, 61, 62, 63, 65, 69], "auto": [32, 47, 66, 67, 68, 131, 134, 135, 146, 147, 148, 150, 153, 189, 312, 315, 323, 327, 334, 354, 355, 367, 378], "mix": [32, 38, 47, 186, 254, 277], "precis": [32, 38, 47, 186, 254, 277, 388], "incompat": [33, 49], "between": 33, "v1": [33, 110, 114, 354, 355], "transform": [33, 52, 155, 157, 159, 160, 164, 168, 169, 187, 210, 234, 241, 244, 249, 251, 282, 284, 285, 288, 290, 298, 308, 313, 360, 388], "metric": [33, 37, 59, 140, 165, 314], "infrastructur": 34, "featur": [34, 46, 140, 155, 168, 178, 251, 273, 374, 375, 378], "legal": 36, "licens": [36, 70, 71, 117, 319, 332], "citat": [36, 133, 157, 261, 263, 264, 269, 273, 281, 319], "trademark": 36, "singl": [37, 41, 140, 319], "multi": [37, 42, 126, 158, 219, 242, 319], "framework": [39, 240, 388], "convers": [40, 120, 126], "orchestr": [42, 56], "One": 42, "shot": [42, 275], "network": [44, 121], "pattern": 44, "criteria": 44, "schedul": [44, 142, 143, 181, 186, 187], "full": [45, 126, 241, 363], "44": 45, "2022": 45, "26": 45, "2021": 45, "14": [45, 159, 354], "2018": 45, "2020": [45, 130], "4": [45, 58, 59, 60, 61, 62, 63, 64, 65, 142, 143, 145, 146, 148, 154, 159, 187, 314, 323, 334, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368], "fundament": [46, 285, 288], "approach": [46, 271, 357, 362, 368], "post": 46, "accuraci": [46, 140, 308, 309, 311, 312, 318, 323, 326, 334, 388], "turn": 47, "ON": 47, "dure": [47, 143], "releas": [49, 379, 382], "known": 49, "sigopt": [50, 53], "strategi": [50, 53, 181, 312, 323, 326, 334], "prepar": [50, 58, 59, 60, 62, 63, 64, 66, 68, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 131, 134, 135, 136, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 159, 240, 264, 279, 285, 288, 290, 293, 296, 297, 298, 303, 308, 309, 310, 311, 312, 313, 315, 323, 327, 329, 330, 333, 334, 335, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 360, 361, 362, 363, 364, 365, 366, 367, 368], "perform": [50, 69, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 260, 270, 319, 371, 388], "benefit": 50, "comparison": [50, 318], "differ": [50, 121], "tensorboard": [51, 328], "part": [53, 359, 360, 361, 362, 368], "bayesian": 53, "mse": [53, 308], "tpe": 53, "exhaust": 53, "random": [53, 251], "mlperf": [54, 93, 117], "10": [54, 351, 354, 355], "0": [54, 66, 68, 165, 258, 277, 319, 335, 351, 352, 354], "torch": [54, 136], "12": [54, 130, 354, 355], "mode": 54, "qat": [54, 143, 149, 341], "11": [54, 354, 355, 359], "7": [54, 354, 355, 362, 363, 365, 366], "qdq": [54, 73], "int8": [54, 69], "helloworld": [56, 59], "notebook": [56, 70, 71, 162, 186, 240, 282, 319], "hello": 57, "world": 57, "tf_example1": 58, "download": [58, 61, 62, 63, 65, 169, 279, 308, 309, 311, 312, 314, 326, 328, 356, 357, 358, 359, 360, 362, 363, 365, 366], "updat": [58, 62, 63, 66, 67, 68, 131, 134, 135, 139, 145, 146, 148, 150, 153, 187, 280, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 368], "root": [58, 62, 63], "conf": [58, 59, 60, 62, 63], "5": [58, 59, 60, 62, 63, 130, 145, 146, 159, 187, 314, 341, 345, 354, 355, 356, 357, 358, 359, 362, 363, 364, 365, 366, 367, 368], "command": [58, 59, 60, 61, 62, 63, 64, 65, 117, 138, 258, 271, 290, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 356, 357, 358, 359, 360, 361, 362, 363, 365, 366, 368], "6": [58, 60, 62, 63, 145, 354, 355, 362, 363, 365, 366, 368], "tf_example2": 59, "step": [59, 66, 67, 68, 69, 72, 131, 134, 135, 139, 142, 143, 145, 146, 147, 148, 150, 152, 153, 159, 240, 279, 285, 288, 290, 291, 292, 293, 294, 296, 297, 298, 299, 300, 301, 302, 304, 306, 308, 309, 310, 311, 312, 313, 314, 315, 317, 321, 323, 326, 327, 329, 330, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368], "add": [59, 159, 240, 284, 285, 288, 388], "input": [59, 167, 187, 246, 249], "output": [59, 171, 182, 187, 188, 192, 205, 206, 210, 211, 212, 216, 217, 218, 221, 226, 227, 233, 234, 236, 239, 251, 273, 323, 334], "tensor": [59, 73, 145, 146], "name": [59, 219, 250, 251, 285, 320, 363], "pleas": 59, "py": [59, 320], "mnist": [59, 86, 132], "data": [59, 119, 126, 138, 173, 246, 264, 273, 279, 281, 314, 363], "loader": 59, "tf_example3": 60, "tf_example4": 61, "tf_example5": 62, "tf_example6": 63, "tf_example7": 64, "tf_example8": 65, "resnet18_v1": 66, "resnet50_v1": [66, 68], "resnet152_v1": 66, "squeezenet1": 66, "mobilenet1": [66, 68], "mobilenetv2_1": 66, "inception_v3": [66, 355], "enabl": [66, 67, 68, 131, 134, 135, 139, 146, 147, 148, 150, 153, 290, 296, 298, 308, 309, 310, 311, 312, 313, 315, 323, 326, 327, 329, 330, 333, 334, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368, 372, 378], "resnet50": [66, 69, 145, 146, 147, 148, 150, 354], "analysi": [66, 67, 68, 131, 134, 135, 139, 146, 147, 148, 150, 153, 290, 298, 308, 313, 315, 327, 329, 330, 333, 354, 355, 356, 357, 359, 360, 361, 362, 367, 368], "write": [66, 67, 68, 131, 134, 135, 139, 146, 147, 148, 150, 153, 158, 251, 290, 295, 296, 298, 305, 308, 309, 310, 311, 313, 315, 327, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 354, 355, 356, 357, 358, 359, 360, 361, 362, 367, 368], "finetun": [67, 116, 272, 273, 290, 319], "bert_bas": 67, "mrpc": [67, 152, 153, 305], "squad": [67, 165, 184, 258, 291, 292, 294, 295], "ssd": [68, 109, 110, 114, 115, 325], "voc": [68, 321], "coco": [68, 136, 319, 321, 324, 328, 363], "detect": [68, 75, 136], "v": [69, 241], "learn": [69, 136, 155, 157, 181], "boost": 69, "setup": [69, 70, 71, 262, 264, 269, 271, 325], "script": [69, 273, 277, 279, 284], "activ": 69, "sampl": [69, 70, 71], "result": [69, 70, 71, 133, 136, 140, 151, 251, 255, 258, 261, 295, 300, 305, 306, 388], "devcloud": [70, 71], "oneapi": [70, 71], "analyt": [70, 71], "toolkit": [70, 71], "jupyt": [70, 71, 319, 370, 379, 382], "ssh": [70, 71], "login": [70, 71], "job": [70, 71], "submit": [70, 71, 155], "statu": [70, 71], "log": [70, 71, 179, 254, 328], "png": [70, 71], "server": [70, 71, 387], "pypi": [70, 71, 136, 374], "conda": [70, 71, 157, 169, 379, 382], "oper": 73, "orient": 73, "qlinearop": 73, "format": [73, 119, 138, 173, 321], "emot": 74, "ferplu": 74, "ultra": 75, "lightweight": 75, "mobilenet": [76, 77, 87, 110, 114, 115, 354], "v2": [76, 115, 202, 351, 354], "v3": [77, 187, 354, 363], "alexnet": 78, "arcfac": 79, "caffenet": 80, "densenet": [81, 354], "efficientnet": [82, 130, 354], "lite4": 82, "fcn": 83, "googlenet": 84, "incept": [85, 140, 354, 355], "resnet": [88, 93, 131, 134, 140, 146, 147, 148, 150, 315, 351, 354], "50": [88, 93, 220, 354], "shufflenet": 89, "squeezenet": 90, "vgg16": [91, 95, 355], "zfnet": 92, "torchvis": [93, 140], "unet": 94, "bert": [96, 102, 152, 153, 164, 187, 192, 214, 241, 242, 256, 258, 263, 293, 296, 297, 309, 310, 311, 312, 356, 357], "distilbert": [97, 204, 241, 256, 264, 297, 359], "huggingfac": [98, 99, 155, 280, 308, 309, 311, 312], "answer": [98, 165, 250, 265], "text": [99, 250, 262, 271, 277], "classif": [99, 165, 250, 275, 277, 279], "mobilebert": [100, 104, 221], "bidaf": 101, "gpt2": [103, 212], "roberta": [105, 230, 238, 241, 242, 256], "resnet101": [106, 354], "duc": 106, "faster": [107, 318, 319], "r": [107, 108, 318, 319], "cnn": [107, 108, 273, 318, 319], "mask": [108, 167, 190, 250, 256, 267, 318, 319], "tini": 111, "yolov3": [111, 112, 327, 328], "yolov4": 113, "A": [116, 264], "textual": 116, "invers": 116, "method": [116, 158, 269], "person": 116, "text2imag": 116, "nezha": 116, "cartoon": 116, "acceler": 116, "medic": 117, "imag": [117, 317, 328], "3d": [117, 124, 126], "segment": [117, 136, 320], "disclaim": 117, "calibr": [117, 366], "cmd": [118, 365], "baselin": [118, 318, 319], "instruct": 120, "decathlon": 120, "extend": [121, 126], "nnu": [121, 122, 126], "net": [121, 122, 124, 126], "blueprint": 121, "paramet": [121, 258, 269, 324], "pretrain": [122, 126, 130, 134, 136, 137, 138, 140, 141, 152, 153, 159, 187, 247, 248, 262, 281, 285, 288, 290, 293, 298, 308, 309, 310, 311, 328, 329, 330, 333, 336, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 353, 356, 357, 358, 360, 368], "up": [123, 321], "path": [123, 363], "variabl": [123, 251, 371], "an": [123, 144, 328], "altern": 123, "wai": [123, 155], "u": [124, 126, 378], "hippocampu": 124, "experi": [126, 254], "plan": 126, "preprocess": [126, 246, 281, 314], "2d": 126, "resolut": 126, "cascad": 126, "low": 126, "identifi": 126, "best": [126, 160, 371, 378], "faq": 126, "manual": [126, 357, 362, 363, 368, 379, 382], "split": 126, "i": [126, 155, 157, 187, 214, 264, 296, 309, 310, 311, 323, 334], "need": 126, "alwai": [126, 187, 246], "all": [126, 240, 251, 292, 301, 388], "share": [126, 159, 160, 186, 240, 285, 288], "can": [126, 155], "smaller": 126, "error": [126, 320], "seg": 126, "prev": 126, "stage": 126, "miss": 126, "when": [126, 320], "why": [126, 157], "am": 126, "runtimeerror": 126, "cuda": [126, 317], "devic": [126, 169], "side": 126, "assert": 126, "trigger": 126, "3d_lowr": 126, "cifar100": [127, 129, 151], "cifar10": 128, "gener": [130, 158, 159, 167, 170, 171, 180, 250, 271, 274, 277, 278, 285, 286, 288, 363], "what": [130, 264, 280, 370], "april": 130, "march": 130, "23": 130, "feb": 130, "jan": 130, "22": 130, "nov": 130, "2019": [130, 366], "15": [130, 354], "oct": 130, "30": 130, "27": 130, "port": [130, 140, 159, 285, 288], "weight": [130, 249, 254, 314, 315, 319, 327, 328, 363], "hub": [130, 240, 308, 309, 311, 312], "export": [130, 249], "efficientnet_b0": 131, "mobilenetv3_rw": 131, "peleenet": 133, "imagenet": [133, 136, 138, 140], "ilsvrc": 133, "2012": 133, "resnest50": 135, "resnest": [135, 136, 138, 153], "github": [136, 156], "gluon": [136, 137, 138], "transfer": [136, 368], "detectron": [136, 318, 319], "m": 136, "instanc": 136, "panopt": 136, "semant": 136, "ade20k": 136, "cityscap": [136, 321], "verifi": [136, 138], "backbon": 136, "major": 136, "recordio": 138, "first": [139, 293], "se_resnext": 139, "se_resnext50_32x4d": 139, "origin": [139, 159, 241, 285, 288, 293], "readm": [139, 293], "progress": [140, 251], "repo": [140, 187, 280], "quick": [140, 157, 248, 373], "few": [140, 319], "case": [140, 312], "comput": 140, "logit": 140, "reproduc": [140, 251, 262], "avail": [140, 176, 274], "nasnet": [140, 354], "facebook": 140, "caff": 140, "bnincept": 140, "resnext": 140, "dualpathnetwork": 140, "xception": 140, "senet": 140, "pnasnet": 140, "polynet": 140, "input_s": 140, "input_spac": 140, "input_rang": 140, "mean": 140, "std": 140, "forward": [140, 167], "last_linear": 140, "hand": 140, "resnet152": 140, "automat": [140, 186, 251, 356, 357, 358, 360, 362, 363], "inceptionv4": 140, "inceptionresnetv2": 140, "acknowledg": 140, "non": 144, "other": [144, 170, 179, 241, 269, 338, 365], "resnet18": [145, 146, 147, 148, 150], "resnext101_32x8d": [145, 146, 148, 150], "inceptionv3": [145, 146], "mobilenet_v2": [145, 146], "dump": [145, 146, 320], "debug": [145, 146, 251, 285, 288], "save": [145, 146, 147, 249, 274, 315, 337, 351], "load": [145, 146, 249, 315], "With": [147, 148, 157, 169], "resnext101_32x16d": 147, "Of": [148, 150, 327], "On": [148, 150, 327], "buildin": 148, "without": [148, 242], "paper": 151, "blendcnn": [152, 153], "teacher": [152, 153, 273], "fine": [152, 153, 165, 233, 253, 257, 258, 269, 270, 277, 312], "correct": 154, "warn": 154, "temporari": [154, 251], "ban": 154, "perman": 154, "you": [155, 169, 246, 285, 288, 378], "so": [155, 187], "mani": 155, "did": 155, "find": 155, "bug": 155, "want": [155, 169, 246], "style": [155, 219, 332, 368], "guid": [155, 168], "wa": 155, "heavili": 155, "inspir": 155, "awesom": 155, "scikit": 155, "sync": 155, "fork": 155, "master": 155, "upstream": [155, 308, 309, 311, 312], "The": [156, 183, 187, 254, 323, 334, 365], "forum": 156, "onlin": [157, 251], "demo": [157, 266, 319], "tour": [157, 248], "should": 157, "shouldn": 157, "t": 157, "more": [157, 241, 285, 288], "packag": [158, 187, 354, 362, 363, 365, 368, 377, 379, 381, 382], "element": 158, "tree": 158, "toc": 158, "preview": 158, "tutori": [158, 296, 309, 310, 311], "argument": [158, 173, 187, 373], "line": [158, 319], "block": 158, "return": 158, "token": [159, 165, 167, 174, 185, 187, 246, 248, 252, 279, 285, 287, 288], "recip": [159, 285, 288], "theoret": [159, 285, 288], "aspect": [159, 241, 285, 288], "brandnewbert": 159, "next": [159, 285, 288], "your": [159, 160, 240, 272, 273, 285, 288, 319], "checkpoint": [159, 164, 224, 273, 285, 288, 357], "repositori": [159, 285, 288], "practic": 160, "bertologi": 161, "commun": [162, 282], "resourc": [162, 165, 186, 253, 285, 288], "convert": [164, 273, 283, 321], "albert": [164, 188, 241], "openai": [164, 211, 212], "gpt": [164, 211, 241, 244, 256], "xl": [164, 234, 241], "xlnet": [164, 239, 241, 256, 258, 310], "xlm": [164, 236, 237, 238, 241, 242], "t5": [164, 232, 241], "sequenc": [165, 241, 250, 273, 276], "imdb": [165, 268], "review": 165, "trainer": [165, 175, 186, 253, 258], "nativ": [165, 253], "w": 165, "nut": 165, "emerg": 165, "entiti": [165, 250], "nlp": [165, 296, 309, 310, 311], "librari": [165, 320], "glossari": 167, "term": 167, "id": 167, "attent": [167, 217, 228, 241], "posit": [167, 187, 228, 258], "label": [167, 273, 274], "decod": [167, 207], "feed": 167, "chunk": 167, "research": [168, 259], "main": [168, 186, 245], "intern": [168, 175, 234], "cach": 169, "continu": 169, "integr": [169, 186], "larg": [169, 258, 297], "scale": 169, "mobil": [169, 354], "util": [170, 171, 172, 173, 174, 175, 322], "enum": [170, 174], "namedtupl": [170, 174], "special": 170, "decor": 170, "properti": 170, "greedysearchoutput": 171, "sampleoutput": 171, "beamsearchoutput": 171, "beamsampleoutput": 171, "logitsprocessor": 171, "beamsearch": 171, "modul": [172, 251, 320], "loss": [172, 314], "pipelin": [173, 183, 187, 248], "handl": 173, "pretrainedtokenizerbas": 174, "specialtokensmixin": 174, "callback": [175, 176], "trainercallback": 176, "trainerst": 176, "trainercontrol": 176, "pretrainedconfig": 177, "extractor": 178, "pretrainedfeatureextractor": 178, "batchfeatur": 178, "setter": 179, "pretrainedmodel": 180, "moduleutilsmixin": 180, "tfpretrainedmodel": 180, "tfmodelutilsmixin": 180, "flaxpretrainedmodel": 180, "adamw": [181, 187], "adafactor": 181, "adamweightdecai": 181, "rate": 181, "warmup": 181, "gradient": [181, 186], "gradientaccumul": 181, "modeloutput": 182, "basemodeloutput": 182, "basemodeloutputwithpool": 182, "basemodeloutputwithcrossattent": 182, "basemodeloutputwithpoolingandcrossattent": 182, "basemodeloutputwithpast": 182, "basemodeloutputwithpastandcrossattent": 182, "seq2seqmodeloutput": 182, "causallmoutput": 182, "causallmoutputwithcrossattent": 182, "causallmoutputwithpast": 182, "maskedlmoutput": 182, "seq2seqlmoutput": 182, "nextsentencepredictoroutput": 182, "sequenceclassifieroutput": 182, "seq2seqsequenceclassifieroutput": 182, "multiplechoicemodeloutput": 182, "tokenclassifieroutput": 182, "questionansweringmodeloutput": 182, "seq2seqquestionansweringmodeloutput": 182, "tfbasemodeloutput": 182, "tfbasemodeloutputwithpool": 182, "tfbasemodeloutputwithpast": 182, "tfseq2seqmodeloutput": 182, "tfcausallmoutput": 182, "tfcausallmoutputwithpast": 182, "tfmaskedlmoutput": 182, "tfseq2seqlmoutput": 182, "tfnextsentencepredictoroutput": 182, "tfsequenceclassifieroutput": 182, "tfseq2seqsequenceclassifieroutput": 182, "tfmultiplechoicemodeloutput": 182, "tftokenclassifieroutput": 182, "tfquestionansweringmodeloutput": 182, "tfseq2seqquestionansweringmodeloutput": 182, "abstract": [183, 316, 319], "task": [183, 248, 250, 254, 290, 291, 292, 294, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311], "conversationalpipelin": 183, "featureextractionpipelin": 183, "fillmaskpipelin": 183, "nerpipelin": 183, "questionansweringpipelin": 183, "summarizationpipelin": 183, "tablequestionansweringpipelin": 183, "textclassificationpipelin": 183, "textgenerationpipelin": 183, "text2textgenerationpipelin": 183, "tokenclassificationpipelin": 183, "translationpipelin": 183, "zeroshotclassificationpipelin": 183, "parent": 183, "glue": [184, 290, 305, 308, 309, 310, 311], "xnli": [184, 277], "pretrainedtoken": 185, "pretrainedtokenizerfast": 185, "batchencod": 185, "seq2seqtrain": 186, "tftrainer": 186, "trainingargu": 186, "seq2seqtrainingargu": 186, "tftrainingargu": 186, "fairscal": 186, "deepspe": 186, "one": [186, 363], "zero": [186, 275], "accumul": 186, "clip": 186, "migrat": [187, 386], "previou": 187, "x": 187, "v4": [187, 354], "autotoken": [187, 189], "now": [187, 280], "fast": 187, "rust": 187, "obtain": 187, "same": 187, "sentencepiec": [187, 252], "each": [187, 251, 280], "resid": 187, "its": [187, 251, 308, 309, 311, 312, 323, 326, 334], "folder": [187, 328], "switch": 187, "return_dict": 187, "true": 187, "some": 187, "deprec": 187, "order": [187, 251, 314], "keyword": 187, "attention_mask": 187, "token_type_id": 187, "tupl": 187, "serial": 187, "bertadam": 187, "openaiadam": 187, "albertconfig": 188, "alberttoken": 188, "alberttokenizerfast": 188, "albertmodel": 188, "albertforpretrain": 188, "albertformaskedlm": 188, "albertforsequenceclassif": 188, "albertformultiplechoic": 188, "albertfortokenclassif": 188, "albertforquestionansw": 188, "tfalbertmodel": 188, "tfalbertforpretrain": 188, "tfalbertformaskedlm": 188, "tfalbertforsequenceclassif": 188, "tfalbertformultiplechoic": 188, "tfalbertfortokenclassif": 188, "tfalbertforquestionansw": 188, "autoconfig": 189, "automodel": 189, "automodelforpretrain": 189, "automodelforcausallm": 189, "automodelformaskedlm": 189, "automodelforseq2seqlm": 189, "automodelforsequenceclassif": 189, "automodelformultiplechoic": 189, "automodelfornextsentencepredict": 189, "automodelfortokenclassif": 189, "automodelforquestionansw": 189, "automodelfortablequestionansw": 189, "tfautomodel": 189, "tfautomodelforpretrain": 189, "tfautomodelforcausallm": 189, "tfautomodelformaskedlm": 189, "tfautomodelforseq2seqlm": 189, "tfautomodelforsequenceclassif": 189, "tfautomodelformultiplechoic": 189, "tfautomodelfortokenclassif": 189, "tfautomodelforquestionansw": 189, "flaxautomodel": 189, "bart": [190, 241], "fill": 190, "bartconfig": 190, "barttoken": 190, "barttokenizerfast": 190, "bartmodel": 190, "bartforconditionalgener": 190, "bartforsequenceclassif": 190, "bartforquestionansw": 190, "bartforcausallm": 190, "tfbartmodel": 190, "tfbartforconditionalgener": 190, "barthez": 191, "bartheztoken": 191, "bartheztokenizerfast": 191, "bertconfig": 192, "berttoken": 192, "berttokenizerfast": 192, "bertmodel": 192, "bertforpretrain": 192, "bertmodellmheadmodel": 192, "bertformaskedlm": 192, "bertfornextsentencepredict": 192, "bertforsequenceclassif": 192, "bertformultiplechoic": 192, "bertfortokenclassif": 192, "bertforquestionansw": 192, "tfbertmodel": 192, "tfbertforpretrain": 192, "tfbertmodellmheadmodel": 192, "tfbertformaskedlm": 192, "tfbertfornextsentencepredict": 192, "tfbertforsequenceclassif": 192, "tfbertformultiplechoic": 192, "tfbertfortokenclassif": 192, "tfbertforquestionansw": 192, "flaxbertmodel": 192, "flaxbertformaskedlm": 192, "bertgener": 193, "bertgenerationconfig": 193, "bertgenerationtoken": 193, "bertgenerationencod": 193, "bertgenerationdecod": 193, "bertweet": 194, "bertweettoken": 194, "blenderbot": [195, 196], "blenderbotconfig": 195, "blenderbottoken": 195, "blenderbotmodel": 195, "blenderbotforconditionalgener": 195, "blenderbotforcausallm": 195, "tfblenderbotmodel": 195, "tfblenderbotforconditionalgener": 195, "small": 196, "blenderbotsmallconfig": 196, "blenderbotsmalltoken": 196, "blenderbotsmallmodel": 196, "blenderbotsmallforconditionalgener": 196, "blenderbotsmallforcausallm": 196, "tfblenderbotsmallmodel": 196, "tfblenderbotsmallforconditionalgener": 196, "bort": 197, "camembert": 198, "camembertconfig": 198, "camemberttoken": 198, "camemberttokenizerfast": 198, "camembertmodel": 198, "camembertforcausallm": 198, "camembertformaskedlm": 198, "camembertforsequenceclassif": 198, "camembertformultiplechoic": 198, "camembertfortokenclassif": 198, "camembertforquestionansw": 198, "tfcamembertmodel": 198, "tfcamembertformaskedlm": 198, "tfcamembertforsequenceclassif": 198, "tfcamembertformultiplechoic": 198, "tfcamembertfortokenclassif": 198, "tfcamembertforquestionansw": 198, "convbert": [199, 241], "convbertconfig": 199, "convberttoken": 199, "convberttokenizerfast": 199, "convbertmodel": 199, "convbertformaskedlm": 199, "convbertforsequenceclassif": 199, "convbertformultiplechoic": 199, "convbertfortokenclassif": 199, "convbertforquestionansw": 199, "tfconvbertmodel": 199, "tfconvbertformaskedlm": 199, "tfconvbertforsequenceclassif": 199, "tfconvbertformultiplechoic": 199, "tfconvbertfortokenclassif": 199, "tfconvbertforquestionansw": 199, "ctrl": [200, 241], "ctrlconfig": 200, "ctrltoken": 200, "ctrlmodel": 200, "ctrllmheadmodel": 200, "ctrlforsequenceclassif": 200, "tfctrlmodel": 200, "tfctrllmheadmodel": 200, "tfctrlforsequenceclassif": 200, "deberta": [201, 202], "debertaconfig": 201, "debertatoken": 201, "debertamodel": 201, "debertapretrainedmodel": 201, "debertaformaskedlm": 201, "debertaforsequenceclassif": 201, "debertafortokenclassif": 201, "debertaforquestionansw": 201, "debertav2config": 202, "debertav2token": 202, "debertav2model": 202, "debertav2pretrainedmodel": 202, "debertav2formaskedlm": 202, "debertav2forsequenceclassif": 202, "debertav2fortokenclassif": 202, "debertav2forquestionansw": 202, "dialogpt": 203, "distilbertconfig": 204, "distilberttoken": 204, "distilberttokenizerfast": 204, "distilbertmodel": 204, "distilbertformaskedlm": 204, "distilbertforsequenceclassif": 204, "distilbertformultiplechoic": 204, "distilbertfortokenclassif": 204, "distilbertforquestionansw": 204, "tfdistilbertmodel": 204, "tfdistilbertformaskedlm": 204, "tfdistilbertforsequenceclassif": 204, "tfdistilbertformultiplechoic": 204, "tfdistilbertfortokenclassif": 204, "tfdistilbertforquestionansw": 204, "dpr": [205, 241], "dprconfig": 205, "dprcontextencodertoken": 205, "dprcontextencodertokenizerfast": 205, "dprquestionencodertoken": 205, "dprquestionencodertokenizerfast": 205, "dprreadertoken": 205, "dprreadertokenizerfast": 205, "dprcontextencod": 205, "dprquestionencod": 205, "dprreader": 205, "tfdprcontextencod": 205, "tfdprquestionencod": 205, "tfdprreader": 205, "electra": [206, 241], "electraconfig": 206, "electratoken": 206, "electratokenizerfast": 206, "electramodel": 206, "electraforpretrain": 206, "electraformaskedlm": 206, "electraforsequenceclassif": 206, "electraformultiplechoic": 206, "electrafortokenclassif": 206, "electraforquestionansw": 206, "tfelectramodel": 206, "tfelectraforpretrain": 206, "tfelectraformaskedlm": 206, "tfelectraforsequenceclassif": 206, "tfelectraformultiplechoic": 206, "tfelectrafortokenclassif": 206, "tfelectraforquestionansw": 206, "encod": [207, 228, 252, 253, 262], "encoderdecoderconfig": 207, "encoderdecodermodel": 207, "flaubert": [208, 241], "flaubertconfig": 208, "flauberttoken": 208, "flaubertmodel": 208, "flaubertwithlmheadmodel": 208, "flaubertforsequenceclassif": 208, "flaubertformultiplechoic": 208, "flaubertfortokenclassif": 208, "flaubertforquestionansweringsimpl": 208, "flaubertforquestionansw": 208, "tfflaubertmodel": 208, "tfflaubertwithlmheadmodel": 208, "tfflaubertforsequenceclassif": 208, "tfflaubertformultiplechoic": 208, "tfflaubertfortokenclassif": 208, "tfflaubertforquestionansweringsimpl": 208, "fsmt": [209, 273], "fsmtconfig": 209, "fsmttoken": 209, "fsmtmodel": 209, "fsmtforconditionalgener": 209, "funnel": [210, 241], "funnelconfig": 210, "funneltoken": 210, "funneltokenizerfast": 210, "funnelbasemodel": 210, "funnelmodel": 210, "funnelmodelforpretrain": 210, "funnelformaskedlm": 210, "funnelforsequenceclassif": 210, "funnelformultiplechoic": 210, "funnelfortokenclassif": 210, "funnelforquestionansw": 210, "tffunnelbasemodel": 210, "tffunnelmodel": 210, "tffunnelmodelforpretrain": 210, "tffunnelformaskedlm": 210, "tffunnelforsequenceclassif": 210, "tffunnelformultiplechoic": 210, "tffunnelfortokenclassif": 210, "tffunnelforquestionansw": 210, "openaigptconfig": 211, "openaigpttoken": 211, "openaigpttokenizerfast": 211, "openaigptmodel": 211, "openaigptlmheadmodel": 211, "openaigptdoubleheadsmodel": 211, "openaigptforsequenceclassif": 211, "tfopenaigptmodel": 211, "tfopenaigptlmheadmodel": 211, "tfopenaigptdoubleheadsmodel": 211, "tfopenaigptforsequenceclassif": 211, "gpt2config": 212, "gpt2token": 212, "gpt2tokenizerfast": 212, "gpt2model": 212, "gpt2lmheadmodel": 212, "gpt2doubleheadsmodel": 212, "gpt2forsequenceclassif": 212, "tfgpt2model": 212, "tfgpt2lmheadmodel": 212, "tfgpt2doubleheadsmodel": 212, "tfgpt2forsequenceclassif": 212, "tfsequenceclassifieroutputwithpast": 212, "herbert": 213, "herberttoken": 213, "herberttokenizerfast": 213, "ibertconfig": 214, "ibertmodel": 214, "ibertformaskedlm": 214, "ibertforsequenceclassif": 214, "ibertformultiplechoic": 214, "ibertfortokenclassif": 214, "ibertforquestionansw": 214, "layoutlm": 215, "layoutlmconfig": 215, "layoutlmtoken": 215, "layoutlmtokenizerfast": 215, "layoutlmmodel": 215, "layoutlmformaskedlm": 215, "layoutlmforsequenceclassif": 215, "layoutlmfortokenclassif": 215, "led": 216, "ledconfig": 216, "ledtoken": 216, "ledtokenizerfast": 216, "ledmodel": 216, "ledforconditionalgener": 216, "ledforsequenceclassif": 216, "ledforquestionansw": 216, "tfledmodel": 216, "tfledforconditionalgener": 216, "longform": [217, 241], "longformerconfig": 217, "longformertoken": 217, "longformertokenizerfast": 217, "longformermodel": 217, "longformerformaskedlm": 217, "longformerforsequenceclassif": 217, "longformerformultiplechoic": 217, "longformerfortokenclassif": 217, "longformerforquestionansw": 217, "tflongformermodel": 217, "tflongformerformaskedlm": 217, "tflongformerforquestionansw": 217, "tflongformerforsequenceclassif": 217, "tflongformerfortokenclassif": 217, "tflongformerformultiplechoic": 217, "lxmert": [218, 266], "lxmertconfig": 218, "lxmerttoken": 218, "lxmerttokenizerfast": 218, "lxmertmodel": 218, "lxmertforpretrain": 218, "lxmertforquestionansw": 218, "tflxmertmodel": 218, "tflxmertforpretrain": 218, "marianmt": [219, 241], "multilingu": 219, "old": [219, 279], "lingual": [219, 242], "marianconfig": 219, "mariantoken": 219, "marianmodel": 219, "marianmtmodel": 219, "marianforcausallm": 219, "tfmarianmodel": 219, "tfmarianmtmodel": 219, "mbart": [220, 241], "mbartconfig": 220, "mbarttoken": 220, "mbarttokenizerfast": 220, "mbart50token": 220, "mbart50tokenizerfast": 220, "mbartmodel": 220, "mbartforconditionalgener": 220, "mbartforquestionansw": 220, "mbartforsequenceclassif": 220, "mbartforcausallm": 220, "tfmbartmodel": 220, "tfmbartforconditionalgener": 220, "mobilebertconfig": 221, "mobileberttoken": 221, "mobileberttokenizerfast": 221, "mobilebertmodel": 221, "mobilebertforpretrain": 221, "mobilebertformaskedlm": 221, "mobilebertfornextsentencepredict": 221, "mobilebertforsequenceclassif": 221, "mobilebertformultiplechoic": 221, "mobilebertfortokenclassif": 221, "mobilebertforquestionansw": 221, "tfmobilebertmodel": 221, "tfmobilebertforpretrain": 221, "tfmobilebertformaskedlm": 221, "tfmobilebertfornextsentencepredict": 221, "tfmobilebertforsequenceclassif": 221, "tfmobilebertformultiplechoic": 221, "tfmobilebertfortokenclassif": 221, "tfmobilebertforquestionansw": 221, "mpnet": 222, "mpnetconfig": 222, "mpnettoken": 222, "mpnettokenizerfast": 222, "mpnetmodel": 222, "mpnetformaskedlm": 222, "mpnetforsequenceclassif": 222, "mpnetformultiplechoic": 222, "mpnetfortokenclassif": 222, "mpnetforquestionansw": 222, "tfmpnetmodel": 222, "tfmpnetformaskedlm": 222, "tfmpnetforsequenceclassif": 222, "tfmpnetformultiplechoic": 222, "tfmpnetfortokenclassif": 222, "tfmpnetforquestionansw": 222, "mt5": [223, 241], "mt5config": 223, "mt5token": 223, "mt5tokenizerfast": 223, "mt5model": 223, "mt5forconditionalgener": 223, "mt5encodermodel": 223, "tfmt5model": 223, "tfmt5forconditionalgener": 223, "tfmt5encodermodel": 223, "pegasu": [224, 241, 273], "pegasusconfig": 224, "pegasustoken": 224, "pegasustokenizerfast": 224, "pegasusmodel": 224, "pegasusforconditionalgener": 224, "pegasusforcausallm": 224, "tfpegasusmodel": 224, "tfpegasusforconditionalgener": 224, "phobert": 225, "phoberttoken": 225, "prophetnet": [226, 237, 241], "prophetnetconfig": 226, "prophetnettoken": 226, "prophetnetmodel": 226, "prophetnetencod": 226, "prophetnetdecod": 226, "prophetnetforconditionalgener": 226, "prophetnetforcausallm": 226, "rag": [227, 241], "ragconfig": 227, "ragtoken": 227, "ragretriev": 227, "ragmodel": 227, "ragsequenceforgener": 227, "ragtokenforgener": 227, "reform": [228, 241], "axial": 228, "lsh": 228, "local": 228, "reformerconfig": 228, "reformertoken": 228, "reformertokenizerfast": 228, "reformermodel": 228, "reformermodelwithlmhead": 228, "reformerformaskedlm": 228, "reformerforsequenceclassif": 228, "reformerforquestionansw": 228, "retribert": 229, "retribertconfig": 229, "retriberttoken": 229, "retriberttokenizerfast": 229, "retribertmodel": 229, "robertaconfig": 230, "robertatoken": 230, "robertatokenizerfast": 230, "robertamodel": 230, "robertaforcausallm": 230, "robertaformaskedlm": 230, "robertaforsequenceclassif": 230, "robertaformultiplechoic": 230, "robertafortokenclassif": 230, "robertaforquestionansw": 230, "tfrobertamodel": 230, "tfrobertaformaskedlm": 230, "tfrobertaforsequenceclassif": 230, "tfrobertaformultiplechoic": 230, "tfrobertafortokenclassif": 230, "tfrobertaforquestionansw": 230, "flaxrobertamodel": 230, "squeezebert": 231, "squeezebertconfig": 231, "squeezeberttoken": 231, "squeezeberttokenizerfast": 231, "squeezebertmodel": 231, "squeezebertformaskedlm": 231, "squeezebertforsequenceclassif": 231, "squeezebertformultiplechoic": 231, "squeezebertfortokenclassif": 231, "squeezebertforquestionansw": 231, "t5config": 232, "t5token": 232, "t5tokenizerfast": 232, "t5model": 232, "t5forconditionalgener": 232, "t5encodermodel": 232, "tft5model": 232, "tft5forconditionalgener": 232, "tft5encodermodel": 232, "tapa": [233, 281], "tapasconfig": 233, "tapastoken": 233, "tapasmodel": 233, "tapasformaskedlm": 233, "tapasforsequenceclassif": 233, "tapasforquestionansw": 233, "transfoxlconfig": 234, "transfoxltoken": 234, "transfoxl": 234, "transfoxlmodel": 234, "transfoxllmheadmodel": 234, "transfoxlforsequenceclassif": 234, "tftransfoxlmodel": 234, "tftransfoxllmheadmodel": 234, "tftransfoxlforsequenceclassif": 234, "wav2vec2": [235, 335], "wav2vec2config": 235, "wav2vec2ctctoken": 235, "wav2vec2featureextractor": 235, "wav2vec2processor": 235, "wav2vec2model": 235, "wav2vec2forctc": 235, "xlmconfig": 236, "xlmtoken": 236, "xlmmodel": 236, "xlmwithlmheadmodel": 236, "xlmforsequenceclassif": 236, "xlmformultiplechoic": 236, "xlmfortokenclassif": 236, "xlmforquestionansweringsimpl": 236, "xlmforquestionansw": 236, "tfxlmmodel": 236, "tfxlmwithlmheadmodel": 236, "tfxlmforsequenceclassif": 236, "tfxlmformultiplechoic": 236, "tfxlmfortokenclassif": 236, "tfxlmforquestionansweringsimpl": 236, "xlmprophetnetconfig": 237, "xlmprophetnettoken": 237, "xlmprophetnetmodel": 237, "xlmprophetnetencod": 237, "xlmprophetnetdecod": 237, "xlmprophetnetforconditionalgener": 237, "xlmprophetnetforcausallm": 237, "xlmrobertaconfig": 238, "xlmrobertatoken": 238, "xlmrobertatokenizerfast": 238, "xlmrobertamodel": 238, "xlmrobertaforcausallm": 238, "xlmrobertaformaskedlm": 238, "xlmrobertaforsequenceclassif": 238, "xlmrobertaformultiplechoic": 238, "xlmrobertafortokenclassif": 238, "xlmrobertaforquestionansw": 238, "tfxlmrobertamodel": 238, "tfxlmrobertaformaskedlm": 238, "tfxlmrobertaforsequenceclassif": 238, "tfxlmrobertaformultiplechoic": 238, "tfxlmrobertafortokenclassif": 238, "tfxlmrobertaforquestionansw": 238, "xlnetconfig": 239, "xlnettoken": 239, "xlnettokenizerfast": 239, "xlnetmodel": 239, "xlnetlmheadmodel": 239, "xlnetforsequenceclassif": 239, "xlnetformultiplechoic": 239, "xlnetfortokenclassif": 239, "xlnetforquestionansweringsimpl": 239, "xlnetforquestionansw": 239, "tfxlnetmodel": 239, "tfxlnetlmheadmodel": 239, "tfxlnetforsequenceclassif": 239, "tflnetformultiplechoic": 239, "tfxlnetfortokenclassif": 239, "tfxlnetforquestionansweringsimpl": 239, "upload": [240, 283], "version": [240, 277, 279, 290, 291, 292, 294, 296, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 313], "make": [240, 285, 288, 379, 382], "directori": [240, 251], "befor": 240, "push": 240, "card": [240, 280], "colab": [240, 257], "autoregress": 241, "autoencod": 241, "multimod": 241, "mmbt": 241, "retriev": [241, 272], "technic": 241, "spars": 241, "trick": [241, 273], "languag": [242, 250, 256, 267, 271, 278, 290], "embed": [242, 258], "perplex": 244, "fix": 244, "length": [244, 249], "calcul": 244, "ppl": 244, "philosophi": 245, "concept": 245, "pair": [246, 252], "sentenc": 246, "everyth": 246, "know": 246, "about": 246, "pad": 246, "truncat": 246, "under": 248, "hood": 248, "access": 248, "onnxruntim": 249, "torchscript": 249, "implic": 249, "flag": 249, "ti": 249, "dummi": 249, "trace": 249, "extract": 250, "causal": [250, 256], "recognit": 250, "summar": [250, 262, 273, 276], "translat": [250, 273, 276], "choos": 251, "which": 251, "modifi": [251, 306], "rerun": 251, "fail": 251, "modif": [251, 283], "skip": 251, "clear": 251, "state": 251, "parallel": 251, "repetit": 251, "repeat": 251, "look": 251, "feel": 251, "variat": 251, "pytest": 251, "sugar": 251, "sub": 251, "instantli": 251, "show": 251, "captur": 251, "color": 251, "control": [251, 271, 371], "send": 251, "pastebin": 251, "servic": 251, "parametr": 251, "slow": 251, "stdout": 251, "stderr": 251, "logger": 251, "stream": 251, "ci": 251, "subword": 252, "byte": 252, "bpe": 252, "level": 252, "wordpiec": 252, "unigram": 252, "freez": 253, "import": [254, 288, 320, 385], "big": 254, "tpu": 254, "track": 254, "bias": 254, "comet": 254, "ml": 254, "whole": [256, 267], "word": [256, 267, 271], "permut": 256, "choic": 257, "swag": 257, "squad1": 258, "beam": 258, "squad2": 258, "previous": 258, "hyper": [258, 269], "rel": 258, "adversari": 260, "patienc": 261, "earli": [261, 263], "exit": [261, 263], "author": 262, "roug": 262, "score": 262, "ani": 262, "deebert": 263, "train_deebert": 263, "sh": 263, "eval_deebert": 263, "entropy_ev": 263, "b": 264, "long": 265, "form": 265, "mm": 268, "movement": 269, "adapt": [269, 359, 360, 361, 362, 368], "sparsiti": 269, "extrem": 269, "effici": 269, "storag": 269, "after": 269, "speed": [269, 318], "plug": 271, "plai": 271, "simpl": 271, "pplm": 271, "bow": 271, "bag": 271, "hyperparamet": 271, "discrim": 271, "discrimin": 271, "sentiment": 271, "intro": [272, 295, 305], "end": [272, 318, 387], "own": [272, 319], "xsum": 273, "dailymail": 273, "wmt16": 273, "english": 273, "romanian": 273, "wmt": 273, "german": [273, 279], "tip": 273, "param": 273, "lightn": 273, "batch": 273, "size": 273, "mt": 273, "distilbart": 273, "recommend": 273, "initi": [273, 314], "sft": 273, "No": [273, 320], "pseudo": [273, 274], "direct": [273, 314], "kd": 273, "pseudolabel": 274, "classifi": 275, "csv": [276, 388], "jsonfil": 276, "germev": 279, "2014": 279, "ner": 279, "process": [279, 365], "live": 280, "insid": 280, "co": 280, "happen": 280, "here": 280, "intend": 281, "limit": 281, "procedur": 281, "bibtex": 281, "info": 281, "hug": 282, "camelcas": 285, "sure": [285, 288], "ve": [285, 288], "understood": [285, 288], "cookiecutt": [286, 287], "modelnam": 287, "camelcase_modelnam": 287, "tokenizerfast": 287, "formaskedlm": 287, "forsequenceclassif": 287, "formultiplechoic": 287, "fortokenclassif": 287, "forquestionansw": 287, "forcausallm": 287, "tf": 287, "bigbird": 288, "neural_compressor": [290, 291, 292, 293, 294, 296, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 313, 368], "seq2seq": [290, 298], "onc": [292, 301], "For": [292, 301, 362], "pruner": [295, 305], "two": [296, 309, 310, 311], "summarization_billsum": 298, "sst": [299, 300, 301, 302, 304, 305], "mnli": [299, 300, 301, 304], "qqp": [299, 300, 301, 304], "cola": 299, "qnli": [300, 301, 304], "while": 306, "sst2": 306, "extern": 306, "notic": 307, "includ": [308, 309, 311, 312, 323, 326, 334], "batch_siz": [308, 309, 311, 312, 323, 326, 334], "throughput": [308, 309, 311, 312, 323, 326, 334], "shaplei": 308, "uncas": 312, "machin": 314, "separ": 314, "bia": 314, "qualiti": 314, "target": 314, "frequenc": [314, 371], "thorough": 314, "imagelist": 316, "boxlist": 316, "docker": 317, "zoo": [318, 319], "mmdetect": 318, "memori": 318, "highlight": 319, "webcam": [319, 320], "troubleshoot": [319, 320], "maskrcnn": 319, "compil": [320, 362], "importerror": 320, "maskrcnn_benchmark": 320, "undefin": 320, "symbol": 320, "__cudapopcallconfigur": 320, "_c": 320, "fault": 320, "core": 320, "symlink": 321, "pascal": 321, "annot": [321, 328], "ssd_resnet34": [323, 326, 362], "brief": [323, 334], "upscal": 324, "resnet34": 325, "quant": 326, "clone": 328, "credit": 328, "increment": 328, "improv": 328, "dlrm": 332, "agreement": 332, "cla": 332, "rnnt": 334, "hubert": 335, "vit": 337, "abov": [351, 352], "tensorflow_model_optim": 352, "up2": 354, "8": [354, 355, 363, 365, 366], "9": [354, 355, 363, 365], "vgg": 354, "16": 354, "19": 354, "13": 354, "101": 354, "152": 354, "121": 354, "17": 354, "161": 354, "18": 354, "169": 354, "20": 354, "b0": 354, "resnet_v1_50": 355, "resnet_v1_101": 355, "resnet_v1_152": 355, "resnet_v2_50": 355, "resnet_v2_101": 355, "resnet_v2_152": 355, "inception_v1": 355, "inception_v2": 355, "inception_v4": 355, "vgg19": 355, "frozen": [357, 361, 365], "pb": [357, 362, 363, 365], "dev202242": 359, "q_dataload": [359, 360, 361, 362], "lt": 360, "transformer_lt_mlperf": 361, "protocol": 362, "buffer": 362, "autom": [362, 368, 379, 382], "ssd_resnet50_v1": 362, "ssd_mobilenet_v1": 362, "faster_rcnn_inception_resnet_v2": 362, "faster_rcnn_resnet101": 362, "faster_rcnn_resnet50": 362, "mask_rcnn_inception_v2": 362, "ckpt": 362, "yolo": 363, "yolo_v3": 363, "cocoraw": 363, "yolo_v3_itex": 363, "below": 363, "wnd": 365, "brat": 366, "deeplab": 367, "section": 369, "coder": [370, 372, 374], "we": 370, "offer": 370, "lab": 370, "contact": 370, "platform": 371, "mkl": 371, "openmp": 371, "jemalloc": 371, "numa": 371, "govern": 371, "superbench": 372, "launcher": 373, "changelog": [376, 380], "neural_compressor_ext_lab": [377, 379], "uninstal": [377, 381], "Or": 378, "let": 378, "help": [378, 387], "requisit": 378, "npm": [379, 382], "publish": [379, 382], "forg": [379, 382], "neural_compressor_ext_lab_alibaba": [381, 382], "execut": [384, 388], "endpoint": [384, 388], "databas": 386, "scaffold": 387, "unit": 387, "further": 387, "delet": 388, "pin": 388, "boundari": 388, "node": 388, "dictionari": 388, "domain": 388, "flavour": 388, "specifi": 388}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Type of Change": [[0, "type-of-change"]], "Description": [[0, "description"], [324, "description"]], "Expected Behavior & Potential Risk": [[0, "expected-behavior-potential-risk"]], "How has this PR been tested?": [[0, "how-has-this-pr-been-tested"]], "Dependency Change?": [[0, "dependency-change"]], "Intel\u00ae Neural Compressor": [[1, "intel-neural-compressor"]], "Installation": [[1, "installation"], [31, "installation"], [35, "installation"], [126, "installation"], [140, "installation"], [149, "installation"], [157, "installation"], [169, "installation"], [186, "installation"], [317, "installation"], [319, "installation"], [328, "installation"], [378, "installation"]], "Prerequisites": [[1, "prerequisites"], [35, "prerequisites"], [35, "id1"], [117, "prerequisites"], [118, "prerequisites"]], "Install on Linux": [[1, "install-on-linux"]], "Getting Started": [[1, "getting-started"], [31, "getting-started"]], "Quantization with Python API": [[1, "quantization-with-python-api"]], "Quantization with JupyterLab Extension": [[1, "quantization-with-jupyterlab-extension"]], "Quantization with GUI": [[1, "quantization-with-gui"]], "System Requirements": [[1, "system-requirements"], [31, "system-requirements"]], "Validated Hardware Environment": [[1, "validated-hardware-environment"]], "Intel\u00ae Neural Compressor supports CPUs based on Intel 64 architecture or compatible processors:": [[1, "intel-neural-compressor-supports-cpus-based-on-intel-64-architecture-or-compatible-processors"]], "Intel\u00ae Neural Compressor supports GPUs built on Intel\u2019s Xe architecture:": [[1, "intel-neural-compressor-supports-gpus-built-on-intel-s-xe-architecture"]], "Intel\u00ae Neural Compressor quantized ONNX models support multiple hardware vendors through ONNX Runtime:": [[1, "intel-neural-compressor-quantized-onnx-models-support-multiple-hardware-vendors-through-onnx-runtime"]], "Validated Software Environment": [[1, "validated-software-environment"]], "Validated Models": [[1, "validated-models"], [31, "validated-models"], [48, "validated-models"], [54, "validated-models"]], "Documentation": [[1, "documentation"], [140, "documentation"]], "Selected Publications/Events": [[1, "selected-publications-events"]], "Additional Content": [[1, "additional-content"]], "Hiring": [[1, "hiring"]], "Security Policy": [[2, "security-policy"]], "Report a Vulnerability": [[2, "report-a-vulnerability"]], "API Reference": [[3, "api-reference"]], "APIs": [[4, "apis"]], "Benchmark": [[5, "benchmark"], [66, "benchmark"], [76, "benchmark"], [77, "benchmark"], [78, "benchmark"], [79, "benchmark"], [80, "benchmark"], [82, "benchmark"], [83, "benchmark"], [84, "benchmark"], [85, "benchmark"], [87, "benchmark"], [88, "benchmark"], [89, "benchmark"], [90, "benchmark"], [91, "benchmark"], [92, "benchmark"], [93, "benchmark"], [94, "benchmark"], [95, "benchmark"], [96, "benchmark"], [97, "benchmark"], [98, "benchmark"], [99, "benchmark"], [100, "benchmark"], [100, "id1"], [101, "benchmark"], [102, "benchmark"], [104, "benchmark"], [105, "benchmark"], [107, "benchmark"], [108, "benchmark"], [109, "benchmark"], [110, "benchmark"], [114, "benchmark"], [115, "benchmark"], [356, "benchmark"], [357, "benchmark"], [367, "benchmark"], [388, "benchmark"]], "Objective": [[6, "objective"], [41, "objective"]], "Pruning": [[7, "pruning"], [44, "pruning"], [56, "pruning"], [56, "id2"], [303, "pruning"]], "Quantization": [[8, "quantization"], [46, "quantization"], [56, "quantization"], [56, "id1"], [56, "id4"], [74, "quantization"], [75, "quantization"], [76, "quantization"], [77, "quantization"], [78, "quantization"], [79, "quantization"], [80, "quantization"], [81, "quantization"], [82, "quantization"], [83, "quantization"], [84, "quantization"], [85, "quantization"], [86, "quantization"], [87, "quantization"], [88, "quantization"], [89, "quantization"], [90, "quantization"], [91, "quantization"], [92, "quantization"], [93, "quantization"], [94, "quantization"], [95, "quantization"], [96, "quantization"], [97, "quantization"], [98, "quantization"], [99, "quantization"], [101, "quantization"], [102, "quantization"], [104, "quantization"], [105, "quantization"], [106, "quantization"], [107, "quantization"], [108, "quantization"], [109, "quantization"], [110, "quantization"], [111, "quantization"], [112, "quantization"], [113, "quantization"], [114, "quantization"], [115, "quantization"], [249, "quantization"]], "build Neural Compressor(INC) Containers:": [[9, "build-neural-compressor-inc-containers"]], "To build the the Pip based deployment container:": [[9, "to-build-the-the-pip-based-deployment-container"]], "To build the the Pip based development container:": [[9, "to-build-the-the-pip-based-development-container"]], "Check the Containers built:": [[9, "check-the-containers-built"]], "Contributor Covenant Code of Conduct": [[10, "contributor-covenant-code-of-conduct"], [20, "contributor-covenant-code-of-conduct"], [154, "contributor-covenant-code-of-conduct"]], "Our Pledge": [[10, "our-pledge"], [20, "our-pledge"], [154, "our-pledge"]], "Our Standards": [[10, "our-standards"], [20, "our-standards"], [154, "our-standards"]], "Our Responsibilities": [[10, "our-responsibilities"], [20, "our-responsibilities"]], "Scope": [[10, "scope"], [20, "scope"], [154, "scope"]], "Enforcement": [[10, "enforcement"], [20, "enforcement"], [154, "enforcement"]], "Attribution": [[10, "attribution"], [20, "attribution"], [154, "attribution"]], "FX": [[11, "fx"]], "Overview": [[11, "overview"], [188, "overview"], [190, "overview"], [191, "overview"], [192, "overview"], [193, "overview"], [194, "overview"], [195, "overview"], [196, "overview"], [197, "overview"], [198, "overview"], [199, "overview"], [200, "overview"], [201, "overview"], [202, "overview"], [203, "overview"], [204, "overview"], [205, "overview"], [206, "overview"], [208, "overview"], [209, "overview"], [210, "overview"], [211, "overview"], [212, "overview"], [213, "overview"], [214, "overview"], [215, "overview"], [216, "overview"], [217, "overview"], [218, "overview"], [221, "overview"], [222, "overview"], [223, "overview"], [224, "overview"], [225, "overview"], [226, "overview"], [227, "overview"], [228, "overview"], [229, "overview"], [230, "overview"], [231, "overview"], [232, "overview"], [233, "overview"], [234, "overview"], [235, "overview"], [236, "overview"], [237, "overview"], [238, "overview"], [239, "overview"], [287, "overview"]], "Usage": [[11, "usage"], [14, "usage"], [51, "usage"], [51, "id2"], [53, "usage"], [53, "id2"], [53, "id4"], [53, "id6"], [53, "id8"], [53, "id10"], [53, "id12"], [126, "usage"], [130, "usage"], [195, "usage"], [263, "usage"], [275, "usage"], [286, "usage"], [295, "usage"], [305, "usage"], [374, "usage"]], "Note": [[11, "note"], [69, "note"]], "Details": [[11, "details"], [117, "details"]], "Common Problem": [[11, "common-problem"]], "Dynamic Quantization": [[11, "dynamic-quantization"], [28, "dynamic-quantization"]], "Static Quantization & Quantization Aware Training": [[11, "static-quantization-quantization-aware-training"]], "Neural Architecture Search": [[12, "neural-architecture-search"]], "Introduction": [[12, "introduction"], [16, "introduction"], [18, "introduction"], [24, "introduction"], [25, "introduction"], [26, "introduction"], [32, "introduction"], [34, "introduction"], [37, "introduction"], [38, "introduction"], [39, "introduction"], [40, "introduction"], [41, "introduction"], [42, "introduction"], [44, "introduction"], [51, "introduction"], [53, "introduction"], [59, "introduction"], [69, "introduction"], [70, "introduction"], [71, "introduction"], [118, "introduction"], [252, "introduction"], [383, "introduction"]], "NAS API": [[12, "nas-api"]], "Basic Usage": [[12, "basic-usage"]], "1. Python code + YAML": [[12, "python-code-yaml"]], "2. Python code only": [[12, "python-code-only"]], "Advanced Usage (Custom NAS)": [[12, "advanced-usage-custom-nas"]], "Basic NAS": [[12, "basic-nas"]], "Dynamic NAS": [[12, "dynamic-nas"]], "Examples": [[12, "examples"], [14, "examples"], [19, "examples"], [24, "examples"], [25, "examples"], [29, "examples"], [31, "examples"], [32, "examples"], [38, "examples"], [39, "examples"], [42, "examples"], [44, "examples"], [46, "examples"], [51, "examples"], [51, "id3"], [56, "examples"], [126, "examples"], [190, "examples"], [191, "examples"], [219, "examples"], [224, "examples"], [254, "examples"], [270, "examples"], [295, "examples"], [305, "examples"], [388, "examples"], [388, "id1"]], "PTQ": [[13, "ptq"], [13, "id1"]], "Design": [[13, "design"], [14, "design"], [23, "design"], [51, "design"], [51, "id1"], [53, "design"], [53, "id1"], [53, "id3"], [53, "id5"], [53, "id7"], [53, "id9"], [53, "id11"]], "PyTorch Usage": [[13, "pytorch-usage"]], "MobileNetV2 Model Architecture": [[13, "mobilenetv2-model-architecture"]], "Helper Functions": [[13, "helper-functions"]], "Example": [[13, "example"], [41, "example"], [72, "example"], [374, "example"], [384, "example"]], "Quantization-aware Training": [[14, "quantization-aware-training"]], "Adaptor": [[15, "adaptor"]], "Adaptor Layer Introduction": [[15, "adaptor-layer-introduction"]], "Working Flow": [[15, "working-flow"], [46, "working-flow"]], "Adaptor API Summary": [[15, "adaptor-api-summary"]], "Query API": [[15, "query-api"]], "Background": [[15, "background"], [70, "background"], [71, "background"]], "Unify Config Introduction": [[15, "unify-config-introduction"]], "Query API Introduction": [[15, "query-api-introduction"]], "Example of Adding a New Backend Support": [[15, "example-of-adding-a-new-backend-support"]], "Capability": [[15, "capability"]], "Implement ONNXRTAdaptor Class": [[15, "implement-onnxrtadaptor-class"]], "Pre-optimize": [[15, "pre-optimize"]], "Setting Tune Config": [[15, "setting-tune-config"]], "Do Quantization": [[15, "do-quantization"]], "API Documentation": [[16, "api-documentation"]], "User-facing APIs": [[16, "user-facing-apis"], [33, "user-facing-apis"]], "Experimental user-facing APIs": [[16, "experimental-user-facing-apis"]], "Quantization-related APIs": [[16, "quantization-related-apis"]], "Pruning-related APIs (POC)": [[16, "pruning-related-apis-poc"]], "Benchmarking-related APIs": [[16, "benchmarking-related-apis"]], "Default user-facing APIs": [[16, "default-user-facing-apis"]], "Quantization Support Matrix": [[17, "quantization-support-matrix"]], "TensorFlow": [[17, "tensorflow"], [22, "tensorflow"], [37, "tensorflow"], [52, "tensorflow"]], "PyTorch": [[17, "pytorch"], [22, "pytorch"], [37, "pytorch"], [47, "pytorch"]], "PyTorch IPEX": [[17, "pytorch-ipex"]], "MXNet": [[17, "mxnet"], [22, "mxnet"], [37, "mxnet"], [52, "mxnet"]], "ONNX Runtime": [[17, "onnx-runtime"]], "Reference": [[17, "reference"], [136, "reference"]], "Intel\u00ae Neural Compressor Bench": [[18, "intel-neural-compressor-bench"], [388, "intel-neural-compressor-bench"]], "Table of Contents": [[18, "table-of-contents"], [126, "table-of-contents"], [136, "table-of-contents"], [388, "table-of-contents"]], "Install Intel\u00ae Neural Compressor with Bench": [[18, "install-intel-neural-compressor-with-bench"]], "Option 1 Install from binary": [[18, "option-1-install-from-binary"], [35, "option-1-install-from-binary"], [35, "id2"]], "Option 2 Install from source": [[18, "option-2-install-from-source"], [35, "option-2-install-from-source"], [35, "id3"]], "Start the Intel\u00ae Neural Compressor Bench": [[18, "start-the-intel-neural-compressor-bench"]], "Home screen": [[18, "home-screen"]], "Create new project": [[18, "create-new-project"]], "Predefined model": [[18, "predefined-model"]], "Custom model": [[18, "custom-model"], [328, "custom-model"]], "Display model graph": [[18, "display-model-graph"]], "Project list": [[18, "project-list"]], "Remove project": [[18, "remove-project"]], "Develop the project": [[18, "develop-the-project"]], "Optimization tab": [[18, "optimization-tab"]], "Optimization table": [[18, "optimization-table"]], "Optimization wizard": [[18, "optimization-wizard"]], "Editing optimization entries": [[18, "editing-optimization-entries"]], "Optimization details": [[18, "optimization-details"]], "Benchmark tab": [[18, "benchmark-tab"]], "Benchmark table": [[18, "benchmark-table"]], "Benchmark wizard": [[18, "benchmark-wizard"]], "Editing benchmark entries": [[18, "editing-benchmark-entries"]], "Benchmark details": [[18, "benchmark-details"]], "Profiling tab": [[18, "profiling-tab"]], "Profiling table": [[18, "profiling-table"]], "Profiling wizard": [[18, "profiling-wizard"]], "Editing profiling entries": [[18, "editing-profiling-entries"]], "Profiling details": [[18, "profiling-details"]], "Diagnosis tab": [[18, "diagnosis-tab"]], "Dataset tab": [[18, "dataset-tab"]], "Dataset list": [[18, "dataset-list"]], "Dataset wizard": [[18, "dataset-wizard"]], "Dataset details": [[18, "dataset-details"]], "Custom dataset": [[18, "custom-dataset"]], "Project information": [[18, "project-information"]], "System information": [[18, "system-information"]], "Security": [[18, "security"]], "Benchmarking": [[19, "benchmarking"]], "Config evaluation filed in a yaml file": [[19, "config-evaluation-filed-in-a-yaml-file"]], "Use a user-specific dataloader to run benchmark": [[19, "use-a-user-specific-dataloader-to-run-benchmark"]], "Contribution Guidelines": [[20, "contribution-guidelines"]], "Pull Request Checklist": [[20, "pull-request-checklist"]], "Pull Request Template": [[20, "pull-request-template"]], "Support": [[20, "support"]], "DataLoader": [[21, "dataloader"]], "How to use it": [[21, "how-to-use-it"], [32, "how-to-use-it"], [40, "how-to-use-it"]], "Config dataloader in a yaml file": [[21, "config-dataloader-in-a-yaml-file"]], "Create a user-specific dataloader": [[21, "create-a-user-specific-dataloader"]], "Dataset": [[22, "dataset"], [325, "dataset"], [388, "dataset"]], "Built-in dataset support list": [[22, "built-in-dataset-support-list"]], "ONNXRT": [[22, "onnxrt"], [37, "onnxrt"], [52, "onnxrt"]], "User-specific dataset": [[22, "user-specific-dataset"]], "Architecture": [[23, "architecture"], [34, "architecture"]], "Workflow": [[23, "workflow"]], "Distillation": [[24, "distillation"], [56, "distillation"], [56, "id3"], [273, "distillation"]], "Knowledge Distillation": [[24, "knowledge-distillation"]], "Intermediate Layer Knowledge Distillation": [[24, "intermediate-layer-knowledge-distillation"]], "Self Distillation": [[24, "self-distillation"]], "Distillation Support Matrix": [[24, "distillation-support-matrix"]], "Get Started with Distillation API": [[24, "get-started-with-distillation-api"]], "Distillation for Quantization": [[25, "distillation-for-quantization"]], "User-defined yaml": [[25, "user-defined-yaml"]], "Distributed Training and Inference (Evaluation)": [[26, "distributed-training-and-inference-evaluation"]], "horovod installation": [[26, "horovod-installation"]], "Distributed training and inference (evaluation)": [[26, "id1"]], "Option 1: pure yaml configuration": [[26, "option-1-pure-yaml-configuration"]], "Option2: user defined training function": [[26, "option2-user-defined-training-function"]], "horovodrun": [[26, "horovodrun"]], "security": [[26, "security"]], "Following examples are supported": [[26, "following-examples-are-supported"]], "Developer Documentation": [[27, "developer-documentation"], [31, "developer-documentation"]], "Get Started": [[27, "get-started"], [46, "get-started"]], "Deep Dive": [[27, "deep-dive"]], "Advanced Topics": [[27, "advanced-topics"]], "Frequently Asked Questions": [[30, "frequently-asked-questions"]], "Common Build Issues": [[30, "common-build-issues"]], "Issue 1:": [[30, "issue-1"]], "Issue 2:": [[30, "issue-2"]], "Issue 3:": [[30, "issue-3"]], "Linux Installation": [[31, "linux-installation"], [35, "linux-installation"]], "Install from binary": [[31, "install-from-binary"], [31, "id1"]], "Install from source": [[31, "install-from-source"], [31, "id2"]], "Install from AI Kit": [[31, "install-from-ai-kit"]], "Windows Installation": [[31, "windows-installation"], [35, "windows-installation"]], "Validated Hardware/Software Environment": [[31, "validated-hardware-software-environment"]], "Graph Optimization": [[32, "graph-optimization"]], "FP32 Optimization": [[32, "fp32-optimization"]], "Auto-mixed Precision Optimization": [[32, "auto-mixed-precision-optimization"]], "Default auto-mixed precision": [[32, "default-auto-mixed-precision"]], "Auto-mixed precision with auto-tuning": [[32, "auto-mixed-precision-with-auto-tuning"]], "FP32 optimization": [[32, "id1"]], "Incompatible changes between v1.2 and v1.1": [[33, "incompatible-changes-between-v1-2-and-v1-1"]], "Built-in transform/dataset/metric APIs": [[33, "built-in-transform-dataset-metric-apis"]], "Infrastructure of Intel\u00ae Neural Compressor": [[34, "infrastructure-of-intel-neural-compressor"]], "Supported Feature Matrix": [[34, "supported-feature-matrix"], [46, "supported-feature-matrix"]], "Option 3 Install from AI Kit": [[35, "option-3-install-from-ai-kit"]], "Legal Information": [[36, "legal-information"]], "License": [[36, "license"], [70, "license"], [71, "license"], [117, "license"], [319, "license"], [332, "license"]], "Citation": [[36, "citation"], [133, "citation"], [157, "citation"], [261, "citation"], [263, "citation"], [264, "citation"], [269, "citation"], [273, "citation"]], "Trademarks": [[36, "trademarks"]], "Metrics": [[37, "metrics"]], "Supported Built-in Metric Matrix": [[37, "supported-built-in-metric-matrix"]], "Get Start with Metrics": [[37, "get-start-with-metrics"]], "Support Single-metric and Multi-metrics": [[37, "support-single-metric-and-multi-metrics"]], "Build Custom Metric with Python API": [[37, "build-custom-metric-with-python-api"]], "Mixed Precision": [[38, "mixed-precision"]], "Mixed Precision Support Matrix": [[38, "mixed-precision-support-matrix"]], "Get start with Mixed Precision API": [[38, "get-start-with-mixed-precision-api"]], "Model": [[39, "model"], [388, "model"]], "Supported Framework Model Matrix": [[39, "supported-framework-model-matrix"]], "Model Conversion": [[40, "model-conversion"]], "Single Objective": [[41, "single-objective"]], "Multiple Objectives": [[41, "multiple-objectives"]], "Objective Support Matrix": [[41, "objective-support-matrix"]], "Get Start with Objective API": [[41, "get-start-with-objective-api"]], "Config Single Objective": [[41, "config-single-objective"]], "Config Multiple Objectives": [[41, "config-multiple-objectives"]], "Config Custom Objective": [[41, "config-custom-objective"]], "Optimization Orchestration": [[42, "optimization-orchestration"]], "One-shot": [[42, "one-shot"]], "Multi-shot": [[42, "multi-shot"]], "Orchestration Support Matrix": [[42, "orchestration-support-matrix"]], "Get Started with Orchestration API": [[42, "get-started-with-orchestration-api"]], "SYSTEM CONFIGURATION": [[43, "system-configuration"]], "Neural Network Pruning": [[44, "neural-network-pruning"]], "Pruning Patterns": [[44, "pruning-patterns"]], "Pruning Criteria": [[44, "pruning-criteria"]], "Pruning Schedule": [[44, "pruning-schedule"]], "Pruning Support Matrix": [[44, "pruning-support-matrix"]], "Get Started with Pruning API": [[44, "get-started-with-pruning-api"]], "Full Publications/Events (44)": [[45, "full-publications-events-44"]], "2022 (26)": [[45, "id1"]], "2021 (14)": [[45, "id2"]], "2018 - 2020 (4)": [[45, "id3"]], "Quantization Introduction": [[46, "quantization-introduction"]], "Quantization Fundamentals": [[46, "quantization-fundamentals"]], "Quantization Approaches": [[46, "quantization-approaches"]], "Post Training Dynamic Quantization": [[46, "post-training-dynamic-quantization"]], "Post Training Static Quantization": [[46, "post-training-static-quantization"]], "Quantization Aware Training": [[46, "quantization-aware-training"]], "Accuracy Aware Tuning": [[46, "accuracy-aware-tuning"]], "Turn ON Auto Mixed Precision during Quantization": [[47, "turn-on-auto-mixed-precision-during-quantization"]], "Tensorflow": [[47, "tensorflow"], [257, "tensorflow"]], "Reference Examples": [[48, "reference-examples"]], "Release": [[49, "release"]], "Known Issues": [[49, "known-issues"]], "Incompatible Changes": [[49, "incompatible-changes"]], "SigOpt Strategy": [[50, "sigopt-strategy"]], "Preparation": [[50, "preparation"]], "SigOpt introduction": [[50, "sigopt-introduction"]], "Neural Compressor configuration": [[50, "neural-compressor-configuration"]], "Performance": [[50, "performance"], [74, "performance"], [75, "performance"], [81, "performance"], [86, "performance"], [106, "performance"], [111, "performance"], [112, "performance"], [113, "performance"]], "Benefit for Sigopt strategy": [[50, "benefit-for-sigopt-strategy"]], "Performance comparison of different strategies": [[50, "performance-comparison-of-different-strategies"]], "TensorBoard": [[51, "tensorboard"]], "PyTorch TensorBoard": [[51, "pytorch-tensorboard"]], "TensorFlow Tensorboard": [[51, "tensorflow-tensorboard"]], "Transform": [[52, "transform"]], "Transform support list": [[52, "transform-support-list"]], "Pytorch": [[52, "pytorch"]], "Tuning Strategies": [[53, "tuning-strategies"]], "Strategy Design": [[53, "strategy-design"]], "Configurations": [[53, "configurations"]], "Model-specific configurations": [[53, "model-specific-configurations"]], "Strategy tuning part-related configurations": [[53, "strategy-tuning-part-related-configurations"]], "Basic": [[53, "basic"]], "Bayesian": [[53, "bayesian"]], "MSE": [[53, "mse"]], "TPE": [[53, "tpe"]], "Exhaustive": [[53, "exhaustive"]], "Random": [[53, "random"]], "SigOpt": [[53, "sigopt"]], "Customize a New Tuning Strategy": [[53, "customize-a-new-tuning-strategy"]], "Validated MLPerf Models": [[54, "validated-mlperf-models"]], "Validated Quantization Examples": [[54, "validated-quantization-examples"]], "TensorFlow models with TensorFlow 2.10.0": [[54, "tensorflow-models-with-tensorflow-2-10-0"]], "PyTorch models with Torch 1.12.1+cpu in PTQ mode": [[54, "pytorch-models-with-torch-1-12-1-cpu-in-ptq-mode"]], "PyTorch models with Torch 1.12.1+cpu in QAT mode": [[54, "pytorch-models-with-torch-1-12-1-cpu-in-qat-mode"]], "PyTorch models with Torch and Intel\u00ae Extension for PyTorch* 1.11.0+cpu": [[54, "pytorch-models-with-torch-and-intel-extension-for-pytorch-1-11-0-cpu"]], "ONNX Models with ONNX Runtime 1.12.1": [[54, "onnx-models-with-onnx-runtime-1-12-1"]], "MXNet models with MXNet 1.7.0": [[54, "mxnet-models-with-mxnet-1-7-0"]], "Validated Pruning Examples": [[54, "validated-pruning-examples"]], "Validated Knowledge Distillation Examples": [[54, "validated-knowledge-distillation-examples"]], "Validated ONNX QDQ INT8 models on multiple hardware through ONNX Runtime": [[54, "validated-onnx-qdq-int8-models-on-multiple-hardware-through-onnx-runtime"]], "Introduction to Intel\u00ae Neural Compressor": [[55, "introduction-to-intel-neural-compressor"]], "Helloworld Examples": [[56, "helloworld-examples"]], "Notebook Examples": [[56, "notebook-examples"]], "TensorFlow Examples": [[56, "tensorflow-examples"]], "PyTorch  Examples": [[56, "pytorch-examples"]], "Orchestration": [[56, "orchestration"]], "ONNX Runtime Examples": [[56, "onnx-runtime-examples"]], "Hello World Examples": [[57, "hello-world-examples"]], "tf_example1 example": [[58, "tf-example1-example"]], "1. Installation": [[58, "installation"], [59, "installation"], [60, "installation"], [61, "installation"], [62, "installation"], [63, "installation"], [64, "installation"], [65, "installation"], [66, "installation"], [67, "installation"], [68, "installation"], [131, "installation"], [134, "installation"], [135, "installation"], [139, "installation"], [142, "installation"], [143, "installation"], [145, "installation"], [146, "installation"], [147, "installation"], [148, "installation"], [150, "installation"], [152, "installation"], [153, "installation"], [290, "installation"], [293, "installation"], [296, "installation"], [298, "installation"], [308, "installation"], [309, "installation"], [310, "installation"], [311, "installation"], [312, "installation"], [313, "installation"], [315, "installation"], [323, "installation"], [326, "installation"], [327, "installation"], [329, "installation"], [330, "installation"], [333, "installation"], [334, "installation"], [335, "installation"], [336, "installation"], [337, "installation"], [339, "installation"], [340, "installation"], [341, "installation"], [342, "installation"], [343, "installation"], [344, "installation"], [345, "installation"], [346, "installation"], [347, "installation"], [348, "installation"], [349, "installation"], [350, "installation"], [351, "installation"], [352, "installation"], [354, "installation"], [355, "installation"], [356, "installation"], [357, "installation"], [358, "installation"], [360, "installation"], [361, "installation"], [362, "installation"], [363, "installation"], [364, "installation"], [365, "installation"], [366, "installation"], [367, "installation"], [368, "installation"]], "2. Prepare Dataset": [[58, "prepare-dataset"], [60, "prepare-dataset"], [62, "prepare-dataset"], [63, "prepare-dataset"], [66, "prepare-dataset"], [68, "prepare-dataset"], [131, "prepare-dataset"], [134, "prepare-dataset"], [135, "prepare-dataset"], [139, "prepare-dataset"], [142, "prepare-dataset"], [143, "prepare-dataset"], [145, "prepare-dataset"], [146, "prepare-dataset"], [148, "prepare-dataset"], [150, "prepare-dataset"], [315, "prepare-dataset"], [323, "prepare-dataset"], [327, "prepare-dataset"], [329, "prepare-dataset"], [330, "prepare-dataset"], [333, "prepare-dataset"], [334, "prepare-dataset"], [335, "prepare-dataset"], [355, "prepare-dataset"]], "3. Download the FP32 model": [[58, "download-the-fp32-model"], [62, "download-the-fp32-model"], [63, "download-the-fp32-model"]], "4. Update the root of dataset in conf.yaml": [[58, "update-the-root-of-dataset-in-conf-yaml"], [62, "update-the-root-of-dataset-in-conf-yaml"], [63, "update-the-root-of-dataset-in-conf-yaml"]], "5. Run Command": [[58, "run-command"], [60, "run-command"], [62, "run-command"], [63, "run-command"]], "6. Introduction": [[58, "introduction"], [60, "introduction"], [62, "introduction"], [63, "introduction"]], "tf_example2 example": [[59, "tf-example2-example"]], "Step-by-Step": [[59, "step-by-step"], [66, "step-by-step"], [67, "step-by-step"], [68, "step-by-step"], [131, "step-by-step"], [134, "step-by-step"], [135, "step-by-step"], [139, "step-by-step"], [142, "step-by-step"], [143, "step-by-step"], [145, "step-by-step"], [146, "step-by-step"], [147, "step-by-step"], [148, "step-by-step"], [150, "step-by-step"], [152, "step-by-step"], [153, "step-by-step"], [290, "step-by-step"], [291, "step-by-step"], [292, "step-by-step"], [293, "step-by-step"], [294, "step-by-step"], [296, "step-by-step"], [298, "step-by-step"], [299, "step-by-step"], [300, "step-by-step"], [301, "step-by-step"], [302, "step-by-step"], [304, "step-by-step"], [308, "step-by-step"], [309, "step-by-step"], [310, "step-by-step"], [311, "step-by-step"], [312, "step-by-step"], [313, "step-by-step"], [315, "step-by-step"], [323, "step-by-step"], [326, "step-by-step"], [327, "step-by-step"], [329, "step-by-step"], [330, "step-by-step"], [333, "step-by-step"], [334, "step-by-step"], [335, "step-by-step"], [336, "step-by-step"], [337, "step-by-step"], [338, "step-by-step"], [339, "step-by-step"], [340, "step-by-step"], [341, "step-by-step"], [342, "step-by-step"], [343, "step-by-step"], [344, "step-by-step"], [345, "step-by-step"], [346, "step-by-step"], [347, "step-by-step"], [348, "step-by-step"], [349, "step-by-step"], [350, "step-by-step"], [351, "step-by-step"], [352, "step-by-step"], [354, "step-by-step"], [355, "step-by-step"], [356, "step-by-step"], [357, "step-by-step"], [358, "step-by-step"], [359, "step-by-step"], [360, "step-by-step"], [361, "step-by-step"], [362, "step-by-step"], [364, "step-by-step"], [365, "step-by-step"], [366, "step-by-step"], [367, "step-by-step"], [368, "step-by-step"]], "Prerequisite": [[59, "prerequisite"], [66, "prerequisite"], [67, "prerequisite"], [68, "prerequisite"], [131, "prerequisite"], [134, "prerequisite"], [135, "prerequisite"], [139, "prerequisite"], [142, "prerequisite"], [143, "prerequisite"], [145, "prerequisite"], [146, "prerequisite"], [147, "prerequisite"], [148, "prerequisite"], [150, "prerequisite"], [152, "prerequisite"], [153, "prerequisite"], [290, "prerequisite"], [291, "prerequisite"], [292, "prerequisite"], [293, "prerequisite"], [294, "prerequisite"], [296, "prerequisite"], [298, "prerequisite"], [299, "prerequisite"], [300, "prerequisite"], [301, "prerequisite"], [302, "prerequisite"], [304, "prerequisite"], [308, "prerequisite"], [309, "prerequisite"], [310, "prerequisite"], [311, "prerequisite"], [312, "prerequisite"], [313, "prerequisite"], [315, "prerequisite"], [323, "prerequisite"], [326, "prerequisite"], [327, "prerequisite"], [329, "prerequisite"], [330, "prerequisite"], [333, "prerequisite"], [334, "prerequisite"], [335, "prerequisite"], [336, "prerequisite"], [337, "prerequisite"], [338, "prerequisite"], [339, "prerequisite"], [340, "prerequisite"], [341, "prerequisite"], [342, "prerequisite"], [343, "prerequisite"], [344, "prerequisite"], [345, "prerequisite"], [346, "prerequisite"], [347, "prerequisite"], [348, "prerequisite"], [349, "prerequisite"], [350, "prerequisite"], [351, "prerequisite"], [352, "prerequisite"], [354, "prerequisite"], [355, "prerequisite"], [356, "prerequisite"], [357, "prerequisite"], [358, "prerequisite"], [359, "prerequisite"], [360, "prerequisite"], [361, "prerequisite"], [362, "prerequisite"], [363, "prerequisite"], [364, "prerequisite"], [365, "prerequisite"], [366, "prerequisite"], [367, "prerequisite"], [368, "prerequisite"]], "2. Prepare FP32 model": [[59, "prepare-fp32-model"]], "Run Command": [[59, "run-command"], [336, "run-command"], [339, "run-command"], [340, "run-command"], [341, "run-command"], [342, "run-command"], [343, "run-command"], [344, "run-command"], [345, "run-command"], [346, "run-command"], [347, "run-command"], [348, "run-command"], [349, "run-command"], [350, "run-command"], [352, "run-command"], [356, "run-command"], [357, "run-command"], [358, "run-command"], [359, "run-command"], [360, "run-command"], [361, "run-command"], [362, "run-command"], [368, "run-command"]], "1. Add inputs and outputs information into conf.yaml, to get the input and output tensor name please refer to helloworld/train.py.": [[59, "add-inputs-and-outputs-information-into-conf-yaml-to-get-the-input-and-output-tensor-name-please-refer-to-helloworld-train-py"]], "2. Define a customer dataloader for mnist": [[59, "define-a-customer-dataloader-for-mnist"]], "3. Define a customized metric": [[59, "define-a-customized-metric"]], "4. Use the customized data loader and metric for quantization": [[59, "use-the-customized-data-loader-and-metric-for-quantization"]], "5. Run quantized model": [[59, "run-quantized-model"]], "tf_example3 example": [[60, "tf-example3-example"]], "3. Prepare the FP32 model": [[60, "prepare-the-fp32-model"]], "4. Config dataloader in conf.yaml": [[60, "config-dataloader-in-conf-yaml"]], "tf_example4 example": [[61, "tf-example4-example"]], "2. Download the FP32 model": [[61, "download-the-fp32-model"], [65, "download-the-fp32-model"]], "3. Run Command": [[61, "run-command"], [64, "run-command"], [65, "run-command"]], "4. Introduction": [[61, "introduction"], [64, "introduction"], [65, "introduction"]], "tf_example5 example": [[62, "tf-example5-example"]], "tf_example6 example": [[63, "tf-example6-example"]], "tf_example7 example": [[64, "tf-example7-example"]], "2. Prepare Model": [[64, "prepare-model"]], "tf_example8 example": [[65, "tf-example8-example"]], "2. Prepare Pre-trained model": [[66, "prepare-pre-trained-model"]], "Run": [[66, "run"], [67, "run"], [68, "run"], [131, "run"], [134, "run"], [135, "run"], [139, "run"], [144, "run"], [145, "run"], [146, "run"], [147, "run"], [148, "run"], [149, "run"], [150, "run"], [153, "run"], [297, "run"], [312, "run"], [315, "run"], [323, "run"], [325, "run"], [326, "run"], [327, "run"], [329, "run"], [330, "run"], [333, "run"], [334, "run"], [335, "run"], [354, "run"], [355, "run"], [364, "run"], [367, "run"]], "ResNet18_v1": [[66, "resnet18-v1"]], "ResNet50_v1": [[66, "resnet50-v1"]], "ResNet152_v1": [[66, "resnet152-v1"]], "SqueezeNet1": [[66, "squeezenet1"]], "MobileNet1.0": [[66, "mobilenet1-0"]], "MobileNetv2_1.0": [[66, "mobilenetv2-1-0"]], "Inception_v3": [[66, "inception-v3"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on MXNet ResNet50": [[66, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-mxnet-resnet50"]], "User Code Analysis": [[66, "user-code-analysis"], [67, "user-code-analysis"], [68, "user-code-analysis"], [131, "user-code-analysis"], [134, "user-code-analysis"], [135, "user-code-analysis"], [139, "user-code-analysis"], [146, "user-code-analysis"], [147, "user-code-analysis"], [148, "user-code-analysis"], [150, "user-code-analysis"], [153, "user-code-analysis"], [290, "user-code-analysis"], [298, "user-code-analysis"], [308, "user-code-analysis"], [313, "user-code-analysis"], [315, "user-code-analysis"], [327, "user-code-analysis"], [329, "user-code-analysis"], [330, "user-code-analysis"], [333, "user-code-analysis"], [354, "user-code-analysis"], [355, "user-code-analysis"], [356, "user-code-analysis"], [357, "user-code-analysis"], [359, "user-code-analysis"], [360, "user-code-analysis"], [361, "user-code-analysis"], [362, "user-code-analysis"], [367, "user-code-analysis"], [368, "user-code-analysis"]], "Write Yaml config file": [[66, "write-yaml-config-file"], [67, "write-yaml-config-file"], [68, "write-yaml-config-file"], [135, "write-yaml-config-file"], [153, "write-yaml-config-file"], [290, "write-yaml-config-file"], [296, "write-yaml-config-file"], [298, "write-yaml-config-file"], [308, "write-yaml-config-file"], [309, "write-yaml-config-file"], [310, "write-yaml-config-file"], [311, "write-yaml-config-file"], [313, "write-yaml-config-file"], [329, "write-yaml-config-file"], [330, "write-yaml-config-file"], [333, "write-yaml-config-file"], [336, "write-yaml-config-file"], [339, "write-yaml-config-file"], [340, "write-yaml-config-file"], [341, "write-yaml-config-file"], [342, "write-yaml-config-file"], [343, "write-yaml-config-file"], [344, "write-yaml-config-file"], [345, "write-yaml-config-file"], [346, "write-yaml-config-file"], [347, "write-yaml-config-file"], [348, "write-yaml-config-file"], [349, "write-yaml-config-file"], [350, "write-yaml-config-file"], [354, "write-yaml-config-file"], [355, "write-yaml-config-file"], [356, "write-yaml-config-file"], [357, "write-yaml-config-file"], [358, "write-yaml-config-file"], [360, "write-yaml-config-file"], [361, "write-yaml-config-file"], [362, "write-yaml-config-file"], [367, "write-yaml-config-file"], [368, "write-yaml-config-file"]], "code update": [[66, "code-update"], [67, "code-update"], [68, "code-update"], [135, "code-update"], [153, "code-update"], [329, "code-update"], [330, "code-update"], [333, "code-update"], [354, "code-update"], [355, "code-update"]], "2. Dataset": [[67, "dataset"]], "3. Finetune model": [[67, "finetune-model"]], "bert_base MRPC": [[67, "bert-base-mrpc"]], "bert_base Squad": [[67, "bert-base-squad"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on MXNet BERT_base": [[67, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-mxnet-bert-base"]], "SSD-ResNet50_v1-VOC": [[68, "ssd-resnet50-v1-voc"]], "SSD-Mobilenet1.0-VOC": [[68, "ssd-mobilenet1-0-voc"]], "SSD-ResNet50_v1-COCO": [[68, "ssd-resnet50-v1-coco"]], "SSD-Mobilenet1.0-COCO": [[68, "ssd-mobilenet1-0-coco"]], "benchmark": [[68, "benchmark"], [329, "benchmark"], [330, "benchmark"], [333, "benchmark"], [355, "benchmark"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on MXNet Object detection": [[68, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-mxnet-object-detection"]], "Performance of FP32 Vs. INT8 ResNet50 Model": [[69, "performance-of-fp32-vs-int8-resnet50-model"]], "Steps": [[69, "steps"], [72, "steps"]], "Check CPU Support Intel\u00ae Deep Learning Boost": [[69, "check-cpu-support-intel-deep-learning-boost"]], "Setup Environment": [[69, "setup-environment"]], "Script": [[69, "script"]], "Activate Running Environment": [[69, "activate-running-environment"]], "Run Sample": [[69, "run-sample"]], "Check Result": [[69, "check-result"], [70, "check-result"], [71, "check-result"]], "Intel\u00ae Neural Compressor Sample for PyTorch*": [[70, "intel-neural-compressor-sample-for-pytorch"]], "Code": [[70, "code"], [71, "code"]], "Hardware Environment": [[70, "hardware-environment"], [71, "hardware-environment"]], "Running Environment": [[70, "running-environment"], [71, "running-environment"]], "Intel\u00ae DevCloud": [[70, "intel-devcloud"], [71, "intel-devcloud"]], "Getting Started with Intel\u00ae DevCloud": [[70, "getting-started-with-intel-devcloud"], [71, "getting-started-with-intel-devcloud"]], "Setup based on Intel\u00ae oneAPI AI Analytics Toolkit": [[70, "setup-based-on-intel-oneapi-ai-analytics-toolkit"], [71, "setup-based-on-intel-oneapi-ai-analytics-toolkit"]], "Run in Jupyter Notebook in Intel\u00ae DevCloud for oneAPI": [[70, "run-in-jupyter-notebook-in-intel-devcloud-for-oneapi"], [71, "run-in-jupyter-notebook-in-intel-devcloud-for-oneapi"]], "Run in SSH Login Intel\u00ae DevCloud for oneAPI": [[70, "run-in-ssh-login-intel-devcloud-for-oneapi"], [71, "run-in-ssh-login-intel-devcloud-for-oneapi"]], "Job Submit": [[70, "job-submit"], [71, "job-submit"]], "Check job status": [[70, "check-job-status"], [71, "check-job-status"]], "Check Result in Log File": [[70, "check-result-in-log-file"], [71, "check-result-in-log-file"]], "Check Result in PNG file": [[70, "check-result-in-png-file"], [71, "check-result-in-png-file"]], "Customer Server": [[70, "customer-server"], [71, "customer-server"]], "Install by PyPi": [[70, "install-by-pypi"], [71, "install-by-pypi"]], "Install by Conda": [[70, "install-by-conda"], [71, "install-by-conda"]], "Run by SSH": [[70, "run-by-ssh"], [71, "run-by-ssh"]], "Run by Jupyter Notebook": [[70, "run-by-jupyter-notebook"], [71, "run-by-jupyter-notebook"]], "Intel\u00ae Neural Compressor Sample for TensorFlow*": [[71, "intel-neural-compressor-sample-for-tensorflow"]], "Usage Example": [[72, "usage-example"], [224, "usage-example"]], "ONNX model quantization": [[73, "onnx-model-quantization"]], "Dynamic quantization": [[73, "dynamic-quantization"]], "How to use": [[73, "how-to-use"], [73, "id1"]], "Static quantization": [[73, "static-quantization"]], "Operator oriented with QLinearOps": [[73, "operator-oriented-with-qlinearops"]], "Tensor oriented (QDQ format)": [[73, "tensor-oriented-qdq-format"]], "Evaluate performance of ONNX Runtime(Emotion FERPlus)": [[74, "evaluate-performance-of-onnx-runtime-emotion-ferplus"]], "Environment": [[74, "environment"], [75, "environment"], [76, "environment"], [77, "environment"], [78, "environment"], [79, "environment"], [80, "environment"], [81, "environment"], [82, "environment"], [83, "environment"], [84, "environment"], [85, "environment"], [86, "environment"], [87, "environment"], [88, "environment"], [89, "environment"], [90, "environment"], [91, "environment"], [92, "environment"], [93, "environment"], [94, "environment"], [95, "environment"], [96, "environment"], [97, "environment"], [98, "environment"], [99, "environment"], [100, "environment"], [101, "environment"], [102, "environment"], [103, "environment"], [104, "environment"], [105, "environment"], [106, "environment"], [107, "environment"], [108, "environment"], [109, "environment"], [110, "environment"], [111, "environment"], [112, "environment"], [113, "environment"], [114, "environment"], [115, "environment"], [130, "environment"]], "Prepare model": [[74, "prepare-model"], [75, "prepare-model"], [76, "prepare-model"], [77, "prepare-model"], [78, "prepare-model"], [79, "prepare-model"], [80, "prepare-model"], [81, "prepare-model"], [82, "prepare-model"], [83, "prepare-model"], [84, "prepare-model"], [85, "prepare-model"], [86, "prepare-model"], [87, "prepare-model"], [88, "prepare-model"], [89, "prepare-model"], [90, "prepare-model"], [91, "prepare-model"], [92, "prepare-model"], [93, "prepare-model"], [94, "prepare-model"], [95, "prepare-model"], [96, "prepare-model"], [97, "prepare-model"], [98, "prepare-model"], [99, "prepare-model"], [100, "prepare-model"], [101, "prepare-model"], [102, "prepare-model"], [103, "prepare-model"], [105, "prepare-model"], [106, "prepare-model"], [107, "prepare-model"], [108, "prepare-model"], [109, "prepare-model"], [110, "prepare-model"], [111, "prepare-model"], [112, "prepare-model"], [113, "prepare-model"], [114, "prepare-model"], [115, "prepare-model"]], "Evaluate performance of ONNX Runtime(Ultra-lightweight face detection)": [[75, "evaluate-performance-of-onnx-runtime-ultra-lightweight-face-detection"]], "Evaluate performance of ONNX Runtime(Mobilenet v2)": [[76, "evaluate-performance-of-onnx-runtime-mobilenet-v2"]], "Evaluate performance of ONNX Runtime(Mobilenet v3)": [[77, "evaluate-performance-of-onnx-runtime-mobilenet-v3"]], "Evaluate performance of ONNX Runtime(Alexnet)": [[78, "evaluate-performance-of-onnx-runtime-alexnet"]], "Evaluate performance of ONNX Runtime(ArcFace)": [[79, "evaluate-performance-of-onnx-runtime-arcface"]], "Evaluate performance of ONNX Runtime(Caffenet)": [[80, "evaluate-performance-of-onnx-runtime-caffenet"]], "Evaluate performance of ONNX Runtime(Densenet)": [[81, "evaluate-performance-of-onnx-runtime-densenet"]], "Evaluate performance of ONNX Runtime(EfficientNet-Lite4)": [[82, "evaluate-performance-of-onnx-runtime-efficientnet-lite4"]], "Evaluate performance of ONNX Runtime(FCN)": [[83, "evaluate-performance-of-onnx-runtime-fcn"]], "Evaluate performance of ONNX Runtime(Googlenet)": [[84, "evaluate-performance-of-onnx-runtime-googlenet"]], "Evaluate performance of ONNX Runtime(Inception)": [[85, "evaluate-performance-of-onnx-runtime-inception"]], "Evaluate performance of ONNX Runtime(MNIST)": [[86, "evaluate-performance-of-onnx-runtime-mnist"]], "Evaluate performance of ONNX Runtime(Mobilenet)": [[87, "evaluate-performance-of-onnx-runtime-mobilenet"]], "Evaluate performance of ONNX Runtime(ResNet 50)": [[88, "evaluate-performance-of-onnx-runtime-resnet-50"], [93, "evaluate-performance-of-onnx-runtime-resnet-50"]], "Evaluate performance of ONNX Runtime(Shufflenet)": [[89, "evaluate-performance-of-onnx-runtime-shufflenet"]], "Evaluate performance of ONNX Runtime(Squeezenet)": [[90, "evaluate-performance-of-onnx-runtime-squeezenet"]], "Evaluate performance of ONNX Runtime(VGG16)": [[91, "evaluate-performance-of-onnx-runtime-vgg16"], [95, "evaluate-performance-of-onnx-runtime-vgg16"]], "Evaluate performance of ONNX Runtime(ZFNet)": [[92, "evaluate-performance-of-onnx-runtime-zfnet"]], "ResNet 50 from torchvision": [[93, "resnet-50-from-torchvision"]], "ResNet 50 from MLPerf": [[93, "resnet-50-from-mlperf"]], "Evaluate performance of ONNX Runtime(unet)": [[94, "evaluate-performance-of-onnx-runtime-unet"]], "Evaluate performance of ONNX Runtime(BERT)": [[96, "evaluate-performance-of-onnx-runtime-bert"], [102, "evaluate-performance-of-onnx-runtime-bert"]], "Dynamic quantization environment:": [[96, "dynamic-quantization-environment"]], "Static quantization environment:": [[96, "static-quantization-environment"]], "Prepare dataset": [[96, "prepare-dataset"], [97, "prepare-dataset"], [98, "prepare-dataset"], [99, "prepare-dataset"], [100, "prepare-dataset"], [102, "prepare-dataset"], [103, "prepare-dataset"], [104, "prepare-dataset"], [105, "prepare-dataset"], [141, "prepare-dataset"], [144, "prepare-dataset"], [298, "prepare-dataset"], [303, "prepare-dataset"]], "Evaluate performance of ONNX Runtime(DistilBERT)": [[97, "evaluate-performance-of-onnx-runtime-distilbert"]], "Evaluate performance of ONNX Runtime(Huggingface Question Answering)": [[98, "evaluate-performance-of-onnx-runtime-huggingface-question-answering"]], "Evaluate performance of ONNX Runtime(Huggingface Text Classification)": [[99, "evaluate-performance-of-onnx-runtime-huggingface-text-classification"]], "Evaluate performance of ONNX Runtime(MobileBERT)": [[100, "evaluate-performance-of-onnx-runtime-mobilebert"], [104, "evaluate-performance-of-onnx-runtime-mobilebert"]], "Evaluate performance of ONNX Runtime(BiDAF)": [[101, "evaluate-performance-of-onnx-runtime-bidaf"]], "Evaluate performance of ONNX Runtime(GPT2)": [[103, "evaluate-performance-of-onnx-runtime-gpt2"]], "Evaluating": [[103, "evaluating"]], "Evaluate performance of ONNX Runtime(RoBERTa)": [[105, "evaluate-performance-of-onnx-runtime-roberta"]], "Evaluate performance of ONNX Runtime(ResNet101-DUC)": [[106, "evaluate-performance-of-onnx-runtime-resnet101-duc"]], "Evaluate performance of ONNX Runtime(Faster R-CNN)": [[107, "evaluate-performance-of-onnx-runtime-faster-r-cnn"]], "Evaluate performance of ONNX Runtime(Mask R-CNN)": [[108, "evaluate-performance-of-onnx-runtime-mask-r-cnn"]], "Evaluate performance of ONNX Runtime(SSD)": [[109, "evaluate-performance-of-onnx-runtime-ssd"]], "Evaluate performance of ONNX Runtime(SSD Mobilenet v1)": [[110, "evaluate-performance-of-onnx-runtime-ssd-mobilenet-v1"], [114, "evaluate-performance-of-onnx-runtime-ssd-mobilenet-v1"]], "Evaluate performance of ONNX Runtime(Tiny-YOLOv3)": [[111, "evaluate-performance-of-onnx-runtime-tiny-yolov3"]], "Evaluate performance of ONNX Runtime(yolov3)": [[112, "evaluate-performance-of-onnx-runtime-yolov3"]], "Evaluate performance of ONNX Runtime(YOLOv4)": [[113, "evaluate-performance-of-onnx-runtime-yolov4"]], "Evaluate performance of ONNX Runtime(SSD Mobilenet v2)": [[115, "evaluate-performance-of-onnx-runtime-ssd-mobilenet-v2"]], "A example using Textual Inversion method to personalize text2image": [[116, "a-example-using-textual-inversion-method-to-personalize-text2image"]], "Installing the dependencies": [[116, "installing-the-dependencies"]], "Nezha cartoon example": [[116, "nezha-cartoon-example"]], "finetune with CPU using IPEX": [[116, "finetune-with-cpu-using-ipex"]], "Distributed": [[116, "distributed"], [144, "distributed"]], "finetune with GPU using accelerate": [[116, "finetune-with-gpu-using-accelerate"]], "Inference": [[116, "inference"], [261, "inference"], [328, "inference"]], "MLPerf Inference Benchmarks for Medical Image 3D Segmentation": [[117, "mlperf-inference-benchmarks-for-medical-image-3d-segmentation"]], "Supported Models": [[117, "supported-models"]], "Disclaimer": [[117, "disclaimer"]], "Commands": [[117, "commands"]], "Calibration Set": [[117, "calibration-set"]], "running cmd": [[118, "running-cmd"]], "Model Baseline": [[118, "model-baseline"]], "Data format for Inference": [[119, "data-format-for-inference"]], "Dataset conversion instructions": [[120, "dataset-conversion-instructions"]], "How to use decathlon datasets": [[120, "how-to-use-decathlon-datasets"]], "Extending/Changing nnU-Net": [[121, "extending-changing-nnu-net"], [126, "extending-changing-nnu-net"]], "Changes to blueprint parameters": [[121, "changes-to-blueprint-parameters"]], "Changes to Inferred Parameters": [[121, "changes-to-inferred-parameters"]], "Use a different network architecture": [[121, "use-a-different-network-architecture"]], "Example: inference with pretrained nnU-Net models": [[122, "example-inference-with-pretrained-nnu-net-models"]], "Setting up Paths": [[123, "setting-up-paths"]], "How to set environment variables": [[123, "how-to-set-environment-variables"]], "An alternative way of setting these paths": [[123, "an-alternative-way-of-setting-these-paths"]], "Example: 3D U-Net training on the Hippocampus dataset": [[124, "example-3d-u-net-training-on-the-hippocampus-dataset"]], "nnU-Net": [[126, "nnu-net"]], "How to run nnU-Net on a new dataset": [[126, "how-to-run-nnu-net-on-a-new-dataset"]], "Dataset conversion": [[126, "dataset-conversion"]], "Experiment planning and preprocessing": [[126, "experiment-planning-and-preprocessing"]], "Model training": [[126, "model-training"]], "2D U-Net": [[126, "d-u-net"]], "3D full resolution U-Net": [[126, "d-full-resolution-u-net"], [126, "id1"]], "3D U-Net cascade": [[126, "d-u-net-cascade"]], "3D low resolution U-Net": [[126, "d-low-resolution-u-net"]], "Multi GPU training": [[126, "multi-gpu-training"]], "Identifying the best U-Net configuration": [[126, "identifying-the-best-u-net-configuration"]], "Run inference": [[126, "run-inference"]], "How to run inference with pretrained models": [[126, "how-to-run-inference-with-pretrained-models"]], "FAQ": [[126, "faq"]], "Manual Splitting of Data": [[126, "manual-splitting-of-data"]], "Do I need to always run all U-Net configurations?": [[126, "do-i-need-to-always-run-all-u-net-configurations"]], "Sharing Models": [[126, "sharing-models"]], "Can I run nnU-Net on smaller GPUs?": [[126, "can-i-run-nnu-net-on-smaller-gpus"]], "I get the error seg from prev stage missing when running the cascade": [[126, "i-get-the-error-seg-from-prev-stage-missing-when-running-the-cascade"]], "Why am I getting RuntimeError: CUDA error: device-side assert triggered?": [[126, "why-am-i-getting-runtimeerror-cuda-error-device-side-assert-triggered"]], "Why is no 3d_lowres model created?": [[126, "why-is-no-3d-lowres-model-created"]], "CIFAR100 Distillation Example": [[127, "cifar100-distillation-example"], [129, "cifar100-distillation-example"]], "CIFAR10 Distillation Example": [[128, "cifar10-distillation-example"]], "(Generic) EfficientNets for PyTorch": [[130, "generic-efficientnets-for-pytorch"]], "What\u2019s New": [[130, "what-s-new"]], "April 5, 2020": [[130, "april-5-2020"]], "March 23, 2020": [[130, "march-23-2020"]], "Feb 12, 2020": [[130, "feb-12-2020"]], "Jan 22, 2020": [[130, "jan-22-2020"]], "Nov 22, 2019": [[130, "nov-22-2019"]], "Nov 15, 2019": [[130, "nov-15-2019"]], "Oct 30, 2019": [[130, "oct-30-2019"]], "Oct 27, 2019": [[130, "oct-27-2019"]], "Models": [[130, "models"], [168, null], [180, "models"]], "Pretrained": [[130, "pretrained"]], "Ported Weights": [[130, "ported-weights"]], "PyTorch Hub": [[130, "pytorch-hub"]], "Pip": [[130, "pip"]], "Exporting": [[130, "exporting"]], "1. Efficientnet_b0": [[131, "efficientnet-b0"]], "2. Mobilenetv3_rw": [[131, "mobilenetv3-rw"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on PyTorch ResNet": [[131, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-pytorch-resnet"], [134, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-pytorch-resnet"]], "Write Yaml Config File": [[131, "write-yaml-config-file"], [134, "write-yaml-config-file"], [139, "write-yaml-config-file"], [146, "write-yaml-config-file"], [147, "write-yaml-config-file"], [148, "write-yaml-config-file"], [148, "id1"], [150, "write-yaml-config-file"], [315, "write-yaml-config-file"], [327, "write-yaml-config-file"], [359, "write-yaml-config-file"]], "Prepare": [[131, "prepare"], [134, "prepare"], [139, "prepare"], [145, "prepare"], [146, "prepare"], [147, "prepare"], [148, "prepare"], [148, "id2"], [150, "prepare"], [297, "prepare"], [315, "prepare"], [327, "prepare"]], "Code Update": [[131, "code-update"], [134, "code-update"], [139, "code-update"], [145, "code-update"], [146, "code-update"], [148, "code-update"], [148, "id3"], [150, "code-update"], [315, "code-update"], [327, "code-update"], [359, "code-update"]], "Distributed MNIST Example": [[132, "distributed-mnist-example"]], "PeleeNet": [[133, "peleenet"]], "Results on ImageNet ILSVRC 2012": [[133, "results-on-imagenet-ilsvrc-2012"]], "3. Prepare pretrained model": [[134, "prepare-pretrained-model"], [329, "prepare-pretrained-model"], [330, "prepare-pretrained-model"], [333, "prepare-pretrained-model"]], "1. ResNest50": [[135, "resnest50"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on PyTorch ResNest": [[135, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-pytorch-resnest"], [153, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-pytorch-resnest"]], "prepare": [[135, "prepare"], [153, "prepare"], [329, "prepare"], [355, "prepare"]], "ResNeSt": [[136, "resnest"]], "Pypi / GitHub Install": [[136, "pypi-github-install"]], "Pretrained Models": [[136, "pretrained-models"], [137, "pretrained-models"]], "PyTorch Models": [[136, "pytorch-models"], [137, "pytorch-models"]], "Gluon Models": [[136, "gluon-models"], [137, "gluon-models"]], "Transfer Learning Models": [[136, "transfer-learning-models"]], "Detectron Models": [[136, "detectron-models"], [136, "id1"]], "Object Detection on MS-COCO validation set": [[136, "object-detection-on-ms-coco-validation-set"]], "Instance Segmentation": [[136, "instance-segmentation"]], "Panoptic Segmentation": [[136, "panoptic-segmentation"]], "Semantic Segmentation": [[136, "semantic-segmentation"], [136, "id2"]], "Results on ADE20K": [[136, "results-on-ade20k"]], "Results on Cityscapes": [[136, "results-on-cityscapes"]], "Verify Backbone Models:": [[136, "verify-backbone-models"]], "Prepare ImageNet dataset:": [[136, "prepare-imagenet-dataset"]], "Torch Model": [[136, "torch-model"]], "Gluon Model": [[136, "gluon-model"]], "How to Train": [[136, "how-to-train"]], "ImageNet Models": [[136, "imagenet-models"]], "Major Contributors": [[136, "major-contributors"]], "Train ResNeSt with MXNet Gluon": [[138, "train-resnest-with-mxnet-gluon"]], "Install MXNet with Horovod": [[138, "install-mxnet-with-horovod"]], "Prepare ImageNet recordio data format": [[138, "prepare-imagenet-recordio-data-format"]], "Training command": [[138, "training-command"]], "Verify pretrained model": [[138, "verify-pretrained-model"]], "Python First": [[139, "python-first"], [293, "python-first"]], "Install dependency": [[139, "install-dependency"], [290, "install-dependency"], [291, "install-dependency"], [292, "install-dependency"], [294, "install-dependency"], [296, "install-dependency"], [298, "install-dependency"], [299, "install-dependency"], [300, "install-dependency"], [301, "install-dependency"], [302, "install-dependency"], [304, "install-dependency"], [308, "install-dependency"], [309, "install-dependency"], [310, "install-dependency"], [311, "install-dependency"], [313, "install-dependency"]], "Install SE_ResNext model": [[139, "install-se-resnext-model"]], "SE_ResNext50_32x4d": [[139, "se-resnext50-32x4d"]], "Examples of enabling Intel\u00ae Neural Compressor": [[139, "examples-of-enabling-intel-neural-compressor"], [290, "examples-of-enabling-intel-neural-compressor"], [298, "examples-of-enabling-intel-neural-compressor"], [308, "examples-of-enabling-intel-neural-compressor"], [313, "examples-of-enabling-intel-neural-compressor"], [329, "examples-of-enabling-intel-neural-compressor"], [330, "examples-of-enabling-intel-neural-compressor"], [333, "examples-of-enabling-intel-neural-compressor"]], "Original SE_ResNext README": [[139, "original-se-resnext-readme"]], "Pretrained models for Pytorch (Work in progress)": [[140, "pretrained-models-for-pytorch-work-in-progress"]], "Summary": [[140, "summary"]], "Install from pip": [[140, "install-from-pip"]], "Install from repo": [[140, "install-from-repo"]], "Quick examples": [[140, "quick-examples"]], "Few use cases": [[140, "few-use-cases"]], "Compute imagenet logits": [[140, "compute-imagenet-logits"]], "Compute imagenet evaluation metrics": [[140, "compute-imagenet-evaluation-metrics"]], "Evaluation on imagenet": [[140, "evaluation-on-imagenet"]], "Accuracy on validation set (single model)": [[140, "accuracy-on-validation-set-single-model"]], "Reproducing results": [[140, "reproducing-results"]], "Available models": [[140, "available-models"]], "NASNet*": [[140, "nasnet"]], "FaceBook ResNet*": [[140, "facebook-resnet"]], "Caffe ResNet*": [[140, "caffe-resnet"]], "Inception*": [[140, "inception"]], "BNInception": [[140, "bninception"]], "ResNeXt*": [[140, "resnext"]], "DualPathNetworks": [[140, "dualpathnetworks"]], "Xception": [[140, "xception"]], "SENet*": [[140, "senet"]], "PNASNet*": [[140, "pnasnet"]], "PolyNet": [[140, "polynet"]], "TorchVision": [[140, "torchvision"]], "Model API": [[140, "model-api"]], "model.input_size": [[140, "model-input-size"]], "model.input_space": [[140, "model-input-space"]], "model.input_range": [[140, "model-input-range"]], "model.mean": [[140, "model-mean"]], "model.std": [[140, "model-std"]], "model.features": [[140, "model-features"]], "model.logits": [[140, "model-logits"]], "model.forward": [[140, "model-forward"]], "model.last_linear": [[140, "model-last-linear"]], "Reproducing": [[140, "reproducing"]], "Hand porting of ResNet152": [[140, "hand-porting-of-resnet152"]], "Automatic porting of ResNeXt": [[140, "automatic-porting-of-resnext"]], "Hand porting of NASNet, InceptionV4 and InceptionResNetV2": [[140, "hand-porting-of-nasnet-inceptionv4-and-inceptionresnetv2"]], "Acknowledgement": [[140, "acknowledgement"]], "Run pretraining": [[141, "run-pretraining"], [353, "run-pretraining"]], "3. Run": [[142, "run"], [143, "run"], [293, "run"]], "Run prune and PTQ": [[142, "run-prune-and-ptq"]], "Run prune only": [[142, "run-prune-only"]], "Run PTQ only": [[142, "run-ptq-only"]], "4. Scheduler": [[142, "scheduler"], [143, "scheduler"]], "Run qat during prune": [[143, "run-qat-during-prune"]], "Prepare an environment": [[144, "prepare-an-environment"]], "Prepare configuration": [[144, "prepare-configuration"]], "Non-distributed": [[144, "non-distributed"]], "Other notes": [[144, "other-notes"]], "1. ResNet50": [[145, "resnet50"], [146, "resnet50"], [148, "resnet50"], [150, "resnet50"]], "2. ResNet18": [[145, "resnet18"], [146, "resnet18"], [148, "resnet18"], [150, "resnet18"]], "3. ResNext101_32x8d": [[145, "resnext101-32x8d"], [148, "resnext101-32x8d"], [150, "resnext101-32x8d"]], "4. InceptionV3": [[145, "inceptionv3"], [146, "inceptionv3"]], "5. Mobilenet_v2": [[145, "mobilenet-v2"], [146, "mobilenet-v2"]], "6. ResNet50 dump tensors for debug": [[145, "resnet50-dump-tensors-for-debug"]], "Saving and loading model:": [[145, "saving-and-loading-model"], [146, "saving-and-loading-model"], [315, "saving-and-loading-model"]], "Dump tensors for debug": [[145, "dump-tensors-for-debug"], [146, "dump-tensors-for-debug"]], "3. ResNeXt101_32x8d": [[146, "resnext101-32x8d"]], "Examples of enabling Neural Compressor auto tuning on PyTorch ResNet": [[146, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet"], [147, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet"], [315, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet"]], "2. Install pytorch and intel-pytorch-extension": [[147, "install-pytorch-and-intel-pytorch-extension"]], "3. Prepare Dataset": [[147, "prepare-dataset"], [364, "prepare-dataset"]], "1. ResNet18 With Intel PyTorch Extension": [[147, "resnet18-with-intel-pytorch-extension"]], "2. ResNet50 With Intel PyTorch Extension": [[147, "resnet50-with-intel-pytorch-extension"]], "3. ResNext101_32x16d With Intel PyTorch Extension": [[147, "resnext101-32x16d-with-intel-pytorch-extension"]], "Saving model:": [[147, "saving-model"]], "Tuning With Intel PyTorch Extension": [[147, "tuning-with-intel-pytorch-extension"]], "Examples Of Enabling Neural Compressor Auto Tuning On PyTorch ResNet": [[148, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet"], [150, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-resnet"]], "With buildin training function": [[148, "with-buildin-training-function"]], "Without buildin training function": [[148, "without-buildin-training-function"]], "4. MobileNetV2": [[148, "mobilenetv2"]], "distributed example on QAT": [[149, "distributed-example-on-qat"]], "Prepare requirements": [[151, "prepare-requirements"]], "Run self distillation": [[151, "run-self-distillation"]], "CIFAR100 benchmark": [[151, "cifar100-benchmark"]], "Paper:": [[151, "paper"]], "Our results in CIFAR100": [[151, "our-results-in-cifar100"]], "2. Prepare model and Dataset": [[152, "prepare-model-and-dataset"], [153, "prepare-model-and-dataset"]], "model": [[152, "model"], [153, "model"]], "3. Distillation of BlendCNN with BERT-Base as Teacher": [[152, "distillation-of-blendcnn-with-bert-base-as-teacher"], [153, "distillation-of-blendcnn-with-bert-base-as-teacher"]], "3.1 Fine-tune the pretrained BERT-Base model on MRPC dataset": [[152, "fine-tune-the-pretrained-bert-base-model-on-mrpc-dataset"], [153, "fine-tune-the-pretrained-bert-base-model-on-mrpc-dataset"]], "3.2 Distilling the BlendCNN with BERT-Base": [[152, "distilling-the-blendcnn-with-bert-base"], [153, "distilling-the-blendcnn-with-bert-base"]], "dataset": [[153, "dataset"]], "blendcnn": [[153, "blendcnn"]], "Enforcement Responsibilities": [[154, "enforcement-responsibilities"]], "Enforcement Guidelines": [[154, "enforcement-guidelines"]], "1. Correction": [[154, "correction"]], "2. Warning": [[154, "warning"]], "3. Temporary Ban": [[154, "temporary-ban"]], "4. Permanent Ban": [[154, "permanent-ban"]], "How to contribute to transformers?": [[155, "how-to-contribute-to-transformers"]], "You can contribute in so many ways!": [[155, "you-can-contribute-in-so-many-ways"]], "Submitting a new issue or feature request": [[155, "submitting-a-new-issue-or-feature-request"]], "Did you find a bug?": [[155, "did-you-find-a-bug"]], "Do you want to implement a new model?": [[155, "do-you-want-to-implement-a-new-model"]], "Do you want a new feature (that is not a model)?": [[155, "do-you-want-a-new-feature-that-is-not-a-model"]], "Start contributing! (Pull Requests)": [[155, "start-contributing-pull-requests"]], "Checklist": [[155, "checklist"]], "Tests": [[155, "tests"]], "Style guide": [[155, "style-guide"]], "This guide was heavily inspired by the awesome scikit-learn guide to contributing": [[155, "this-guide-was-heavily-inspired-by-the-awesome-scikit-learn-guide-to-contributing"]], "Develop on Windows": [[155, "develop-on-windows"]], "Syncing forked master with upstream (HuggingFace) master": [[155, "syncing-forked-master-with-upstream-huggingface-master"]], "How To Request Support": [[156, "how-to-request-support"]], "The Forums": [[156, "the-forums"]], "The GitHub Issues": [[156, "the-github-issues"]], "Online demos": [[157, "online-demos"]], "Quick tour": [[157, "quick-tour"], [248, "quick-tour"]], "Why should I use transformers?": [[157, "why-should-i-use-transformers"]], "Why shouldn\u2019t I use transformers?": [[157, "why-shouldn-t-i-use-transformers"]], "With pip": [[157, "with-pip"]], "With conda": [[157, "with-conda"], [169, "with-conda"]], "Models architectures": [[157, "models-architectures"]], "Learn more": [[157, "learn-more"]], "Generating the documentation": [[158, "generating-the-documentation"]], "Packages installed": [[158, "packages-installed"]], "Building the documentation": [[158, "building-the-documentation"]], "Adding a new element to the tree (toc-tree)": [[158, "adding-a-new-element-to-the-tree-toc-tree"]], "Preview the documentation in a pull request": [[158, "preview-the-documentation-in-a-pull-request"]], "Writing Documentation - Specification": [[158, "writing-documentation-specification"]], "Adding a new tutorial": [[158, "adding-a-new-tutorial"]], "Adding a new model": [[158, "adding-a-new-model"]], "Writing source documentation": [[158, "writing-source-documentation"]], "Defining arguments in a method": [[158, "defining-arguments-in-a-method"]], "Writing a multi-line code block": [[158, "writing-a-multi-line-code-block"]], "Writing a return block": [[158, "writing-a-return-block"]], "How to add a model to \ud83e\udd17 Transformers?": [[159, "how-to-add-a-model-to-transformers"]], "General overview of \ud83e\udd17 Transformers": [[159, "general-overview-of-transformers"], [285, "general-overview-of-transformers"], [288, "general-overview-of-transformers"]], "Overview of models": [[159, "overview-of-models"], [285, "overview-of-models"], [288, "overview-of-models"]], "Overview of tokenizers": [[159, "overview-of-tokenizers"], [285, "overview-of-tokenizers"], [288, "overview-of-tokenizers"]], "Step-by-step recipe to add a model to \ud83e\udd17 Transformers": [[159, "step-by-step-recipe-to-add-a-model-to-transformers"], [285, "step-by-step-recipe-to-add-a-model-to-transformers"], [288, "step-by-step-recipe-to-add-a-model-to-transformers"]], "1. (Optional) Theoretical aspects of BrandNewBert": [[159, "optional-theoretical-aspects-of-brandnewbert"]], "2. Next prepare your environment": [[159, "next-prepare-your-environment"], [285, "next-prepare-your-environment"], [288, "next-prepare-your-environment"]], "3.-4. Run a pretrained checkpoint using the original repository": [[159, "run-a-pretrained-checkpoint-using-the-original-repository"]], "5.-14. Port BrandNewBert to \ud83e\udd17 Transformers": [[159, "port-brandnewbert-to-transformers"]], "Share your work!!": [[159, "share-your-work"], [285, "share-your-work"], [288, "share-your-work"]], "Benchmarks": [[160, "benchmarks"]], "How to benchmark \ud83e\udd17 Transformer models": [[160, "how-to-benchmark-transformer-models"]], "Benchmark best practices": [[160, "benchmark-best-practices"]], "Sharing your benchmark": [[160, "sharing-your-benchmark"]], "BERTology": [[161, "bertology"]], "Community": [[162, "community"]], "Community resources:": [[162, "community-resources"]], "Community notebooks:": [[162, "community-notebooks"], [282, "community-notebooks"]], "Converting Tensorflow Checkpoints": [[164, "converting-tensorflow-checkpoints"]], "BERT": [[164, "bert"], [192, "bert"], [241, "bert"], [242, "bert"]], "ALBERT": [[164, "albert"], [188, "albert"], [241, "albert"]], "OpenAI GPT": [[164, "openai-gpt"], [211, "openai-gpt"]], "OpenAI GPT-2": [[164, "openai-gpt-2"]], "Transformer-XL": [[164, "transformer-xl"], [241, "transformer-xl"]], "XLNet": [[164, "xlnet"], [239, "xlnet"], [241, "xlnet"], [310, "xlnet"]], "XLM": [[164, "xlm"], [236, "xlm"], [241, "xlm"], [242, "xlm"]], "T5": [[164, "t5"], [232, "t5"], [241, "t5"]], "Fine-tuning with custom datasets": [[165, "fine-tuning-with-custom-datasets"]], "Sequence Classification with IMDb Reviews": [[165, "sequence-classification-with-imdb-reviews"]], "Fine-tuning with Trainer": [[165, "fine-tuning-with-trainer"]], "Fine-tuning with native PyTorch/TensorFlow": [[165, "fine-tuning-with-native-pytorch-tensorflow"]], "Token Classification with W-NUT Emerging Entities": [[165, "token-classification-with-w-nut-emerging-entities"]], "Question Answering with SQuAD 2.0": [[165, "question-answering-with-squad-2-0"]], "Additional Resources": [[165, "additional-resources"]], "Using the \ud83e\udd17 NLP Datasets & Metrics library": [[165, "using-the-nlp-datasets-metrics-library"]], "Glossary": [[167, "glossary"]], "General terms": [[167, "general-terms"]], "Model inputs": [[167, "model-inputs"]], "Input IDs": [[167, "input-ids"]], "Attention mask": [[167, "attention-mask"]], "Token Type IDs": [[167, "token-type-ids"]], "Position IDs": [[167, "position-ids"]], "Labels": [[167, "labels"]], "Decoder input IDs": [[167, "decoder-input-ids"]], "Feed Forward Chunking": [[167, "feed-forward-chunking"]], "Transformers": [[168, "transformers"]], "Features": [[168, "features"]], "Contents": [[168, "contents"]], "Get started": [[168, null]], "Using \ud83e\udd17 Transformers": [[168, null]], "Advanced guides": [[168, null]], "Research": [[168, null]], "Main Classes": [[168, null]], "Internal Helpers": [[168, null]], "Installation with pip": [[169, "installation-with-pip"]], "Installing from source": [[169, "installing-from-source"]], "Editable install": [[169, "editable-install"]], "Caching models": [[169, "caching-models"]], "Note on model downloads (Continuous Integration or large-scale deployments)": [[169, "note-on-model-downloads-continuous-integration-or-large-scale-deployments"]], "Do you want to run a Transformer model on a mobile device?": [[169, "do-you-want-to-run-a-transformer-model-on-a-mobile-device"]], "General Utilities": [[170, "general-utilities"]], "Enums and namedtuples": [[170, "enums-and-namedtuples"], [174, "enums-and-namedtuples"]], "Special Decorators": [[170, "special-decorators"]], "Special Properties": [[170, "special-properties"]], "Other Utilities": [[170, "other-utilities"]], "Utilities for Generation": [[171, "utilities-for-generation"]], "Generate Outputs": [[171, "generate-outputs"]], "GreedySearchOutput": [[171, "greedysearchoutput"]], "SampleOutput": [[171, "sampleoutput"]], "BeamSearchOutput": [[171, "beamsearchoutput"]], "BeamSampleOutput": [[171, "beamsampleoutput"]], "LogitsProcessor": [[171, "logitsprocessor"]], "BeamSearch": [[171, "beamsearch"]], "Utilities": [[171, "utilities"], [173, "utilities"], [175, "utilities"]], "Custom Layers and Utilities": [[172, "custom-layers-and-utilities"]], "Pytorch custom modules": [[172, "pytorch-custom-modules"]], "PyTorch Helper Functions": [[172, "pytorch-helper-functions"]], "TensorFlow custom layers": [[172, "tensorflow-custom-layers"]], "TensorFlow loss functions": [[172, "tensorflow-loss-functions"]], "TensorFlow Helper Functions": [[172, "tensorflow-helper-functions"]], "Utilities for pipelines": [[173, "utilities-for-pipelines"]], "Argument handling": [[173, "argument-handling"]], "Data format": [[173, "data-format"]], "Utilities for Tokenizers": [[174, "utilities-for-tokenizers"]], "PreTrainedTokenizerBase": [[174, "pretrainedtokenizerbase"]], "SpecialTokensMixin": [[174, "specialtokensmixin"]], "Utilities for Trainer": [[175, "utilities-for-trainer"]], "Callbacks internals": [[175, "callbacks-internals"]], "Distributed Evaluation": [[175, "distributed-evaluation"], [175, "id1"]], "Callbacks": [[176, "callbacks"]], "Available Callbacks": [[176, "available-callbacks"]], "TrainerCallback": [[176, "trainercallback"]], "TrainerState": [[176, "trainerstate"]], "TrainerControl": [[176, "trainercontrol"]], "Configuration": [[177, "configuration"], [186, "configuration"]], "PretrainedConfig": [[177, "pretrainedconfig"]], "Feature Extractor": [[178, "feature-extractor"]], "PreTrainedFeatureExtractor": [[178, "pretrainedfeatureextractor"]], "BatchFeature": [[178, "batchfeature"]], "Logging": [[179, "logging"]], "Base setters": [[179, "base-setters"]], "Other functions": [[179, "other-functions"]], "PreTrainedModel": [[180, "pretrainedmodel"]], "ModuleUtilsMixin": [[180, "moduleutilsmixin"]], "TFPreTrainedModel": [[180, "tfpretrainedmodel"]], "TFModelUtilsMixin": [[180, "tfmodelutilsmixin"]], "FlaxPreTrainedModel": [[180, "flaxpretrainedmodel"]], "Generation": [[180, "generation"]], "Optimization": [[181, "optimization"], [388, "optimization"]], "AdamW (PyTorch)": [[181, "adamw-pytorch"]], "AdaFactor (PyTorch)": [[181, "adafactor-pytorch"]], "AdamWeightDecay (TensorFlow)": [[181, "adamweightdecay-tensorflow"]], "Schedules": [[181, "schedules"]], "Learning Rate Schedules (Pytorch)": [[181, "learning-rate-schedules-pytorch"]], "Warmup (TensorFlow)": [[181, "warmup-tensorflow"]], "Gradient Strategies": [[181, "gradient-strategies"]], "GradientAccumulator (TensorFlow)": [[181, "gradientaccumulator-tensorflow"]], "Model outputs": [[182, "model-outputs"]], "ModelOutput": [[182, "modeloutput"]], "BaseModelOutput": [[182, "basemodeloutput"]], "BaseModelOutputWithPooling": [[182, "basemodeloutputwithpooling"]], "BaseModelOutputWithCrossAttentions": [[182, "basemodeloutputwithcrossattentions"]], "BaseModelOutputWithPoolingAndCrossAttentions": [[182, "basemodeloutputwithpoolingandcrossattentions"]], "BaseModelOutputWithPast": [[182, "basemodeloutputwithpast"]], "BaseModelOutputWithPastAndCrossAttentions": [[182, "basemodeloutputwithpastandcrossattentions"]], "Seq2SeqModelOutput": [[182, "seq2seqmodeloutput"]], "CausalLMOutput": [[182, "causallmoutput"]], "CausalLMOutputWithCrossAttentions": [[182, "causallmoutputwithcrossattentions"]], "CausalLMOutputWithPast": [[182, "causallmoutputwithpast"]], "MaskedLMOutput": [[182, "maskedlmoutput"]], "Seq2SeqLMOutput": [[182, "seq2seqlmoutput"]], "NextSentencePredictorOutput": [[182, "nextsentencepredictoroutput"]], "SequenceClassifierOutput": [[182, "sequenceclassifieroutput"]], "Seq2SeqSequenceClassifierOutput": [[182, "seq2seqsequenceclassifieroutput"]], "MultipleChoiceModelOutput": [[182, "multiplechoicemodeloutput"]], "TokenClassifierOutput": [[182, "tokenclassifieroutput"]], "QuestionAnsweringModelOutput": [[182, "questionansweringmodeloutput"]], "Seq2SeqQuestionAnsweringModelOutput": [[182, "seq2seqquestionansweringmodeloutput"]], "TFBaseModelOutput": [[182, "tfbasemodeloutput"]], "TFBaseModelOutputWithPooling": [[182, "tfbasemodeloutputwithpooling"]], "TFBaseModelOutputWithPast": [[182, "tfbasemodeloutputwithpast"]], "TFSeq2SeqModelOutput": [[182, "tfseq2seqmodeloutput"]], "TFCausalLMOutput": [[182, "tfcausallmoutput"]], "TFCausalLMOutputWithPast": [[182, "tfcausallmoutputwithpast"]], "TFMaskedLMOutput": [[182, "tfmaskedlmoutput"]], "TFSeq2SeqLMOutput": [[182, "tfseq2seqlmoutput"]], "TFNextSentencePredictorOutput": [[182, "tfnextsentencepredictoroutput"]], "TFSequenceClassifierOutput": [[182, "tfsequenceclassifieroutput"]], "TFSeq2SeqSequenceClassifierOutput": [[182, "tfseq2seqsequenceclassifieroutput"]], "TFMultipleChoiceModelOutput": [[182, "tfmultiplechoicemodeloutput"]], "TFTokenClassifierOutput": [[182, "tftokenclassifieroutput"]], "TFQuestionAnsweringModelOutput": [[182, "tfquestionansweringmodeloutput"]], "TFSeq2SeqQuestionAnsweringModelOutput": [[182, "tfseq2seqquestionansweringmodeloutput"]], "Pipelines": [[183, "pipelines"]], "The pipeline abstraction": [[183, "the-pipeline-abstraction"]], "The task specific pipelines": [[183, "the-task-specific-pipelines"]], "ConversationalPipeline": [[183, "conversationalpipeline"]], "FeatureExtractionPipeline": [[183, "featureextractionpipeline"]], "FillMaskPipeline": [[183, "fillmaskpipeline"]], "NerPipeline": [[183, "nerpipeline"]], "QuestionAnsweringPipeline": [[183, "questionansweringpipeline"]], "SummarizationPipeline": [[183, "summarizationpipeline"]], "TableQuestionAnsweringPipeline": [[183, "tablequestionansweringpipeline"]], "TextClassificationPipeline": [[183, "textclassificationpipeline"]], "TextGenerationPipeline": [[183, "textgenerationpipeline"]], "Text2TextGenerationPipeline": [[183, "text2textgenerationpipeline"]], "TokenClassificationPipeline": [[183, "tokenclassificationpipeline"]], "TranslationPipeline": [[183, "translationpipeline"]], "ZeroShotClassificationPipeline": [[183, "zeroshotclassificationpipeline"]], "Parent class: Pipeline": [[183, "parent-class-pipeline"]], "Processors": [[184, "processors"], [184, "id1"], [184, "id2"]], "GLUE": [[184, "glue"]], "Example usage": [[184, "example-usage"], [184, "id3"]], "XNLI": [[184, "xnli"], [277, "xnli"]], "SQuAD": [[184, "squad"], [258, "squad"], [295, "squad"]], "Tokenizer": [[185, "tokenizer"]], "PreTrainedTokenizer": [[185, "pretrainedtokenizer"]], "PreTrainedTokenizerFast": [[185, "pretrainedtokenizerfast"]], "BatchEncoding": [[185, "batchencoding"]], "Trainer": [[186, "trainer"], [186, "id1"], [253, "trainer"]], "Seq2SeqTrainer": [[186, "seq2seqtrainer"]], "TFTrainer": [[186, "tftrainer"]], "TrainingArguments": [[186, "trainingarguments"]], "Seq2SeqTrainingArguments": [[186, "seq2seqtrainingarguments"]], "TFTrainingArguments": [[186, "tftrainingarguments"]], "Trainer Integrations": [[186, "trainer-integrations"]], "Installation Notes": [[186, "installation-notes"]], "FairScale": [[186, "fairscale"]], "DeepSpeed": [[186, "deepspeed"]], "Deployment with multiple GPUs": [[186, "deployment-with-multiple-gpus"]], "Deployment with one GPU": [[186, "deployment-with-one-gpu"]], "Deployment in Notebooks": [[186, "deployment-in-notebooks"]], "Shared Configuration": [[186, "shared-configuration"]], "ZeRO": [[186, "zero"]], "Optimizer": [[186, "optimizer"], [314, "optimizer"]], "Scheduler": [[186, "scheduler"]], "Automatic Mixed Precision": [[186, "automatic-mixed-precision"]], "Gradient Accumulation": [[186, "gradient-accumulation"]], "Gradient Clipping": [[186, "gradient-clipping"]], "Notes": [[186, "notes"], [324, "notes"]], "Main DeepSpeed Resources": [[186, "main-deepspeed-resources"]], "Migrating from previous packages": [[187, "migrating-from-previous-packages"]], "Migrating from transformers v3.x to v4.x": [[187, "migrating-from-transformers-v3-x-to-v4-x"]], "1. AutoTokenizers and pipelines now use fast (rust) tokenizers by default.": [[187, "autotokenizers-and-pipelines-now-use-fast-rust-tokenizers-by-default"]], "How to obtain the same behavior as v3.x in v4.x": [[187, "how-to-obtain-the-same-behavior-as-v3-x-in-v4-x"], [187, "id1"], [187, "id2"], [187, "id3"]], "2. SentencePiece is removed from the required dependencies": [[187, "sentencepiece-is-removed-from-the-required-dependencies"]], "3. The architecture of the repo has been updated so that each model resides in its folder": [[187, "the-architecture-of-the-repo-has-been-updated-so-that-each-model-resides-in-its-folder"]], "4. Switching the return_dict argument to True by default": [[187, "switching-the-return-dict-argument-to-true-by-default"]], "5. Removed some deprecated attributes": [[187, "removed-some-deprecated-attributes"]], "Migrating from pytorch-transformers to \ud83e\udd17 Transformers": [[187, "migrating-from-pytorch-transformers-to-transformers"]], "Positional order of some models\u2019 keywords inputs (attention_mask, token_type_ids\u2026) changed": [[187, "positional-order-of-some-models-keywords-inputs-attention-mask-token-type-ids-changed"]], "Migrating from pytorch-pretrained-bert": [[187, "migrating-from-pytorch-pretrained-bert"]], "Models always output tuples": [[187, "models-always-output-tuples"]], "Serialization": [[187, "serialization"]], "Optimizers: BertAdam & OpenAIAdam are now AdamW, schedules are standard PyTorch schedules": [[187, "optimizers-bertadam-openaiadam-are-now-adamw-schedules-are-standard-pytorch-schedules"]], "AlbertConfig": [[188, "albertconfig"]], "AlbertTokenizer": [[188, "alberttokenizer"]], "AlbertTokenizerFast": [[188, "alberttokenizerfast"]], "Albert specific outputs": [[188, "albert-specific-outputs"]], "AlbertModel": [[188, "albertmodel"]], "AlbertForPreTraining": [[188, "albertforpretraining"]], "AlbertForMaskedLM": [[188, "albertformaskedlm"]], "AlbertForSequenceClassification": [[188, "albertforsequenceclassification"]], "AlbertForMultipleChoice": [[188, "albertformultiplechoice"]], "AlbertForTokenClassification": [[188, "albertfortokenclassification"]], "AlbertForQuestionAnswering": [[188, "albertforquestionanswering"]], "TFAlbertModel": [[188, "tfalbertmodel"]], "TFAlbertForPreTraining": [[188, "tfalbertforpretraining"]], "TFAlbertForMaskedLM": [[188, "tfalbertformaskedlm"]], "TFAlbertForSequenceClassification": [[188, "tfalbertforsequenceclassification"]], "TFAlbertForMultipleChoice": [[188, "tfalbertformultiplechoice"]], "TFAlbertForTokenClassification": [[188, "tfalbertfortokenclassification"]], "TFAlbertForQuestionAnswering": [[188, "tfalbertforquestionanswering"]], "Auto Classes": [[189, "auto-classes"]], "AutoConfig": [[189, "autoconfig"]], "AutoTokenizer": [[189, "autotokenizer"]], "AutoModel": [[189, "automodel"]], "AutoModelForPreTraining": [[189, "automodelforpretraining"]], "AutoModelForCausalLM": [[189, "automodelforcausallm"]], "AutoModelForMaskedLM": [[189, "automodelformaskedlm"]], "AutoModelForSeq2SeqLM": [[189, "automodelforseq2seqlm"]], "AutoModelForSequenceClassification": [[189, "automodelforsequenceclassification"]], "AutoModelForMultipleChoice": [[189, "automodelformultiplechoice"]], "AutoModelForNextSentencePrediction": [[189, "automodelfornextsentenceprediction"]], "AutoModelForTokenClassification": [[189, "automodelfortokenclassification"]], "AutoModelForQuestionAnswering": [[189, "automodelforquestionanswering"]], "AutoModelForTableQuestionAnswering": [[189, "automodelfortablequestionanswering"]], "TFAutoModel": [[189, "tfautomodel"]], "TFAutoModelForPreTraining": [[189, "tfautomodelforpretraining"]], "TFAutoModelForCausalLM": [[189, "tfautomodelforcausallm"]], "TFAutoModelForMaskedLM": [[189, "tfautomodelformaskedlm"]], "TFAutoModelForSeq2SeqLM": [[189, "tfautomodelforseq2seqlm"]], "TFAutoModelForSequenceClassification": [[189, "tfautomodelforsequenceclassification"]], "TFAutoModelForMultipleChoice": [[189, "tfautomodelformultiplechoice"]], "TFAutoModelForTokenClassification": [[189, "tfautomodelfortokenclassification"]], "TFAutoModelForQuestionAnswering": [[189, "tfautomodelforquestionanswering"]], "FlaxAutoModel": [[189, "flaxautomodel"]], "BART": [[190, "bart"], [241, "bart"]], "Implementation Notes": [[190, "implementation-notes"], [195, "implementation-notes"], [209, "implementation-notes"], [219, "implementation-notes"], [224, "implementation-notes"]], "Mask Filling": [[190, "mask-filling"]], "BartConfig": [[190, "bartconfig"]], "BartTokenizer": [[190, "barttokenizer"]], "BartTokenizerFast": [[190, "barttokenizerfast"]], "BartModel": [[190, "bartmodel"]], "BartForConditionalGeneration": [[190, "bartforconditionalgeneration"]], "BartForSequenceClassification": [[190, "bartforsequenceclassification"]], "BartForQuestionAnswering": [[190, "bartforquestionanswering"]], "BartForCausalLM": [[190, "bartforcausallm"]], "TFBartModel": [[190, "tfbartmodel"]], "TFBartForConditionalGeneration": [[190, "tfbartforconditionalgeneration"]], "BARThez": [[191, "barthez"]], "BarthezTokenizer": [[191, "bartheztokenizer"]], "BarthezTokenizerFast": [[191, "bartheztokenizerfast"]], "BertConfig": [[192, "bertconfig"]], "BertTokenizer": [[192, "berttokenizer"]], "BertTokenizerFast": [[192, "berttokenizerfast"]], "Bert specific outputs": [[192, "bert-specific-outputs"]], "BertModel": [[192, "bertmodel"]], "BertForPreTraining": [[192, "bertforpretraining"]], "BertModelLMHeadModel": [[192, "bertmodellmheadmodel"]], "BertForMaskedLM": [[192, "bertformaskedlm"]], "BertForNextSentencePrediction": [[192, "bertfornextsentenceprediction"]], "BertForSequenceClassification": [[192, "bertforsequenceclassification"]], "BertForMultipleChoice": [[192, "bertformultiplechoice"]], "BertForTokenClassification": [[192, "bertfortokenclassification"]], "BertForQuestionAnswering": [[192, "bertforquestionanswering"]], "TFBertModel": [[192, "tfbertmodel"]], "TFBertForPreTraining": [[192, "tfbertforpretraining"]], "TFBertModelLMHeadModel": [[192, "tfbertmodellmheadmodel"]], "TFBertForMaskedLM": [[192, "tfbertformaskedlm"]], "TFBertForNextSentencePrediction": [[192, "tfbertfornextsentenceprediction"]], "TFBertForSequenceClassification": [[192, "tfbertforsequenceclassification"]], "TFBertForMultipleChoice": [[192, "tfbertformultiplechoice"]], "TFBertForTokenClassification": [[192, "tfbertfortokenclassification"]], "TFBertForQuestionAnswering": [[192, "tfbertforquestionanswering"]], "FlaxBertModel": [[192, "flaxbertmodel"]], "FlaxBertForMaskedLM": [[192, "flaxbertformaskedlm"]], "BertGeneration": [[193, "bertgeneration"]], "BertGenerationConfig": [[193, "bertgenerationconfig"]], "BertGenerationTokenizer": [[193, "bertgenerationtokenizer"]], "BertGenerationEncoder": [[193, "bertgenerationencoder"]], "BertGenerationDecoder": [[193, "bertgenerationdecoder"]], "Bertweet": [[194, "bertweet"]], "BertweetTokenizer": [[194, "bertweettokenizer"]], "Blenderbot": [[195, "blenderbot"]], "BlenderbotConfig": [[195, "blenderbotconfig"]], "BlenderbotTokenizer": [[195, "blenderbottokenizer"]], "BlenderbotModel": [[195, "blenderbotmodel"]], "BlenderbotForConditionalGeneration": [[195, "blenderbotforconditionalgeneration"]], "BlenderbotForCausalLM": [[195, "blenderbotforcausallm"]], "TFBlenderbotModel": [[195, "tfblenderbotmodel"]], "TFBlenderbotForConditionalGeneration": [[195, "tfblenderbotforconditionalgeneration"]], "Blenderbot Small": [[196, "blenderbot-small"]], "BlenderbotSmallConfig": [[196, "blenderbotsmallconfig"]], "BlenderbotSmallTokenizer": [[196, "blenderbotsmalltokenizer"]], "BlenderbotSmallModel": [[196, "blenderbotsmallmodel"]], "BlenderbotSmallForConditionalGeneration": [[196, "blenderbotsmallforconditionalgeneration"]], "BlenderbotSmallForCausalLM": [[196, "blenderbotsmallforcausallm"]], "TFBlenderbotSmallModel": [[196, "tfblenderbotsmallmodel"]], "TFBlenderbotSmallForConditionalGeneration": [[196, "tfblenderbotsmallforconditionalgeneration"]], "BORT": [[197, "bort"]], "CamemBERT": [[198, "camembert"]], "CamembertConfig": [[198, "camembertconfig"]], "CamembertTokenizer": [[198, "camemberttokenizer"]], "CamembertTokenizerFast": [[198, "camemberttokenizerfast"]], "CamembertModel": [[198, "camembertmodel"]], "CamembertForCausalLM": [[198, "camembertforcausallm"]], "CamembertForMaskedLM": [[198, "camembertformaskedlm"]], "CamembertForSequenceClassification": [[198, "camembertforsequenceclassification"]], "CamembertForMultipleChoice": [[198, "camembertformultiplechoice"]], "CamembertForTokenClassification": [[198, "camembertfortokenclassification"]], "CamembertForQuestionAnswering": [[198, "camembertforquestionanswering"]], "TFCamembertModel": [[198, "tfcamembertmodel"]], "TFCamembertForMaskedLM": [[198, "tfcamembertformaskedlm"]], "TFCamembertForSequenceClassification": [[198, "tfcamembertforsequenceclassification"]], "TFCamembertForMultipleChoice": [[198, "tfcamembertformultiplechoice"]], "TFCamembertForTokenClassification": [[198, "tfcamembertfortokenclassification"]], "TFCamembertForQuestionAnswering": [[198, "tfcamembertforquestionanswering"]], "ConvBERT": [[199, "convbert"], [241, "convbert"]], "ConvBertConfig": [[199, "convbertconfig"]], "ConvBertTokenizer": [[199, "convberttokenizer"]], "ConvBertTokenizerFast": [[199, "convberttokenizerfast"]], "ConvBertModel": [[199, "convbertmodel"]], "ConvBertForMaskedLM": [[199, "convbertformaskedlm"]], "ConvBertForSequenceClassification": [[199, "convbertforsequenceclassification"]], "ConvBertForMultipleChoice": [[199, "convbertformultiplechoice"]], "ConvBertForTokenClassification": [[199, "convbertfortokenclassification"]], "ConvBertForQuestionAnswering": [[199, "convbertforquestionanswering"]], "TFConvBertModel": [[199, "tfconvbertmodel"]], "TFConvBertForMaskedLM": [[199, "tfconvbertformaskedlm"]], "TFConvBertForSequenceClassification": [[199, "tfconvbertforsequenceclassification"]], "TFConvBertForMultipleChoice": [[199, "tfconvbertformultiplechoice"]], "TFConvBertForTokenClassification": [[199, "tfconvbertfortokenclassification"]], "TFConvBertForQuestionAnswering": [[199, "tfconvbertforquestionanswering"]], "CTRL": [[200, "ctrl"], [241, "ctrl"]], "CTRLConfig": [[200, "ctrlconfig"]], "CTRLTokenizer": [[200, "ctrltokenizer"]], "CTRLModel": [[200, "ctrlmodel"]], "CTRLLMHeadModel": [[200, "ctrllmheadmodel"]], "CTRLForSequenceClassification": [[200, "ctrlforsequenceclassification"]], "TFCTRLModel": [[200, "tfctrlmodel"]], "TFCTRLLMHeadModel": [[200, "tfctrllmheadmodel"]], "TFCTRLForSequenceClassification": [[200, "tfctrlforsequenceclassification"]], "DeBERTa": [[201, "deberta"]], "DebertaConfig": [[201, "debertaconfig"]], "DebertaTokenizer": [[201, "debertatokenizer"]], "DebertaModel": [[201, "debertamodel"]], "DebertaPreTrainedModel": [[201, "debertapretrainedmodel"]], "DebertaForMaskedLM": [[201, "debertaformaskedlm"]], "DebertaForSequenceClassification": [[201, "debertaforsequenceclassification"]], "DebertaForTokenClassification": [[201, "debertafortokenclassification"]], "DebertaForQuestionAnswering": [[201, "debertaforquestionanswering"]], "DeBERTa-v2": [[202, "deberta-v2"]], "DebertaV2Config": [[202, "debertav2config"]], "DebertaV2Tokenizer": [[202, "debertav2tokenizer"]], "DebertaV2Model": [[202, "debertav2model"]], "DebertaV2PreTrainedModel": [[202, "debertav2pretrainedmodel"]], "DebertaV2ForMaskedLM": [[202, "debertav2formaskedlm"]], "DebertaV2ForSequenceClassification": [[202, "debertav2forsequenceclassification"]], "DebertaV2ForTokenClassification": [[202, "debertav2fortokenclassification"]], "DebertaV2ForQuestionAnswering": [[202, "debertav2forquestionanswering"]], "DialoGPT": [[203, "dialogpt"]], "DistilBERT": [[204, "distilbert"], [241, "distilbert"]], "DistilBertConfig": [[204, "distilbertconfig"]], "DistilBertTokenizer": [[204, "distilberttokenizer"]], "DistilBertTokenizerFast": [[204, "distilberttokenizerfast"]], "DistilBertModel": [[204, "distilbertmodel"]], "DistilBertForMaskedLM": [[204, "distilbertformaskedlm"]], "DistilBertForSequenceClassification": [[204, "distilbertforsequenceclassification"]], "DistilBertForMultipleChoice": [[204, "distilbertformultiplechoice"]], "DistilBertForTokenClassification": [[204, "distilbertfortokenclassification"]], "DistilBertForQuestionAnswering": [[204, "distilbertforquestionanswering"]], "TFDistilBertModel": [[204, "tfdistilbertmodel"]], "TFDistilBertForMaskedLM": [[204, "tfdistilbertformaskedlm"]], "TFDistilBertForSequenceClassification": [[204, "tfdistilbertforsequenceclassification"]], "TFDistilBertForMultipleChoice": [[204, "tfdistilbertformultiplechoice"]], "TFDistilBertForTokenClassification": [[204, "tfdistilbertfortokenclassification"]], "TFDistilBertForQuestionAnswering": [[204, "tfdistilbertforquestionanswering"]], "DPR": [[205, "dpr"], [241, "dpr"]], "DPRConfig": [[205, "dprconfig"]], "DPRContextEncoderTokenizer": [[205, "dprcontextencodertokenizer"]], "DPRContextEncoderTokenizerFast": [[205, "dprcontextencodertokenizerfast"]], "DPRQuestionEncoderTokenizer": [[205, "dprquestionencodertokenizer"]], "DPRQuestionEncoderTokenizerFast": [[205, "dprquestionencodertokenizerfast"]], "DPRReaderTokenizer": [[205, "dprreadertokenizer"]], "DPRReaderTokenizerFast": [[205, "dprreadertokenizerfast"]], "DPR specific outputs": [[205, "dpr-specific-outputs"]], "DPRContextEncoder": [[205, "dprcontextencoder"]], "DPRQuestionEncoder": [[205, "dprquestionencoder"]], "DPRReader": [[205, "dprreader"]], "TFDPRContextEncoder": [[205, "tfdprcontextencoder"]], "TFDPRQuestionEncoder": [[205, "tfdprquestionencoder"]], "TFDPRReader": [[205, "tfdprreader"]], "ELECTRA": [[206, "electra"], [241, "electra"]], "ElectraConfig": [[206, "electraconfig"]], "ElectraTokenizer": [[206, "electratokenizer"]], "ElectraTokenizerFast": [[206, "electratokenizerfast"]], "Electra specific outputs": [[206, "electra-specific-outputs"]], "ElectraModel": [[206, "electramodel"]], "ElectraForPreTraining": [[206, "electraforpretraining"]], "ElectraForMaskedLM": [[206, "electraformaskedlm"]], "ElectraForSequenceClassification": [[206, "electraforsequenceclassification"]], "ElectraForMultipleChoice": [[206, "electraformultiplechoice"]], "ElectraForTokenClassification": [[206, "electrafortokenclassification"]], "ElectraForQuestionAnswering": [[206, "electraforquestionanswering"]], "TFElectraModel": [[206, "tfelectramodel"]], "TFElectraForPreTraining": [[206, "tfelectraforpretraining"]], "TFElectraForMaskedLM": [[206, "tfelectraformaskedlm"]], "TFElectraForSequenceClassification": [[206, "tfelectraforsequenceclassification"]], "TFElectraForMultipleChoice": [[206, "tfelectraformultiplechoice"]], "TFElectraForTokenClassification": [[206, "tfelectrafortokenclassification"]], "TFElectraForQuestionAnswering": [[206, "tfelectraforquestionanswering"]], "Encoder Decoder Models": [[207, "encoder-decoder-models"]], "EncoderDecoderConfig": [[207, "encoderdecoderconfig"]], "EncoderDecoderModel": [[207, "encoderdecodermodel"]], "FlauBERT": [[208, "flaubert"], [241, "flaubert"]], "FlaubertConfig": [[208, "flaubertconfig"]], "FlaubertTokenizer": [[208, "flauberttokenizer"]], "FlaubertModel": [[208, "flaubertmodel"]], "FlaubertWithLMHeadModel": [[208, "flaubertwithlmheadmodel"]], "FlaubertForSequenceClassification": [[208, "flaubertforsequenceclassification"]], "FlaubertForMultipleChoice": [[208, "flaubertformultiplechoice"]], "FlaubertForTokenClassification": [[208, "flaubertfortokenclassification"]], "FlaubertForQuestionAnsweringSimple": [[208, "flaubertforquestionansweringsimple"]], "FlaubertForQuestionAnswering": [[208, "flaubertforquestionanswering"]], "TFFlaubertModel": [[208, "tfflaubertmodel"]], "TFFlaubertWithLMHeadModel": [[208, "tfflaubertwithlmheadmodel"]], "TFFlaubertForSequenceClassification": [[208, "tfflaubertforsequenceclassification"]], "TFFlaubertForMultipleChoice": [[208, "tfflaubertformultiplechoice"]], "TFFlaubertForTokenClassification": [[208, "tfflaubertfortokenclassification"]], "TFFlaubertForQuestionAnsweringSimple": [[208, "tfflaubertforquestionansweringsimple"]], "FSMT": [[209, "fsmt"]], "FSMTConfig": [[209, "fsmtconfig"]], "FSMTTokenizer": [[209, "fsmttokenizer"]], "FSMTModel": [[209, "fsmtmodel"]], "FSMTForConditionalGeneration": [[209, "fsmtforconditionalgeneration"]], "Funnel Transformer": [[210, "funnel-transformer"], [241, "funnel-transformer"]], "FunnelConfig": [[210, "funnelconfig"]], "FunnelTokenizer": [[210, "funneltokenizer"]], "FunnelTokenizerFast": [[210, "funneltokenizerfast"]], "Funnel specific outputs": [[210, "funnel-specific-outputs"]], "FunnelBaseModel": [[210, "funnelbasemodel"]], "FunnelModel": [[210, "funnelmodel"]], "FunnelModelForPreTraining": [[210, "funnelmodelforpretraining"]], "FunnelForMaskedLM": [[210, "funnelformaskedlm"]], "FunnelForSequenceClassification": [[210, "funnelforsequenceclassification"]], "FunnelForMultipleChoice": [[210, "funnelformultiplechoice"]], "FunnelForTokenClassification": [[210, "funnelfortokenclassification"]], "FunnelForQuestionAnswering": [[210, "funnelforquestionanswering"]], "TFFunnelBaseModel": [[210, "tffunnelbasemodel"]], "TFFunnelModel": [[210, "tffunnelmodel"]], "TFFunnelModelForPreTraining": [[210, "tffunnelmodelforpretraining"]], "TFFunnelForMaskedLM": [[210, "tffunnelformaskedlm"]], "TFFunnelForSequenceClassification": [[210, "tffunnelforsequenceclassification"]], "TFFunnelForMultipleChoice": [[210, "tffunnelformultiplechoice"]], "TFFunnelForTokenClassification": [[210, "tffunnelfortokenclassification"]], "TFFunnelForQuestionAnswering": [[210, "tffunnelforquestionanswering"]], "OpenAIGPTConfig": [[211, "openaigptconfig"]], "OpenAIGPTTokenizer": [[211, "openaigpttokenizer"]], "OpenAIGPTTokenizerFast": [[211, "openaigpttokenizerfast"]], "OpenAI specific outputs": [[211, "openai-specific-outputs"]], "OpenAIGPTModel": [[211, "openaigptmodel"]], "OpenAIGPTLMHeadModel": [[211, "openaigptlmheadmodel"]], "OpenAIGPTDoubleHeadsModel": [[211, "openaigptdoubleheadsmodel"]], "OpenAIGPTForSequenceClassification": [[211, "openaigptforsequenceclassification"]], "TFOpenAIGPTModel": [[211, "tfopenaigptmodel"]], "TFOpenAIGPTLMHeadModel": [[211, "tfopenaigptlmheadmodel"]], "TFOpenAIGPTDoubleHeadsModel": [[211, "tfopenaigptdoubleheadsmodel"]], "TFOpenAIGPTForSequenceClassification": [[211, "tfopenaigptforsequenceclassification"]], "OpenAI GPT2": [[212, "openai-gpt2"]], "GPT2Config": [[212, "gpt2config"]], "GPT2Tokenizer": [[212, "gpt2tokenizer"]], "GPT2TokenizerFast": [[212, "gpt2tokenizerfast"]], "GPT2 specific outputs": [[212, "gpt2-specific-outputs"]], "GPT2Model": [[212, "gpt2model"]], "GPT2LMHeadModel": [[212, "gpt2lmheadmodel"]], "GPT2DoubleHeadsModel": [[212, "gpt2doubleheadsmodel"]], "GPT2ForSequenceClassification": [[212, "gpt2forsequenceclassification"]], "TFGPT2Model": [[212, "tfgpt2model"]], "TFGPT2LMHeadModel": [[212, "tfgpt2lmheadmodel"]], "TFGPT2DoubleHeadsModel": [[212, "tfgpt2doubleheadsmodel"]], "TFGPT2ForSequenceClassification": [[212, "tfgpt2forsequenceclassification"]], "TFSequenceClassifierOutputWithPast": [[212, "tfsequenceclassifieroutputwithpast"]], "herBERT": [[213, "herbert"]], "HerbertTokenizer": [[213, "herberttokenizer"]], "HerbertTokenizerFast": [[213, "herberttokenizerfast"]], "I-BERT": [[214, "i-bert"]], "IBertConfig": [[214, "ibertconfig"]], "IBertModel": [[214, "ibertmodel"]], "IBertForMaskedLM": [[214, "ibertformaskedlm"]], "IBertForSequenceClassification": [[214, "ibertforsequenceclassification"]], "IBertForMultipleChoice": [[214, "ibertformultiplechoice"]], "IBertForTokenClassification": [[214, "ibertfortokenclassification"]], "IBertForQuestionAnswering": [[214, "ibertforquestionanswering"]], "LayoutLM": [[215, "layoutlm"]], "LayoutLMConfig": [[215, "layoutlmconfig"]], "LayoutLMTokenizer": [[215, "layoutlmtokenizer"]], "LayoutLMTokenizerFast": [[215, "layoutlmtokenizerfast"]], "LayoutLMModel": [[215, "layoutlmmodel"]], "LayoutLMForMaskedLM": [[215, "layoutlmformaskedlm"]], "LayoutLMForSequenceClassification": [[215, "layoutlmforsequenceclassification"]], "LayoutLMForTokenClassification": [[215, "layoutlmfortokenclassification"]], "LED": [[216, "led"]], "LEDConfig": [[216, "ledconfig"]], "LEDTokenizer": [[216, "ledtokenizer"]], "LEDTokenizerFast": [[216, "ledtokenizerfast"]], "LED specific outputs": [[216, "led-specific-outputs"]], "LEDModel": [[216, "ledmodel"]], "LEDForConditionalGeneration": [[216, "ledforconditionalgeneration"]], "LEDForSequenceClassification": [[216, "ledforsequenceclassification"]], "LEDForQuestionAnswering": [[216, "ledforquestionanswering"]], "TFLEDModel": [[216, "tfledmodel"]], "TFLEDForConditionalGeneration": [[216, "tfledforconditionalgeneration"]], "Longformer": [[217, "longformer"], [241, "longformer"]], "Longformer Self Attention": [[217, "longformer-self-attention"]], "Training": [[217, "training"], [228, "training"], [232, "training"], [261, "training"]], "LongformerConfig": [[217, "longformerconfig"]], "LongformerTokenizer": [[217, "longformertokenizer"]], "LongformerTokenizerFast": [[217, "longformertokenizerfast"]], "Longformer specific outputs": [[217, "longformer-specific-outputs"]], "LongformerModel": [[217, "longformermodel"]], "LongformerForMaskedLM": [[217, "longformerformaskedlm"]], "LongformerForSequenceClassification": [[217, "longformerforsequenceclassification"]], "LongformerForMultipleChoice": [[217, "longformerformultiplechoice"]], "LongformerForTokenClassification": [[217, "longformerfortokenclassification"]], "LongformerForQuestionAnswering": [[217, "longformerforquestionanswering"]], "TFLongformerModel": [[217, "tflongformermodel"]], "TFLongformerForMaskedLM": [[217, "tflongformerformaskedlm"]], "TFLongformerForQuestionAnswering": [[217, "tflongformerforquestionanswering"]], "TFLongformerForSequenceClassification": [[217, "tflongformerforsequenceclassification"]], "TFLongformerForTokenClassification": [[217, "tflongformerfortokenclassification"]], "TFLongformerForMultipleChoice": [[217, "tflongformerformultiplechoice"]], "LXMERT": [[218, "lxmert"]], "LxmertConfig": [[218, "lxmertconfig"]], "LxmertTokenizer": [[218, "lxmerttokenizer"]], "LxmertTokenizerFast": [[218, "lxmerttokenizerfast"]], "Lxmert specific outputs": [[218, "lxmert-specific-outputs"]], "LxmertModel": [[218, "lxmertmodel"]], "LxmertForPreTraining": [[218, "lxmertforpretraining"]], "LxmertForQuestionAnswering": [[218, "lxmertforquestionanswering"]], "TFLxmertModel": [[218, "tflxmertmodel"]], "TFLxmertForPreTraining": [[218, "tflxmertforpretraining"]], "MarianMT": [[219, "marianmt"], [241, "marianmt"]], "Naming": [[219, "naming"]], "Multilingual Models": [[219, "multilingual-models"]], "Old Style Multi-Lingual Models": [[219, "old-style-multi-lingual-models"]], "MarianConfig": [[219, "marianconfig"]], "MarianTokenizer": [[219, "mariantokenizer"]], "MarianModel": [[219, "marianmodel"]], "MarianMTModel": [[219, "marianmtmodel"]], "MarianForCausalLM": [[219, "marianforcausallm"]], "TFMarianModel": [[219, "tfmarianmodel"]], "TFMarianMTModel": [[219, "tfmarianmtmodel"]], "MBart and MBart-50": [[220, "mbart-and-mbart-50"]], "Overview of MBart": [[220, "overview-of-mbart"]], "Training of MBart": [[220, "training-of-mbart"]], "Overview of MBart-50": [[220, "overview-of-mbart-50"]], "Training of MBart-50": [[220, "training-of-mbart-50"]], "MBartConfig": [[220, "mbartconfig"]], "MBartTokenizer": [[220, "mbarttokenizer"]], "MBartTokenizerFast": [[220, "mbarttokenizerfast"]], "MBart50Tokenizer": [[220, "mbart50tokenizer"]], "MBart50TokenizerFast": [[220, "mbart50tokenizerfast"]], "MBartModel": [[220, "mbartmodel"]], "MBartForConditionalGeneration": [[220, "mbartforconditionalgeneration"]], "MBartForQuestionAnswering": [[220, "mbartforquestionanswering"]], "MBartForSequenceClassification": [[220, "mbartforsequenceclassification"]], "MBartForCausalLM": [[220, "mbartforcausallm"]], "TFMBartModel": [[220, "tfmbartmodel"]], "TFMBartForConditionalGeneration": [[220, "tfmbartforconditionalgeneration"]], "MobileBERT": [[221, "mobilebert"]], "MobileBertConfig": [[221, "mobilebertconfig"]], "MobileBertTokenizer": [[221, "mobileberttokenizer"]], "MobileBertTokenizerFast": [[221, "mobileberttokenizerfast"]], "MobileBert specific outputs": [[221, "mobilebert-specific-outputs"]], "MobileBertModel": [[221, "mobilebertmodel"]], "MobileBertForPreTraining": [[221, "mobilebertforpretraining"]], "MobileBertForMaskedLM": [[221, "mobilebertformaskedlm"]], "MobileBertForNextSentencePrediction": [[221, "mobilebertfornextsentenceprediction"]], "MobileBertForSequenceClassification": [[221, "mobilebertforsequenceclassification"]], "MobileBertForMultipleChoice": [[221, "mobilebertformultiplechoice"]], "MobileBertForTokenClassification": [[221, "mobilebertfortokenclassification"]], "MobileBertForQuestionAnswering": [[221, "mobilebertforquestionanswering"]], "TFMobileBertModel": [[221, "tfmobilebertmodel"]], "TFMobileBertForPreTraining": [[221, "tfmobilebertforpretraining"]], "TFMobileBertForMaskedLM": [[221, "tfmobilebertformaskedlm"]], "TFMobileBertForNextSentencePrediction": [[221, "tfmobilebertfornextsentenceprediction"]], "TFMobileBertForSequenceClassification": [[221, "tfmobilebertforsequenceclassification"]], "TFMobileBertForMultipleChoice": [[221, "tfmobilebertformultiplechoice"]], "TFMobileBertForTokenClassification": [[221, "tfmobilebertfortokenclassification"]], "TFMobileBertForQuestionAnswering": [[221, "tfmobilebertforquestionanswering"]], "MPNet": [[222, "mpnet"]], "MPNetConfig": [[222, "mpnetconfig"]], "MPNetTokenizer": [[222, "mpnettokenizer"]], "MPNetTokenizerFast": [[222, "mpnettokenizerfast"]], "MPNetModel": [[222, "mpnetmodel"]], "MPNetForMaskedLM": [[222, "mpnetformaskedlm"]], "MPNetForSequenceClassification": [[222, "mpnetforsequenceclassification"]], "MPNetForMultipleChoice": [[222, "mpnetformultiplechoice"]], "MPNetForTokenClassification": [[222, "mpnetfortokenclassification"]], "MPNetForQuestionAnswering": [[222, "mpnetforquestionanswering"]], "TFMPNetModel": [[222, "tfmpnetmodel"]], "TFMPNetForMaskedLM": [[222, "tfmpnetformaskedlm"]], "TFMPNetForSequenceClassification": [[222, "tfmpnetforsequenceclassification"]], "TFMPNetForMultipleChoice": [[222, "tfmpnetformultiplechoice"]], "TFMPNetForTokenClassification": [[222, "tfmpnetfortokenclassification"]], "TFMPNetForQuestionAnswering": [[222, "tfmpnetforquestionanswering"]], "MT5": [[223, "mt5"], [241, "mt5"]], "MT5Config": [[223, "mt5config"]], "MT5Tokenizer": [[223, "mt5tokenizer"]], "MT5TokenizerFast": [[223, "mt5tokenizerfast"]], "MT5Model": [[223, "mt5model"]], "MT5ForConditionalGeneration": [[223, "mt5forconditionalgeneration"]], "MT5EncoderModel": [[223, "mt5encodermodel"]], "TFMT5Model": [[223, "tfmt5model"]], "TFMT5ForConditionalGeneration": [[223, "tfmt5forconditionalgeneration"]], "TFMT5EncoderModel": [[223, "tfmt5encodermodel"]], "Pegasus": [[224, "pegasus"], [241, "pegasus"], [273, "pegasus"]], "Checkpoints": [[224, "checkpoints"]], "PegasusConfig": [[224, "pegasusconfig"]], "PegasusTokenizer": [[224, "pegasustokenizer"]], "PegasusTokenizerFast": [[224, "pegasustokenizerfast"]], "PegasusModel": [[224, "pegasusmodel"]], "PegasusForConditionalGeneration": [[224, "pegasusforconditionalgeneration"]], "PegasusForCausalLM": [[224, "pegasusforcausallm"]], "TFPegasusModel": [[224, "tfpegasusmodel"]], "TFPegasusForConditionalGeneration": [[224, "tfpegasusforconditionalgeneration"]], "PhoBERT": [[225, "phobert"]], "PhobertTokenizer": [[225, "phoberttokenizer"]], "ProphetNet": [[226, "prophetnet"], [241, "prophetnet"]], "ProphetNetConfig": [[226, "prophetnetconfig"]], "ProphetNetTokenizer": [[226, "prophetnettokenizer"]], "ProphetNet specific outputs": [[226, "prophetnet-specific-outputs"]], "ProphetNetModel": [[226, "prophetnetmodel"]], "ProphetNetEncoder": [[226, "prophetnetencoder"]], "ProphetNetDecoder": [[226, "prophetnetdecoder"]], "ProphetNetForConditionalGeneration": [[226, "prophetnetforconditionalgeneration"]], "ProphetNetForCausalLM": [[226, "prophetnetforcausallm"]], "RAG": [[227, "rag"], [241, "rag"]], "RagConfig": [[227, "ragconfig"]], "RagTokenizer": [[227, "ragtokenizer"]], "Rag specific outputs": [[227, "rag-specific-outputs"]], "RagRetriever": [[227, "ragretriever"]], "RagModel": [[227, "ragmodel"]], "RagSequenceForGeneration": [[227, "ragsequenceforgeneration"]], "RagTokenForGeneration": [[227, "ragtokenforgeneration"]], "Reformer": [[228, "reformer"], [241, "reformer"]], "Axial Positional Encodings": [[228, "axial-positional-encodings"]], "LSH Self Attention": [[228, "lsh-self-attention"]], "Local Self Attention": [[228, "local-self-attention"]], "ReformerConfig": [[228, "reformerconfig"]], "ReformerTokenizer": [[228, "reformertokenizer"]], "ReformerTokenizerFast": [[228, "reformertokenizerfast"]], "ReformerModel": [[228, "reformermodel"]], "ReformerModelWithLMHead": [[228, "reformermodelwithlmhead"]], "ReformerForMaskedLM": [[228, "reformerformaskedlm"]], "ReformerForSequenceClassification": [[228, "reformerforsequenceclassification"]], "ReformerForQuestionAnswering": [[228, "reformerforquestionanswering"]], "RetriBERT": [[229, "retribert"]], "RetriBertConfig": [[229, "retribertconfig"]], "RetriBertTokenizer": [[229, "retriberttokenizer"]], "RetriBertTokenizerFast": [[229, "retriberttokenizerfast"]], "RetriBertModel": [[229, "retribertmodel"]], "RoBERTa": [[230, "roberta"], [241, "roberta"]], "RobertaConfig": [[230, "robertaconfig"]], "RobertaTokenizer": [[230, "robertatokenizer"]], "RobertaTokenizerFast": [[230, "robertatokenizerfast"]], "RobertaModel": [[230, "robertamodel"]], "RobertaForCausalLM": [[230, "robertaforcausallm"]], "RobertaForMaskedLM": [[230, "robertaformaskedlm"]], "RobertaForSequenceClassification": [[230, "robertaforsequenceclassification"]], "RobertaForMultipleChoice": [[230, "robertaformultiplechoice"]], "RobertaForTokenClassification": [[230, "robertafortokenclassification"]], "RobertaForQuestionAnswering": [[230, "robertaforquestionanswering"]], "TFRobertaModel": [[230, "tfrobertamodel"]], "TFRobertaForMaskedLM": [[230, "tfrobertaformaskedlm"]], "TFRobertaForSequenceClassification": [[230, "tfrobertaforsequenceclassification"]], "TFRobertaForMultipleChoice": [[230, "tfrobertaformultiplechoice"]], "TFRobertaForTokenClassification": [[230, "tfrobertafortokenclassification"]], "TFRobertaForQuestionAnswering": [[230, "tfrobertaforquestionanswering"]], "FlaxRobertaModel": [[230, "flaxrobertamodel"]], "SqueezeBERT": [[231, "squeezebert"]], "SqueezeBertConfig": [[231, "squeezebertconfig"]], "SqueezeBertTokenizer": [[231, "squeezeberttokenizer"]], "SqueezeBertTokenizerFast": [[231, "squeezeberttokenizerfast"]], "SqueezeBertModel": [[231, "squeezebertmodel"]], "SqueezeBertForMaskedLM": [[231, "squeezebertformaskedlm"]], "SqueezeBertForSequenceClassification": [[231, "squeezebertforsequenceclassification"]], "SqueezeBertForMultipleChoice": [[231, "squeezebertformultiplechoice"]], "SqueezeBertForTokenClassification": [[231, "squeezebertfortokenclassification"]], "SqueezeBertForQuestionAnswering": [[231, "squeezebertforquestionanswering"]], "T5Config": [[232, "t5config"]], "T5Tokenizer": [[232, "t5tokenizer"]], "T5TokenizerFast": [[232, "t5tokenizerfast"]], "T5Model": [[232, "t5model"]], "T5ForConditionalGeneration": [[232, "t5forconditionalgeneration"]], "T5EncoderModel": [[232, "t5encodermodel"]], "TFT5Model": [[232, "tft5model"]], "TFT5ForConditionalGeneration": [[232, "tft5forconditionalgeneration"]], "TFT5EncoderModel": [[232, "tft5encodermodel"]], "TAPAS": [[233, "tapas"]], "Usage: fine-tuning": [[233, "usage-fine-tuning"]], "Usage: inference": [[233, "usage-inference"]], "Tapas specific outputs": [[233, "tapas-specific-outputs"]], "TapasConfig": [[233, "tapasconfig"]], "TapasTokenizer": [[233, "tapastokenizer"]], "TapasModel": [[233, "tapasmodel"]], "TapasForMaskedLM": [[233, "tapasformaskedlm"]], "TapasForSequenceClassification": [[233, "tapasforsequenceclassification"]], "TapasForQuestionAnswering": [[233, "tapasforquestionanswering"]], "Transformer XL": [[234, "transformer-xl"]], "TransfoXLConfig": [[234, "transfoxlconfig"]], "TransfoXLTokenizer": [[234, "transfoxltokenizer"]], "TransfoXL specific outputs": [[234, "transfoxl-specific-outputs"]], "TransfoXLModel": [[234, "transfoxlmodel"]], "TransfoXLLMHeadModel": [[234, "transfoxllmheadmodel"]], "TransfoXLForSequenceClassification": [[234, "transfoxlforsequenceclassification"]], "TFTransfoXLModel": [[234, "tftransfoxlmodel"]], "TFTransfoXLLMHeadModel": [[234, "tftransfoxllmheadmodel"]], "TFTransfoXLForSequenceClassification": [[234, "tftransfoxlforsequenceclassification"]], "Internal Layers": [[234, "internal-layers"]], "Wav2Vec2": [[235, "wav2vec2"]], "Wav2Vec2Config": [[235, "wav2vec2config"]], "Wav2Vec2CTCTokenizer": [[235, "wav2vec2ctctokenizer"]], "Wav2Vec2FeatureExtractor": [[235, "wav2vec2featureextractor"]], "Wav2Vec2Processor": [[235, "wav2vec2processor"]], "Wav2Vec2Model": [[235, "wav2vec2model"]], "Wav2Vec2ForCTC": [[235, "wav2vec2forctc"]], "XLMConfig": [[236, "xlmconfig"]], "XLMTokenizer": [[236, "xlmtokenizer"]], "XLM specific outputs": [[236, "xlm-specific-outputs"]], "XLMModel": [[236, "xlmmodel"]], "XLMWithLMHeadModel": [[236, "xlmwithlmheadmodel"]], "XLMForSequenceClassification": [[236, "xlmforsequenceclassification"]], "XLMForMultipleChoice": [[236, "xlmformultiplechoice"]], "XLMForTokenClassification": [[236, "xlmfortokenclassification"]], "XLMForQuestionAnsweringSimple": [[236, "xlmforquestionansweringsimple"]], "XLMForQuestionAnswering": [[236, "xlmforquestionanswering"]], "TFXLMModel": [[236, "tfxlmmodel"]], "TFXLMWithLMHeadModel": [[236, "tfxlmwithlmheadmodel"]], "TFXLMForSequenceClassification": [[236, "tfxlmforsequenceclassification"]], "TFXLMForMultipleChoice": [[236, "tfxlmformultiplechoice"]], "TFXLMForTokenClassification": [[236, "tfxlmfortokenclassification"]], "TFXLMForQuestionAnsweringSimple": [[236, "tfxlmforquestionansweringsimple"]], "XLM-ProphetNet": [[237, "xlm-prophetnet"], [241, "xlm-prophetnet"]], "XLMProphetNetConfig": [[237, "xlmprophetnetconfig"]], "XLMProphetNetTokenizer": [[237, "xlmprophetnettokenizer"]], "XLMProphetNetModel": [[237, "xlmprophetnetmodel"]], "XLMProphetNetEncoder": [[237, "xlmprophetnetencoder"]], "XLMProphetNetDecoder": [[237, "xlmprophetnetdecoder"]], "XLMProphetNetForConditionalGeneration": [[237, "xlmprophetnetforconditionalgeneration"]], "XLMProphetNetForCausalLM": [[237, "xlmprophetnetforcausallm"]], "XLM-RoBERTa": [[238, "xlm-roberta"], [241, "xlm-roberta"], [242, "xlm-roberta"]], "XLMRobertaConfig": [[238, "xlmrobertaconfig"]], "XLMRobertaTokenizer": [[238, "xlmrobertatokenizer"]], "XLMRobertaTokenizerFast": [[238, "xlmrobertatokenizerfast"]], "XLMRobertaModel": [[238, "xlmrobertamodel"]], "XLMRobertaForCausalLM": [[238, "xlmrobertaforcausallm"]], "XLMRobertaForMaskedLM": [[238, "xlmrobertaformaskedlm"]], "XLMRobertaForSequenceClassification": [[238, "xlmrobertaforsequenceclassification"]], "XLMRobertaForMultipleChoice": [[238, "xlmrobertaformultiplechoice"]], "XLMRobertaForTokenClassification": [[238, "xlmrobertafortokenclassification"]], "XLMRobertaForQuestionAnswering": [[238, "xlmrobertaforquestionanswering"]], "TFXLMRobertaModel": [[238, "tfxlmrobertamodel"]], "TFXLMRobertaForMaskedLM": [[238, "tfxlmrobertaformaskedlm"]], "TFXLMRobertaForSequenceClassification": [[238, "tfxlmrobertaforsequenceclassification"]], "TFXLMRobertaForMultipleChoice": [[238, "tfxlmrobertaformultiplechoice"]], "TFXLMRobertaForTokenClassification": [[238, "tfxlmrobertafortokenclassification"]], "TFXLMRobertaForQuestionAnswering": [[238, "tfxlmrobertaforquestionanswering"]], "XLNetConfig": [[239, "xlnetconfig"]], "XLNetTokenizer": [[239, "xlnettokenizer"]], "XLNetTokenizerFast": [[239, "xlnettokenizerfast"]], "XLNet specific outputs": [[239, "xlnet-specific-outputs"]], "XLNetModel": [[239, "xlnetmodel"]], "XLNetLMHeadModel": [[239, "xlnetlmheadmodel"]], "XLNetForSequenceClassification": [[239, "xlnetforsequenceclassification"]], "XLNetForMultipleChoice": [[239, "xlnetformultiplechoice"]], "XLNetForTokenClassification": [[239, "xlnetfortokenclassification"]], "XLNetForQuestionAnsweringSimple": [[239, "xlnetforquestionansweringsimple"]], "XLNetForQuestionAnswering": [[239, "xlnetforquestionanswering"]], "TFXLNetModel": [[239, "tfxlnetmodel"]], "TFXLNetLMHeadModel": [[239, "tfxlnetlmheadmodel"]], "TFXLNetForSequenceClassification": [[239, "tfxlnetforsequenceclassification"]], "TFLNetForMultipleChoice": [[239, "tflnetformultiplechoice"]], "TFXLNetForTokenClassification": [[239, "tfxlnetfortokenclassification"]], "TFXLNetForQuestionAnsweringSimple": [[239, "tfxlnetforquestionansweringsimple"]], "Model sharing and uploading": [[240, "model-sharing-and-uploading"]], "Prepare your model for uploading": [[240, "prepare-your-model-for-uploading"]], "Model versioning": [[240, "model-versioning"]], "Basic steps": [[240, "basic-steps"]], "Make your model work on all frameworks": [[240, "make-your-model-work-on-all-frameworks"]], "Check the directory before pushing to the model hub.": [[240, "check-the-directory-before-pushing-to-the-model-hub"]], "Uploading your files": [[240, "uploading-your-files"]], "Add a model card": [[240, "add-a-model-card"]], "Using your model": [[240, "using-your-model"]], "Workflow in a Colab notebook": [[240, "workflow-in-a-colab-notebook"]], "Summary of the models": [[241, "summary-of-the-models"]], "Autoregressive models": [[241, "autoregressive-models"]], "Original GPT": [[241, "original-gpt"]], "GPT-2": [[241, "gpt-2"]], "Autoencoding models": [[241, "autoencoding-models"]], "Sequence-to-sequence models": [[241, "sequence-to-sequence-models"]], "MBart": [[241, "mbart"]], "Multimodal models": [[241, "multimodal-models"]], "MMBT": [[241, "mmbt"]], "Retrieval-based models": [[241, "retrieval-based-models"]], "More technical aspects": [[241, "more-technical-aspects"]], "Full vs sparse attention": [[241, "full-vs-sparse-attention"]], "Other tricks": [[241, "other-tricks"]], "Multi-lingual models": [[242, "multi-lingual-models"]], "XLM & Language Embeddings": [[242, "xlm-language-embeddings"]], "XLM without Language Embeddings": [[242, "xlm-without-language-embeddings"]], "Perplexity of fixed-length models": [[244, "perplexity-of-fixed-length-models"]], "Calculating PPL with fixed-length models": [[244, "calculating-ppl-with-fixed-length-models"]], "Example: Calculating perplexity with GPT-2 in \ud83e\udd17 Transformers": [[244, "example-calculating-perplexity-with-gpt-2-in-transformers"]], "Philosophy": [[245, "philosophy"]], "Main concepts": [[245, "main-concepts"]], "Preprocessing data": [[246, "preprocessing-data"]], "Base use": [[246, "base-use"]], "Preprocessing pairs of sentences": [[246, "preprocessing-pairs-of-sentences"]], "Everything you always wanted to know about padding and truncation": [[246, "everything-you-always-wanted-to-know-about-padding-and-truncation"]], "Pre-tokenized inputs": [[246, "pre-tokenized-inputs"]], "Pretrained models": [[247, "pretrained-models"]], "Getting started on a task with a pipeline": [[248, "getting-started-on-a-task-with-a-pipeline"]], "Under the hood: pretrained models": [[248, "under-the-hood-pretrained-models"]], "Using the tokenizer": [[248, "using-the-tokenizer"]], "Using the model": [[248, "using-the-model"]], "Accessing the code": [[248, "accessing-the-code"]], "Customizing the model": [[248, "customizing-the-model"]], "Exporting transformers models": [[249, "exporting-transformers-models"]], "ONNX / ONNXRuntime": [[249, "onnx-onnxruntime"]], "Optimizations": [[249, "optimizations"]], "TorchScript": [[249, "torchscript"]], "Implications": [[249, "implications"]], "TorchScript flag and tied weights": [[249, "torchscript-flag-and-tied-weights"]], "Dummy inputs and standard lengths": [[249, "dummy-inputs-and-standard-lengths"]], "Using TorchScript in Python": [[249, "using-torchscript-in-python"]], "Saving a model": [[249, "saving-a-model"]], "Loading a model": [[249, "loading-a-model"]], "Using a traced model for inference": [[249, "using-a-traced-model-for-inference"]], "Summary of the tasks": [[250, "summary-of-the-tasks"]], "Sequence Classification": [[250, "sequence-classification"]], "Extractive Question Answering": [[250, "extractive-question-answering"]], "Language Modeling": [[250, "language-modeling"]], "Masked Language Modeling": [[250, "masked-language-modeling"]], "Causal Language Modeling": [[250, "causal-language-modeling"]], "Text Generation": [[250, "text-generation"]], "Named Entity Recognition": [[250, "named-entity-recognition"]], "Summarization": [[250, "summarization"], [276, "summarization"]], "Translation": [[250, "translation"], [276, "translation"]], "Testing": [[251, "testing"]], "How transformers are tested": [[251, "how-transformers-are-tested"]], "Running tests": [[251, "running-tests"]], "Choosing which tests to run": [[251, "choosing-which-tests-to-run"]], "Getting the list of all tests": [[251, "getting-the-list-of-all-tests"]], "Run a specific test module": [[251, "run-a-specific-test-module"]], "Run specific tests": [[251, "run-specific-tests"]], "Run only modified tests": [[251, "run-only-modified-tests"]], "Automatically rerun failed tests on source modification": [[251, "automatically-rerun-failed-tests-on-source-modification"]], "Skip a test module": [[251, "skip-a-test-module"]], "Clearing state": [[251, "clearing-state"]], "Running tests in parallel": [[251, "running-tests-in-parallel"]], "Test order and repetition": [[251, "test-order-and-repetition"]], "Repeat tests": [[251, "repeat-tests"]], "Run tests in a random order": [[251, "run-tests-in-a-random-order"]], "Look and feel variations": [[251, "look-and-feel-variations"]], "pytest-sugar": [[251, "pytest-sugar"]], "Report each sub-test name and its progress": [[251, "report-each-sub-test-name-and-its-progress"]], "Instantly shows failed tests": [[251, "instantly-shows-failed-tests"]], "To GPU or not to GPU": [[251, "to-gpu-or-not-to-gpu"]], "Distributed training": [[251, "distributed-training"], [258, "distributed-training"]], "Output capture": [[251, "output-capture"]], "Color control": [[251, "color-control"]], "Sending test report to online pastebin service": [[251, "sending-test-report-to-online-pastebin-service"]], "Writing tests": [[251, "writing-tests"]], "Parametrization": [[251, "parametrization"]], "Files and directories": [[251, "files-and-directories"]], "Temporary files and directories": [[251, "temporary-files-and-directories"]], "Skipping tests": [[251, "skipping-tests"]], "Implementation": [[251, "implementation"]], "Slow tests": [[251, "slow-tests"]], "Testing the stdout/stderr output": [[251, "testing-the-stdout-stderr-output"]], "Capturing logger stream": [[251, "capturing-logger-stream"]], "Testing with environment variables": [[251, "testing-with-environment-variables"]], "Getting reproducible results": [[251, "getting-reproducible-results"]], "Debugging tests": [[251, "debugging-tests"]], "Testing Experimental CI Features": [[251, "testing-experimental-ci-features"]], "Summary of the tokenizers": [[252, "summary-of-the-tokenizers"]], "Subword tokenization": [[252, "subword-tokenization"]], "Byte-Pair Encoding (BPE)": [[252, "byte-pair-encoding-bpe"]], "Byte-level BPE": [[252, "byte-level-bpe"]], "WordPiece": [[252, "wordpiece"]], "Unigram": [[252, "unigram"]], "SentencePiece": [[252, "sentencepiece"]], "Training and fine-tuning": [[253, "training-and-fine-tuning"]], "Fine-tuning in native PyTorch": [[253, "fine-tuning-in-native-pytorch"]], "Freezing the encoder": [[253, "freezing-the-encoder"]], "Fine-tuning in native TensorFlow 2": [[253, "fine-tuning-in-native-tensorflow-2"]], "Additional resources": [[253, "additional-resources"], [285, "additional-resources"], [288, "additional-resources"]], "Important note": [[254, "important-note"]], "The Big Table of Tasks": [[254, "the-big-table-of-tasks"]], "Distributed training and mixed precision": [[254, "distributed-training-and-mixed-precision"]], "Running on TPUs": [[254, "running-on-tpus"]], "Logging & Experiment tracking": [[254, "logging-experiment-tracking"]], "Weights & Biases": [[254, "weights-biases"]], "Comet.ml": [[254, "comet-ml"]], "\ud83e\udd17 Benchmark results": [[255, "benchmark-results"]], "Language model training": [[256, "language-model-training"]], "GPT-2/GPT and causal language modeling": [[256, "gpt-2-gpt-and-causal-language-modeling"]], "RoBERTa/BERT/DistilBERT and masked language modeling": [[256, "roberta-bert-distilbert-and-masked-language-modeling"]], "Whole word masking": [[256, "whole-word-masking"]], "XLNet and permutation language modeling": [[256, "xlnet-and-permutation-language-modeling"]], "Multiple Choice": [[257, "multiple-choice"]], "Fine-tuning on SWAG": [[257, "fine-tuning-on-swag"]], "Run it in colab": [[257, "run-it-in-colab"]], "Fine-tuning BERT on SQuAD1.0": [[258, "fine-tuning-bert-on-squad1-0"]], "Fine-tuning XLNet with beam search on SQuAD": [[258, "fine-tuning-xlnet-with-beam-search-on-squad"]], "Command for SQuAD1.0:": [[258, "command-for-squad1-0"]], "Command for SQuAD2.0:": [[258, "command-for-squad2-0"]], "Results for SQuAD1.0 with the previously defined hyper-parameters:": [[258, "results-for-squad1-0-with-the-previously-defined-hyper-parameters"]], "Results for SQuAD2.0 with the previously defined hyper-parameters:": [[258, "results-for-squad2-0-with-the-previously-defined-hyper-parameters"]], "Fine-tuning BERT on SQuAD1.0 with relative position embeddings": [[258, "fine-tuning-bert-on-squad1-0-with-relative-position-embeddings"]], "Base models fine-tuning": [[258, "base-models-fine-tuning"]], "Large models fine-tuning": [[258, "large-models-fine-tuning"]], "SQuAD with the Tensorflow Trainer": [[258, "squad-with-the-tensorflow-trainer"]], "Research projects": [[259, "research-projects"]], "Adversarial evaluation of model performances": [[260, "adversarial-evaluation-of-model-performances"]], "Patience-based Early Exit": [[261, "patience-based-early-exit"]], "Results": [[261, "results"], [295, "results"], [300, "results"], [305, "results"], [306, "results"]], "Text Summarization with Pretrained Encoders": [[262, "text-summarization-with-pretrained-encoders"]], "Setup": [[262, "setup"], [264, "setup"], [269, "setup"], [271, "setup"]], "Reproduce the authors\u2019  ROUGE score": [[262, "reproduce-the-authors-rouge-score"]], "Summarize any text": [[262, "summarize-any-text"]], "DeeBERT: Early Exiting for *BERT": [[263, "deebert-early-exiting-for-bert"]], "train_deebert.sh": [[263, "train-deebert-sh"]], "eval_deebert.sh": [[263, "eval-deebert-sh"]], "entropy_eval.sh": [[263, "entropy-eval-sh"]], "Distil*": [[264, "distil"]], "What is Distil*": [[264, "what-is-distil"]], "How to use DistilBERT": [[264, "how-to-use-distilbert"]], "How to train Distil*": [[264, "how-to-train-distil"]], "A. Preparing the data": [[264, "a-preparing-the-data"]], "B. Training": [[264, "b-training"]], "Long Form Question Answering": [[265, "long-form-question-answering"]], "LXMERT DEMO": [[266, "lxmert-demo"]], "Whole Word Mask Language Model": [[267, "whole-word-mask-language-model"]], "MM-IMDb": [[268, "mm-imdb"]], "Training on MM-IMDb": [[268, "training-on-mm-imdb"]], "Movement Pruning: Adaptive Sparsity by Fine-Tuning": [[269, "movement-pruning-adaptive-sparsity-by-fine-tuning"]], "Extreme sparsity and efficient storage": [[269, "extreme-sparsity-and-efficient-storage"]], "Fine-pruned models": [[269, "fine-pruned-models"]], "How to fine-prune?": [[269, "how-to-fine-prune"]], "Fine-pruning with movement pruning": [[269, "fine-pruning-with-movement-pruning"]], "Fine-pruning with other methods": [[269, "fine-pruning-with-other-methods"]], "After fine-pruning": [[269, "after-fine-pruning"]], "Hyper-parameters": [[269, "hyper-parameters"]], "Inference speed": [[269, "inference-speed"]], "Performer fine-tuning": [[270, "performer-fine-tuning"]], "Requirements": [[270, "requirements"], [377, "requirements"], [381, "requirements"]], "Plug and Play Language Models: a Simple Approach to Controlled Text Generation": [[271, "plug-and-play-language-models-a-simple-approach-to-controlled-text-generation"]], "PPLM-BoW": [[271, "pplm-bow"]], "Example command for bag-of-words control": [[271, "example-command-for-bag-of-words-control"]], "Tuning hyperparameters for bag-of-words control": [[271, "tuning-hyperparameters-for-bag-of-words-control"]], "PPLM-Discrim": [[271, "pplm-discrim"]], "Example command for discriminator based sentiment control": [[271, "example-command-for-discriminator-based-sentiment-control"]], "Tuning hyperparameters for discriminator control": [[271, "tuning-hyperparameters-for-discriminator-control"]], "Intro": [[272, "intro"], [295, "intro"], [305, "intro"]], "Finetuning": [[272, "finetuning"]], "Document Retrieval": [[272, "document-retrieval"]], "Evaluation": [[272, "evaluation"], [273, "evaluation"]], "Retrieval evaluation": [[272, "retrieval-evaluation"]], "End-to-end evaluation": [[272, "end-to-end-evaluation"]], "Use your own knowledge source": [[272, "use-your-own-knowledge-source"]], "Sequence to Sequence Training and Evaluation": [[273, "sequence-to-sequence-training-and-evaluation"], [276, "sequence-to-sequence-training-and-evaluation"]], "Supported Architectures": [[273, "supported-architectures"], [276, "supported-architectures"]], "Datasets": [[273, "datasets"]], "XSUM": [[273, "xsum"]], "CNN/DailyMail": [[273, "cnn-dailymail"]], "WMT16 English-Romanian Translation Data": [[273, "wmt16-english-romanian-translation-data"]], "WMT English-German": [[273, "wmt-english-german"]], "FSMT datasets (wmt)": [[273, "fsmt-datasets-wmt"]], "Pegasus (multiple datasets)": [[273, "pegasus-multiple-datasets"]], "Your Data": [[273, "your-data"]], "Potential issues": [[273, "potential-issues"]], "Tips and Tricks": [[273, "tips-and-tricks"]], "Finetuning Scripts": [[273, "finetuning-scripts"]], "Finetuning Training Params": [[273, "finetuning-training-params"]], "Summarization Finetuning": [[273, "summarization-finetuning"]], "Translation Finetuning": [[273, "translation-finetuning"]], "Finetuning Outputs": [[273, "finetuning-outputs"]], "Converting pytorch-lightning checkpoints": [[273, "converting-pytorch-lightning-checkpoints"]], "Experimental Features": [[273, "experimental-features"]], "Dynamic Batch Size for MT": [[273, "dynamic-batch-size-for-mt"]], "DistilBART": [[273, "distilbart"]], "Recommended Workflow": [[273, "recommended-workflow"]], "Initialization": [[273, "initialization"]], "SFT (No Teacher Distillation)": [[273, "sft-no-teacher-distillation"]], "Pseudo-Labeling": [[273, "pseudo-labeling"]], "Direct Knowledge Distillation (KD)": [[273, "direct-knowledge-distillation-kd"]], "Saved Pseudo-Labels": [[274, "saved-pseudo-labels"]], "Available Pseudo-labels": [[274, "available-pseudo-labels"]], "Generating New Pseudolabels": [[274, "generating-new-pseudolabels"]], "Contributions": [[274, "contributions"]], "Zero-shot classifier distillation": [[275, "zero-shot-classifier-distillation"]], "Example: Topic classification": [[275, "example-topic-classification"]], "Custom CSV Files": [[276, "custom-csv-files"]], "Custom JSONFILES Files": [[276, "custom-jsonfiles-files"]], "Text classification examples": [[277, "text-classification-examples"]], "PyTorch version": [[277, "pytorch-version"]], "Mixed precision training": [[277, "mixed-precision-training"]], "Run TensorFlow 2.0 version": [[277, "run-tensorflow-2-0-version"]], "Run generic text classification script in TensorFlow": [[277, "run-generic-text-classification-script-in-tensorflow"]], "Fine-tuning on XNLI": [[277, "fine-tuning-on-xnli"]], "Language generation": [[278, "language-generation"]], "Token classification": [[279, "token-classification"]], "Old version of the script": [[279, "old-version-of-the-script"]], "TensorFlow version": [[279, "tensorflow-version"]], "GermEval 2014 (German NER) dataset": [[279, "germeval-2014-german-ner-dataset"]], "Data (Download and pre-processing steps)": [[279, "data-download-and-pre-processing-steps"]], "Prepare the run": [[279, "prepare-the-run"]], "\ud83d\udd25 Model cards now live inside each huggingface.co model repo \ud83d\udd25": [[280, "model-cards-now-live-inside-each-huggingface-co-model-repo"]], "How to update a model card": [[280, "how-to-update-a-model-card"]], "What happened to the model cards here?": [[280, "what-happened-to-the-model-cards-here"]], "TAPAS base model": [[281, "tapas-base-model"]], "Model description": [[281, "model-description"]], "Intended uses & limitations": [[281, "intended-uses-limitations"]], "Training data": [[281, "training-data"]], "Training procedure": [[281, "training-procedure"]], "Preprocessing": [[281, "preprocessing"]], "Pretraining": [[281, "pretraining"]], "BibTeX entry and citation info": [[281, "bibtex-entry-and-citation-info"]], "\ud83e\udd17 Transformers Notebooks": [[282, "transformers-notebooks"]], "Hugging Face\u2019s notebooks \ud83e\udd17": [[282, "hugging-face-s-notebooks"]], "Upload converted models": [[283, "upload-converted-models"]], "Modifications": [[283, "modifications"]], "How to add a new example script in \ud83e\udd17 Transformers": [[284, "how-to-add-a-new-example-script-in-transformers"]], "TEMPLATE": [[285, "template"]], "How to add [camelcase name of model] to \ud83e\udd17 Transformers?": [[285, "how-to-add-camelcase-name-of-model-to-transformers"]], "1. (Optional) Theoretical aspects of [camelcase name of model]": [[285, "optional-theoretical-aspects-of-camelcase-name-of-model"]], "Make sure you\u2019ve understood the fundamental aspects of [camelcase name of model]": [[285, "make-sure-you-ve-understood-the-fundamental-aspects-of-camelcase-name-of-model"]], "Run a pretrained checkpoint using the original repository": [[285, "run-a-pretrained-checkpoint-using-the-original-repository"], [288, "run-a-pretrained-checkpoint-using-the-original-repository"]], "More details on how to create a debugging environment for [camelcase name of model]": [[285, "more-details-on-how-to-create-a-debugging-environment-for-camelcase-name-of-model"]], "Port [camelcase name of model] to \ud83e\udd17 Transformers": [[285, "port-camelcase-name-of-model-to-transformers"]], "Using cookiecutter to generate models": [[286, "using-cookiecutter-to-generate-models"]], "{{cookiecutter.modelname}}": [[287, "cookiecutter-modelname"]], "{{cookiecutter.camelcase_modelname}}Config": [[287, "cookiecutter-camelcase-modelname-config"]], "{{cookiecutter.camelcase_modelname}}Tokenizer": [[287, "cookiecutter-camelcase-modelname-tokenizer"]], "{{cookiecutter.camelcase_modelname}}TokenizerFast": [[287, "cookiecutter-camelcase-modelname-tokenizerfast"]], "{{cookiecutter.camelcase_modelname}}ForMaskedLM": [[287, "cookiecutter-camelcase-modelname-formaskedlm"]], "{{cookiecutter.camelcase_modelname}}ForSequenceClassification": [[287, "cookiecutter-camelcase-modelname-forsequenceclassification"], [287, "id1"]], "{{cookiecutter.camelcase_modelname}}ForMultipleChoice": [[287, "cookiecutter-camelcase-modelname-formultiplechoice"]], "{{cookiecutter.camelcase_modelname}}ForTokenClassification": [[287, "cookiecutter-camelcase-modelname-fortokenclassification"]], "{{cookiecutter.camelcase_modelname}}ForQuestionAnswering": [[287, "cookiecutter-camelcase-modelname-forquestionanswering"], [287, "id2"]], "{{cookiecutter.camelcase_modelname}}ForCausalLM": [[287, "cookiecutter-camelcase-modelname-forcausallm"]], "TF{{cookiecutter.camelcase_modelname}}Model": [[287, "tf-cookiecutter-camelcase-modelname-model"]], "TF{{cookiecutter.camelcase_modelname}}ForCausalLM": [[287, "tf-cookiecutter-camelcase-modelname-forcausallm"]], "TF{{cookiecutter.camelcase_modelname}}ForSequenceClassification": [[287, "tf-cookiecutter-camelcase-modelname-forsequenceclassification"]], "TF{{cookiecutter.camelcase_modelname}}ForMultipleChoice": [[287, "tf-cookiecutter-camelcase-modelname-formultiplechoice"]], "TF{{cookiecutter.camelcase_modelname}}ForTokenClassification": [[287, "tf-cookiecutter-camelcase-modelname-fortokenclassification"]], "TF{{cookiecutter.camelcase_modelname}}ForQuestionAnswering": [[287, "tf-cookiecutter-camelcase-modelname-forquestionanswering"]], "How to add BigBird to \ud83e\udd17 Transformers?": [[288, "how-to-add-bigbird-to-transformers"]], "1. (Optional) Theoretical aspects of BigBird": [[288, "optional-theoretical-aspects-of-bigbird"]], "Make sure you\u2019ve understood the fundamental aspects of BigBird": [[288, "make-sure-you-ve-understood-the-fundamental-aspects-of-bigbird"]], "(Important) More details on how to create a debugging environment for BigBird": [[288, "important-more-details-on-how-to-create-a-debugging-environment-for-bigbird"]], "Port BigBird to \ud83e\udd17 Transformers": [[288, "port-bigbird-to-transformers"]], "Python Version": [[290, "python-version"], [291, "python-version"], [292, "python-version"], [294, "python-version"], [296, "python-version"], [298, "python-version"], [299, "python-version"], [300, "python-version"], [301, "python-version"], [302, "python-version"], [304, "python-version"], [308, "python-version"], [309, "python-version"], [310, "python-version"], [311, "python-version"], [313, "python-version"]], "Install transformers": [[290, "install-transformers"], [298, "install-transformers"], [308, "install-transformers"], [313, "install-transformers"]], "Install PyTorch": [[290, "install-pytorch"], [293, "install-pytorch"], [296, "install-pytorch"], [298, "install-pytorch"], [308, "install-pytorch"], [309, "install-pytorch"], [310, "install-pytorch"], [311, "install-pytorch"], [313, "install-pytorch"]], "2. Prepare pretrained model": [[290, "prepare-pretrained-model"], [293, "prepare-pretrained-model"], [298, "prepare-pretrained-model"], [308, "prepare-pretrained-model"], [309, "prepare-pretrained-model"], [310, "prepare-pretrained-model"], [311, "prepare-pretrained-model"]], "Language-modeling": [[290, "language-modeling"]], "Finetune command": [[290, "finetune-command"]], "Start to neural_compressor tune for Model Quantization": [[290, "start-to-neural-compressor-tune-for-model-quantization"], [296, "start-to-neural-compressor-tune-for-model-quantization"], [298, "start-to-neural-compressor-tune-for-model-quantization"], [308, "start-to-neural-compressor-tune-for-model-quantization"], [309, "start-to-neural-compressor-tune-for-model-quantization"], [310, "start-to-neural-compressor-tune-for-model-quantization"], [311, "start-to-neural-compressor-tune-for-model-quantization"], [313, "start-to-neural-compressor-tune-for-model-quantization"]], "Glue task": [[290, "glue-task"], [308, "glue-task"], [309, "glue-task"], [310, "glue-task"], [311, "glue-task"]], "Seq2seq task": [[290, "seq2seq-task"]], "Language-modeling task": [[290, "language-modeling-task"]], "Code Prepare": [[290, "code-prepare"], [296, "code-prepare"], [298, "code-prepare"], [308, "code-prepare"], [309, "code-prepare"], [310, "code-prepare"], [311, "code-prepare"], [313, "code-prepare"]], "Start to neural_compressor tune for Model Distillation": [[291, "start-to-neural-compressor-tune-for-model-distillation"], [299, "start-to-neural-compressor-tune-for-model-distillation"]], "SQuAD task": [[291, "squad-task"], [292, "squad-task"], [294, "squad-task"]], "Start running neural_compressor implementation of Prune Once For All": [[292, "start-running-neural-compressor-implementation-of-prune-once-for-all"], [301, "start-running-neural-compressor-implementation-of-prune-once-for-all"]], "Install neural_compressor": [[293, "install-neural-compressor"]], "Install BERT dependency": [[293, "install-bert-dependency"]], "1. Prepare Dataset": [[293, "prepare-dataset"]], "Original BERT README": [[293, "original-bert-readme"]], "Start to neural_compressor tune for Model Pruning": [[294, "start-to-neural-compressor-tune-for-model-pruning"], [302, "start-to-neural-compressor-tune-for-model-pruning"], [304, "start-to-neural-compressor-tune-for-model-pruning"]], "Pytorch Pruner": [[295, "pytorch-pruner"], [305, "pytorch-pruner"]], "Write a config yaml file": [[295, "write-a-config-yaml-file"], [305, "write-a-config-yaml-file"]], "Coding template:": [[295, "coding-template"], [305, "coding-template"]], "References": [[295, "references"], [305, "references"]], "Install BERT model": [[296, "install-bert-model"], [309, "install-bert-model"], [310, "install-bert-model"], [311, "install-bert-model"]], "This is a tutorial of how to enable NLP model with Intel\u00ae Neural Compressor.": [[296, "this-is-a-tutorial-of-how-to-enable-nlp-model-with-intel-neural-compressor"], [309, "this-is-a-tutorial-of-how-to-enable-nlp-model-with-intel-neural-compressor"], [310, "this-is-a-tutorial-of-how-to-enable-nlp-model-with-intel-neural-compressor"], [311, "this-is-a-tutorial-of-how-to-enable-nlp-model-with-intel-neural-compressor"]], "Intel\u00ae Neural Compressor supports two usages:": [[296, "intel-neural-compressor-supports-two-usages"], [309, "intel-neural-compressor-supports-two-usages"], [310, "intel-neural-compressor-supports-two-usages"], [311, "intel-neural-compressor-supports-two-usages"]], "Step by step": [[297, "step-by-step"]], "Bert-Large Inference": [[297, "bert-large-inference"]], "Distilbert-base Inference": [[297, "distilbert-base-inference"]], "Seq2seq": [[298, "seq2seq"]], "summarization_billsum task": [[298, "summarization-billsum-task"]], "SST-2 task": [[299, "sst-2-task"], [300, "sst-2-task"], [301, "sst-2-task"], [302, "sst-2-task"], [304, "sst-2-task"]], "MNLI task": [[299, "mnli-task"], [300, "mnli-task"], [301, "mnli-task"], [304, "mnli-task"]], "QQP task": [[299, "qqp-task"], [300, "qqp-task"], [301, "qqp-task"], [304, "qqp-task"]], "COLA task": [[299, "cola-task"]], "Start running neural_compressor implementation of distillation for quantization": [[300, "start-running-neural-compressor-implementation-of-distillation-for-quantization"]], "QNLI task": [[300, "qnli-task"], [301, "qnli-task"], [304, "qnli-task"]], "Prepare environment": [[303, "prepare-environment"]], "Glue": [[305, "glue"]], "MRPC": [[305, "mrpc"]], "SST-2": [[305, "sst-2"]], "\u201cPruning while distillation\u201d step by step": [[306, "pruning-while-distillation-step-by-step"]], "1 Requirements": [[306, "requirements"]], "2 Run the example on SST2 and external datasets": [[306, "run-the-example-on-sst2-and-external-datasets"]], "2.1 Modify the configurations": [[306, "modify-the-configurations"]], "2.2 Run the code": [[306, "run-the-code"]], "2.3 Reference": [[306, "reference"]], "Notice": [[307, "notice"]], "1. To get the tuned model and its accuracy:": [[308, "to-get-the-tuned-model-and-its-accuracy"], [309, "to-get-the-tuned-model-and-its-accuracy"], [311, "to-get-the-tuned-model-and-its-accuracy"]], "2. To get the benchmark of tuned model, includes batch_size and throughput:": [[308, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"]], "HuggingFace model hub": [[308, "huggingface-model-hub"], [309, "huggingface-model-hub"], [311, "huggingface-model-hub"], [312, "huggingface-model-hub"]], "To upstream into HuggingFace model hub": [[308, "to-upstream-into-huggingface-model-hub"], [309, "to-upstream-into-huggingface-model-hub"], [311, "to-upstream-into-huggingface-model-hub"], [312, "to-upstream-into-huggingface-model-hub"]], "To download into HuggingFace model hub": [[308, "to-download-into-huggingface-model-hub"], [309, "to-download-into-huggingface-model-hub"], [311, "to-download-into-huggingface-model-hub"], [312, "to-download-into-huggingface-model-hub"]], "Using Shapley MSE as Objective": [[308, "using-shapley-mse-as-objective"]], "2. To get the benchmark of tuned model, includes Batch_size and Throughput:": [[309, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"], [311, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"]], "2. Prepare fine-tuned model": [[312, "prepare-fine-tuned-model"]], "1. Enable bert-base-cased/uncased example with the auto quantization aware training strategy of Neural Compressor.": [[312, "enable-bert-base-cased-uncased-example-with-the-auto-quantization-aware-training-strategy-of-neural-compressor"]], "2. To get the tuned model and its accuracy:": [[312, "to-get-the-tuned-model-and-its-accuracy"], [323, "to-get-the-tuned-model-and-its-accuracy"], [326, "to-get-the-tuned-model-and-its-accuracy"], [334, "to-get-the-tuned-model-and-its-accuracy"]], "3. To get the benchmark of tuned model, includes Batch_size and Throughput:": [[312, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"], [323, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"], [326, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"], [334, "to-get-the-benchmark-of-tuned-model-includes-batch-size-and-throughput"]], "1. Problem": [[314, "problem"]], "2. Directions": [[314, "directions"]], "Steps to configure machine": [[314, "steps-to-configure-machine"]], "Steps to download data": [[314, "steps-to-download-data"]], "Steps to run benchmark.": [[314, "steps-to-run-benchmark"]], "3. Dataset/Environment": [[314, "dataset-environment"]], "Publication/Attribution": [[314, "publication-attribution"], [314, "id1"]], "Data preprocessing": [[314, "data-preprocessing"]], "Training and test data separation": [[314, "training-and-test-data-separation"]], "Training data order": [[314, "training-data-order"]], "Test data order": [[314, "test-data-order"]], "4. Model": [[314, "model"]], "List of layers": [[314, "list-of-layers"]], "Weight and bias initialization": [[314, "weight-and-bias-initialization"]], "Loss function": [[314, "loss-function"]], "5. Quality": [[314, "quality"]], "Quality metric": [[314, "quality-metric"]], "Quality target": [[314, "quality-target"]], "Evaluation frequency": [[314, "evaluation-frequency"]], "Evaluation thoroughness": [[314, "evaluation-thoroughness"]], "Prepare weights": [[315, "prepare-weights"]], "Abstractions": [[316, "abstractions"], [319, "abstractions"]], "ImageList": [[316, "imagelist"]], "BoxList": [[316, "boxlist"]], "Requirements:": [[317, "requirements"]], "Option 1: Step-by-step installation": [[317, "option-1-step-by-step-installation"]], "Option 2: Docker Image (Requires CUDA, Linux only)": [[317, "option-2-docker-image-requires-cuda-linux-only"]], "Model Zoo and Baselines": [[318, "model-zoo-and-baselines"], [319, "model-zoo-and-baselines"]], "Hardware": [[318, "hardware"]], "Software": [[318, "software"]], "End-to-end Faster and Mask R-CNN baselines": [[318, "end-to-end-faster-and-mask-r-cnn-baselines"]], "Comparison with Detectron and mmdetection": [[318, "comparison-with-detectron-and-mmdetection"]], "Training speed": [[318, "training-speed"]], "Training memory": [[318, "training-memory"]], "Accuracy": [[318, "accuracy"]], "Faster R-CNN and Mask R-CNN in PyTorch 1.0": [[319, "faster-r-cnn-and-mask-r-cnn-in-pytorch-1-0"]], "Highlights": [[319, "highlights"]], "Webcam and Jupyter notebook demo": [[319, "webcam-and-jupyter-notebook-demo"]], "Inference in a few lines": [[319, "inference-in-a-few-lines"]], "Perform training on COCO dataset": [[319, "perform-training-on-coco-dataset"]], "Single GPU training": [[319, "single-gpu-training"]], "Multi-GPU training": [[319, "multi-gpu-training"]], "Adding your own dataset": [[319, "adding-your-own-dataset"]], "Note:": [[319, "note"]], "Finetuning from Detectron weights on custom datasets": [[319, "finetuning-from-detectron-weights-on-custom-datasets"]], "Troubleshooting": [[319, "troubleshooting"], [320, "troubleshooting"]], "Citations": [[319, "citations"]], "Projects using maskrcnn-benchmark": [[319, "projects-using-maskrcnn-benchmark"]], "Compilation errors when compiling the library": [[320, "compilation-errors-when-compiling-the-library"]], "ImportError: No module named maskrcnn_benchmark.config when running webcam.py": [[320, "importerror-no-module-named-maskrcnn-benchmark-config-when-running-webcam-py"]], "ImportError: Undefined symbol: __cudaPopCallConfiguration error when import _C": [[320, "importerror-undefined-symbol-cudapopcallconfiguration-error-when-import-c"]], "Segmentation fault (core dumped) when running the library": [[320, "segmentation-fault-core-dumped-when-running-the-library"]], "Setting Up Datasets": [[321, "setting-up-datasets"]], "Creating Symlinks for PASCAL VOC": [[321, "creating-symlinks-for-pascal-voc"]], "PASCAL VOC Annotations in COCO Format": [[321, "pascal-voc-annotations-in-coco-format"]], "Creating Symlinks for Cityscapes:": [[321, "creating-symlinks-for-cityscapes"]], "Steps to convert Cityscapes Annotations to COCO Format": [[321, "steps-to-convert-cityscapes-annotations-to-coco-format"]], "Utility functions": [[322, "utility-functions"]], "3. Prepare pre-trained model": [[323, "prepare-pre-trained-model"], [334, "prepare-pre-trained-model"], [355, "prepare-pre-trained-model"]], "1. Enable ssd_resnet34 example with the auto dynamic quantization strategy of Neural Compressor.": [[323, "enable-ssd-resnet34-example-with-the-auto-dynamic-quantization-strategy-of-neural-compressor"]], "4. The following is the brief output information:": [[323, "the-following-is-the-brief-output-information"], [334, "the-following-is-the-brief-output-information"]], "Upscaled COCO Dataset": [[324, "upscaled-coco-dataset"]], "Parameters": [[324, "parameters"]], "How to run": [[324, "how-to-run"]], "SSD-ResNet34 Inference": [[325, "ssd-resnet34-inference"]], "Model Specific Setup": [[325, "model-specific-setup"]], "2. Download Dataset": [[326, "download-dataset"]], "3. Train the Model": [[326, "train-the-model"]], "1. Enable ssd_resnet34 example with quant aware training strategy of Neural Compressor.": [[326, "enable-ssd-resnet34-example-with-quant-aware-training-strategy-of-neural-compressor"]], "3. Prepare Weights": [[327, "prepare-weights"]], "Examples Of Enabling Neural Compressor Auto Tuning On PyTorch YOLOV3": [[327, "examples-of-enabling-neural-compressor-auto-tuning-on-pytorch-yolov3"]], "PyTorch-YOLOv3": [[328, "pytorch-yolov3"]], "Clone and install requirements": [[328, "clone-and-install-requirements"]], "Download pretrained weights": [[328, "download-pretrained-weights"]], "Download COCO": [[328, "download-coco"]], "Test": [[328, "test"]], "Train": [[328, "train"], [328, "id1"]], "Example (COCO)": [[328, "example-coco"]], "Training log": [[328, "training-log"]], "Tensorboard": [[328, "tensorboard"]], "Train on Custom Dataset": [[328, "train-on-custom-dataset"]], "Classes": [[328, "classes"]], "Image Folder": [[328, "image-folder"]], "Annotation Folder": [[328, "annotation-folder"]], "Define Train and Validation Sets": [[328, "define-train-and-validation-sets"]], "Credit": [[328, "credit"]], "YOLOv3: An Incremental Improvement": [[328, "yolov3-an-incremental-improvement"]], "tune with INC": [[329, "tune-with-inc"], [330, "tune-with-inc"], [333, "tune-with-inc"]], "Code of Conduct": [[331, "code-of-conduct"]], "Contributing to DLRM": [[332, "contributing-to-dlrm"]], "Pull Requests": [[332, "pull-requests"]], "Contributor License Agreement (\u201dCLA\u201d)": [[332, "contributor-license-agreement-cla"]], "Issues": [[332, "issues"]], "Coding Style": [[332, "coding-style"]], "1. Enable RNNT example with the auto dynamic quantization strategy of Neural Compressor.": [[334, "enable-rnnt-example-with-the-auto-dynamic-quantization-strategy-of-neural-compressor"]], "1. Wav2vec2.0": [[335, "wav2vec2-0"]], "2. Hubert": [[335, "hubert"]], "2. Install Intel Tensorflow": [[336, "install-intel-tensorflow"], [339, "install-intel-tensorflow"], [340, "install-intel-tensorflow"], [342, "install-intel-tensorflow"], [343, "install-intel-tensorflow"], [344, "install-intel-tensorflow"], [345, "install-intel-tensorflow"], [346, "install-intel-tensorflow"], [347, "install-intel-tensorflow"], [348, "install-intel-tensorflow"], [349, "install-intel-tensorflow"], [350, "install-intel-tensorflow"], [354, "install-intel-tensorflow"], [356, "install-intel-tensorflow"], [357, "install-intel-tensorflow"], [358, "install-intel-tensorflow"], [360, "install-intel-tensorflow"], [362, "install-intel-tensorflow"], [363, "install-intel-tensorflow"], [365, "install-intel-tensorflow"], [366, "install-intel-tensorflow"], [367, "install-intel-tensorflow"], [368, "install-intel-tensorflow"]], "3. Install Intel Extension for Tensorflow": [[336, "install-intel-extension-for-tensorflow"], [339, "install-intel-extension-for-tensorflow"], [340, "install-intel-extension-for-tensorflow"], [341, "install-intel-extension-for-tensorflow"], [342, "install-intel-extension-for-tensorflow"], [343, "install-intel-extension-for-tensorflow"], [344, "install-intel-extension-for-tensorflow"], [345, "install-intel-extension-for-tensorflow"], [346, "install-intel-extension-for-tensorflow"], [347, "install-intel-extension-for-tensorflow"], [348, "install-intel-extension-for-tensorflow"], [349, "install-intel-extension-for-tensorflow"], [350, "install-intel-extension-for-tensorflow"], [356, "install-intel-extension-for-tensorflow"], [357, "install-intel-extension-for-tensorflow"], [358, "install-intel-extension-for-tensorflow"], [360, "install-intel-extension-for-tensorflow"], [361, "install-intel-extension-for-tensorflow"], [365, "install-intel-extension-for-tensorflow"], [366, "install-intel-extension-for-tensorflow"], [367, "install-intel-extension-for-tensorflow"]], "Quantizing the model on Intel GPU": [[336, "quantizing-the-model-on-intel-gpu"], [339, "quantizing-the-model-on-intel-gpu"], [340, "quantizing-the-model-on-intel-gpu"], [341, "quantizing-the-model-on-intel-gpu"], [342, "quantizing-the-model-on-intel-gpu"], [343, "quantizing-the-model-on-intel-gpu"], [344, "quantizing-the-model-on-intel-gpu"], [345, "quantizing-the-model-on-intel-gpu"], [346, "quantizing-the-model-on-intel-gpu"], [347, "quantizing-the-model-on-intel-gpu"], [348, "quantizing-the-model-on-intel-gpu"], [349, "quantizing-the-model-on-intel-gpu"], [350, "quantizing-the-model-on-intel-gpu"], [354, "quantizing-the-model-on-intel-gpu"], [356, "quantizing-the-model-on-intel-gpu"], [357, "quantizing-the-model-on-intel-gpu"], [358, "quantizing-the-model-on-intel-gpu"], [360, "quantizing-the-model-on-intel-gpu"], [361, "quantizing-the-model-on-intel-gpu"], [362, "quantizing-the-model-on-intel-gpu"], [363, "quantizing-the-model-on-intel-gpu"], [364, "quantizing-the-model-on-intel-gpu"], [365, "quantizing-the-model-on-intel-gpu"], [366, "quantizing-the-model-on-intel-gpu"], [367, "quantizing-the-model-on-intel-gpu"], [368, "quantizing-the-model-on-intel-gpu"]], "Quantizing the model on Intel CPU(Experimental)": [[336, "quantizing-the-model-on-intel-cpu-experimental"], [339, "quantizing-the-model-on-intel-cpu-experimental"], [340, "quantizing-the-model-on-intel-cpu-experimental"], [341, "quantizing-the-model-on-intel-cpu-experimental"], [342, "quantizing-the-model-on-intel-cpu-experimental"], [343, "quantizing-the-model-on-intel-cpu-experimental"], [344, "quantizing-the-model-on-intel-cpu-experimental"], [345, "quantizing-the-model-on-intel-cpu-experimental"], [346, "quantizing-the-model-on-intel-cpu-experimental"], [347, "quantizing-the-model-on-intel-cpu-experimental"], [348, "quantizing-the-model-on-intel-cpu-experimental"], [349, "quantizing-the-model-on-intel-cpu-experimental"], [350, "quantizing-the-model-on-intel-cpu-experimental"], [354, "quantizing-the-model-on-intel-cpu-experimental"], [356, "quantizing-the-model-on-intel-cpu-experimental"], [357, "quantizing-the-model-on-intel-cpu-experimental"], [358, "quantizing-the-model-on-intel-cpu-experimental"], [360, "quantizing-the-model-on-intel-cpu-experimental"], [361, "quantizing-the-model-on-intel-cpu-experimental"], [362, "quantizing-the-model-on-intel-cpu-experimental"], [363, "quantizing-the-model-on-intel-cpu-experimental"], [364, "quantizing-the-model-on-intel-cpu-experimental"], [365, "quantizing-the-model-on-intel-cpu-experimental"], [366, "quantizing-the-model-on-intel-cpu-experimental"], [367, "quantizing-the-model-on-intel-cpu-experimental"], [368, "quantizing-the-model-on-intel-cpu-experimental"]], "4. Prepare Pretrained model": [[336, "prepare-pretrained-model"], [339, "prepare-pretrained-model"], [340, "prepare-pretrained-model"], [341, "prepare-pretrained-model"], [342, "prepare-pretrained-model"], [343, "prepare-pretrained-model"], [344, "prepare-pretrained-model"], [345, "prepare-pretrained-model"], [346, "prepare-pretrained-model"], [347, "prepare-pretrained-model"], [348, "prepare-pretrained-model"], [349, "prepare-pretrained-model"], [350, "prepare-pretrained-model"]], "2. Install requirements": [[337, "install-requirements"]], "3. Train and save a ViT model": [[337, "train-and-save-a-vit-model"]], "Run command to prune the model": [[337, "run-command-to-prune-the-model"], [338, "run-command-to-prune-the-model"], [351, "run-command-to-prune-the-model"]], "1. Install Intel\u00ae Neural Compressor": [[338, "install-intel-neural-compressor"], [359, "install-intel-neural-compressor"]], "2. Install other requirements": [[338, "install-other-requirements"]], "2. Install Intel Tensorflow and TensorFlow Model Optimization": [[341, "install-intel-tensorflow-and-tensorflow-model-optimization"]], "5. Prepare QAT model": [[341, "prepare-qat-model"]], "5. Prepare dataset": [[345, "prepare-dataset"]], "2. Install TensorFlow 2.10.0 or above.": [[351, "install-tensorflow-2-10-0-or-above"]], "3. Train and save a ResNet-V2 model": [[351, "train-and-save-a-resnet-v2-model"]], "2. Install Intel Tensorflow 2.4.0 or above.": [[352, "install-intel-tensorflow-2-4-0-or-above"]], "3. Install tensorflow_model_optimization": [[352, "install-tensorflow-model-optimization"]], "3. Installation Dependency packages": [[354, "installation-dependency-packages"], [362, "installation-dependency-packages"], [363, "installation-dependency-packages"]], "4. Install Intel Extension for Tensorflow": [[354, "install-intel-extension-for-tensorflow"], [363, "install-intel-extension-for-tensorflow"], [368, "install-intel-extension-for-tensorflow"]], "5. Prepare Dataset": [[354, "prepare-dataset"], [365, "prepare-dataset"], [368, "prepare-dataset"]], "6. Prepare pre-trained model": [[354, "prepare-pre-trained-model"]], "Install Intel Tensorflow 1.15 up2": [[354, "install-intel-tensorflow-1-15-up2"]], "1. ResNet50 V1.0": [[354, "resnet50-v1-0"]], "2. ResNet50 V1.5": [[354, "resnet50-v1-5"]], "3. ResNet101": [[354, "resnet101"]], "4. MobileNet V1": [[354, "mobilenet-v1"]], "5. MobileNet V2*": [[354, "mobilenet-v2"]], "6. Inception V1*": [[354, "inception-v1"]], "7. Inception V2*": [[354, "inception-v2"]], "8. Inception V3": [[354, "inception-v3"]], "9. Inception V4": [[354, "inception-v4"]], "10. Inception ResNet V2*": [[354, "inception-resnet-v2"]], "11. VGG 16*": [[354, "vgg-16"]], "12. VGG 19*": [[354, "vgg-19"]], "13. ResNet v2 50": [[354, "resnet-v2-50"]], "14. ResNet v2 101": [[354, "resnet-v2-101"]], "15. ResNet v2 152": [[354, "resnet-v2-152"]], "16. Densenet-121": [[354, "densenet-121"]], "17. Densenet-161": [[354, "densenet-161"]], "18. Densenet-169": [[354, "densenet-169"]], "19. Nasnet-mobile*": [[354, "nasnet-mobile"]], "20. EfficientNet-b0": [[354, "efficientnet-b0"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on TensorFlow ResNet50 V1.5": [[354, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-tensorflow-resnet50-v1-5"]], "preparation": [[354, "preparation"]], "tune": [[355, "tune"]], "1. resnet_v1_50": [[355, "resnet-v1-50"]], "2. resnet_v1_101": [[355, "resnet-v1-101"]], "3. resnet_v1_152": [[355, "resnet-v1-152"]], "4. resnet_v2_50": [[355, "resnet-v2-50"]], "5. resnet_v2_101": [[355, "resnet-v2-101"]], "6. resnet_v2_152": [[355, "resnet-v2-152"]], "7. inception_v1": [[355, "inception-v1"]], "8. inception_v2": [[355, "inception-v2"]], "9. inception_v3": [[355, "inception-v3"]], "10. inception_v4": [[355, "inception-v4"]], "11. vgg16": [[355, "vgg16"]], "12. vgg19": [[355, "vgg19"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on TensorFlow Inception V1": [[355, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-tensorflow-inception-v1"]], "4. Prepare Dataset": [[356, "prepare-dataset"], [357, "prepare-dataset"], [358, "prepare-dataset"], [367, "prepare-dataset"]], "Automatic dataset download": [[356, "automatic-dataset-download"], [357, "automatic-dataset-download"], [358, "automatic-dataset-download"], [362, "automatic-dataset-download"], [363, "automatic-dataset-download"]], "5. Prepare pretrained model": [[356, "prepare-pretrained-model"]], "Automatic model download": [[356, "automatic-model-download"], [357, "automatic-model-download"]], "Details of enabling Intel\u00ae Neural Compressor on bert model for Tensorflow.": [[356, "details-of-enabling-intel-neural-compressor-on-bert-model-for-tensorflow"], [357, "details-of-enabling-intel-neural-compressor-on-bert-model-for-tensorflow"]], "Code update": [[356, "code-update"], [357, "code-update"], [360, "code-update"], [361, "code-update"], [362, "code-update"], [368, "code-update"]], "Tune": [[356, "tune"], [357, "tune"], [367, "tune"]], "5. Prepare Pretrained model": [[357, "prepare-pretrained-model"], [358, "prepare-pretrained-model"]], "Manual approach": [[357, "manual-approach"], [362, "manual-approach"], [368, "manual-approach"]], "Prepare frozen pb from checkpoint": [[357, "prepare-frozen-pb-from-checkpoint"]], "Run Tuning": [[358, "run-tuning"]], "Run Benchmark": [[358, "run-benchmark"]], "Model Details": [[359, "model-details"]], "Dataset Details": [[359, "dataset-details"]], "2. Install TensorFlow 2.11.dev202242": [[359, "install-tensorflow-2-11-dev202242"]], "3. Install Requirements": [[359, "install-requirements"]], "4. Install Intel\u00ae Extension for TensorFlow": [[359, "install-intel-extension-for-tensorflow"]], "Quantizing the model on Intel GPU:": [[359, "quantizing-the-model-on-intel-gpu"]], "Quantizing the model on Intel CPU (Experimental):": [[359, "quantizing-the-model-on-intel-cpu-experimental"]], "5. Download Dataset": [[359, "download-dataset"]], "Run Tuning:": [[359, "run-tuning"], [361, "run-tuning"]], "Run Benchmark:": [[359, "run-benchmark"], [361, "run-benchmark"]], "Details of enabling Intel\u00ae Neural Compressor on DistilBERT base for TensorFlow": [[359, "details-of-enabling-intel-neural-compressor-on-distilbert-base-for-tensorflow"]], "q_dataloader Part Adaption": [[359, "q-dataloader-part-adaption"], [360, "q-dataloader-part-adaption"], [361, "q-dataloader-part-adaption"], [362, "q-dataloader-part-adaption"]], "4. Prepare Dataset & Pretrained model": [[360, "prepare-dataset-pretrained-model"]], "Automatic dataset & model download": [[360, "automatic-dataset-model-download"]], "Details of enabling Intel\u00ae Neural Compressor on transformer-lt for Tensorflow.": [[360, "details-of-enabling-intel-neural-compressor-on-transformer-lt-for-tensorflow"]], "Evaluation Part Adaption": [[360, "evaluation-part-adaption"], [361, "evaluation-part-adaption"], [362, "evaluation-part-adaption"], [368, "evaluation-part-adaption"]], "2. Install TensorFlow": [[361, "install-tensorflow"]], "4. Prepare Dataset & Frozen Model": [[361, "prepare-dataset-frozen-model"]], "Details of enabling Intel\u00ae Neural Compressor on Transformer_LT_mlperf for Tensorflow.": [[361, "details-of-enabling-intel-neural-compressor-on-transformer-lt-mlperf-for-tensorflow"]], "4. Install Protocol Buffer Compiler": [[362, "install-protocol-buffer-compiler"]], "5. Install Intel Extension for Tensorflow": [[362, "install-intel-extension-for-tensorflow"]], "6. Prepare Dataset": [[362, "prepare-dataset"]], "Manual dataset download": [[362, "manual-dataset-download"], [363, "manual-dataset-download"]], "7. Download Model": [[362, "download-model"]], "Automated approach": [[362, "automated-approach"], [368, "automated-approach"]], "ssd_resnet50_v1": [[362, "ssd-resnet50-v1"]], "ssd_mobilenet_V1": [[362, "ssd-mobilenet-v1"]], "faster_rcnn_inception_resnet_v2": [[362, "faster-rcnn-inception-resnet-v2"]], "faster_rcnn_resnet101": [[362, "faster-rcnn-resnet101"]], "faster_rcnn_resnet50": [[362, "faster-rcnn-resnet50"]], "mask_rcnn_inception_v2": [[362, "mask-rcnn-inception-v2"]], "ssd_resnet34": [[362, "ssd-resnet34"]], "For PB model": [[362, "for-pb-model"]], "For ckpt model": [[362, "for-ckpt-model"]], "Details of enabling Intel\u00ae Neural Compressor on ssd_resnet50_v1 for Tensorflow.": [[362, "details-of-enabling-intel-neural-compressor-on-ssd-resnet50-v1-for-tensorflow"]], "5. Downloaded Yolo-v3 model": [[363, "downloaded-yolo-v3-model"]], "6. Download COCO Class Names File": [[363, "download-coco-class-names-file"]], "7. Download Model Weights (Full):": [[363, "download-model-weights-full"]], "8. Generate PB:": [[363, "generate-pb"]], "9. Prepare Dataset": [[363, "prepare-dataset"]], "Get Quantized Yolo-v3 model with Neural Compressor": [[363, "get-quantized-yolo-v3-model-with-neural-compressor"]], "1.Config the yolo_v3.yaml with the valid cocoraw data path or the yolo_v3_itex.yaml if using the Intel Extension for Tensorflow.": [[363, "config-the-yolo-v3-yaml-with-the-valid-cocoraw-data-path-or-the-yolo-v3-itex-yaml-if-using-the-intel-extension-for-tensorflow"]], "2.Config the yaml file": [[363, "config-the-yaml-file"]], "3.Run below command one by one.": [[363, "run-below-command-one-by-one"]], "2. Install Intel Extension for Tensorflow": [[364, "install-intel-extension-for-tensorflow"]], "4. Prepare pre-trained model": [[364, "prepare-pre-trained-model"]], "5. Config the yaml file": [[364, "config-the-yaml-file"]], "run tuning": [[364, "run-tuning"]], "run benchmarking": [[364, "run-benchmarking"]], "4. Install Additional Dependency packages": [[365, "install-additional-dependency-packages"]], "6. Process Dataset": [[365, "process-dataset"]], "7. Download Frozen PB": [[365, "download-frozen-pb"]], "8. Config the yaml file": [[365, "config-the-yaml-file"]], "9. Run Command": [[365, "run-command"]], "The cmd of running WnD": [[365, "the-cmd-of-running-wnd"]], "Other": [[365, "other"]], "4. Download BraTS 2019 dataset": [[366, "download-brats-2019-dataset"]], "5. Download Pre-trained model": [[366, "download-pre-trained-model"]], "6. Prepare Calibration set": [[366, "prepare-calibration-set"]], "7. Config the yaml file": [[366, "config-the-yaml-file"]], "8. Test command": [[366, "test-command"]], "5. Prepare pre-trained model": [[367, "prepare-pre-trained-model"]], "Examples of enabling Intel\u00ae Neural Compressor auto tuning on Deeplab model for tensorflow": [[367, "examples-of-enabling-intel-neural-compressor-auto-tuning-on-deeplab-model-for-tensorflow"]], "3. Install Additional Dependency packages": [[368, "install-additional-dependency-packages"]], "6. Prepare Pretrained model": [[368, "prepare-pretrained-model"]], "Quantize with neural_compressor": [[368, "quantize-with-neural-compressor"]], "1. Tune model with neural_compressor": [[368, "tune-model-with-neural-compressor"]], "2. check benchmark of tuned model": [[368, "check-benchmark-of-tuned-model"]], "Details of enabling Intel\u00ae Neural Compressor on style transfer for Tensorflow.": [[368, "details-of-enabling-intel-neural-compressor-on-style-transfer-for-tensorflow"]], "Intel\u00ae Neural Compressor Documentation": [[369, "intel-neural-compressor-documentation"]], "Sections": [[369, "sections"]], "Neural Coder": [[370, "neural-coder"]], "What do we offer?": [[370, "what-do-we-offer"]], "Getting Started!": [[370, "getting-started"], [378, "getting-started"]], "Jupyter Lab Extension": [[370, "jupyter-lab-extension"]], "Python API": [[370, "python-api"]], "Contact": [[370, "contact"]], "Intel CPU Platforms: Best Performance Setting": [[371, "intel-cpu-platforms-best-performance-setting"]], "Install MKL, OpenMP and JEMALLOC": [[371, "install-mkl-openmp-and-jemalloc"]], "Install NUMA Controller": [[371, "install-numa-controller"]], "Environment Variables": [[371, "environment-variables"]], "Frequency Governers": [[371, "frequency-governers"]], "Neural Coder as Python API": [[372, "neural-coder-as-python-api"]], "Enable": [[372, "enable"]], "Bench": [[372, "bench"]], "SuperBench": [[372, "superbench"]], "Python Launcher": [[373, "python-launcher"]], "Quick-Start": [[373, "quick-start"]], "Launcher Arguments (Optional)": [[373, "launcher-arguments-optional"]], "Neural Coder for Quantization": [[374, "neural-coder-for-quantization"]], "Features Supported": [[374, "features-supported"]], "Models Supported": [[374, "models-supported"]], "PyPI distribution:": [[374, "pypi-distribution"]], "Supported Optimization Features": [[375, "supported-optimization-features"]], "Changelog": [[376, "changelog"], [380, "changelog"]], "neural_compressor_ext_lab": [[377, "neural-compressor-ext-lab"]], "Install": [[377, "install"], [381, "install"]], "Uninstall": [[377, "uninstall"], [381, "uninstall"]], "Contributing": [[377, "contributing"], [381, "contributing"]], "Development install": [[377, "development-install"], [381, "development-install"]], "Development uninstall": [[377, "development-uninstall"], [381, "development-uninstall"]], "Packaging the extension": [[377, "packaging-the-extension"], [381, "packaging-the-extension"]], "Intel\u00ae Neural Compressor as JupyterLab Extension": [[378, "intel-neural-compressor-as-jupyterlab-extension"]], "Auto-enable a feature": [[378, "auto-enable-a-feature"]], "Or let us help you auto-select the best feature": [[378, "or-let-us-help-you-auto-select-the-best-feature"]], "Pre-requisites": [[378, "pre-requisites"]], "Making a new release of neural_compressor_ext_lab": [[379, "making-a-new-release-of-neural-compressor-ext-lab"]], "Manual release": [[379, "manual-release"], [382, "manual-release"]], "Python package": [[379, "python-package"], [382, "python-package"]], "NPM package": [[379, "npm-package"], [382, "npm-package"]], "Automated releases with the Jupyter Releaser": [[379, "automated-releases-with-the-jupyter-releaser"], [382, "automated-releases-with-the-jupyter-releaser"]], "Publishing to conda-forge": [[379, "publishing-to-conda-forge"], [382, "publishing-to-conda-forge"]], "neural_compressor_ext_lab_alibaba": [[381, "neural-compressor-ext-lab-alibaba"]], "Making a new release of neural_compressor_ext_lab_alibaba": [[382, "making-a-new-release-of-neural-compressor-ext-lab-alibaba"]], "Execute benchmark endpoint": [[384, "execute-benchmark-endpoint"]], "Request": [[384, "request"]], "Configuration for predefined models": [[385, "configuration-for-predefined-models"]], "Configuration for imported models": [[385, "configuration-for-imported-models"]], "Database migration": [[386, "database-migration"]], "Gui": [[387, "gui"]], "Development server": [[387, "development-server"]], "Code scaffolding": [[387, "code-scaffolding"]], "Build": [[387, "build"]], "Running unit tests": [[387, "running-unit-tests"]], "Running end-to-end tests": [[387, "running-end-to-end-tests"]], "Further help": [[387, "further-help"]], "Endpoints": [[388, "endpoints"]], "Project": [[388, "project"]], "Create project": [[388, "create-project"]], "Delete project": [[388, "delete-project"]], "Get project details": [[388, "get-project-details"]], "Add notes to project": [[388, "add-notes-to-project"]], "List projects": [[388, "list-projects"]], "Add dataset to project": [[388, "add-dataset-to-project"]], "Get dataset details": [[388, "get-dataset-details"]], "List datasets": [[388, "list-datasets"]], "Add optimization to project": [[388, "add-optimization-to-project"]], "Get optimization details": [[388, "get-optimization-details"]], "Edit optimization": [[388, "edit-optimization"]], "List optimizations": [[388, "list-optimizations"]], "Execute optimization": [[388, "execute-optimization"]], "Pin accuracy benchmark to optimization": [[388, "pin-accuracy-benchmark-to-optimization"]], "Pin performance benchmark to optimization": [[388, "pin-performance-benchmark-to-optimization"]], "Add benchmark to project": [[388, "add-benchmark-to-project"]], "Get benchmark details": [[388, "get-benchmark-details"]], "Edit benchmark": [[388, "edit-benchmark"]], "List benchmarks": [[388, "list-benchmarks"]], "Execute benchmark": [[388, "execute-benchmark"]], "Profiling": [[388, "profiling"]], "Add profiling to project": [[388, "add-profiling-to-project"]], "Get profiling details": [[388, "get-profiling-details"]], "Edit profiling": [[388, "edit-profiling"]], "Get profiling result as csv": [[388, "get-profiling-result-as-csv"]], "List profilings": [[388, "list-profilings"]], "Execute profiling": [[388, "execute-profiling"]], "List example models": [[388, "list-example-models"], [388, "id2"]], "Create project from examples": [[388, "create-project-from-examples"], [388, "id3"]], "List models": [[388, "list-models"]], "Get model\u2019s boundary nodes": [[388, "get-model-s-boundary-nodes"]], "Get model\u2019s graph": [[388, "get-model-s-graph"]], "Dictionaries": [[388, "dictionaries"]], "Domains": [[388, "domains"]], "Domain flavours": [[388, "domain-flavours"]], "Optimization Types": [[388, "optimization-types"]], "Optimization Types and support for specific precision": [[388, "optimization-types-and-support-for-specific-precision"]], "Precisions": [[388, "precisions"]], "Dataloaders": [[388, "dataloaders"]], "Get all dataloaders": [[388, "get-all-dataloaders"]], "Get dataloaders for specified framework": [[388, "get-dataloaders-for-specified-framework"]], "Transforms": [[388, "transforms"]], "Get all transforms": [[388, "get-all-transforms"]], "Get transforms for specified framework": [[388, "get-transforms-for-specified-framework"]], "Get transforms for specified domain": [[388, "get-transforms-for-specified-domain"]]}, "indexentries": {}})