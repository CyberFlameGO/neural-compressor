<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Mixed Precision &mdash; Intel® Neural Compressor  documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Graph Optimization" href="graph_optimization.html" />
    <link rel="prev" title="Benchmarking" href="benchmark.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Intel® Neural Compressor
          </a>
              <div class="version">
                1.14.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README.html">Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-documentation/apis.html">APIs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="doclist.html">Developer Documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="doclist.html#get-started">Get Started</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="doclist.html#deep-dive">Deep Dive</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="Quantization.html">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="PTQ.html">PTQ</a></li>
<li class="toctree-l3"><a class="reference internal" href="QAT.html">Quantization-aware Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="dynamic_quantization.html">Dynamic Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="pruning.html">Pruning</a></li>
<li class="toctree-l3"><a class="reference internal" href="benchmark.html">Benchmarking</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Mixed Precision</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mixed-precision-support-matrix">Mixed Precision Support Matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-start-with-mixed-precision-api">Get start with Mixed Precision API</a></li>
<li class="toctree-l4"><a class="reference internal" href="#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="graph_optimization.html">Graph Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_conversion.html">Model Conversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="tensorboard.html">TensorBoard</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="doclist.html#advanced-topics">Advanced Topics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="doclist.html">Developer Documentation</a></li>
      <li class="breadcrumb-item active">Mixed Precision</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/docs/mixed_precision.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="mixed-precision">
<h1>Mixed Precision<a class="headerlink" href="#mixed-precision" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p><a class="reference external" href="#introduction">Introduction</a></p></li>
<li><p><a class="reference external" href="#mixed-precision-support-matrix">Mixed Precision Support Matrix</a></p></li>
<li><p><a class="reference external" href="#get-start-with-mixed-precision-api">Get start with Mixed Precision API</a></p></li>
<li><p><a class="reference external" href="#examples">Examples</a></p></li>
</ol>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The recent growth of Deep Learning has driven the development of more complex models that require significantly more compute and memory capabilities. Several low precision numeric formats have been proposed to address the problem. Google’s <a class="reference external" href="https://cloud.google.com/tpu/docs/bfloat16">bfloat16</a> and the <a class="reference external" href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format">FP16: IEEE</a> half-precision format are two of the most widely used sixteen bit formats. <a class="reference external" href="https://arxiv.org/abs/1710.03740">Mixed precision</a> training and inference using low precision formats have been developed to reduce compute and bandwidth requirements.</p>
<p>The recently launched 3rd Gen Intel® Xeon® Scalable processor (codenamed Cooper Lake), featuring Intel® Deep Learning Boost, is the first general-purpose x86 CPU to support the bfloat16 format. Specifically, three new bfloat16 instructions are added as a part of the AVX512_BF16 extension within Intel Deep Learning Boost: VCVTNE2PS2BF16, VCVTNEPS2BF16, and VDPBF16PS. The first two instructions allow converting to and from bfloat16 data type, while the last one performs a dot product of bfloat16 pairs. Further details can be found in the <a class="reference external" href="https://software.intel.com/content/www/us/en/develop/download/bfloat16-hardware-numerics-definition.html">hardware numerics document</a> published by Intel.</p>
<a target="_blank" href="./imgs/data_format.png" text-align:center>
    <center> 
        <img src="./imgs/data_format.png" alt="Architecture" height=200> 
    </center>
</a></div>
<div class="section" id="mixed-precision-support-matrix">
<h2>Mixed Precision Support Matrix<a class="headerlink" href="#mixed-precision-support-matrix" title="Permalink to this headline">¶</a></h2>
<table border="1" class="docutils">
<thead>
<tr>
<th>Framework</th>
<th style="text-align: center;">BF16</th>
</tr>
</thead>
<tbody>
<tr>
<td>TensorFlow</td>
<td style="text-align: center;">&#10004;</td>
</tr>
<tr>
<td>PyTorch</td>
<td style="text-align: center;">&#10004;</td>
</tr>
<tr>
<td>ONNX</td>
<td style="text-align: center;">plan to support in the future</td>
</tr>
<tr>
<td>MXNet</td>
<td style="text-align: center;">&#10004;</td>
</tr>
</tbody>
</table><blockquote>
<div><p><strong>During quantization, BF16 conversion can be executed if force enabled. Please refer to this <a class="reference internal" href="quantization_mixed_precision.html"><span class="doc">document</span></a> for its workflow.</strong></p>
</div></blockquote>
</div>
<div class="section" id="get-start-with-mixed-precision-api">
<h2>Get start with Mixed Precision API<a class="headerlink" href="#get-start-with-mixed-precision-api" title="Permalink to this headline">¶</a></h2>
<p>To get a bf16 model, users can use the Mixed Precision API step by step.</p>
<ul class="simple">
<li><p>First, initialize an object of MixedPrecision.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">neural_compressor.experimental</span> <span class="kn">import</span> <span class="n">MixedPrecision</span>
<span class="n">converter</span> <span class="o">=</span> <span class="n">MixedPrecision</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Next, assign target precision and fp32 model to the attributes of MixedPrecision.</p></li>
</ul>
<blockquote>
<div><p><strong>BF16 conversion may lead to accuracy drop. Intel® Neural Compressor provides an accuracy-aware tuning function to reduce accuracy loss, which will fallback converted ops to FP32 automatically to get better accuracy. To enable this function, users only need to provide an evaluation function (or dataloader + metric).</strong></p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">converter</span><span class="o">.</span><span class="n">precisions</span> <span class="o">=</span> <span class="s1">&#39;bf16&#39;</span>
<span class="n">converter</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span> <span class="c1"># model is a fp32 model</span>
<span class="n">converter</span><span class="o">.</span><span class="n">eval_func</span> <span class="o">=</span> <span class="n">user_defined_function</span> <span class="c1"># optional, this function only accepts model as input and return a higher-is-better scalar as accuracy</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Last, execute convertion and save model.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">converted_model</span> <span class="o">=</span> <span class="n">converter</span><span class="p">()</span>
<span class="n">converted_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<p>There are 2 pre-requirements to run BF16 mixed precision examples:</p>
<ul class="simple">
<li><p>Hardware: CPU supports <code class="docutils literal notranslate"><span class="pre">avx512_bf16</span></code> instruction set.</p></li>
<li><p>Software: intel-tensorflow &gt;= <a class="reference external" href="https://pypi.org/project/intel-tensorflow/2.3.0/">2.3.0</a> or torch &gt;= <a class="reference external" href="https://download.pytorch.org/whl/torch_stable.html">1.11.0</a>.</p></li>
</ul>
<p>If either pre-requirement can’t be met, the program would exit consequently.</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="benchmark.html" class="btn btn-neutral float-left" title="Benchmarking" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="graph_optimization.html" class="btn btn-neutral float-right" title="Graph Optimization" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Intel® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>