

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Pruning &mdash; Intel® Low Precision Optimization Tool  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Benchmarking" href="benchmark.html" />
    <link rel="prev" title="Dynamic Quantization" href="dynamic_quantization.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Intel® Low Precision Optimization Tool
          

          
          </a>

          
            
            
              <div class="version">
                1.4.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README.html">Introduction to Intel® LPOT</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api-introduction.html">API Documentation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="doclist.html">Developer Documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="doclist.html#get-started">Get Started</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="doclist.html#deep-dive">Deep Dive</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="Quantization.html">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="PTQ.html">PTQ</a></li>
<li class="toctree-l3"><a class="reference internal" href="QAT.html">QAT</a></li>
<li class="toctree-l3"><a class="reference internal" href="dynamic_quantization.html">Dynamic Quantization</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Pruning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#design">Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="#usage">Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-of-user-pass-in-training-function">Example of user pass-in training function</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="benchmark.html">Benchmarking</a></li>
<li class="toctree-l3"><a class="reference internal" href="mixed_precision.html">Mixed Precision</a></li>
<li class="toctree-l3"><a class="reference internal" href="graph_optimization.html">Graph Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_conversion.html">Model Conversion</a></li>
<li class="toctree-l3"><a class="reference internal" href="tensorboard.html">TensorBoard</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="doclist.html#advanced-topics">Advanced Topics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../security_policy.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/lpot">Intel® LPOT repository</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Low Precision Optimization Tool</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="doclist.html">Developer Documentation</a> &raquo;</li>
        
      <li>Pruning</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/docs/pruning.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pruning">
<h1>Pruning<a class="headerlink" href="#pruning" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Sparsity is a measure of how many percents of elements in a tensor are <a class="reference external" href="https://nervanasystems.github.io/distiller/pruning.html">exact zeros</a>. A tensor is considered sparse if most of its elements are zero. Only non-zero elements will be stored and computed so the inference process could be accelerated due to TOPS (teraoperations/second) and memory saved (acceleration needs sparse compute kernels which are a work in process).</p>
<p>The <a href="https://en.wikipedia.org/wiki/Lp_space#When_p_=_0"><img src="http://latex.codecogs.com/svg.latex?\l_{1}&space;" title="http://latex.codecogs.com/svg.latex?\l_{1} " />-“norm” function</a> measures how many zero-elements are in a tensor <em>x</em>:
<img src="http://latex.codecogs.com/svg.latex?\left|\left|&space;x\right|&space;\right|_{0}\doteq&space;\left|x_{1}&space;\right|^{0}&plus;&space;\left|x_{2}&space;\right|^{0}&plus;...&plus;\left|x_{n}&space;\right|^{0}&space;" title="http://latex.codecogs.com/svg.latex?\left|\left| x\right| \right|_{0}\doteq \left|x_{1} \right|^{0}+ \left|x_{2} \right|^{0}+...+\left|x_{n} \right|^{0} " />
In other words, an element contributes either a value of 1 or 0 to (l_0).  Anything but an exact zero contributes a value of 1 - which is good. Sometimes it helps to think about density, the number of non-zero elements (NNZ) and sparsity’s complement:
[
density = 1 - sparsity
]
A common method for introducing sparsity in weights and activations is called <strong>pruning</strong>. Pruning is the application of a binary criteria to decide which weights to prune: weights which match the pruning criteria are assigned a value of zero. Pruned elements are “trimmed” from the model: we replace their values with zero and also make sure they don’t take part in the back-propagation process.</p></p>
</div>
<div class="section" id="design">
<h2>Design<a class="headerlink" href="#design" title="Permalink to this headline">¶</a></h2>
<p>The pruning process is similar to quantization-aware training (QAT). Intel® Low Precision Optimization Tool will do related model transformation during training and retrain the model to meet the accuracy goal.</p>
<p>We implemented two kinds of object: Pruner and PrunePolicy. First, we define a sparsity goal (model-wise or op-wise, depending on whether there are ops not suitable for pruning) and the way to reach the sparsity goal (usually we increase the sparsity target linearly as the epochs). The pruner is in singleton mode, and will update the sparsity goal and schedule all PrunePolicy during different phases of training.</p>
<p>PrunePolicy carries different pruning algos. For example, MagnitudePrunePolicy sets thresholds of absolute value so that elements whose absolute value lower than the threshold will be zeroed. The zeroing process happens at the beginning and end of each mini batch iteration.</p>
</div>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<p>Pruning configs need to be added into yaml as a <code class="docutils literal notranslate"><span class="pre">pruning</span></code> field.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">pruning</span><span class="p">:</span>                                             <span class="c1"># mandatory only for pruning.</span>
  <span class="nt">train</span><span class="p">:</span>
    <span class="nt">start_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
    <span class="nt">end_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
    <span class="nt">iteration</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">100</span>
    <span class="nt">frequency</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
    
    <span class="nt">dataloader</span><span class="p">:</span>
      <span class="nt">batch_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
      <span class="nt">dataset</span><span class="p">:</span>
        <span class="nt">ImageFolder</span><span class="p">:</span>
          <span class="nt">root</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/path/to/imagenet/train</span>
      <span class="nt">transform</span><span class="p">:</span>
        <span class="nt">RandomResizedCrop</span><span class="p">:</span>
          <span class="nt">size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">224</span>
        <span class="nt">RandomHorizontalFlip</span><span class="p">:</span>
        <span class="nt">ToTensor</span><span class="p">:</span>
        <span class="nt">Normalize</span><span class="p">:</span>
          <span class="nt">mean</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.485</span><span class="p p-Indicator">,</span> <span class="nv">0.456</span><span class="p p-Indicator">,</span> <span class="nv">0.406</span><span class="p p-Indicator">]</span>
          <span class="nt">std</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.229</span><span class="p p-Indicator">,</span> <span class="nv">0.224</span><span class="p p-Indicator">,</span> <span class="nv">0.225</span><span class="p p-Indicator">]</span> 
    <span class="nt">criterion</span><span class="p">:</span>
      <span class="nt">CrossEntropyLoss</span><span class="p">:</span>
        <span class="nt">reduction</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">None</span>
    <span class="nt">optimizer</span><span class="p">:</span>
      <span class="nt">SGD</span><span class="p">:</span>
        <span class="nt">learning_rate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
        <span class="nt">momentum</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.9</span>
        <span class="nt">weight_decay</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0004</span>
        <span class="nt">nesterov</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span>

  <span class="nt">approach</span><span class="p">:</span>
    <span class="nt">weight_compression</span><span class="p">:</span>
      <span class="nt">initial_sparsity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
      <span class="nt">target_sparsity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.3</span>
      <span class="nt">pruners</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="kt">!Pruner</span>
            <span class="nt">initial_sparsity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
            <span class="nt">target_sparsity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.97</span>
            <span class="nt">prune_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">basic_magnitude</span>              <span class="c1"># currently only support basic_magnitude</span>
            <span class="nt">names</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&#39;layer1.0.conv1.weight&#39;</span><span class="p p-Indicator">]</span>         <span class="c1"># tensor name to be pruned.</span>
            <span class="nt">start_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
            <span class="nt">end_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>
            <span class="nt">update_frequency</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
</pre></div>
</div>
<div class="section" id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<p>Most of pruning methods need <code class="docutils literal notranslate"><span class="pre">training</span></code> to keep the accuracy. There are two ways that Users can define the training process in <code class="docutils literal notranslate"><span class="pre">lpot</span></code>. One is completely configured in the yaml and <code class="docutils literal notranslate"><span class="pre">lpot</span></code> will create a training function automatically as the above example yaml.</p>
<p>Or users can pass in <code class="docutils literal notranslate"><span class="pre">def</span> <span class="pre">train</span></code> by themselves and insert <code class="docutils literal notranslate"><span class="pre">pruner</span></code> manually like the previous version. This is more suitable for complex and customize training function like NLP tasks especially text-generation models.</p>
<p>We provide examples of both 2 usages. For completely Yaml config, please refer to <a class="reference external" href="examples/pytorch/eager/image_recognition/imagenet/cpu/prune/conf.yaml">resnet example</a>. For users’ training function, please refer to <a class="reference external" href="examples/pytorch/eager/language_translation/prune/conf.yaml">BERT example</a>.</p>
</div>
<div class="section" id="pruning-config">
<h3>Pruning config<a class="headerlink" href="#pruning-config" title="Permalink to this headline">¶</a></h3>
<p>We divide the pruning into 2 kinds: <code class="docutils literal notranslate"><span class="pre">weight</span> <span class="pre">compression</span></code> and <code class="docutils literal notranslate"><span class="pre">activation</span> <span class="pre">compression</span></code>, the last is WIP. <code class="docutils literal notranslate"><span class="pre">weight</span> <span class="pre">compression</span></code> means zeroing the weight matrix.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">weight_compression</span></code>, we dived params into global parameters and local parameters in different <code class="docutils literal notranslate"><span class="pre">pruners</span></code>. Global parameters may contain <strong>start_epoch</strong> (on which epoch pruning begins), <strong>end_epoch</strong> (on which epoch pruning ends), <strong>initial_sparsity</strong> (initial sparsity goal default 0), <strong>target_sparsity</strong> (target sparsity goal) and <strong>frequency</strong> (of updating sparsity). At least one pruner instance needs to be defined under specific algos (currently only <code class="docutils literal notranslate"><span class="pre">basic_magnitude</span></code> supported). You can override all global params in a specific pruner using field names and specify names of which weight of model to be pruned. If no weight is specified, all weights of the model will be pruned.</p>
</div>
</div>
<div class="section" id="example-of-user-pass-in-training-function">
<h2>Example of user pass-in training function<a class="headerlink" href="#example-of-user-pass-in-training-function" title="Permalink to this headline">¶</a></h2>
<p>Users pass a modified training function to Intel® Low Precision Optimization Tool. The following is part of example from BERT training:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_train_epochs</span><span class="p">)):</span>
        <span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">(</span><span class="n">n_total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">prune</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">):</span>
            <span class="n">prune</span><span class="o">.</span><span class="n">on_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">)</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;input_ids&#39;</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                      <span class="s1">&#39;attention_mask&#39;</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                      <span class="s1">&#39;labels&#39;</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="mi">3</span><span class="p">]}</span>
            <span class="c1">#inputs[&#39;token_type_ids&#39;] = batch[2]</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># model outputs are always tuple in transformers (see doc)</span>

            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">n_gpu</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c1"># mean() to average on multi-gpu parallel training</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>

            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">args</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>

            
            <span class="k">if</span> <span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># Update learning rate schedule</span>
                <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    
            <span class="n">prune</span><span class="o">.</span><span class="n">on_batch_end</span><span class="p">()</span>
<span class="o">...</span>
</pre></div>
</div>
<p>Then users can use LPOT like the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Pruning</span><span class="p">,</span> <span class="n">common</span>
<span class="n">prune</span> <span class="o">=</span> <span class="n">Pruning</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
<span class="n">prune</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">prune</span><span class="o">.</span><span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">train_dataloader</span>
<span class="n">prune</span><span class="o">.</span><span class="n">pruning_func</span> <span class="o">=</span> <span class="n">train_func</span>
<span class="n">prune</span><span class="o">.</span><span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">train_dataloader</span>
<span class="n">prune</span><span class="o">.</span><span class="n">eval_func</span> <span class="o">=</span> <span class="n">eval_func</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">prune</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="benchmark.html" class="btn btn-neutral float-right" title="Benchmarking" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="dynamic_quantization.html" class="btn btn-neutral float-left" title="Dynamic Quantization" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Intel® Low Precision Optimization Tool.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>