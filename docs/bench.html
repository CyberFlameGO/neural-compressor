<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Intel® Neural Compressor Bench &mdash; Intel® Neural Compressor  documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Intel® Neural Compressor
          </a>
              <div class="version">
                1.8.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../README.html">Introduction to Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api-introduction.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../releases_info.html">Release</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../security_policy.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/neural-compressor">Intel® Neural Compressor repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Neural Compressor</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Intel® Neural Compressor Bench</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/docs/bench.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="intel-neural-compressor-bench">
<h1>Intel® Neural Compressor Bench<a class="headerlink" href="#intel-neural-compressor-bench" title="Permalink to this headline">¶</a></h1>
<p>Intel® Neural Compressor Bench is a web application for easier use of Intel® Neural Compressor. It is only available on Linux based hosts.</p>
</div>
<div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<div class="section" id="start-the-intel-neural-compressor-bench">
<h2>Start the Intel® Neural Compressor Bench<a class="headerlink" href="#start-the-intel-neural-compressor-bench" title="Permalink to this headline">¶</a></h2>
<p>To start the Intel® Neural Compressor Bench server execute <code class="docutils literal notranslate"><span class="pre">inc_bench</span></code> command:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>inc_bench
</pre></div>
</div>
<p>The server generates a self-signed TLS certificate and prints instruction how to access the Web UI.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Intel(r) Neural Compressor Bench Server started.

Open address https://10.11.12.13:5000/?token=338174d13706855fc6924cec7b3a8ae8
</pre></div>
</div>
<p>Server generated certificate is not trusted by your web browser, you will need to accept usage of such certificate.</p>
<p>You might also use additional parameters and settings:</p>
<ul>
<li><p>Intel® Neural Compressor Bench listens on port 5000.
Make sure that port 5000 is accessible to your browser (you might need to open it in your firewall),
or specify different port that is already opened, for example 8080:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>inc_bench -p <span class="m">8080</span>
</pre></div>
</div>
</li>
<li><p>When using TF 2.5.0, set environment variable <code class="docutils literal notranslate"><span class="pre">TF_ENABLE_MKL_NATIVE_FORMAT=0</span></code> for INT8 tuning:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">TF_ENABLE_MKL_NATIVE_FORMAT</span><span class="o">=</span><span class="m">0</span> inc_bench
</pre></div>
</div>
</li>
<li><p>To start the Intel® Neural Compressor Bench server with your own TLS certificate add <code class="docutils literal notranslate"><span class="pre">--cert</span></code> and <code class="docutils literal notranslate"><span class="pre">--key</span></code> parameters:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>inc_bench --cert path_to_cert.crt --key path_to_private_key.key
</pre></div>
</div>
</li>
<li><p>To start the Intel® Neural Compressor Bench server without TLS encryption use <code class="docutils literal notranslate"><span class="pre">--allow-insecure-connections</span></code> parameter:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>inc_bench --allow-insecure-connections
</pre></div>
</div>
<p>This enables access to the server from any machine in your local network (or the whole Internet if your server is exposed to it).</p>
<p>You are forfeiting security, confidentiality and integrity of all client-server communication. Your server is exposed to external threats.</p>
</li>
</ul>
</div>
<div class="section" id="home">
<h2>Home<a class="headerlink" href="#home" title="Permalink to this headline">¶</a></h2>
<p>This view shows introduction to Intel® Neural Compressor Bench and 2 buttons for creating new configurations in 2 different ways. First one links to <strong>Quantize from presets</strong> where you can find examples of models to chose from, the second one to <strong>Quantize using wizard</strong> where you can your custom models with many configurable parameters.
<img alt="Home" src="../_images/home.png" /></p>
</div>
</div>
<div class="section" id="quantize-from-presets">
<h1>Quantize from presets<a class="headerlink" href="#quantize-from-presets" title="Permalink to this headline">¶</a></h1>
<div class="section" id="description">
<h2>Description<a class="headerlink" href="#description" title="Permalink to this headline">¶</a></h2>
<p>In this scenario you can use one of preset models divided into 2 domain categories: image recognition and object detection.
<img alt="Examples" src="../_images/examples.png" /></p>
<p>You can use included models to test tuning. You have to point to the Dataset that you want to use and click <strong>Finish</strong> to add it to your models. A new model will be downloaded and added to the <strong>My models</strong> list, ready for tuning.</p>
</div>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<div class="section" id="resnet50-v1-5">
<h3>ResNet50 v1.5<a class="headerlink" href="#resnet50-v1-5" title="Permalink to this headline">¶</a></h3>
<p>Follow <a class="reference external" href="../examples/tensorflow/image_recognition/README">instructions</a> to get the ImageRecord dataset. Then go to <strong>Examples</strong>, choose <strong>Image Recognition</strong> domain, then click on <strong>resnet50 v1 5</strong> button and in the last step select the ImageRecord dataset like in the example below:
<img alt="examples1" src="../_images/examples-resnet.png" /></p>
</div>
<div class="section" id="mobilenet-v1">
<h3>MobileNet v1<a class="headerlink" href="#mobilenet-v1" title="Permalink to this headline">¶</a></h3>
<p>Follow <a class="reference external" href="../examples/tensorflow/image_recognition/README">instructions</a> to get the ImageRecord dataset. Then go to <strong>Examples</strong>, choose  <strong>Image Recognition</strong> domain, then click on <strong>mobilenet v1</strong> button and in the last step select the ImageRecord dataset like in the example below:
<img alt="examples2" src="../_images/examples-mobilenet.png" /></p>
</div>
<div class="section" id="ssd-mobilenet-v1">
<h3>SSD MobileNet v1<a class="headerlink" href="#ssd-mobilenet-v1" title="Permalink to this headline">¶</a></h3>
<p>Follow <a class="reference external" href="../examples/tensorflow/object_detection/README">instructions</a> to get the COCORecord dataset. Then go to <strong>Examples</strong>, choose  <strong>Object Detection</strong> domain, then click on <strong>ssd mobilenet v1</strong> button and in the last step select the COCORecord dataset like in the example below:
<img alt="examples3" src="../_images/examples-ssd.png" /></p>
</div>
</div>
</div>
<div class="section" id="quantize-using-wizard">
<h1>Quantize using wizard<a class="headerlink" href="#quantize-using-wizard" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2>Description<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<div class="section" id="basic-parameters">
<h3>Basic parameters<a class="headerlink" href="#basic-parameters" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Enter information in all required fields (marked by a *) in the Wizard:</p></li>
</ol>
<p><img alt="Wizard1" src="../_images/wizard1.png" />
<img alt="Wizard2" src="../_images/wizard2.png" /></p>
<ol class="simple">
<li><p>Either save this configuration (by clicking <strong>Finish</strong>), or change some advanced parameters (by checking the checkbox <img alt="Show advanced" src="../_images/show_advanced.png" />
).</p></li>
</ol>
</div>
</div>
<div class="section" id="id2">
<h2>Examples<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id3">
<h3>ResNet50 v1.5<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Follow <a class="reference external" href="../examples/tensorflow/image_recognition/README">instructions</a> to:</p>
<ul>
<li><p>install Intel Tensorflow 1.15 up2</p></li>
<li><p>prepare dataset and a frozen pb model</p></li>
</ul>
</li>
<li><p>In the <strong>Create low precision model</strong> in first step:</p>
<ul>
<li><p>select created frozen model</p></li>
<li><p>inputs, outputs and model domain will be selected automatically
<img alt="resnet1" src="../_images/resnet1.png" /></p></li>
</ul>
</li>
<li><p>in second step :</p>
<ul>
<li><p>in <strong>Calibration/dataset location</strong>, select <strong>ImageRecord</strong> file from created dataset</p></li>
<li><p>transformation and other parameters will be filled automatically</p></li>
<li><p>click <strong>Finish</strong> or change Advanced parameters
<img alt="resnet2" src="../_images/resnet2.png" /></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="ssd-resnet34">
<h3>SSD-ResNet34<a class="headerlink" href="#ssd-resnet34" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Follow <a class="reference external" href="../examples/tensorflow/object_detection/README">instructions</a> to:</p>
<ul>
<li><p>install Intel Tensorflow 1.15 up2</p></li>
<li><p>prepare dataset and a frozen pb model</p></li>
</ul>
</li>
<li><p>In the <strong>Create low precision model</strong> in first step:</p>
<ul>
<li><p>select created frozen model</p></li>
<li><p>inputs, outputs and model domain will be selected automatically
<img alt="ssd1" src="../_images/ssd1.png" /></p></li>
</ul>
</li>
<li><p>in second step :</p>
<ul>
<li><p>in <strong>Calibration/dataset location</strong>, select <strong>coco record</strong> file from created dataset</p></li>
<li><p>transformation and other parameters will be filled automatically</p></li>
<li><p>click <strong>Finish</strong> or change Advanced parameters
<img alt="ssd2" src="../_images/ssd2.png" /></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="bert">
<h3>BERT<a class="headerlink" href="#bert" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Follow <a class="reference external" href="../examples/tensorflow/nlp/bert_large_squad/README">instructions</a> to:</p>
<ul>
<li><p>install Intel Tensorflow 1.15 up2</p></li>
<li><p>prepare dataset and a frozen pb model</p></li>
</ul>
</li>
<li><p>In the <strong>Create low precision model</strong> in first step:</p>
<ul>
<li><p>select created frozen model</p></li>
<li><p>select <code class="docutils literal notranslate"><span class="pre">input_file</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> in inputs (in that order)</p></li>
<li><p>choose <strong>custom</strong> in output and enter <code class="docutils literal notranslate"><span class="pre">IteratorGetNext:3,</span> <span class="pre">unstack:0,</span> <span class="pre">unstack:1</span></code> in input field</p></li>
<li><p>choose NLP as model domain
<img alt="Bert1" src="../_images/bert1.png" /></p></li>
</ul>
</li>
<li><p>in second step :</p>
<ul>
<li><p>in <strong>Calibration/dataset location</strong>, select <strong>eval.tf_record</strong> file from created dataset</p></li>
<li><p>label_file and vocab_file fields should be filled automatically</p></li>
<li><p>click <strong>Finish</strong> or change Advanced parameters
<img alt="Bert2" src="../_images/bert2.png" /></p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="advanced-configs">
<h2>Advanced configs<a class="headerlink" href="#advanced-configs" title="Permalink to this headline">¶</a></h2>
<div class="section" id="advanced-parameters">
<h3>Advanced parameters<a class="headerlink" href="#advanced-parameters" title="Permalink to this headline">¶</a></h3>
<p>From the advanced parameters page, you can configure more features such as tuning, quantization, and benchmarking.</p>
<p><img alt="Wizard advanced" src="../_images/wizard_advanced.png" /></p>
</div>
<div class="section" id="custom-dataset-or-metric">
<h3>Custom dataset or metric<a class="headerlink" href="#custom-dataset-or-metric" title="Permalink to this headline">¶</a></h3>
<p>If you choose <strong>custom</strong> in the Dataset or Metric section, the appropriate code templates will be generated for you to fill in with your code. The path to the template will be available by clicking the <strong>Copy code template path</strong> button located in the right-most column in the <strong>My models</strong> list.</p>
<p>Follow the comments in the generated code template to fill in required methods with your own code.</p>
</div>
</div>
</div>
<div class="section" id="available-views">
<h1>Available views<a class="headerlink" href="#available-views" title="Permalink to this headline">¶</a></h1>
<p>On the left hand side there is a panel with list of configurations.</p>
<p><img alt="Menu" src="../_images/menu.png" /></p>
<p>One can see system information by clicking <img alt="System info" src="../_images/system_info.png" /> button. The result is details dialog:</p>
<p><img alt="System info table" src="../_images/system_info_table.png" /></p>
<p>By clicking <img alt="See models" src="../_images/see_models.png" />  button you can navigate to <strong>My models list</strong>.</p>
<div class="section" id="my-models-list">
<h2>My Models list<a class="headerlink" href="#my-models-list" title="Permalink to this headline">¶</a></h2>
<p>This view lists all Model Configurations defined on a given server.</p>
<p>You can create a new model using pre-defined models by using a New Model Wizard or <strong>Examples</strong>:</p>
<p><img alt="My models" src="../_images/my_models.png" /></p>
</div>
<div class="section" id="configuration-details">
<h2>Configuration details<a class="headerlink" href="#configuration-details" title="Permalink to this headline">¶</a></h2>
<p>When clicking on configuration from the left hand side list, you can see its details view. You can see the results, rerun the tuning, check the configuration and console output. You can also see the model graph.</p>
<p><img alt="Details" src="../_images/details.png" /></p>
</div>
<div class="section" id="tuning">
<h2>Tuning<a class="headerlink" href="#tuning" title="Permalink to this headline">¶</a></h2>
<p>Now that you have created a Model Configuration, you can do the following:</p>
<ul class="simple">
<li><p>See the generated config (by clicking the <strong>Show config</strong> link).</p></li>
<li><p>Start the tuning process:</p>
<ul>
<li><p>Click the blue arrow <img alt="Start Tuning button" src="../_images/tuning_start.png" /> to start the tuning.</p></li>
<li><p>Click <strong>Show output</strong> to see logs that are generated during tuning.</p></li>
<li><p>Your model will be tuned according to configuration.</p></li>
<li><p>When the tuning is finished, you will see accuracy results in the <strong>My Models</strong> list:</p>
<ul>
<li><p>The <strong>Accuracy</strong> section displays comparisons in accuracy metrics between the original and tuned models.</p></li>
<li><p><strong>Model size</strong> compares the sizes of both models.</p></li>
<li><p>When automatic benchmarking is finished, <strong>Throughput</strong> shows the performance gain from tuning.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="section" id="tuning-history">
<h3>Tuning history<a class="headerlink" href="#tuning-history" title="Permalink to this headline">¶</a></h3>
<p>If the configuration was tuned several times, in the details view there will be a chart showing accuracy and duration of historical tunings.</p>
</div>
<div class="section" id="profiling">
<h3>Profiling<a class="headerlink" href="#profiling" title="Permalink to this headline">¶</a></h3>
<p>You can also run profiling to check the performance of model layers. To do that you need to click <img alt="Start profiling button" src="../_images/profiling_start.png" /> button and when the profiling is finished, a table with profiling data will be shown:
<img alt="Profiling table" src="../_images/profiling_table.png" /></p>
</div>
</div>
<div class="section" id="model-graph-display">
<h2>Model Graph Display<a class="headerlink" href="#model-graph-display" title="Permalink to this headline">¶</a></h2>
<p>For Tensorflow frozen pb models there will be a new button available <img alt="Show graph" src="../_images/show_graph_button.png" />.</p>
<p>Click it to display graph of selected model:</p>
<p><img alt="Bert model graph" src="../_images/graph_bert.png" />.</p>
</div>
<div class="section" id="security">
<h2>Security<a class="headerlink" href="#security" title="Permalink to this headline">¶</a></h2>
<p>Intel® Neural Compressor Bench uses encrypted connections to ensure security, confidentiality and integrity of all client-server communication.</p>
<p>You can use automatically generated self-signed certificate or provide your own trusted certificate.</p>
<p>You can also choose to start the server without encryption exposing it to threats from network.</p>
<p>Intel® Neural Compressor Bench uses external packages to run the web-server and provide encryption. Please report any security issues to correct organizations:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://cryptography.io/en/latest/security/">Cryptography module</a></p></li>
<li><p><a class="reference external" href="https://flask.palletsprojects.com/en/2.0.x/contributing/#reporting-issues">Flask</a></p></li>
<li><p><a class="reference external" href="https://github.com/miguelgrinberg/Flask-SocketIO/blob/main/SECURITY.md">Flask-SocketIO</a></p></li>
</ul>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Intel® Neural Compressor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>