Full Validated Models
=====================

The below tables are models enabled by the IntelÂ® Neural Compressor.


### TensorFlow 2.x models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">Version</th>
    <th rowspan="2">Model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance</th>
  </tr>
  <tr>
    <th>INT8 Tuning Accuracy</th>
    <th>FP32 Accuracy Baseline</th>
    <th>Acc Ratio [(INT8-FP32)/FP32]</th>
    <th>INT8 realtime(ms)<br>CLX8280 1s 4c per instance</th>
    <th>FP32 realtime(ms)<br>CLX8280 1s 4c per instance</th>
    <th>Realtime Latency Ratio[FP32/INT8]</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>resnet50v1.0</td>
    <td>74.24%</td>
    <td>74.27%</td>
    <td>-0.04%</td>
    <td>7.56</td>
    <td>21.24</td>
    <td>2.81x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>resnet50v1.5</td>
    <td>76.94%</td>
    <td>76.46%</td>
    <td>0.63%</td>
    <td>9.64</td>
    <td>24.86</td>
    <td>2.58x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>resnet101</td>
    <td>77.21%</td>
    <td>76.45%</td>
    <td>0.99%</td>
    <td>12.73</td>
    <td>30.80</td>
    <td>2.42x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>inception_v1</td>
    <td>70.30%</td>
    <td>69.74%</td>
    <td>0.80%</td>
    <td>5.57</td>
    <td>9.92</td>
    <td>1.78x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>inception_v2</td>
    <td>74.27%</td>
    <td>73.97%</td>
    <td>0.41%</td>
    <td>6.69</td>
    <td>12.33</td>
    <td>1.84x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>inception_v3</td>
    <td>77.29%</td>
    <td>76.75%</td>
    <td>0.70%</td>
    <td>12.90</td>
    <td>27.46</td>
    <td>2.13x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>inception_v4</td>
    <td>80.36%</td>
    <td>80.27%</td>
    <td>0.11%</td>
    <td>20.88</td>
    <td>54.13</td>
    <td>2.59x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>inception_resnet_v2</td>
    <td>80.42%</td>
    <td>80.40%</td>
    <td>0.02%</td>
    <td>44.47</td>
    <td>87.69</td>
    <td>1.97x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>mobilenetv1</td>
    <td>73.93%</td>
    <td>70.96%</td>
    <td>4.19%</td>
    <td>2.95</td>
    <td>10.12</td>
    <td>3.43x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>mobilenetv2</td>
    <td>71.96%</td>
    <td>71.76%</td>
    <td>0.28%</td>
    <td>4.97</td>
    <td>10.39</td>
    <td>2.09x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>ssd_resnet50_v1</td>
    <td>37.91%</td>
    <td>38.00%</td>
    <td>-0.24%</td>
    <td>140.46</td>
    <td>411.03</td>
    <td>2.93x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>ssd_mobilenet_v1</td>
    <td>23.02%</td>
    <td>23.13%</td>
    <td>-0.48%</td>
    <td>12.25</td>
    <td>26.90</td>
    <td>2.20x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>ssd_resnet34</td>
    <td>21.97%</td>
    <td>22.16%</td>
    <td>-0.86%</td>
    <td>264.26</td>
    <td>960.48</td>
    <td>3.63x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>faster_rcnn_resnet101</td>
    <td>30.33%</td>
    <td>30.38%</td>
    <td>-0.16%</td>
    <td>153.96</td>
    <td>538.67</td>
    <td>3.50x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>faster_rcnn_resnet101_saved</td>
    <td>30.37%</td>
    <td>30.38%</td>
    <td>-0.03%</td>
    <td>152.12</td>
    <td>615.97</td>
    <td>4.05x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>mask_rcnn_inception_v2</td>
    <td>28.61%</td>
    <td>28.73%</td>
    <td>-0.42%</td>
    <td>77.97</td>
    <td>196.76</td>
    <td>2.52x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>wide_deep_large_ds</td>
    <td>77.61%</td>
    <td>77.67%</td>
    <td>-0.08%</td>
    <td>1.24</td>
    <td>1.88</td>
    <td>1.52x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>vgg16</td>
    <td>72.13%</td>
    <td>70.89%</td>
    <td>1.75%</td>
    <td>17.20</td>
    <td>61.26</td>
    <td>3.56x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>vgg19</td>
    <td>72.35%</td>
    <td>71.01%</td>
    <td>1.89%</td>
    <td>20.30</td>
    <td>74.16</td>
    <td>3.65x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>resnetv2_50</td>
    <td>70.36%</td>
    <td>69.64%</td>
    <td>1.03%</td>
    <td>15.60</td>
    <td>18.49</td>
    <td>1.19x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>resnetv2_101</td>
    <td>72.58%</td>
    <td>71.87%</td>
    <td>0.99%</td>
    <td>25.75</td>
    <td>34.07</td>
    <td>1.32x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>resnetv2_152</td>
    <td>72.92%</td>
    <td>72.37%</td>
    <td>0.76%</td>
    <td>37.08</td>
    <td>50.42</td>
    <td>1.36x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>densenet121</td>
    <td>72.31%</td>
    <td>72.89%</td>
    <td>-0.80%</td>
    <td>32.78</td>
    <td>48.23</td>
    <td>1.47x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>densenet161</td>
    <td>76.36%</td>
    <td>76.29%</td>
    <td>0.09%</td>
    <td>53.27</td>
    <td>86.78</td>
    <td>1.63x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>densenet169</td>
    <td>74.49%</td>
    <td>74.65%</td>
    <td>-0.21%</td>
    <td>39.31</td>
    <td>56.57</td>
    <td>1.44x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>ssd_resnet50_v1_ckpt</td>
    <td>37.89%</td>
    <td>38.00%</td>
    <td>-0.29%</td>
    <td>142.05</td>
    <td>482.43</td>
    <td>3.40x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>ssd_mobilenet_v1_ckpt</td>
    <td>23.02%</td>
    <td>23.13%</td>
    <td>-0.48%</td>
    <td>12.21</td>
    <td>31.91</td>
    <td>2.61x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>mask_rcnn_inception_v2_ckpt</td>
    <td>28.61%</td>
    <td>28.73%</td>
    <td>-0.42%</td>
    <td>81.49</td>
    <td>205.25</td>
    <td>2.52x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>efficientnet_b0</td>
    <td>78.53%</td>
    <td>76.75%</td>
    <td>2.32%</td>
    <td>25.46</td>
    <td>27.48</td>
    <td>1.08x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>2.5.0</td>
    <td>resnet50_fashion</td>
    <td>78.05%</td>
    <td>78.12%</td>
    <td>-0.09%</td>
    <td>3.14</td>
    <td>7.46</td>
    <td>2.37x</td>
  </tr>
</tbody>
</table>


### TensorFlow 1.x models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">Version</th>
    <th rowspan="2">Model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance</th>
  </tr>
  <tr>
    <th>INT8 Tuning Accuracy</th>
    <th>FP32 Accuracy Baseline</th>
    <th>Acc Ratio [(INT8-FP32)/FP32]</th>
    <th>INT8 realtime(ms)<br> CLX8280 1s 4c per instance</th>
    <th>FP32 realtime(ms)<br> CLX8280 1s 4c per instance</th>
    <th>Realtime Latency Ratio[FP32/INT8]</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>bert_large_squad</td>
    <td>92.4835</td>
    <td>92.9805</td>
    <td>-0.53%</td>
    <td>441.44</td>
    <td>1271.79</td>
    <td>2.88x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>bert_base_mrpc</td>
    <td>86.03%</td>
    <td>86.52%</td>
    <td>-0.57%</td>
    <td>50.61</td>
    <td>76.02</td>
    <td>1.50x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>resnet_v1_50_slim</td>
    <td>76.05%</td>
    <td>75.18%</td>
    <td>1.16%</td>
    <td>9.30</td>
    <td>26.32</td>
    <td>2.83x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>resnet_v1_101_slim</td>
    <td>77.15%</td>
    <td>76.40%</td>
    <td>0.98%</td>
    <td>15.04</td>
    <td>50.26</td>
    <td>3.34x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>resnet_v1_152_slim</td>
    <td>77.56%</td>
    <td>76.81%</td>
    <td>0.98%</td>
    <td>20.40</td>
    <td>74.22</td>
    <td>3.64x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>inception_v1_slim</td>
    <td>70.41%</td>
    <td>69.77%</td>
    <td>0.92%</td>
    <td>5.82</td>
    <td>12.21</td>
    <td>2.10x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>inception_v2_slim</td>
    <td>74.38%</td>
    <td>73.98%</td>
    <td>0.54%</td>
    <td>6.85</td>
    <td>14.36</td>
    <td>2.10x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>inception_v3_slim</td>
    <td>78.32%</td>
    <td>77.99%</td>
    <td>0.42%</td>
    <td>11.84</td>
    <td>31.53</td>
    <td>2.66x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>inception_v4_slim</td>
    <td>80.35%</td>
    <td>80.19%</td>
    <td>0.20%</td>
    <td>21.76</td>
    <td>61.29</td>
    <td>2.82x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>vgg16_slim</td>
    <td>72.16%</td>
    <td>70.89%</td>
    <td>1.79%</td>
    <td>17.03</td>
    <td>61.70</td>
    <td>3.62x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>vgg19_slim</td>
    <td>72.22%</td>
    <td>71.01%</td>
    <td>1.70%</td>
    <td>20.22</td>
    <td>73.62</td>
    <td>3.64x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>resnetv2_50_slim</td>
    <td>70.39%</td>
    <td>69.72%</td>
    <td>0.96%</td>
    <td>15.26</td>
    <td>19.60</td>
    <td>1.28x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>resnetv2_101_slim</td>
    <td>72.51%</td>
    <td>71.91%</td>
    <td>0.83%</td>
    <td>25.26</td>
    <td>36.47</td>
    <td>1.44x</td>
  </tr>
  <tr>
    <td>tensorflow</td>
    <td>1.15.0-up2</td>
    <td>resnetv2_152_slim</td>
    <td>72.98%</td>
    <td>72.40%</td>
    <td>0.80%</td>
    <td>36.10</td>
    <td>52.82</td>
    <td>1.46x</td>
  </tr>
</tbody>
</table>


### PyTorch models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">Version</th>
    <th rowspan="2">Model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance</th>
  </tr>
  <tr>
    <th>INT8 Tuning Accuracy</th>
    <th>FP32 Accuracy Baseline</th>
    <th>Acc Ratio [(INT8-FP32)/FP32]</th>
    <th>INT8 realtime(ms)<br> CLX8280 1s 4c per instance</th>
    <th>FP32 realtime(ms)<br> CLX8280 1s 4c per instance</th>
    <th>Realtime Latency Ratio[FP32/INT8]</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>resnet18</td>
    <td>69.58%</td>
    <td>69.76%</td>
    <td>-0.26%</td>
    <td>14.21</td>
    <td>26.55</td>
    <td>1.87x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>resnet50</td>
    <td>75.87%</td>
    <td>76.13%</td>
    <td>-0.34%</td>
    <td>24.89</td>
    <td>53.84</td>
    <td>2.16x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>resnext101_32x8d</td>
    <td>79.09%</td>
    <td>79.31%</td>
    <td>-0.28%</td>
    <td>64.03</td>
    <td>147.51</td>
    <td>2.30x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>bert_base_mrpc</td>
    <td>88.16%</td>
    <td>88.73%</td>
    <td>-0.64%</td>
    <td>41.15</td>
    <td>81.56</td>
    <td>1.98x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>bert_base_cola</td>
    <td>58.29%</td>
    <td>58.84%</td>
    <td>-0.93%</td>
    <td>39.17</td>
    <td>83.42</td>
    <td>2.13x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>bert_base_sts-b</td>
    <td>88.65%</td>
    <td>89.27%</td>
    <td>-0.70%</td>
    <td>39.59</td>
    <td>83.07</td>
    <td>2.10x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>bert_base_sst-2</td>
    <td>91.63%</td>
    <td>91.86%</td>
    <td>-0.25%</td>
    <td>39.39</td>
    <td>83.17</td>
    <td>2.11x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>bert_base_rte</td>
    <td>69.31%</td>
    <td>69.68%</td>
    <td>-0.52%</td>
    <td>39.51</td>
    <td>81.84</td>
    <td>2.07x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>bert_large_mrpc</td>
    <td>87.48%</td>
    <td>88.33%</td>
    <td>-0.95%</td>
    <td>112.80</td>
    <td>281.91</td>
    <td>2.50x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>bert_large_squad</td>
    <td>92.78988</td>
    <td>93.04683</td>
    <td>-0.28%</td>
    <td>503.92</td>
    <td>934.01</td>
    <td>1.85x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>bert_large_qnli</td>
    <td>91.12%</td>
    <td>91.82%</td>
    <td>-0.76%</td>
    <td>111.08</td>
    <td>289.13</td>
    <td>2.60x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>bert_large_rte</td>
    <td>72.92%</td>
    <td>72.56%</td>
    <td>0.50%</td>
    <td>151.93</td>
    <td>298.53</td>
    <td>1.96x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>bert_large_cola</td>
    <td>	62.85%</td>
    <td>62.57%</td>
    <td>0.45%</td>
    <td>113.04</td>
    <td>285.43</td>
    <td>2.52x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>inception_v3</td>
    <td>69.39%</td>
    <td>69.54%</td>
    <td>-0.21%</td>
    <td>30.39</td>
    <td>53.35</td>
    <td>1.76x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>peleenet</td>
    <td>71.54%</td>
    <td>72.08%</td>
    <td>-0.75%</td>
    <td>25.80</td>
    <td>34.32</td>
    <td>1.33x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>yolo_v3</td>
    <td>24.50%</td>
    <td>24.54%</td>
    <td>-0.17%</td>
    <td>118.46</td>
    <td>245.69</td>
    <td>2.07x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>se_resnext50_32x4d</td>
    <td>79.02%</td>
    <td>79.08%</td>
    <td>-0.07%</td>
    <td>34.31</td>
    <td>64.15</td>
    <td>1.87x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>mobilenet_v2</td>
    <td>70.73%</td>
    <td>71.86%</td>
    <td>-1.57%</td>
    <td>15.73</td>
    <td>21.26</td>
    <td>1.35x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>blendcnn</td>
    <td>68.40%</td>
    <td>68.40%</td>
    <td>0.00%</td>
    <td>2.44</td>
    <td>2.54</td>
    <td>1.04x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.5.0a0+b58f89b</td>
    <td>resnet50_ipex</td>
    <td>75.80%</td>
    <td>76.13%</td>
    <td>-0.44%</td>
    <td>19.79</td>
    <td>32.85</td>
    <td>1.66x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>gpt_wikitext</td>
    <td>60.06256</td>
    <td>60.19923</td>
    <td>-0.23%</td>
    <td>533.84</td>
    <td>580.59</td>
    <td>1.09x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>roberta_base_mrpc</td>
    <td>85.37%</td>
    <td>85.51%</td>
    <td>-0.17%</td>
    <td>40.28</td>
    <td>81.83</td>
    <td>2.03x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>camembert_base_mrpc</td>
    <td>84.72%</td>
    <td>84.22%</td>
    <td>0.60%</td>
    <td>44.26</td>
    <td>82.71</td>
    <td>1.87x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>distilbert_base_mrpc</td>
    <td>81.17%</td>
    <td>80.99%</td>
    <td>0.21%</td>
    <td>25.05</td>
    <td>44.05</td>
    <td>1.76x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>albert_base_mrpc</td>
    <td>88.77%</td>
    <td>88.50%</td>
    <td>0.31%</td>
    <td>305.94</td>
    <td>382.89</td>
    <td>1.25x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>funnel_mrpc</td>
    <td>91.72%</td>
    <td>92.26%</td>
    <td>-0.58%</td>
    <td>88.12</td>
    <td>89.73</td>
    <td>1.02x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>bart_wnli</td>
    <td>49.30%</td>
    <td>52.11%</td>
    <td>-5.41%</td>
    <td>322.04</td>
    <td>351.34</td>
    <td>1.09x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>mbart_wnli</td>
    <td>56.34%</td>
    <td>56.34%</td>
    <td>0.00%</td>
    <td>175.59</td>
    <td>344.12</td>
    <td>1.96x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>t5_wmt_en_ro</td>
    <td>24.3855</td>
    <td>24.5213</td>
    <td>-0.55%</td>
    <td>2536.71</td>
    <td>2699.99</td>
    <td>1.06x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>marianmt_wmt_en_ro</td>
    <td>22.3857</td>
    <td>22.225</td>
    <td>0.72%</td>
    <td>3599.60</td>
    <td>3794.95</td>
    <td>1.05x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>pegasus_billsum</td>
    <td>50.2328</td>
    <td>51.2135</td>
    <td>-1.91%</td>
    <td>40000.00</td>
    <td>62500.00</td>
    <td>1.56x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>dialogpt_wikitext</td>
    <td>36.18182</td>
    <td>36.18182</td>
    <td>0.00%</td>
    <td>1600.46</td>
    <td>1607.39</td>
    <td>1.00x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>xlm-roberta-base_mrpc</td>
    <td>87.93%</td>
    <td>88.62%</td>
    <td>-0.78%</td>
    <td>87.97</td>
    <td>90.37</td>
    <td>1.03x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>flaubert_mrpc</td>
    <td>79.81%</td>
    <td>80.19%</td>
    <td>-0.48%</td>
    <td>19.38</td>
    <td>23.72</td>
    <td>1.22x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>barthez_mrpc</td>
    <td>83.25%</td>
    <td>83.81%</td>
    <td>-0.66%</td>
    <td>62.10</td>
    <td>104.48</td>
    <td>1.68x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>longformer_mrpc</td>
    <td>90.97%</td>
    <td>91.46%</td>
    <td>-0.53%</td>
    <td>539.64</td>
    <td>638.29</td>
    <td>1.18x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>layoutlm_mrpc</td>
    <td>81.22%</td>
    <td>78.01%</td>
    <td>4.12%</td>
    <td>48.19</td>
    <td>89.53</td>
    <td>1.86x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>deberta_mrpc</td>
    <td>90.29%</td>
    <td>90.91%</td>
    <td>-0.68%</td>
    <td>88.94</td>
    <td>137.69</td>
    <td>1.55x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>squeezebert_mrpc</td>
    <td>87.96%</td>
    <td>87.65%</td>
    <td>0.36%</td>
    <td>48.09</td>
    <td>55.24</td>
    <td>1.15x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>dlrm_fx</td>
    <td>80.19%</td>
    <td>80.27%</td>
    <td>-0.10%</td>
    <td>0.00</td>
    <td>0.01</td>
    <td>1.67x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>resnet18_fx</td>
    <td>69.61%</td>
    <td>69.76%</td>
    <td>-0.22%</td>
    <td>13.89</td>
    <td>27.16</td>
    <td>1.96x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>xlnet_base_mrpc</td>
    <td>89.43%</td>
    <td>89.47%</td>
    <td>-0.04%</td>
    <td>103.04</td>
    <td>133.18</td>
    <td>1.29x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>transfo_xl_mrpc</td>
    <td>82.09%</td>
    <td>81.20%</td>
    <td>1.09%</td>
    <td>1054.85</td>
    <td>1415.61</td>
    <td>1.34x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>ctrl_mrpc</td>
    <td>82.00%</td>
    <td>82.00%</td>
    <td>0.00%</td>
    <td>456.33</td>
    <td>1228.72</td>
    <td>2.69x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>xlm_mrpc</td>
    <td>80.50%</td>
    <td>79.56%</td>
    <td>1.18%</td>
    <td>179.22</td>
    <td>542.68</td>
    <td>3.03x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>maskrcnn_fx</td>
    <td>37.70%</td>
    <td>37.80%</td>
    <td>-0.26%</td>
    <td>117.49</td>
    <td>181.06</td>
    <td>1.54x</td>
  </tr>
</tbody>
</table>


### Quantization-aware training models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">Version</th>
    <th rowspan="2">Model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance</th>
  </tr>
  <tr>
    <th>INT8 Tuning Accuracy</th>
    <th>FP32 Accuracy Baseline</th>
    <th>Acc Ratio [(INT8-FP32)/FP32]</th>
    <th>INT8 realtime(ms)<br> CLX8280 1s 4c per instance</th>
    <th>FP32 realtime(ms)<br> CLX8280 1s 4c per instance</th>
    <th>Realtime Latency Ratio[FP32/INT8]</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>resnet18_qat</td>
    <td>69.75%</td>
    <td>69.76%</td>
    <td>-0.02%</td>
    <td>14.20</td>
    <td>26.63</td>
    <td>1.87x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>resnet50_qat</td>
    <td>76.05%</td>
    <td>76.13%</td>
    <td>-0.11%</td>
    <td>25.55</td>
    <td>54.46</td>
    <td>2.13x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>resnet18_qat_fx</td>
    <td>69.72%</td>
    <td>69.76%</td>
    <td>-0.05%</td>
    <td>14.05</td>
    <td>27.17</td>
    <td>1.93x</td>
  </tr>
  <tr>
    <td>pytorch</td>
    <td>1.9.0+cpu</td>
    <td>mobilenet_v2_qat</td>
    <td>71.45%</td>
    <td>71.86%</td>
    <td>-0.56%</td>
    <td>15.55</td>
    <td>22.13</td>
    <td>1.42x</td>
  </tr>
</tbody>
</table>


### MXNet models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">Version</th>
    <th rowspan="2">Model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance</th>
  </tr>
  <tr>
    <th>INT8 Tuning Accuracy</th>
    <th>FP32 Accuracy Baseline</th>
    <th>Acc Ratio [(INT8-FP32)/FP32]</th>
    <th>INT8 realtime(ms)<br> CLX8280 1s 4c per instance</th>
    <th>FP32 realtime(ms)<br> CLX8280 1s 4c per instance</th>
    <th>Realtime Latency Ratio[FP32/INT8]</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>mxnet</td>
    <td>1.7.0</td>
    <td>resnet50v1</td>
    <td>76.08%</td>
    <td>76.33%</td>
    <td>-0.32%</td>
    <td>6.22</td>
    <td>20.86</td>
    <td>3.35x</td>
  </tr>
  <tr>
    <td>mxnet</td>
    <td>1.7.0</td>
    <td>inceptionv3</td>
    <td>77.73%</td>
    <td>77.64%</td>
    <td>0.11%</td>
    <td>11.23</td>
    <td>30.37</td>
    <td>2.71x</td>
  </tr>
  <tr>
    <td>mxnet</td>
    <td>1.7.0</td>
    <td>mobilenet1.0</td>
    <td>71.69%</td>
    <td>72.22%</td>
    <td>-0.74%</td>
    <td>1.60</td>
    <td>4.02</td>
    <td>2.51x</td>
  </tr>
  <tr>
    <td>mxnet</td>
    <td>1.7.0</td>
    <td>mobilenetv2_1.0</td>
    <td>70.78%</td>
    <td>70.87%</td>
    <td>-0.12%</td>
    <td>2.00</td>
    <td>5.45</td>
    <td>2.73x</td>
  </tr>
  <tr>
    <td>mxnet</td>
    <td>1.7.0</td>
    <td>resnet18_v1</td>
    <td>70.02%</td>
    <td>70.14%</td>
    <td>-0.17%</td>
    <td>3.01</td>
    <td>9.57</td>
    <td>3.18x</td>
  </tr>
  <tr>
    <td>mxnet</td>
    <td>1.7.0</td>
    <td>squeezenet1.0</td>
    <td>56.74%</td>
    <td>56.96%</td>
    <td>-0.38%</td>
    <td>2.40</td>
    <td>6.40</td>
    <td>2.67x</td>
  </tr>
  <tr>
    <td>mxnet</td>
    <td>1.7.0</td>
    <td>ssd-resnet50_v1</td>
    <td>80.21%</td>
    <td>80.23%</td>
    <td>-0.03%</td>
    <td>37.27</td>
    <td>174.71</td>
    <td>4.69x</td>
  </tr>
  <tr>
    <td>mxnet</td>
    <td>1.7.0</td>
    <td>ssd-mobilenet1.0</td>
    <td>74.94%</td>
    <td>75.54%</td>
    <td>-0.79%</td>
    <td>15.73</td>
    <td>60.20</td>
    <td>3.83x</td>
  </tr>
  <tr>
    <td>mxnet</td>
    <td>1.7.0</td>
    <td>resnet152_v1</td>
    <td>78.21%</td>
    <td>78.54%</td>
    <td>-0.42%</td>
    <td>17.75</td>
    <td>58.53</td>
    <td>3.30x</td>
  </tr>
</tbody>
</table>


### ONNX Models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">Version</th>
    <th rowspan="2">Model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance</th>
  </tr>
  <tr>
    <th>INT8 Tuning Accuracy</th>
    <th>FP32 Accuracy Baseline</th>
    <th>Acc Ratio [(INT8-FP32)/FP32]</th>
    <th>INT8 realtime(ms)<br> CLX8280 1s 4c per instance</th>
    <th>FP32 realtime(ms)<br> CLX8280 1s 4c per instance</th>
    <th>Realtime Latency Ratio[FP32/INT8]</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>resnet50_v1_5</td>
    <td>72.11%</td>
    <td>72.28%</td>
    <td>-0.24%</td>
    <td>12.82</td>
    <td>20.59</td>
    <td>1.61x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>bert_base_mrpc_static</td>
    <td>85.29%</td>
    <td>86.03%</td>
    <td>-0.86%</td>
    <td>14.61</td>
    <td>33.18</td>
    <td>2.27x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>bert_base_mrpc_dynamic</td>
    <td>85.54%</td>
    <td>86.03%</td>
    <td>-0.57%</td>
    <td>28.59</td>
    <td>70.00</td>
    <td>2.45x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>vgg16</td>
    <td>66.58%</td>
    <td>66.68%</td>
    <td>-0.15%</td>
    <td>69.07</td>
    <td>88.33</td>
    <td>1.28x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>ssd_mobilenet_v1</td>
    <td>22.41%</td>
    <td>23.10%</td>
    <td>-2.99%</td>
    <td>16.36</td>
    <td>18.56</td>
    <td>1.13x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>ssd_mobilenet_v2</td>
    <td>23.80%</td>
    <td>24.68%</td>
    <td>-3.57%</td>
    <td>20.62</td>
    <td>25.01</td>
    <td>1.21x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>distilbert_base_mrpc</td>
    <td>84.56%</td>
    <td>84.56%</td>
    <td>0.00%</td>
    <td>6.47</td>
    <td>18.11</td>
    <td>2.80x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>mobilebert_mrpc</td>
    <td>85.54%</td>
    <td>86.27%</td>
    <td>-0.85%</td>
    <td>16.01</td>
    <td>17.49</td>
    <td>1.09x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>roberta_base_mrpc</td>
    <td>88.73%</td>
    <td>89.46%</td>
    <td>-0.82%</td>
    <td>14.15</td>
    <td>34.33</td>
    <td>2.43x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>resnet50-v1-12</td>
    <td>74.83%</td>
    <td>74.97%</td>
    <td>-0.19%</td>
    <td>10.89</td>
    <td>20.10</td>
    <td>1.85x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>resnet_v1_5_mlperf</td>
    <td>76.11%</td>
    <td>76.47%</td>
    <td>-0.47%</td>
    <td>11.68</td>
    <td>20.38</td>
    <td>1.74x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>mobilenet_v3_mlperf</td>
    <td>75.51%</td>
    <td>75.75%</td>
    <td>-0.32%</td>
    <td>5.01</td>
    <td>6.95</td>
    <td>1.39x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>bert_squad_model_zoo</td>
    <td>80.43519</td>
    <td>80.67171</td>
    <td>-0.29%</td>
    <td>95.01</td>
    <td>171.53</td>
    <td>1.81x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>mobilebert_squad_mlperf</td>
    <td>89.84479</td>
    <td>90.0265</td>
    <td>-0.20%</td>
    <td>115.67</td>
    <td>122.16</td>
    <td>1.06x</td>
  </tr>
  <tr>
    <td>onnxrt</td>
    <td>1.8.0</td>
    <td>vgg16_model_zoo</td>
    <td>72.37%</td>
    <td>72.38%</td>
    <td>-0.01%</td>
    <td>56.98</td>
    <td>87.97</td>
    <td>1.54x</td>
  </tr>
</tbody>
</table>

