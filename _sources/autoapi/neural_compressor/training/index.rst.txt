:orphan:

:py:mod:`neural_compressor.training`
====================================

.. py:module:: neural_compressor.training


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.training.CompressionManager



Functions
~~~~~~~~~

.. autoapisummary::

   neural_compressor.training.prepare_compression



.. py:class:: CompressionManager(component)

   CompressionManager is uesd in train loop for what user want to deal with additional.

   :param commponent: one instance of Distillation, Quantization, Pruning, Scheduler

   .. rubric:: Examples

   import neural_compressor.training.prepare_compression
   compression_manager = prepare_compression(conf, model)
   compression_manager.callbacks.on_train_begin()
   model = compression_manager.model
   train_loop:
       for epoch in range(epochs):
           compression_manager.callbacks.on_epoch_begin(epoch)
           for i, batch in enumerate(dataloader):
               compression_manager.callbacks.on_step_begin(i)
               ......
               output = model(batch)
               loss = ......
               loss = compression_manager.callbacks.on_after_compute_loss(batch, output, loss)
               loss.backward()
               compression_manager.callbacks.on_before_optimizer_step()
               optimizer.step()
               compression_manager.callbacks.on_step_end()
           compression_manager.callbacks.on_epoch_end()
   compression_manager.callbacks.on_train_end()
   compression_manager.save("path_to_save")

   .. py:method:: save(root=None)

      Save compressed model.

      :param root: path to save the model
      :type root: str


   .. py:method:: export(save_path: str, conf)

      Convert the model to another type model, like `onnx` model and so on.

      Args:




.. py:function:: prepare_compression(model: Callable, confs: Union[Callable, List], **kwargs)

   _summary_

   :param model: model to optimize.
   :type model: Callable, optional
   :param confs: config of Distillation, Quantization, Pruning,
                 or list of config for orchestration optimization
   :type confs: Union[Callable, List]
   :param options: The configure for random_seed, workspace,
                   resume path and tensorboard flag.
   :type options: Options, optional

   :returns: CompressionManager

   .. rubric:: Examples

   import neural_compressor.training.prepare_compression
   compression_manager = prepare_compression(conf, model)
   train_loop:
       compression_manager.on_train_begin()
       for epoch in range(epochs):
           compression_manager.on_epoch_begin(epoch)
           for i, batch in enumerate(dataloader):
               compression_manager.on_step_begin(i)
               ......
               output = model(batch)
               loss = ......
               loss = compression_manager.on_after_compute_loss(batch, output, loss)
               loss.backward()
               compression_manager.on_before_optimizer_step()
               optimizer.step()
               compression_manager.on_step_end()
           compression_manager.on_epoch_end()
       compression_manager.on_train_end()


