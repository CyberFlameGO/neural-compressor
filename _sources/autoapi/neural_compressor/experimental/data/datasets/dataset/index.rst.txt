:orphan:

:py:mod:`neural_compressor.experimental.data.datasets.dataset`
==============================================================

.. py:module:: neural_compressor.experimental.data.datasets.dataset


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.experimental.data.datasets.dataset.Dataset
   neural_compressor.experimental.data.datasets.dataset.IterableDataset
   neural_compressor.experimental.data.datasets.dataset.CIFAR10
   neural_compressor.experimental.data.datasets.dataset.PytorchCIFAR10
   neural_compressor.experimental.data.datasets.dataset.MXNetCIFAR10
   neural_compressor.experimental.data.datasets.dataset.TensorflowCIFAR10
   neural_compressor.experimental.data.datasets.dataset.CIFAR100
   neural_compressor.experimental.data.datasets.dataset.PytorchCIFAR100
   neural_compressor.experimental.data.datasets.dataset.MXNetCIFAR100
   neural_compressor.experimental.data.datasets.dataset.TensorflowCIFAR100
   neural_compressor.experimental.data.datasets.dataset.MNIST
   neural_compressor.experimental.data.datasets.dataset.PytorchMNIST
   neural_compressor.experimental.data.datasets.dataset.MXNetMNIST
   neural_compressor.experimental.data.datasets.dataset.TensorflowMNIST
   neural_compressor.experimental.data.datasets.dataset.FashionMNIST
   neural_compressor.experimental.data.datasets.dataset.PytorchFashionMNIST
   neural_compressor.experimental.data.datasets.dataset.MXNetFashionMNIST
   neural_compressor.experimental.data.datasets.dataset.TensorflowFashionMNIST
   neural_compressor.experimental.data.datasets.dataset.ImageFolder
   neural_compressor.experimental.data.datasets.dataset.MXNetImageFolder
   neural_compressor.experimental.data.datasets.dataset.TensorflowImageFolder
   neural_compressor.experimental.data.datasets.dataset.TensorflowTFRecordDataset
   neural_compressor.experimental.data.datasets.dataset.TensorflowImageRecord
   neural_compressor.experimental.data.datasets.dataset.TensorflowVOCRecord



Functions
~~~~~~~~~

.. autoapisummary::

   neural_compressor.experimental.data.datasets.dataset.dataset_registry



Attributes
~~~~~~~~~~

.. autoapisummary::

   neural_compressor.experimental.data.datasets.dataset.framework_datasets


.. py:data:: framework_datasets
   

   The datasets supported by neural_compressor, it's model specific and can be configured by yaml file.

   User could add new datasets by implementing new Dataset subclass under this directory.
   The naming convention of new dataset subclass should be something like ImageClassifier, user
   could choose this dataset by setting "imageclassifier" string in tuning.strategy field of yaml.

   DATASETS variable is used to store all implemented Dataset subclasses to support
   model specific dataset.

.. py:function:: dataset_registry(dataset_type, framework, dataset_format='')

   The class decorator used to register all Dataset subclasses.


   :param cls: The class of register.
   :type cls: class
   :param dataset_type: The dataset registration name
   :type dataset_type: str
   :param framework: support 3 framework including 'tensorflow', 'pytorch', 'mxnet'
   :type framework: str
   :param data_format: The format dataset saved, eg 'raw_image', 'tfrecord'
   :type data_format: str

   :returns: The class of register.
   :rtype: cls


.. py:class:: Dataset

   Bases: :py:obj:`object`

   The base class of dataset. Subclass datasets should overwrite two methods:
   `__getitem__` for indexing to data sample and `__len__`for the size of the dataset



.. py:class:: IterableDataset

   Bases: :py:obj:`object`

   An iterable Dataset. Subclass iterable dataset should also implement a method:
   `__iter__` for interating over the samples of the dataset.



.. py:class:: CIFAR10(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`Dataset`

   Configuration for CIFAR10 and CIFAR100 database

   For CIFAR10: If download is True, it will download dataset to root/ and extract it
                automatically, otherwise user can download file from
                https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to
                root/ and extract it.
   For CIFAR100: If download is True, it will download dataset to root/ and extract it
                 automatically, otherwise user can download file from
                 https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to
                 root/ and extract it.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: PytorchCIFAR10(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`CIFAR10`

   Configuration for CIFAR10 and CIFAR100 database

   For CIFAR10: If download is True, it will download dataset to root/ and extract it
                automatically, otherwise user can download file from
                https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to
                root/ and extract it.
   For CIFAR100: If download is True, it will download dataset to root/ and extract it
                 automatically, otherwise user can download file from
                 https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to
                 root/ and extract it.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: MXNetCIFAR10(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`CIFAR10`

   Configuration for CIFAR10 and CIFAR100 database

   For CIFAR10: If download is True, it will download dataset to root/ and extract it
                automatically, otherwise user can download file from
                https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to
                root/ and extract it.
   For CIFAR100: If download is True, it will download dataset to root/ and extract it
                 automatically, otherwise user can download file from
                 https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to
                 root/ and extract it.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: TensorflowCIFAR10(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`CIFAR10`

   Configuration for CIFAR10 and CIFAR100 database

   For CIFAR10: If download is True, it will download dataset to root/ and extract it
                automatically, otherwise user can download file from
                https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to
                root/ and extract it.
   For CIFAR100: If download is True, it will download dataset to root/ and extract it
                 automatically, otherwise user can download file from
                 https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to
                 root/ and extract it.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: CIFAR100(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`CIFAR10`

   Configuration for CIFAR10 and CIFAR100 database

   For CIFAR10: If download is True, it will download dataset to root/ and extract it
                automatically, otherwise user can download file from
                https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to
                root/ and extract it.
   For CIFAR100: If download is True, it will download dataset to root/ and extract it
                 automatically, otherwise user can download file from
                 https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to
                 root/ and extract it.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: PytorchCIFAR100(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`CIFAR100`

   Configuration for CIFAR10 and CIFAR100 database

   For CIFAR10: If download is True, it will download dataset to root/ and extract it
                automatically, otherwise user can download file from
                https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to
                root/ and extract it.
   For CIFAR100: If download is True, it will download dataset to root/ and extract it
                 automatically, otherwise user can download file from
                 https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to
                 root/ and extract it.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: MXNetCIFAR100(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`CIFAR100`

   Configuration for CIFAR10 and CIFAR100 database

   For CIFAR10: If download is True, it will download dataset to root/ and extract it
                automatically, otherwise user can download file from
                https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to
                root/ and extract it.
   For CIFAR100: If download is True, it will download dataset to root/ and extract it
                 automatically, otherwise user can download file from
                 https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to
                 root/ and extract it.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: TensorflowCIFAR100(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`CIFAR100`

   Configuration for CIFAR10 and CIFAR100 database

   For CIFAR10: If download is True, it will download dataset to root/ and extract it
                automatically, otherwise user can download file from
                https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to
                root/ and extract it.
   For CIFAR100: If download is True, it will download dataset to root/ and extract it
                 automatically, otherwise user can download file from
                 https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to
                 root/ and extract it.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: MNIST(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`Dataset`

   Configuration for Modified National Institute of Standards and Technology database
      and FashionMNIST database

   For MNIST: If download is True, it will download dataset to root/MNIST/, otherwise user
              should put mnist.npz under root/MNIST/ manually.
   For FashionMNIST: If download is True, it will download dataset to root/FashionMNIST/,
                     otherwise user should put train-labels-idx1-ubyte.gz,
                     train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz
                     and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: PytorchMNIST(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`MNIST`

   Configuration for Modified National Institute of Standards and Technology database
      and FashionMNIST database

   For MNIST: If download is True, it will download dataset to root/MNIST/, otherwise user
              should put mnist.npz under root/MNIST/ manually.
   For FashionMNIST: If download is True, it will download dataset to root/FashionMNIST/,
                     otherwise user should put train-labels-idx1-ubyte.gz,
                     train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz
                     and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: MXNetMNIST(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`MNIST`

   Configuration for Modified National Institute of Standards and Technology database
      and FashionMNIST database

   For MNIST: If download is True, it will download dataset to root/MNIST/, otherwise user
              should put mnist.npz under root/MNIST/ manually.
   For FashionMNIST: If download is True, it will download dataset to root/FashionMNIST/,
                     otherwise user should put train-labels-idx1-ubyte.gz,
                     train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz
                     and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: TensorflowMNIST(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`MNIST`

   Configuration for Modified National Institute of Standards and Technology database
      and FashionMNIST database

   For MNIST: If download is True, it will download dataset to root/MNIST/, otherwise user
              should put mnist.npz under root/MNIST/ manually.
   For FashionMNIST: If download is True, it will download dataset to root/FashionMNIST/,
                     otherwise user should put train-labels-idx1-ubyte.gz,
                     train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz
                     and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: FashionMNIST(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`MNIST`

   Configuration for Modified National Institute of Standards and Technology database
      and FashionMNIST database

   For MNIST: If download is True, it will download dataset to root/MNIST/, otherwise user
              should put mnist.npz under root/MNIST/ manually.
   For FashionMNIST: If download is True, it will download dataset to root/FashionMNIST/,
                     otherwise user should put train-labels-idx1-ubyte.gz,
                     train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz
                     and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: PytorchFashionMNIST(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`FashionMNIST`

   Configuration for Modified National Institute of Standards and Technology database
      and FashionMNIST database

   For MNIST: If download is True, it will download dataset to root/MNIST/, otherwise user
              should put mnist.npz under root/MNIST/ manually.
   For FashionMNIST: If download is True, it will download dataset to root/FashionMNIST/,
                     otherwise user should put train-labels-idx1-ubyte.gz,
                     train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz
                     and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: MXNetFashionMNIST(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`FashionMNIST`

   Configuration for Modified National Institute of Standards and Technology database
      and FashionMNIST database

   For MNIST: If download is True, it will download dataset to root/MNIST/, otherwise user
              should put mnist.npz under root/MNIST/ manually.
   For FashionMNIST: If download is True, it will download dataset to root/FashionMNIST/,
                     otherwise user should put train-labels-idx1-ubyte.gz,
                     train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz
                     and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: TensorflowFashionMNIST(root, train=False, transform=None, filter=None, download=True)

   Bases: :py:obj:`FashionMNIST`

   Configuration for Modified National Institute of Standards and Technology database
      and FashionMNIST database

   For MNIST: If download is True, it will download dataset to root/MNIST/, otherwise user
              should put mnist.npz under root/MNIST/ manually.
   For FashionMNIST: If download is True, it will download dataset to root/FashionMNIST/,
                     otherwise user should put train-labels-idx1-ubyte.gz,
                     train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz
                     and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.

   :param root: Root directory of dataset.
   :type root: str
   :param train: If True, creates dataset from train subset,
                 otherwise from validation subset.
   :type train: bool, default=False
   :param transform: transform to process input data.
   :type transform: transform object, default=None
   :param filter: filter out examples according to specific
                  conditions.
   :type filter: Filter objects, default=None
   :param download: If true, downloads the dataset from the internet
                    and puts it in root directory. If dataset is already
                    downloaded, it is not downloaded again.
   :type download: bool, default=True


.. py:class:: ImageFolder(root, transform=None, filter=None)

   Bases: :py:obj:`Dataset`

   Configuration for ImageFolder

   Expects the data folder to contain subfolders representing the classes to which
   its images belong.

   Please arrange data in this way:
       root/class_1/xxx.png
       root/class_1/xxy.png
       root/class_1/xxz.png
       ...
       root/class_n/123.png
       root/class_n/nsdf3.png
       root/class_n/asd932_.png
   Please put images of different categories into different folders.

   Args: root (str): Root directory of dataset.
         transform (transform object, default=None):  transform to process input data.
         filter (Filter objects, default=None): filter out examples according to specific
                                                conditions


.. py:class:: MXNetImageFolder(root, transform=None, filter=None)

   Bases: :py:obj:`ImageFolder`

   Configuration for ImageFolder

   Expects the data folder to contain subfolders representing the classes to which
   its images belong.

   Please arrange data in this way:
       root/class_1/xxx.png
       root/class_1/xxy.png
       root/class_1/xxz.png
       ...
       root/class_n/123.png
       root/class_n/nsdf3.png
       root/class_n/asd932_.png
   Please put images of different categories into different folders.

   Args: root (str): Root directory of dataset.
         transform (transform object, default=None):  transform to process input data.
         filter (Filter objects, default=None): filter out examples according to specific
                                                conditions


.. py:class:: TensorflowImageFolder(root, transform=None, filter=None)

   Bases: :py:obj:`ImageFolder`

   Configuration for ImageFolder

   Expects the data folder to contain subfolders representing the classes to which
   its images belong.

   Please arrange data in this way:
       root/class_1/xxx.png
       root/class_1/xxy.png
       root/class_1/xxz.png
       ...
       root/class_n/123.png
       root/class_n/nsdf3.png
       root/class_n/asd932_.png
   Please put images of different categories into different folders.

   Args: root (str): Root directory of dataset.
         transform (transform object, default=None):  transform to process input data.
         filter (Filter objects, default=None): filter out examples according to specific
                                                conditions


.. py:class:: TensorflowTFRecordDataset

   Bases: :py:obj:`IterableDataset`

   Configuration for TensorflowTFRecordDataset

   Root is a full path to tfrecord file, which contains the file name.

   Args: root (str): filename of dataset.
         transform (transform object, default=None):  transform to process input data.
         filter (Filter objects, default=None): filter out examples according
                                                to specific conditions.


.. py:class:: TensorflowImageRecord

   Bases: :py:obj:`IterableDataset`

   Configuration for ImageNet database in tf record format

   Please arrange data in this way:
       root/validation-000-of-100
       root/validation-001-of-100
       ...
       root/validation-099-of-100
   The file name needs to follow this pattern: '* - * -of- *'

   Args: root (str): Root directory of dataset.
         transform (transform object, default=None):  transform to process input data.
         filter (Filter objects, default=None): filter out examples according
                                                to specific conditions


.. py:class:: TensorflowVOCRecord

   Bases: :py:obj:`IterableDataset`

   Configuration for PASCAL VOC 2012 database in tf record format

   Please arrange data in this way:
       root/val-00000-of-00004.tfrecord
       root/val-00001-of-00004.tfrecord
       ...
       root/val-00003-of-00004.tfrecord
   The file name needs to follow this pattern: 'val-*-of-*'

   Args: root (str): Root directory of dataset.
         transform (transform object, default=None):  transform to process input data.
         filter (Filter objects, default=None): filter out examples according
                                                to specific conditions


