:orphan:

:py:mod:`neural_compressor.adaptor.torch_utils.hawq_metric`
===========================================================

.. py:module:: neural_compressor.adaptor.torch_utils.hawq_metric


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.adaptor.torch_utils.hawq_metric.HessianTrace



Functions
~~~~~~~~~

.. autoapisummary::

   neural_compressor.adaptor.torch_utils.hawq_metric.compare_weights



.. py:class:: HessianTrace(model, dataloader, q_model, criterion=None)

   please refer to
   Yao, Zhewei, et al. "Pyhessian: Neural networks through the lens of the hessian."
   2020 IEEE international conference on big data (Big data). IEEE, 2020.
   Dong, Zhen, et al. "Hawq-v2: Hessian aware trace-weighted quantization of neural networks."
   Advances in neural information processing systems 33 (2020): 18518-18529.
   https://github.com/openvinotoolkit/nncf/blob/develop/nncf/torch/quantization/hessian_trace.py

   .. py:method:: is_fused_module(module)

      This is a helper function for `_propagate_qconfig_helper` to detecte
         if this module is fused.
      :param module: input module
      :type module: object

      :returns: is fused or not
      :rtype: (bool)


   .. py:method:: mse_metric_gap(fp32_tensor, dequantize_tensor)

      Calculate the euclidean distance between fp32 tensor and int8 dequantize tensor
      :param fp32_tensor: The FP32 tensor.
      :type fp32_tensor: tensor
      :param dequantize_tensor: The INT8 dequantize tensor.
      :type dequantize_tensor: tensor


   .. py:method:: get_act_gap(fp32_model, q_model)

      Estimates each activation gap between quantized model and float model


   .. py:method:: get_avg_traces(enable_act=True, num_samples=32)

      Estimates average hessian trace for each parameter



.. py:function:: compare_weights(float_dict: Dict[str, Any], quantized_dict: Dict[str, Any]) -> Dict[str, Dict[str, torch.Tensor]]

   Compare the weights of the float module with its corresponding quantized
   module. Return a dict with key corresponding to module names and each entry being
   a dictionary with two keys 'float' and 'quantized', containing the float and
   quantized weights. This dict can be used to compare and compute the quantization
   error of the weights of float and quantized models.

   Example usage::

       wt_compare_dict = compare_weights(
           float_model.state_dict(), qmodel.state_dict())
       for key in wt_compare_dict:
           print(
               key,
               compute_error(
                   wt_compare_dict[key]['float'],
                   wt_compare_dict[key]['quantized'].dequantize()
               )
           )

   :param float_dict: state dict of the float model
   :param quantized_dict: state dict of the quantized model

   :returns: dict with key corresponding to module names and each entry being
             a dictionary with two keys 'float' and 'quantized', containing the float and
             quantized weights
   :rtype: weight_dict


