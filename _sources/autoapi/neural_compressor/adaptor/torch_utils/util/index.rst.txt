:orphan:

:py:mod:`neural_compressor.adaptor.torch_utils.util`
====================================================

.. py:module:: neural_compressor.adaptor.torch_utils.util


Module Contents
---------------


Functions
~~~~~~~~~

.. autoapisummary::

   neural_compressor.adaptor.torch_utils.util.get_embedding_contiguous
   neural_compressor.adaptor.torch_utils.util.is_fused_module
   neural_compressor.adaptor.torch_utils.util.append_attr
   neural_compressor.adaptor.torch_utils.util.get_mse_order_per_fp32



.. py:function:: get_embedding_contiguous(model)

   This is a helper function for nn.Embedding,
       and it will get input contiguous.

   :param model: input model
   :type model: object

   :returns: None


.. py:function:: is_fused_module(module)

   This is a helper function for `_propagate_qconfig_helper` to detecte
       if this module is fused.

   :param module: input module
   :type module: object

   :returns: is fused or not
   :rtype: (bool)


.. py:function:: append_attr(fx_model, model)

   a helper method to append attributes for the symbolic traced model.

   :param fx_model: The symbolic traced model.
   :type fx_model: torch.fx.GraphModule
   :param model: The original model.
   :type model: torch.nn.Module

   :returns: The symbolic traced model with additional attributes.
   :rtype: fx_model (dir)


.. py:function:: get_mse_order_per_fp32(adaptor, model, example_inp, tune_cfg)

   a helper method to check the mse influence to last module after QDQ(quant/dequant).
   :param model: A torch model.
   :type model: torch.fx.GraphModule/torch.nn.Module
   :param dataloader: The calibration dataloader.
   :type dataloader: torch.utils.data.DataLoader
   :param tune_cfg: dictionary of quantization configuration.
   :type tune_cfg: dict

   :returns: The fallback order for strategy.
   :rtype: fallback_order (dict/list)


