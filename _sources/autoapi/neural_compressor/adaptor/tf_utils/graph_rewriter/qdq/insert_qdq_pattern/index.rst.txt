:orphan:

:py:mod:`neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern`
==================================================================================

.. py:module:: neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern.GenerateGraphWithQDQPattern




.. py:class:: GenerateGraphWithQDQPattern(model, calibration_data, op_wise_config, fake_quant, fp32_ops, bf16_ops, quantized_nodes, device, performance_only, itex_mode)

   Bases: :py:obj:`neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base.GraphRewriterBase`

   Insert Q/DQ pairs before quantizable ops.

   Args: model: input model.
         data: sampling data.
         device: cpu or gpu

   Return: converted model with QDQ pattern

   .. py:method:: do_transformation()

      Base Interface that need to be implemented by each sub class.




