:orphan:

:py:mod:`neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer`
==================================================================================

.. py:module:: neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer.MetaInfoChangingMemOpOptimizer




.. py:class:: MetaInfoChangingMemOpOptimizer(model)

   Bases: :py:obj:`neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base.GraphRewriterBase`

   Fuse the pattern like Dequantize + MetaOp + Quantize into MetaOp(set its type to int8).
   With such changes, the Quantize and Dequantize OP will removed for better performance.

   .. py:method:: do_transformation()

      Base Interface that need to be implemented by each sub class.




