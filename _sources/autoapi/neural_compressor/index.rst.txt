:orphan:

:py:mod:`neural_compressor`
===========================

.. py:module:: neural_compressor


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   experimental/index.rst
   ux/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.Quantization
   neural_compressor.Pruning
   neural_compressor.Benchmark
   neural_compressor.DistillationConfig




.. py:class:: Quantization(conf_fname_or_obj)

   Bases: :py:obj:`object`

   Quantization class automatically searches for optimal quantization recipes for low
      precision model inference, achieving best tuning objectives like inference performance
      within accuracy loss constraints.

      Tuner abstracts out the differences of quantization APIs across various DL frameworks
      and brings a unified API for automatic quantization that works on frameworks including
      tensorflow, pytorch and mxnet.

      Since DL use cases vary in the accuracy metrics (Top-1, MAP, ROC etc.), loss criteria
      (<1% or <0.1% etc.) and tuning objectives (performance, memory footprint etc.).
      Tuner class provides a flexible configuration interface via YAML for users to specify
      these parameters.

   :param conf_fname_or_obj: The path to the YAML configuration file or
                             Quantization_Conf class containing accuracy goal, tuning objective and preferred
                             calibration & quantization tuning space etc.
   :type conf_fname_or_obj: string or obj


.. py:class:: Pruning(conf_fname_or_obj)

   This is base class of pruning object.

      Since DL use cases vary in the accuracy metrics (Top-1, MAP, ROC etc.), loss criteria
      (<1% or <0.1% etc.) and pruning objectives (performance, memory footprint etc.).
      Pruning class provides a flexible configuration interface via YAML for users to specify
      these parameters.

   :param conf_fname_or_obj: The path to the YAML configuration file or
                             Pruning_Conf class containing accuracy goal, pruning objective and related
                             dataloaders etc.
   :type conf_fname_or_obj: string or obj

   .. py:method:: on_epoch_begin(epoch)

      called on the begining of epochs


   .. py:method:: on_step_begin(batch_id)

      called on the begining of batches


   .. py:method:: on_step_end()

      called on the end of batches


   .. py:method:: on_epoch_end()

      called on the end of epochs



.. py:class:: Benchmark(conf_fname_or_obj)

   Bases: :py:obj:`object`

   Benchmark class can be used to evaluate the model performance, with the objective
      setting, user can get the data of what they configured in yaml

   :param conf_fname_or_obj: The path to the YAML configuration file or
                             Benchmark_Conf class containing accuracy goal, tuning objective and preferred
                             calibration & quantization tuning space etc.
   :type conf_fname_or_obj: string or obj


.. py:class:: DistillationConfig(teacher_model, criterion=criterion, optimizer={'SGD': {'learning_rate': 0.0001}})

   Config of distillation.

   :param teacher_model: Teacher model for distillation. Defaults to None.
   :type teacher_model: Callable
   :param features: Teacher features for distillation, features and teacher_model are alternative.
                    Defaults to None.
   :type features: optional
   :param criterion: Distillation loss configure.
   :type criterion: Callable, optional
   :param optimizer: Optimizer configure.
   :type optimizer: dictionary, optional


