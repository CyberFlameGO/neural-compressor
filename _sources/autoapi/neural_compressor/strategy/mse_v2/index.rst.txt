:orphan:

:py:mod:`neural_compressor.strategy.mse_v2`
===========================================

.. py:module:: neural_compressor.strategy.mse_v2


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.strategy.mse_v2.MSE_V2TuneStrategy




.. py:class:: MSE_V2TuneStrategy(model, conf, q_dataloader, q_func=None, eval_dataloader=None, eval_func=None, dicts=None, q_hooks=None)

   Bases: :py:obj:`neural_compressor.strategy.strategy.TuneStrategy`

   The tuning strategy using MSE policy in tuning space.

      This MSE policy runs fp32 model and int8 model seperately to get all activation tensors,
      and then compares those tensors by MSE algorithm to order all ops with MSE distance for
      deciding the impact of each op to final accuracy.
      It will be used to define opwise tuningspace by priority.

   :param model: The FP32 model specified for low precision tuning.
   :type model: object
   :param conf: The Conf class instance initialized from user yaml
                config file.
   :type conf: Class
   :param q_dataloader: Data loader for calibration, mandatory for
                        post-training quantization.
                        It is iterable and should yield a tuple (input,
                        label) for calibration dataset containing label,
                        or yield (input, _) for label-free calibration
                        dataset. The input could be a object, list, tuple or
                        dict, depending on user implementation, as well as
                        it can be taken as model input.
   :type q_dataloader: generator
   :param q_func: Reserved for future use.
   :type q_func: function, optional
   :param eval_dataloader: Data loader for evaluation. It is iterable
                           and should yield a tuple of (input, label).
                           The input could be a object, list, tuple or dict,
                           depending on user implementation, as well as it can
                           be taken as model input. The label should be able
                           to take as input of supported metrics. If this
                           parameter is not None, user needs to specify
                           pre-defined evaluation metrics through configuration
                           file and should set "eval_func" parameter as None.
                           Tuner will combine model, eval_dataloader and
                           pre-defined metrics to run evaluation process.
   :type eval_dataloader: generator, optional
   :param eval_func: The evaluation function provided by user.
                     This function takes model as parameter, and
                     evaluation dataset and metrics should be
                     encapsulated in this function implementation and
                     outputs a higher-is-better accuracy scalar value.

                     The pseudo code should be something like:

                     def eval_func(model):
                          input, label = dataloader()
                          output = model(input)
                          accuracy = metric(output, label)
                          return accuracy
   :type eval_func: function, optional
   :param dicts: The dict containing resume information.
                 Defaults to None.
   :type dicts: dict, optional

   .. py:method:: next_tune_cfg()

      The generator of yielding next tuning config to traverse by concrete strategies
         according to last tuning result.

      :Yields: *tune_config (dict)* -- It's a dict containing the tuning configuration to run.



