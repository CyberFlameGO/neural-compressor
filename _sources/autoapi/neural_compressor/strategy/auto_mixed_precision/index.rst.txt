:orphan:

:py:mod:`neural_compressor.strategy.auto_mixed_precision`
=========================================================

.. py:module:: neural_compressor.strategy.auto_mixed_precision


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.strategy.auto_mixed_precision.AutoMixedPrecisionTuneStrategy




.. py:class:: AutoMixedPrecisionTuneStrategy(model, conf, q_dataloader=None, q_func=None, eval_dataloader=None, eval_func=None, dicts=None, q_hooks=None)

   Bases: :py:obj:`neural_compressor.strategy.strategy.TuneStrategy`

   The auto-mixed precision strategy which tunes the mixed precision model with below order.

   1. modelwise tuning for all tunable ops.
   2. fallback tuning from bottom to top to decide the priority of which op has biggest impact
      on accuracy.
   3. incremental fallback tuning by fallbacking multiple ops with the order got from #2.

   :param model: The FP32 model specified for low precision tuning.
   :type model: object
   :param conf: The Conf class instance initialized from user yaml
                config file.
   :type conf: Class
   :param eval_dataloader: Data loader for evaluation. It is iterable
                           and should yield a tuple of (input, label).
                           The input could be a object, list, tuple or dict,
                           depending on user implementation, as well as it can
                           be taken as model input. The label should be able
                           to take as input of supported metrics. If this
                           parameter is not None, user needs to specify
                           pre-defined evaluation metrics through configuration
                           file and should set "eval_func" parameter as None.
                           Tuner will combine model, eval_dataloader and
                           pre-defined metrics to run evaluation process.
   :type eval_dataloader: generator, optional
   :param eval_func: The evaluation function provided by user.
                     This function takes model as parameter, and
                     evaluation dataset and metrics should be
                     encapsulated in this function implementation and
                     outputs a higher-is-better accuracy scalar value.

                     The pseudo code should be something like:

                     def eval_func(model):
                          input, label = dataloader()
                          output = model(input)
                          accuracy = metric(output, label)
                          return accuracy
   :type eval_func: function, optional
   :param dicts: The dict containing resume information.
                 Defaults to None.
   :type dicts: dict, optional

   .. py:method:: next_tune_cfg()

      The generator of yielding next tuning config to traverse by concrete strategies
         according to last tuning result.

      :Yields: *tune_config (dict)* -- It's a dict containing the tuning configuration to run.


   .. py:method:: traverse()

      The main traverse logic, which could be override by some concrete strategy which needs
      more hooks.



